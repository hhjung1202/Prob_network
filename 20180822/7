Files already downloaded and verified
USE 1 GPUs!
Epoch: 0 | Batch_idx: 0 |  Loss: (2.3084) |  Loss2: (0.0000) | Acc: (9.00%) (12/128)
Epoch: 0 | Batch_idx: 10 |  Loss: (2.3045) |  Loss2: (0.0000) | Acc: (10.00%) (149/1408)
Epoch: 0 | Batch_idx: 20 |  Loss: (2.3011) |  Loss2: (0.0000) | Acc: (11.00%) (306/2688)
Epoch: 0 | Batch_idx: 30 |  Loss: (2.2937) |  Loss2: (0.0000) | Acc: (12.00%) (492/3968)
Epoch: 0 | Batch_idx: 40 |  Loss: (2.2865) |  Loss2: (0.0000) | Acc: (13.00%) (697/5248)
Epoch: 0 | Batch_idx: 50 |  Loss: (2.2780) |  Loss2: (0.0000) | Acc: (14.00%) (933/6528)
Epoch: 0 | Batch_idx: 60 |  Loss: (2.2696) |  Loss2: (0.0000) | Acc: (14.00%) (1156/7808)
Epoch: 0 | Batch_idx: 70 |  Loss: (2.2605) |  Loss2: (0.0000) | Acc: (15.00%) (1417/9088)
Epoch: 0 | Batch_idx: 80 |  Loss: (2.2518) |  Loss2: (0.0000) | Acc: (16.00%) (1679/10368)
Epoch: 0 | Batch_idx: 90 |  Loss: (2.2432) |  Loss2: (0.0000) | Acc: (16.00%) (1940/11648)
Epoch: 0 | Batch_idx: 100 |  Loss: (2.2350) |  Loss2: (0.0000) | Acc: (17.00%) (2219/12928)
Epoch: 0 | Batch_idx: 110 |  Loss: (2.2258) |  Loss2: (0.0000) | Acc: (17.00%) (2526/14208)
Epoch: 0 | Batch_idx: 120 |  Loss: (2.2181) |  Loss2: (0.0000) | Acc: (17.00%) (2769/15488)
Epoch: 0 | Batch_idx: 130 |  Loss: (2.2109) |  Loss2: (0.0000) | Acc: (18.00%) (3075/16768)
Epoch: 0 | Batch_idx: 140 |  Loss: (2.2042) |  Loss2: (0.0000) | Acc: (18.00%) (3365/18048)
Epoch: 0 | Batch_idx: 150 |  Loss: (2.1979) |  Loss2: (0.0000) | Acc: (19.00%) (3695/19328)
Epoch: 0 | Batch_idx: 160 |  Loss: (2.1904) |  Loss2: (0.0000) | Acc: (19.00%) (4009/20608)
Epoch: 0 | Batch_idx: 170 |  Loss: (2.1831) |  Loss2: (0.0000) | Acc: (19.00%) (4329/21888)
Epoch: 0 | Batch_idx: 180 |  Loss: (2.1774) |  Loss2: (0.0000) | Acc: (20.00%) (4652/23168)
Epoch: 0 | Batch_idx: 190 |  Loss: (2.1703) |  Loss2: (0.0000) | Acc: (20.00%) (4977/24448)
Epoch: 0 | Batch_idx: 200 |  Loss: (2.1626) |  Loss2: (0.0000) | Acc: (20.00%) (5321/25728)
Epoch: 0 | Batch_idx: 210 |  Loss: (2.1557) |  Loss2: (0.0000) | Acc: (21.00%) (5678/27008)
Epoch: 0 | Batch_idx: 220 |  Loss: (2.1491) |  Loss2: (0.0000) | Acc: (21.00%) (6026/28288)
Epoch: 0 | Batch_idx: 230 |  Loss: (2.1418) |  Loss2: (0.0000) | Acc: (21.00%) (6382/29568)
Epoch: 0 | Batch_idx: 240 |  Loss: (2.1348) |  Loss2: (0.0000) | Acc: (21.00%) (6731/30848)
Epoch: 0 | Batch_idx: 250 |  Loss: (2.1272) |  Loss2: (0.0000) | Acc: (22.00%) (7107/32128)
Epoch: 0 | Batch_idx: 260 |  Loss: (2.1202) |  Loss2: (0.0000) | Acc: (22.00%) (7471/33408)
Epoch: 0 | Batch_idx: 270 |  Loss: (2.1135) |  Loss2: (0.0000) | Acc: (22.00%) (7841/34688)
Epoch: 0 | Batch_idx: 280 |  Loss: (2.1072) |  Loss2: (0.0000) | Acc: (22.00%) (8233/35968)
Epoch: 0 | Batch_idx: 290 |  Loss: (2.1009) |  Loss2: (0.0000) | Acc: (23.00%) (8614/37248)
Epoch: 0 | Batch_idx: 300 |  Loss: (2.0950) |  Loss2: (0.0000) | Acc: (23.00%) (8998/38528)
Epoch: 0 | Batch_idx: 310 |  Loss: (2.0890) |  Loss2: (0.0000) | Acc: (23.00%) (9401/39808)
Epoch: 0 | Batch_idx: 320 |  Loss: (2.0826) |  Loss2: (0.0000) | Acc: (23.00%) (9779/41088)
Epoch: 0 | Batch_idx: 330 |  Loss: (2.0762) |  Loss2: (0.0000) | Acc: (24.00%) (10183/42368)
Epoch: 0 | Batch_idx: 340 |  Loss: (2.0700) |  Loss2: (0.0000) | Acc: (24.00%) (10597/43648)
Epoch: 0 | Batch_idx: 350 |  Loss: (2.0641) |  Loss2: (0.0000) | Acc: (24.00%) (11033/44928)
Epoch: 0 | Batch_idx: 360 |  Loss: (2.0585) |  Loss2: (0.0000) | Acc: (24.00%) (11441/46208)
Epoch: 0 | Batch_idx: 370 |  Loss: (2.0530) |  Loss2: (0.0000) | Acc: (24.00%) (11866/47488)
Epoch: 0 | Batch_idx: 380 |  Loss: (2.0480) |  Loss2: (0.0000) | Acc: (25.00%) (12274/48768)
Epoch: 0 | Batch_idx: 390 |  Loss: (2.0424) |  Loss2: (0.0000) | Acc: (25.00%) (12685/50000)
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type _Gate. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_000.pth.tar'
# TEST : Loss: (1.8166) | Acc: (33.00%) (3366/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(163.0295, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(771.0239, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(762.5063, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1536.2029, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(507.9894, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2166.6711, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4338.9346, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1452.9956, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6139.5396, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12287.4248, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4107.5103, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17364.3867, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 1 | Batch_idx: 0 |  Loss: (1.8398) |  Loss2: (0.0000) | Acc: (31.00%) (40/128)
Epoch: 1 | Batch_idx: 10 |  Loss: (1.8581) |  Loss2: (0.0000) | Acc: (31.00%) (441/1408)
Epoch: 1 | Batch_idx: 20 |  Loss: (1.8530) |  Loss2: (0.0000) | Acc: (32.00%) (869/2688)
Epoch: 1 | Batch_idx: 30 |  Loss: (1.8368) |  Loss2: (0.0000) | Acc: (33.00%) (1315/3968)
Epoch: 1 | Batch_idx: 40 |  Loss: (1.8222) |  Loss2: (0.0000) | Acc: (33.00%) (1774/5248)
Epoch: 1 | Batch_idx: 50 |  Loss: (1.8157) |  Loss2: (0.0000) | Acc: (33.00%) (2214/6528)
Epoch: 1 | Batch_idx: 60 |  Loss: (1.8121) |  Loss2: (0.0000) | Acc: (34.00%) (2679/7808)
Epoch: 1 | Batch_idx: 70 |  Loss: (1.8093) |  Loss2: (0.0000) | Acc: (34.00%) (3116/9088)
Epoch: 1 | Batch_idx: 80 |  Loss: (1.8070) |  Loss2: (0.0000) | Acc: (34.00%) (3581/10368)
Epoch: 1 | Batch_idx: 90 |  Loss: (1.8047) |  Loss2: (0.0000) | Acc: (34.00%) (4032/11648)
Epoch: 1 | Batch_idx: 100 |  Loss: (1.7995) |  Loss2: (0.0000) | Acc: (34.00%) (4489/12928)
Epoch: 1 | Batch_idx: 110 |  Loss: (1.7978) |  Loss2: (0.0000) | Acc: (34.00%) (4939/14208)
Epoch: 1 | Batch_idx: 120 |  Loss: (1.7934) |  Loss2: (0.0000) | Acc: (34.00%) (5407/15488)
Epoch: 1 | Batch_idx: 130 |  Loss: (1.7905) |  Loss2: (0.0000) | Acc: (34.00%) (5866/16768)
Epoch: 1 | Batch_idx: 140 |  Loss: (1.7870) |  Loss2: (0.0000) | Acc: (35.00%) (6336/18048)
Epoch: 1 | Batch_idx: 150 |  Loss: (1.7854) |  Loss2: (0.0000) | Acc: (34.00%) (6762/19328)
Epoch: 1 | Batch_idx: 160 |  Loss: (1.7824) |  Loss2: (0.0000) | Acc: (34.00%) (7212/20608)
Epoch: 1 | Batch_idx: 170 |  Loss: (1.7788) |  Loss2: (0.0000) | Acc: (35.00%) (7689/21888)
Epoch: 1 | Batch_idx: 180 |  Loss: (1.7764) |  Loss2: (0.0000) | Acc: (35.00%) (8160/23168)
Epoch: 1 | Batch_idx: 190 |  Loss: (1.7728) |  Loss2: (0.0000) | Acc: (35.00%) (8646/24448)
Epoch: 1 | Batch_idx: 200 |  Loss: (1.7693) |  Loss2: (0.0000) | Acc: (35.00%) (9114/25728)
Epoch: 1 | Batch_idx: 210 |  Loss: (1.7653) |  Loss2: (0.0000) | Acc: (35.00%) (9626/27008)
Epoch: 1 | Batch_idx: 220 |  Loss: (1.7625) |  Loss2: (0.0000) | Acc: (35.00%) (10143/28288)
Epoch: 1 | Batch_idx: 230 |  Loss: (1.7607) |  Loss2: (0.0000) | Acc: (35.00%) (10591/29568)
Epoch: 1 | Batch_idx: 240 |  Loss: (1.7593) |  Loss2: (0.0000) | Acc: (35.00%) (11043/30848)
Epoch: 1 | Batch_idx: 250 |  Loss: (1.7572) |  Loss2: (0.0000) | Acc: (35.00%) (11534/32128)
Epoch: 1 | Batch_idx: 260 |  Loss: (1.7540) |  Loss2: (0.0000) | Acc: (35.00%) (12023/33408)
Epoch: 1 | Batch_idx: 270 |  Loss: (1.7516) |  Loss2: (0.0000) | Acc: (36.00%) (12531/34688)
Epoch: 1 | Batch_idx: 280 |  Loss: (1.7488) |  Loss2: (0.0000) | Acc: (36.00%) (12995/35968)
Epoch: 1 | Batch_idx: 290 |  Loss: (1.7457) |  Loss2: (0.0000) | Acc: (36.00%) (13493/37248)
Epoch: 1 | Batch_idx: 300 |  Loss: (1.7425) |  Loss2: (0.0000) | Acc: (36.00%) (14004/38528)
Epoch: 1 | Batch_idx: 310 |  Loss: (1.7397) |  Loss2: (0.0000) | Acc: (36.00%) (14503/39808)
Epoch: 1 | Batch_idx: 320 |  Loss: (1.7356) |  Loss2: (0.0000) | Acc: (36.00%) (15029/41088)
Epoch: 1 | Batch_idx: 330 |  Loss: (1.7328) |  Loss2: (0.0000) | Acc: (36.00%) (15525/42368)
Epoch: 1 | Batch_idx: 340 |  Loss: (1.7298) |  Loss2: (0.0000) | Acc: (36.00%) (16051/43648)
Epoch: 1 | Batch_idx: 350 |  Loss: (1.7274) |  Loss2: (0.0000) | Acc: (36.00%) (16532/44928)
Epoch: 1 | Batch_idx: 360 |  Loss: (1.7249) |  Loss2: (0.0000) | Acc: (36.00%) (17039/46208)
Epoch: 1 | Batch_idx: 370 |  Loss: (1.7216) |  Loss2: (0.0000) | Acc: (36.00%) (17564/47488)
Epoch: 1 | Batch_idx: 380 |  Loss: (1.7199) |  Loss2: (0.0000) | Acc: (36.00%) (18025/48768)
Epoch: 1 | Batch_idx: 390 |  Loss: (1.7174) |  Loss2: (0.0000) | Acc: (37.00%) (18523/50000)
# TEST : Loss: (1.5882) | Acc: (41.00%) (4150/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 2 | Batch_idx: 0 |  Loss: (1.5633) |  Loss2: (0.0000) | Acc: (42.00%) (54/128)
Epoch: 2 | Batch_idx: 10 |  Loss: (1.6066) |  Loss2: (0.0000) | Acc: (41.00%) (587/1408)
Epoch: 2 | Batch_idx: 20 |  Loss: (1.6037) |  Loss2: (0.0000) | Acc: (41.00%) (1122/2688)
Epoch: 2 | Batch_idx: 30 |  Loss: (1.6036) |  Loss2: (0.0000) | Acc: (41.00%) (1636/3968)
Epoch: 2 | Batch_idx: 40 |  Loss: (1.5944) |  Loss2: (0.0000) | Acc: (41.00%) (2185/5248)
Epoch: 2 | Batch_idx: 50 |  Loss: (1.5981) |  Loss2: (0.0000) | Acc: (41.00%) (2685/6528)
Epoch: 2 | Batch_idx: 60 |  Loss: (1.5966) |  Loss2: (0.0000) | Acc: (41.00%) (3253/7808)
Epoch: 2 | Batch_idx: 70 |  Loss: (1.5987) |  Loss2: (0.0000) | Acc: (41.00%) (3771/9088)
Epoch: 2 | Batch_idx: 80 |  Loss: (1.5974) |  Loss2: (0.0000) | Acc: (41.00%) (4302/10368)
Epoch: 2 | Batch_idx: 90 |  Loss: (1.5975) |  Loss2: (0.0000) | Acc: (41.00%) (4838/11648)
Epoch: 2 | Batch_idx: 100 |  Loss: (1.5949) |  Loss2: (0.0000) | Acc: (41.00%) (5388/12928)
Epoch: 2 | Batch_idx: 110 |  Loss: (1.5950) |  Loss2: (0.0000) | Acc: (41.00%) (5921/14208)
Epoch: 2 | Batch_idx: 120 |  Loss: (1.5928) |  Loss2: (0.0000) | Acc: (41.00%) (6465/15488)
Epoch: 2 | Batch_idx: 130 |  Loss: (1.5902) |  Loss2: (0.0000) | Acc: (41.00%) (7007/16768)
Epoch: 2 | Batch_idx: 140 |  Loss: (1.5895) |  Loss2: (0.0000) | Acc: (41.00%) (7536/18048)
Epoch: 2 | Batch_idx: 150 |  Loss: (1.5875) |  Loss2: (0.0000) | Acc: (41.00%) (8104/19328)
Epoch: 2 | Batch_idx: 160 |  Loss: (1.5843) |  Loss2: (0.0000) | Acc: (42.00%) (8679/20608)
Epoch: 2 | Batch_idx: 170 |  Loss: (1.5820) |  Loss2: (0.0000) | Acc: (42.00%) (9245/21888)
Epoch: 2 | Batch_idx: 180 |  Loss: (1.5813) |  Loss2: (0.0000) | Acc: (42.00%) (9783/23168)
Epoch: 2 | Batch_idx: 190 |  Loss: (1.5798) |  Loss2: (0.0000) | Acc: (42.00%) (10343/24448)
Epoch: 2 | Batch_idx: 200 |  Loss: (1.5789) |  Loss2: (0.0000) | Acc: (42.00%) (10878/25728)
Epoch: 2 | Batch_idx: 210 |  Loss: (1.5764) |  Loss2: (0.0000) | Acc: (42.00%) (11454/27008)
Epoch: 2 | Batch_idx: 220 |  Loss: (1.5747) |  Loss2: (0.0000) | Acc: (42.00%) (12007/28288)
Epoch: 2 | Batch_idx: 230 |  Loss: (1.5716) |  Loss2: (0.0000) | Acc: (42.00%) (12589/29568)
Epoch: 2 | Batch_idx: 240 |  Loss: (1.5698) |  Loss2: (0.0000) | Acc: (42.00%) (13131/30848)
Epoch: 2 | Batch_idx: 250 |  Loss: (1.5693) |  Loss2: (0.0000) | Acc: (42.00%) (13650/32128)
Epoch: 2 | Batch_idx: 260 |  Loss: (1.5687) |  Loss2: (0.0000) | Acc: (42.00%) (14171/33408)
Epoch: 2 | Batch_idx: 270 |  Loss: (1.5662) |  Loss2: (0.0000) | Acc: (42.00%) (14743/34688)
Epoch: 2 | Batch_idx: 280 |  Loss: (1.5644) |  Loss2: (0.0000) | Acc: (42.00%) (15300/35968)
Epoch: 2 | Batch_idx: 290 |  Loss: (1.5622) |  Loss2: (0.0000) | Acc: (42.00%) (15905/37248)
Epoch: 2 | Batch_idx: 300 |  Loss: (1.5611) |  Loss2: (0.0000) | Acc: (42.00%) (16480/38528)
Epoch: 2 | Batch_idx: 310 |  Loss: (1.5599) |  Loss2: (0.0000) | Acc: (42.00%) (17028/39808)
Epoch: 2 | Batch_idx: 320 |  Loss: (1.5570) |  Loss2: (0.0000) | Acc: (42.00%) (17619/41088)
Epoch: 2 | Batch_idx: 330 |  Loss: (1.5545) |  Loss2: (0.0000) | Acc: (43.00%) (18225/42368)
Epoch: 2 | Batch_idx: 340 |  Loss: (1.5518) |  Loss2: (0.0000) | Acc: (43.00%) (18823/43648)
Epoch: 2 | Batch_idx: 350 |  Loss: (1.5501) |  Loss2: (0.0000) | Acc: (43.00%) (19379/44928)
Epoch: 2 | Batch_idx: 360 |  Loss: (1.5484) |  Loss2: (0.0000) | Acc: (43.00%) (19975/46208)
Epoch: 2 | Batch_idx: 370 |  Loss: (1.5463) |  Loss2: (0.0000) | Acc: (43.00%) (20565/47488)
Epoch: 2 | Batch_idx: 380 |  Loss: (1.5438) |  Loss2: (0.0000) | Acc: (43.00%) (21177/48768)
Epoch: 2 | Batch_idx: 390 |  Loss: (1.5412) |  Loss2: (0.0000) | Acc: (43.00%) (21746/50000)
# TEST : Loss: (1.4820) | Acc: (44.00%) (4443/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 3 | Batch_idx: 0 |  Loss: (1.5095) |  Loss2: (0.0000) | Acc: (44.00%) (57/128)
Epoch: 3 | Batch_idx: 10 |  Loss: (1.4444) |  Loss2: (0.0000) | Acc: (46.00%) (653/1408)
Epoch: 3 | Batch_idx: 20 |  Loss: (1.4661) |  Loss2: (0.0000) | Acc: (45.00%) (1230/2688)
Epoch: 3 | Batch_idx: 30 |  Loss: (1.4691) |  Loss2: (0.0000) | Acc: (45.00%) (1810/3968)
Epoch: 3 | Batch_idx: 40 |  Loss: (1.4637) |  Loss2: (0.0000) | Acc: (45.00%) (2414/5248)
Epoch: 3 | Batch_idx: 50 |  Loss: (1.4661) |  Loss2: (0.0000) | Acc: (45.00%) (3000/6528)
Epoch: 3 | Batch_idx: 60 |  Loss: (1.4632) |  Loss2: (0.0000) | Acc: (46.00%) (3610/7808)
Epoch: 3 | Batch_idx: 70 |  Loss: (1.4596) |  Loss2: (0.0000) | Acc: (46.00%) (4228/9088)
Epoch: 3 | Batch_idx: 80 |  Loss: (1.4542) |  Loss2: (0.0000) | Acc: (46.00%) (4841/10368)
Epoch: 3 | Batch_idx: 90 |  Loss: (1.4538) |  Loss2: (0.0000) | Acc: (46.00%) (5446/11648)
Epoch: 3 | Batch_idx: 100 |  Loss: (1.4549) |  Loss2: (0.0000) | Acc: (46.00%) (6071/12928)
Epoch: 3 | Batch_idx: 110 |  Loss: (1.4541) |  Loss2: (0.0000) | Acc: (46.00%) (6668/14208)
Epoch: 3 | Batch_idx: 120 |  Loss: (1.4505) |  Loss2: (0.0000) | Acc: (47.00%) (7298/15488)
Epoch: 3 | Batch_idx: 130 |  Loss: (1.4466) |  Loss2: (0.0000) | Acc: (47.00%) (7918/16768)
Epoch: 3 | Batch_idx: 140 |  Loss: (1.4439) |  Loss2: (0.0000) | Acc: (47.00%) (8545/18048)
Epoch: 3 | Batch_idx: 150 |  Loss: (1.4431) |  Loss2: (0.0000) | Acc: (47.00%) (9154/19328)
Epoch: 3 | Batch_idx: 160 |  Loss: (1.4407) |  Loss2: (0.0000) | Acc: (47.00%) (9791/20608)
Epoch: 3 | Batch_idx: 170 |  Loss: (1.4372) |  Loss2: (0.0000) | Acc: (47.00%) (10451/21888)
Epoch: 3 | Batch_idx: 180 |  Loss: (1.4355) |  Loss2: (0.0000) | Acc: (47.00%) (11098/23168)
Epoch: 3 | Batch_idx: 190 |  Loss: (1.4337) |  Loss2: (0.0000) | Acc: (47.00%) (11720/24448)
Epoch: 3 | Batch_idx: 200 |  Loss: (1.4310) |  Loss2: (0.0000) | Acc: (48.00%) (12364/25728)
Epoch: 3 | Batch_idx: 210 |  Loss: (1.4294) |  Loss2: (0.0000) | Acc: (48.00%) (12990/27008)
Epoch: 3 | Batch_idx: 220 |  Loss: (1.4276) |  Loss2: (0.0000) | Acc: (48.00%) (13626/28288)
Epoch: 3 | Batch_idx: 230 |  Loss: (1.4245) |  Loss2: (0.0000) | Acc: (48.00%) (14292/29568)
Epoch: 3 | Batch_idx: 240 |  Loss: (1.4225) |  Loss2: (0.0000) | Acc: (48.00%) (14923/30848)
Epoch: 3 | Batch_idx: 250 |  Loss: (1.4208) |  Loss2: (0.0000) | Acc: (48.00%) (15575/32128)
Epoch: 3 | Batch_idx: 260 |  Loss: (1.4198) |  Loss2: (0.0000) | Acc: (48.00%) (16198/33408)
Epoch: 3 | Batch_idx: 270 |  Loss: (1.4188) |  Loss2: (0.0000) | Acc: (48.00%) (16822/34688)
Epoch: 3 | Batch_idx: 280 |  Loss: (1.4175) |  Loss2: (0.0000) | Acc: (48.00%) (17501/35968)
Epoch: 3 | Batch_idx: 290 |  Loss: (1.4156) |  Loss2: (0.0000) | Acc: (48.00%) (18163/37248)
Epoch: 3 | Batch_idx: 300 |  Loss: (1.4128) |  Loss2: (0.0000) | Acc: (48.00%) (18825/38528)
Epoch: 3 | Batch_idx: 310 |  Loss: (1.4102) |  Loss2: (0.0000) | Acc: (48.00%) (19491/39808)
Epoch: 3 | Batch_idx: 320 |  Loss: (1.4100) |  Loss2: (0.0000) | Acc: (48.00%) (20100/41088)
Epoch: 3 | Batch_idx: 330 |  Loss: (1.4091) |  Loss2: (0.0000) | Acc: (48.00%) (20719/42368)
Epoch: 3 | Batch_idx: 340 |  Loss: (1.4080) |  Loss2: (0.0000) | Acc: (48.00%) (21352/43648)
Epoch: 3 | Batch_idx: 350 |  Loss: (1.4060) |  Loss2: (0.0000) | Acc: (48.00%) (22000/44928)
Epoch: 3 | Batch_idx: 360 |  Loss: (1.4046) |  Loss2: (0.0000) | Acc: (48.00%) (22623/46208)
Epoch: 3 | Batch_idx: 370 |  Loss: (1.4031) |  Loss2: (0.0000) | Acc: (49.00%) (23279/47488)
Epoch: 3 | Batch_idx: 380 |  Loss: (1.4007) |  Loss2: (0.0000) | Acc: (49.00%) (23966/48768)
Epoch: 3 | Batch_idx: 390 |  Loss: (1.3986) |  Loss2: (0.0000) | Acc: (49.00%) (24625/50000)
# TEST : Loss: (1.3675) | Acc: (50.00%) (5045/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 4 | Batch_idx: 0 |  Loss: (1.4281) |  Loss2: (0.0000) | Acc: (47.00%) (61/128)
Epoch: 4 | Batch_idx: 10 |  Loss: (1.3132) |  Loss2: (0.0000) | Acc: (54.00%) (765/1408)
Epoch: 4 | Batch_idx: 20 |  Loss: (1.3187) |  Loss2: (0.0000) | Acc: (53.00%) (1445/2688)
Epoch: 4 | Batch_idx: 30 |  Loss: (1.3111) |  Loss2: (0.0000) | Acc: (53.00%) (2137/3968)
Epoch: 4 | Batch_idx: 40 |  Loss: (1.3164) |  Loss2: (0.0000) | Acc: (53.00%) (2798/5248)
Epoch: 4 | Batch_idx: 50 |  Loss: (1.3113) |  Loss2: (0.0000) | Acc: (53.00%) (3488/6528)
Epoch: 4 | Batch_idx: 60 |  Loss: (1.3053) |  Loss2: (0.0000) | Acc: (53.00%) (4185/7808)
Epoch: 4 | Batch_idx: 70 |  Loss: (1.3027) |  Loss2: (0.0000) | Acc: (53.00%) (4879/9088)
Epoch: 4 | Batch_idx: 80 |  Loss: (1.3019) |  Loss2: (0.0000) | Acc: (53.00%) (5562/10368)
Epoch: 4 | Batch_idx: 90 |  Loss: (1.3068) |  Loss2: (0.0000) | Acc: (53.00%) (6211/11648)
Epoch: 4 | Batch_idx: 100 |  Loss: (1.3092) |  Loss2: (0.0000) | Acc: (53.00%) (6866/12928)
Epoch: 4 | Batch_idx: 110 |  Loss: (1.3057) |  Loss2: (0.0000) | Acc: (53.00%) (7554/14208)
Epoch: 4 | Batch_idx: 120 |  Loss: (1.3055) |  Loss2: (0.0000) | Acc: (53.00%) (8230/15488)
Epoch: 4 | Batch_idx: 130 |  Loss: (1.3019) |  Loss2: (0.0000) | Acc: (53.00%) (8926/16768)
Epoch: 4 | Batch_idx: 140 |  Loss: (1.3014) |  Loss2: (0.0000) | Acc: (53.00%) (9601/18048)
Epoch: 4 | Batch_idx: 150 |  Loss: (1.2990) |  Loss2: (0.0000) | Acc: (53.00%) (10303/19328)
Epoch: 4 | Batch_idx: 160 |  Loss: (1.2994) |  Loss2: (0.0000) | Acc: (53.00%) (10968/20608)
Epoch: 4 | Batch_idx: 170 |  Loss: (1.2993) |  Loss2: (0.0000) | Acc: (53.00%) (11658/21888)
Epoch: 4 | Batch_idx: 180 |  Loss: (1.2973) |  Loss2: (0.0000) | Acc: (53.00%) (12352/23168)
Epoch: 4 | Batch_idx: 190 |  Loss: (1.2955) |  Loss2: (0.0000) | Acc: (53.00%) (13071/24448)
Epoch: 4 | Batch_idx: 200 |  Loss: (1.2947) |  Loss2: (0.0000) | Acc: (53.00%) (13772/25728)
Epoch: 4 | Batch_idx: 210 |  Loss: (1.2953) |  Loss2: (0.0000) | Acc: (53.00%) (14456/27008)
Epoch: 4 | Batch_idx: 220 |  Loss: (1.2942) |  Loss2: (0.0000) | Acc: (53.00%) (15121/28288)
Epoch: 4 | Batch_idx: 230 |  Loss: (1.2924) |  Loss2: (0.0000) | Acc: (53.00%) (15846/29568)
Epoch: 4 | Batch_idx: 240 |  Loss: (1.2918) |  Loss2: (0.0000) | Acc: (53.00%) (16521/30848)
Epoch: 4 | Batch_idx: 250 |  Loss: (1.2902) |  Loss2: (0.0000) | Acc: (53.00%) (17229/32128)
Epoch: 4 | Batch_idx: 260 |  Loss: (1.2892) |  Loss2: (0.0000) | Acc: (53.00%) (17944/33408)
Epoch: 4 | Batch_idx: 270 |  Loss: (1.2875) |  Loss2: (0.0000) | Acc: (53.00%) (18645/34688)
Epoch: 4 | Batch_idx: 280 |  Loss: (1.2859) |  Loss2: (0.0000) | Acc: (53.00%) (19353/35968)
Epoch: 4 | Batch_idx: 290 |  Loss: (1.2853) |  Loss2: (0.0000) | Acc: (53.00%) (20040/37248)
Epoch: 4 | Batch_idx: 300 |  Loss: (1.2835) |  Loss2: (0.0000) | Acc: (53.00%) (20780/38528)
Epoch: 4 | Batch_idx: 310 |  Loss: (1.2811) |  Loss2: (0.0000) | Acc: (54.00%) (21513/39808)
Epoch: 4 | Batch_idx: 320 |  Loss: (1.2790) |  Loss2: (0.0000) | Acc: (54.00%) (22225/41088)
Epoch: 4 | Batch_idx: 330 |  Loss: (1.2771) |  Loss2: (0.0000) | Acc: (54.00%) (22949/42368)
Epoch: 4 | Batch_idx: 340 |  Loss: (1.2757) |  Loss2: (0.0000) | Acc: (54.00%) (23672/43648)
Epoch: 4 | Batch_idx: 350 |  Loss: (1.2757) |  Loss2: (0.0000) | Acc: (54.00%) (24373/44928)
Epoch: 4 | Batch_idx: 360 |  Loss: (1.2736) |  Loss2: (0.0000) | Acc: (54.00%) (25085/46208)
Epoch: 4 | Batch_idx: 370 |  Loss: (1.2721) |  Loss2: (0.0000) | Acc: (54.00%) (25795/47488)
Epoch: 4 | Batch_idx: 380 |  Loss: (1.2708) |  Loss2: (0.0000) | Acc: (54.00%) (26534/48768)
Epoch: 4 | Batch_idx: 390 |  Loss: (1.2695) |  Loss2: (0.0000) | Acc: (54.00%) (27236/50000)
# TEST : Loss: (1.2272) | Acc: (56.00%) (5603/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 5 | Batch_idx: 0 |  Loss: (1.2544) |  Loss2: (0.0000) | Acc: (53.00%) (68/128)
Epoch: 5 | Batch_idx: 10 |  Loss: (1.3236) |  Loss2: (0.0000) | Acc: (51.00%) (724/1408)
Epoch: 5 | Batch_idx: 20 |  Loss: (1.4099) |  Loss2: (0.0000) | Acc: (47.00%) (1290/2688)
Epoch: 5 | Batch_idx: 30 |  Loss: (1.4579) |  Loss2: (0.0000) | Acc: (46.00%) (1839/3968)
Epoch: 5 | Batch_idx: 40 |  Loss: (1.4830) |  Loss2: (0.0000) | Acc: (45.00%) (2392/5248)
Epoch: 5 | Batch_idx: 50 |  Loss: (1.4977) |  Loss2: (0.0000) | Acc: (45.00%) (2956/6528)
Epoch: 5 | Batch_idx: 60 |  Loss: (1.5058) |  Loss2: (0.0000) | Acc: (45.00%) (3514/7808)
Epoch: 5 | Batch_idx: 70 |  Loss: (1.5089) |  Loss2: (0.0000) | Acc: (45.00%) (4096/9088)
Epoch: 5 | Batch_idx: 80 |  Loss: (1.5132) |  Loss2: (0.0000) | Acc: (45.00%) (4673/10368)
Epoch: 5 | Batch_idx: 90 |  Loss: (1.5128) |  Loss2: (0.0000) | Acc: (44.00%) (5229/11648)
Epoch: 5 | Batch_idx: 100 |  Loss: (1.5088) |  Loss2: (0.0000) | Acc: (45.00%) (5828/12928)
Epoch: 5 | Batch_idx: 110 |  Loss: (1.5056) |  Loss2: (0.0000) | Acc: (45.00%) (6406/14208)
Epoch: 5 | Batch_idx: 120 |  Loss: (1.5014) |  Loss2: (0.0000) | Acc: (45.00%) (7007/15488)
Epoch: 5 | Batch_idx: 130 |  Loss: (1.4990) |  Loss2: (0.0000) | Acc: (45.00%) (7600/16768)
Epoch: 5 | Batch_idx: 140 |  Loss: (1.4977) |  Loss2: (0.0000) | Acc: (45.00%) (8169/18048)
Epoch: 5 | Batch_idx: 150 |  Loss: (1.4970) |  Loss2: (0.0000) | Acc: (45.00%) (8750/19328)
Epoch: 5 | Batch_idx: 160 |  Loss: (1.4937) |  Loss2: (0.0000) | Acc: (45.00%) (9357/20608)
Epoch: 5 | Batch_idx: 170 |  Loss: (1.4898) |  Loss2: (0.0000) | Acc: (45.00%) (9971/21888)
Epoch: 5 | Batch_idx: 180 |  Loss: (1.4901) |  Loss2: (0.0000) | Acc: (45.00%) (10551/23168)
Epoch: 5 | Batch_idx: 190 |  Loss: (1.4874) |  Loss2: (0.0000) | Acc: (45.00%) (11180/24448)
Epoch: 5 | Batch_idx: 200 |  Loss: (1.4818) |  Loss2: (0.0000) | Acc: (45.00%) (11809/25728)
Epoch: 5 | Batch_idx: 210 |  Loss: (1.4800) |  Loss2: (0.0000) | Acc: (45.00%) (12377/27008)
Epoch: 5 | Batch_idx: 220 |  Loss: (1.4785) |  Loss2: (0.0000) | Acc: (45.00%) (12994/28288)
Epoch: 5 | Batch_idx: 230 |  Loss: (1.4740) |  Loss2: (0.0000) | Acc: (46.00%) (13607/29568)
Epoch: 5 | Batch_idx: 240 |  Loss: (1.4715) |  Loss2: (0.0000) | Acc: (46.00%) (14232/30848)
Epoch: 5 | Batch_idx: 250 |  Loss: (1.4659) |  Loss2: (0.0000) | Acc: (46.00%) (14894/32128)
Epoch: 5 | Batch_idx: 260 |  Loss: (1.4630) |  Loss2: (0.0000) | Acc: (46.00%) (15502/33408)
Epoch: 5 | Batch_idx: 270 |  Loss: (1.4590) |  Loss2: (0.0000) | Acc: (46.00%) (16138/34688)
Epoch: 5 | Batch_idx: 280 |  Loss: (1.4566) |  Loss2: (0.0000) | Acc: (46.00%) (16739/35968)
Epoch: 5 | Batch_idx: 290 |  Loss: (1.4541) |  Loss2: (0.0000) | Acc: (46.00%) (17346/37248)
Epoch: 5 | Batch_idx: 300 |  Loss: (1.4510) |  Loss2: (0.0000) | Acc: (46.00%) (17995/38528)
Epoch: 5 | Batch_idx: 310 |  Loss: (1.4473) |  Loss2: (0.0000) | Acc: (46.00%) (18649/39808)
Epoch: 5 | Batch_idx: 320 |  Loss: (1.4455) |  Loss2: (0.0000) | Acc: (46.00%) (19267/41088)
Epoch: 5 | Batch_idx: 330 |  Loss: (1.4426) |  Loss2: (0.0000) | Acc: (46.00%) (19907/42368)
Epoch: 5 | Batch_idx: 340 |  Loss: (1.4389) |  Loss2: (0.0000) | Acc: (47.00%) (20586/43648)
Epoch: 5 | Batch_idx: 350 |  Loss: (1.4365) |  Loss2: (0.0000) | Acc: (47.00%) (21217/44928)
Epoch: 5 | Batch_idx: 360 |  Loss: (1.4326) |  Loss2: (0.0000) | Acc: (47.00%) (21881/46208)
Epoch: 5 | Batch_idx: 370 |  Loss: (1.4297) |  Loss2: (0.0000) | Acc: (47.00%) (22517/47488)
Epoch: 5 | Batch_idx: 380 |  Loss: (1.4278) |  Loss2: (0.0000) | Acc: (47.00%) (23146/48768)
Epoch: 5 | Batch_idx: 390 |  Loss: (1.4254) |  Loss2: (0.0000) | Acc: (47.00%) (23778/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_005.pth.tar'
# TEST : Loss: (1.3100) | Acc: (51.00%) (5136/10000)
percent tensor([0.4941, 0.5041, 0.4930, 0.4993, 0.4925, 0.4932, 0.4993, 0.5006, 0.4970,
        0.4992, 0.4980, 0.4921, 0.4961, 0.5080, 0.4992, 0.4999],
       device='cuda:0') torch.Size([16])
percent tensor([0.5010, 0.5021, 0.5006, 0.5007, 0.5012, 0.4999, 0.5020, 0.5004, 0.5021,
        0.5016, 0.5022, 0.5012, 0.5018, 0.5021, 0.5008, 0.5008],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5033, 0.4986, 0.4997, 0.4985, 0.5002, 0.5004, 0.4999, 0.4996,
        0.5010, 0.5008, 0.4988, 0.5003, 0.5044, 0.5016, 0.5007],
       device='cuda:0') torch.Size([16])
percent tensor([0.4971, 0.4930, 0.4981, 0.5013, 0.4963, 0.4979, 0.4924, 0.4986, 0.4942,
        0.4940, 0.4946, 0.4952, 0.4961, 0.4930, 0.4959, 0.4973],
       device='cuda:0') torch.Size([16])
percent tensor([0.4982, 0.4980, 0.4935, 0.4947, 0.4930, 0.4978, 0.4956, 0.4953, 0.4967,
        0.4970, 0.4976, 0.4938, 0.4982, 0.4981, 0.4975, 0.4985],
       device='cuda:0') torch.Size([16])
percent tensor([0.5088, 0.5068, 0.5163, 0.5160, 0.5158, 0.5151, 0.5102, 0.5210, 0.5074,
        0.5102, 0.5073, 0.5135, 0.5071, 0.5061, 0.5098, 0.5160],
       device='cuda:0') torch.Size([16])
percent tensor([0.5043, 0.5019, 0.5032, 0.5068, 0.5034, 0.5123, 0.5019, 0.5083, 0.5001,
        0.5018, 0.5011, 0.5019, 0.5023, 0.4998, 0.5028, 0.5186],
       device='cuda:0') torch.Size([16])
percent tensor([0.5148, 0.5105, 0.5428, 0.5530, 0.5516, 0.5257, 0.5225, 0.5578, 0.5143,
        0.5234, 0.5124, 0.5370, 0.5131, 0.5095, 0.5212, 0.5440],
       device='cuda:0') torch.Size([16])
Epoch: 6 | Batch_idx: 0 |  Loss: (1.1571) |  Loss2: (0.0000) | Acc: (53.00%) (69/128)
Epoch: 6 | Batch_idx: 10 |  Loss: (1.3037) |  Loss2: (0.0000) | Acc: (53.00%) (750/1408)
Epoch: 6 | Batch_idx: 20 |  Loss: (1.3103) |  Loss2: (0.0000) | Acc: (51.00%) (1396/2688)
Epoch: 6 | Batch_idx: 30 |  Loss: (1.3075) |  Loss2: (0.0000) | Acc: (51.00%) (2057/3968)
Epoch: 6 | Batch_idx: 40 |  Loss: (1.3119) |  Loss2: (0.0000) | Acc: (51.00%) (2713/5248)
Epoch: 6 | Batch_idx: 50 |  Loss: (1.3164) |  Loss2: (0.0000) | Acc: (51.00%) (3375/6528)
Epoch: 6 | Batch_idx: 60 |  Loss: (1.3153) |  Loss2: (0.0000) | Acc: (51.00%) (4034/7808)
Epoch: 6 | Batch_idx: 70 |  Loss: (1.3170) |  Loss2: (0.0000) | Acc: (51.00%) (4702/9088)
Epoch: 6 | Batch_idx: 80 |  Loss: (1.3157) |  Loss2: (0.0000) | Acc: (51.00%) (5378/10368)
Epoch: 6 | Batch_idx: 90 |  Loss: (1.3124) |  Loss2: (0.0000) | Acc: (51.00%) (6041/11648)
Epoch: 6 | Batch_idx: 100 |  Loss: (1.3121) |  Loss2: (0.0000) | Acc: (51.00%) (6716/12928)
Epoch: 6 | Batch_idx: 110 |  Loss: (1.3092) |  Loss2: (0.0000) | Acc: (52.00%) (7405/14208)
Epoch: 6 | Batch_idx: 120 |  Loss: (1.3088) |  Loss2: (0.0000) | Acc: (52.00%) (8071/15488)
Epoch: 6 | Batch_idx: 130 |  Loss: (1.3098) |  Loss2: (0.0000) | Acc: (52.00%) (8737/16768)
Epoch: 6 | Batch_idx: 140 |  Loss: (1.3091) |  Loss2: (0.0000) | Acc: (52.00%) (9407/18048)
Epoch: 6 | Batch_idx: 150 |  Loss: (1.3073) |  Loss2: (0.0000) | Acc: (52.00%) (10081/19328)
Epoch: 6 | Batch_idx: 160 |  Loss: (1.3049) |  Loss2: (0.0000) | Acc: (52.00%) (10760/20608)
Epoch: 6 | Batch_idx: 170 |  Loss: (1.3040) |  Loss2: (0.0000) | Acc: (52.00%) (11415/21888)
Epoch: 6 | Batch_idx: 180 |  Loss: (1.3021) |  Loss2: (0.0000) | Acc: (52.00%) (12082/23168)
Epoch: 6 | Batch_idx: 190 |  Loss: (1.3030) |  Loss2: (0.0000) | Acc: (52.00%) (12717/24448)
Epoch: 6 | Batch_idx: 200 |  Loss: (1.3050) |  Loss2: (0.0000) | Acc: (51.00%) (13361/25728)
Epoch: 6 | Batch_idx: 210 |  Loss: (1.3035) |  Loss2: (0.0000) | Acc: (51.00%) (14040/27008)
Epoch: 6 | Batch_idx: 220 |  Loss: (1.3018) |  Loss2: (0.0000) | Acc: (52.00%) (14737/28288)
Epoch: 6 | Batch_idx: 230 |  Loss: (1.3016) |  Loss2: (0.0000) | Acc: (52.00%) (15424/29568)
Epoch: 6 | Batch_idx: 240 |  Loss: (1.2995) |  Loss2: (0.0000) | Acc: (52.00%) (16109/30848)
Epoch: 6 | Batch_idx: 250 |  Loss: (1.2983) |  Loss2: (0.0000) | Acc: (52.00%) (16778/32128)
Epoch: 6 | Batch_idx: 260 |  Loss: (1.2975) |  Loss2: (0.0000) | Acc: (52.00%) (17472/33408)
Epoch: 6 | Batch_idx: 270 |  Loss: (1.2963) |  Loss2: (0.0000) | Acc: (52.00%) (18157/34688)
Epoch: 6 | Batch_idx: 280 |  Loss: (1.2955) |  Loss2: (0.0000) | Acc: (52.00%) (18840/35968)
Epoch: 6 | Batch_idx: 290 |  Loss: (1.2931) |  Loss2: (0.0000) | Acc: (52.00%) (19543/37248)
Epoch: 6 | Batch_idx: 300 |  Loss: (1.2926) |  Loss2: (0.0000) | Acc: (52.00%) (20239/38528)
Epoch: 6 | Batch_idx: 310 |  Loss: (1.2913) |  Loss2: (0.0000) | Acc: (52.00%) (20938/39808)
Epoch: 6 | Batch_idx: 320 |  Loss: (1.2893) |  Loss2: (0.0000) | Acc: (52.00%) (21658/41088)
Epoch: 6 | Batch_idx: 330 |  Loss: (1.2891) |  Loss2: (0.0000) | Acc: (52.00%) (22325/42368)
Epoch: 6 | Batch_idx: 340 |  Loss: (1.2874) |  Loss2: (0.0000) | Acc: (52.00%) (23031/43648)
Epoch: 6 | Batch_idx: 350 |  Loss: (1.2845) |  Loss2: (0.0000) | Acc: (52.00%) (23740/44928)
Epoch: 6 | Batch_idx: 360 |  Loss: (1.2837) |  Loss2: (0.0000) | Acc: (52.00%) (24445/46208)
Epoch: 6 | Batch_idx: 370 |  Loss: (1.2819) |  Loss2: (0.0000) | Acc: (52.00%) (25158/47488)
Epoch: 6 | Batch_idx: 380 |  Loss: (1.2805) |  Loss2: (0.0000) | Acc: (53.00%) (25866/48768)
Epoch: 6 | Batch_idx: 390 |  Loss: (1.2796) |  Loss2: (0.0000) | Acc: (53.00%) (26538/50000)
# TEST : Loss: (1.2297) | Acc: (54.00%) (5499/10000)
percent tensor([0.4904, 0.5086, 0.4878, 0.4994, 0.4870, 0.4889, 0.4994, 0.5015, 0.4955,
        0.4993, 0.4972, 0.4859, 0.4941, 0.5161, 0.4993, 0.5008],
       device='cuda:0') torch.Size([16])
percent tensor([0.4986, 0.4992, 0.4950, 0.4971, 0.4956, 0.4974, 0.4975, 0.4951, 0.4988,
        0.4978, 0.4998, 0.4957, 0.4993, 0.4997, 0.4978, 0.4979],
       device='cuda:0') torch.Size([16])
percent tensor([0.4967, 0.5043, 0.4959, 0.4964, 0.4961, 0.4958, 0.4999, 0.4985, 0.4973,
        0.5003, 0.4988, 0.4966, 0.4977, 0.5058, 0.4999, 0.4977],
       device='cuda:0') torch.Size([16])
percent tensor([0.4960, 0.4865, 0.4988, 0.5056, 0.4951, 0.4990, 0.4864, 0.5003, 0.4899,
        0.4891, 0.4900, 0.4934, 0.4932, 0.4867, 0.4941, 0.4968],
       device='cuda:0') torch.Size([16])
percent tensor([0.4991, 0.4988, 0.4928, 0.4941, 0.4930, 0.4980, 0.4961, 0.4954, 0.4971,
        0.4976, 0.4983, 0.4931, 0.4990, 0.4982, 0.4983, 0.4992],
       device='cuda:0') torch.Size([16])
percent tensor([0.5172, 0.5133, 0.5301, 0.5294, 0.5283, 0.5283, 0.5190, 0.5384, 0.5149,
        0.5190, 0.5145, 0.5254, 0.5143, 0.5124, 0.5178, 0.5287],
       device='cuda:0') torch.Size([16])
percent tensor([0.5128, 0.5094, 0.5096, 0.5174, 0.5111, 0.5263, 0.5072, 0.5213, 0.5059,
        0.5100, 0.5082, 0.5069, 0.5107, 0.5072, 0.5090, 0.5328],
       device='cuda:0') torch.Size([16])
percent tensor([0.6031, 0.5878, 0.6789, 0.7049, 0.6984, 0.6505, 0.6093, 0.7399, 0.6175,
        0.6384, 0.6140, 0.6565, 0.6216, 0.5897, 0.6055, 0.7077],
       device='cuda:0') torch.Size([16])
Epoch: 7 | Batch_idx: 0 |  Loss: (1.1453) |  Loss2: (0.0000) | Acc: (56.00%) (72/128)
Epoch: 7 | Batch_idx: 10 |  Loss: (1.2247) |  Loss2: (0.0000) | Acc: (55.00%) (784/1408)
Epoch: 7 | Batch_idx: 20 |  Loss: (1.2374) |  Loss2: (0.0000) | Acc: (55.00%) (1484/2688)
Epoch: 7 | Batch_idx: 30 |  Loss: (1.2397) |  Loss2: (0.0000) | Acc: (54.00%) (2168/3968)
Epoch: 7 | Batch_idx: 40 |  Loss: (1.2351) |  Loss2: (0.0000) | Acc: (54.00%) (2861/5248)
Epoch: 7 | Batch_idx: 50 |  Loss: (1.2343) |  Loss2: (0.0000) | Acc: (54.00%) (3550/6528)
Epoch: 7 | Batch_idx: 60 |  Loss: (1.2377) |  Loss2: (0.0000) | Acc: (54.00%) (4238/7808)
Epoch: 7 | Batch_idx: 70 |  Loss: (1.2378) |  Loss2: (0.0000) | Acc: (54.00%) (4932/9088)
Epoch: 7 | Batch_idx: 80 |  Loss: (1.2368) |  Loss2: (0.0000) | Acc: (54.00%) (5601/10368)
Epoch: 7 | Batch_idx: 90 |  Loss: (1.2349) |  Loss2: (0.0000) | Acc: (54.00%) (6324/11648)
Epoch: 7 | Batch_idx: 100 |  Loss: (1.2363) |  Loss2: (0.0000) | Acc: (54.00%) (7035/12928)
Epoch: 7 | Batch_idx: 110 |  Loss: (1.2375) |  Loss2: (0.0000) | Acc: (54.00%) (7727/14208)
Epoch: 7 | Batch_idx: 120 |  Loss: (1.2361) |  Loss2: (0.0000) | Acc: (54.00%) (8422/15488)
Epoch: 7 | Batch_idx: 130 |  Loss: (1.2318) |  Loss2: (0.0000) | Acc: (54.00%) (9153/16768)
Epoch: 7 | Batch_idx: 140 |  Loss: (1.2366) |  Loss2: (0.0000) | Acc: (54.00%) (9792/18048)
Epoch: 7 | Batch_idx: 150 |  Loss: (1.2385) |  Loss2: (0.0000) | Acc: (54.00%) (10479/19328)
Epoch: 7 | Batch_idx: 160 |  Loss: (1.2380) |  Loss2: (0.0000) | Acc: (54.00%) (11203/20608)
Epoch: 7 | Batch_idx: 170 |  Loss: (1.2392) |  Loss2: (0.0000) | Acc: (54.00%) (11899/21888)
Epoch: 7 | Batch_idx: 180 |  Loss: (1.2369) |  Loss2: (0.0000) | Acc: (54.00%) (12601/23168)
Epoch: 7 | Batch_idx: 190 |  Loss: (1.2365) |  Loss2: (0.0000) | Acc: (54.00%) (13303/24448)
Epoch: 7 | Batch_idx: 200 |  Loss: (1.2355) |  Loss2: (0.0000) | Acc: (54.00%) (14036/25728)
Epoch: 7 | Batch_idx: 210 |  Loss: (1.2348) |  Loss2: (0.0000) | Acc: (54.00%) (14754/27008)
Epoch: 7 | Batch_idx: 220 |  Loss: (1.2343) |  Loss2: (0.0000) | Acc: (54.00%) (15451/28288)
Epoch: 7 | Batch_idx: 230 |  Loss: (1.2365) |  Loss2: (0.0000) | Acc: (54.00%) (16112/29568)
Epoch: 7 | Batch_idx: 240 |  Loss: (1.2378) |  Loss2: (0.0000) | Acc: (54.00%) (16806/30848)
Epoch: 7 | Batch_idx: 250 |  Loss: (1.2367) |  Loss2: (0.0000) | Acc: (54.00%) (17516/32128)
Epoch: 7 | Batch_idx: 260 |  Loss: (1.2363) |  Loss2: (0.0000) | Acc: (54.00%) (18213/33408)
Epoch: 7 | Batch_idx: 270 |  Loss: (1.2346) |  Loss2: (0.0000) | Acc: (54.00%) (18968/34688)
Epoch: 7 | Batch_idx: 280 |  Loss: (1.2323) |  Loss2: (0.0000) | Acc: (54.00%) (19686/35968)
Epoch: 7 | Batch_idx: 290 |  Loss: (1.2307) |  Loss2: (0.0000) | Acc: (54.00%) (20392/37248)
Epoch: 7 | Batch_idx: 300 |  Loss: (1.2293) |  Loss2: (0.0000) | Acc: (54.00%) (21113/38528)
Epoch: 7 | Batch_idx: 310 |  Loss: (1.2279) |  Loss2: (0.0000) | Acc: (54.00%) (21835/39808)
Epoch: 7 | Batch_idx: 320 |  Loss: (1.2295) |  Loss2: (0.0000) | Acc: (54.00%) (22520/41088)
Epoch: 7 | Batch_idx: 330 |  Loss: (1.2299) |  Loss2: (0.0000) | Acc: (54.00%) (23242/42368)
Epoch: 7 | Batch_idx: 340 |  Loss: (1.2287) |  Loss2: (0.0000) | Acc: (54.00%) (23977/43648)
Epoch: 7 | Batch_idx: 350 |  Loss: (1.2276) |  Loss2: (0.0000) | Acc: (54.00%) (24709/44928)
Epoch: 7 | Batch_idx: 360 |  Loss: (1.2278) |  Loss2: (0.0000) | Acc: (55.00%) (25419/46208)
Epoch: 7 | Batch_idx: 370 |  Loss: (1.2270) |  Loss2: (0.0000) | Acc: (55.00%) (26145/47488)
Epoch: 7 | Batch_idx: 380 |  Loss: (1.2273) |  Loss2: (0.0000) | Acc: (55.00%) (26826/48768)
Epoch: 7 | Batch_idx: 390 |  Loss: (1.2265) |  Loss2: (0.0000) | Acc: (55.00%) (27501/50000)
# TEST : Loss: (1.2109) | Acc: (56.00%) (5602/10000)
percent tensor([0.4895, 0.5111, 0.4853, 0.4995, 0.4848, 0.4880, 0.4998, 0.5017, 0.4953,
        0.4994, 0.4976, 0.4832, 0.4938, 0.5205, 0.4999, 0.5016],
       device='cuda:0') torch.Size([16])
percent tensor([0.4951, 0.4943, 0.4875, 0.4921, 0.4882, 0.4941, 0.4909, 0.4880, 0.4936,
        0.4923, 0.4958, 0.4883, 0.4956, 0.4951, 0.4933, 0.4935],
       device='cuda:0') torch.Size([16])
percent tensor([0.4939, 0.5051, 0.4937, 0.4938, 0.4941, 0.4921, 0.4996, 0.4977, 0.4954,
        0.4997, 0.4971, 0.4948, 0.4954, 0.5071, 0.4984, 0.4952],
       device='cuda:0') torch.Size([16])
percent tensor([0.4972, 0.4830, 0.5024, 0.5114, 0.4973, 0.5030, 0.4836, 0.5053, 0.4885,
        0.4870, 0.4877, 0.4947, 0.4926, 0.4834, 0.4951, 0.4990],
       device='cuda:0') torch.Size([16])
percent tensor([0.5011, 0.5008, 0.4946, 0.4956, 0.4955, 0.5000, 0.4986, 0.4979, 0.4988,
        0.4999, 0.5001, 0.4947, 0.5008, 0.4996, 0.5006, 0.5014],
       device='cuda:0') torch.Size([16])
percent tensor([0.5207, 0.5159, 0.5355, 0.5337, 0.5326, 0.5339, 0.5218, 0.5452, 0.5183,
        0.5217, 0.5176, 0.5301, 0.5180, 0.5152, 0.5198, 0.5337],
       device='cuda:0') torch.Size([16])
percent tensor([0.5165, 0.5126, 0.5125, 0.5218, 0.5147, 0.5314, 0.5103, 0.5280, 0.5086,
        0.5139, 0.5112, 0.5085, 0.5138, 0.5100, 0.5115, 0.5383],
       device='cuda:0') torch.Size([16])
percent tensor([0.6802, 0.6593, 0.7847, 0.8090, 0.8043, 0.7526, 0.6834, 0.8607, 0.7022,
        0.7298, 0.7011, 0.7477, 0.7095, 0.6615, 0.6797, 0.8227],
       device='cuda:0') torch.Size([16])
Epoch: 8 | Batch_idx: 0 |  Loss: (1.3315) |  Loss2: (0.0000) | Acc: (53.00%) (68/128)
Epoch: 8 | Batch_idx: 10 |  Loss: (1.2339) |  Loss2: (0.0000) | Acc: (55.00%) (787/1408)
Epoch: 8 | Batch_idx: 20 |  Loss: (1.2235) |  Loss2: (0.0000) | Acc: (55.00%) (1499/2688)
Epoch: 8 | Batch_idx: 30 |  Loss: (1.2100) |  Loss2: (0.0000) | Acc: (56.00%) (2253/3968)
Epoch: 8 | Batch_idx: 40 |  Loss: (1.2179) |  Loss2: (0.0000) | Acc: (56.00%) (2956/5248)
Epoch: 8 | Batch_idx: 50 |  Loss: (1.2052) |  Loss2: (0.0000) | Acc: (56.00%) (3698/6528)
Epoch: 8 | Batch_idx: 60 |  Loss: (1.2038) |  Loss2: (0.0000) | Acc: (56.00%) (4430/7808)
Epoch: 8 | Batch_idx: 70 |  Loss: (1.2066) |  Loss2: (0.0000) | Acc: (56.00%) (5123/9088)
Epoch: 8 | Batch_idx: 80 |  Loss: (1.2115) |  Loss2: (0.0000) | Acc: (56.00%) (5824/10368)
Epoch: 8 | Batch_idx: 90 |  Loss: (1.2109) |  Loss2: (0.0000) | Acc: (56.00%) (6547/11648)
Epoch: 8 | Batch_idx: 100 |  Loss: (1.2095) |  Loss2: (0.0000) | Acc: (56.00%) (7275/12928)
Epoch: 8 | Batch_idx: 110 |  Loss: (1.2103) |  Loss2: (0.0000) | Acc: (56.00%) (8004/14208)
Epoch: 8 | Batch_idx: 120 |  Loss: (1.2117) |  Loss2: (0.0000) | Acc: (56.00%) (8723/15488)
Epoch: 8 | Batch_idx: 130 |  Loss: (1.2119) |  Loss2: (0.0000) | Acc: (56.00%) (9440/16768)
Epoch: 8 | Batch_idx: 140 |  Loss: (1.2117) |  Loss2: (0.0000) | Acc: (56.00%) (10149/18048)
Epoch: 8 | Batch_idx: 150 |  Loss: (1.2074) |  Loss2: (0.0000) | Acc: (56.00%) (10892/19328)
Epoch: 8 | Batch_idx: 160 |  Loss: (1.2060) |  Loss2: (0.0000) | Acc: (56.00%) (11603/20608)
Epoch: 8 | Batch_idx: 170 |  Loss: (1.2093) |  Loss2: (0.0000) | Acc: (56.00%) (12284/21888)
Epoch: 8 | Batch_idx: 180 |  Loss: (1.2086) |  Loss2: (0.0000) | Acc: (56.00%) (13000/23168)
Epoch: 8 | Batch_idx: 190 |  Loss: (1.2084) |  Loss2: (0.0000) | Acc: (56.00%) (13701/24448)
Epoch: 8 | Batch_idx: 200 |  Loss: (1.2124) |  Loss2: (0.0000) | Acc: (55.00%) (14374/25728)
Epoch: 8 | Batch_idx: 210 |  Loss: (1.2132) |  Loss2: (0.0000) | Acc: (55.00%) (15056/27008)
Epoch: 8 | Batch_idx: 220 |  Loss: (1.2119) |  Loss2: (0.0000) | Acc: (55.00%) (15771/28288)
Epoch: 8 | Batch_idx: 230 |  Loss: (1.2106) |  Loss2: (0.0000) | Acc: (55.00%) (16505/29568)
Epoch: 8 | Batch_idx: 240 |  Loss: (1.2087) |  Loss2: (0.0000) | Acc: (55.00%) (17217/30848)
Epoch: 8 | Batch_idx: 250 |  Loss: (1.2099) |  Loss2: (0.0000) | Acc: (55.00%) (17889/32128)
Epoch: 8 | Batch_idx: 260 |  Loss: (1.2090) |  Loss2: (0.0000) | Acc: (55.00%) (18622/33408)
Epoch: 8 | Batch_idx: 270 |  Loss: (1.2111) |  Loss2: (0.0000) | Acc: (55.00%) (19309/34688)
Epoch: 8 | Batch_idx: 280 |  Loss: (1.2109) |  Loss2: (0.0000) | Acc: (55.00%) (20048/35968)
Epoch: 8 | Batch_idx: 290 |  Loss: (1.2096) |  Loss2: (0.0000) | Acc: (55.00%) (20791/37248)
Epoch: 8 | Batch_idx: 300 |  Loss: (1.2095) |  Loss2: (0.0000) | Acc: (55.00%) (21519/38528)
Epoch: 8 | Batch_idx: 310 |  Loss: (1.2092) |  Loss2: (0.0000) | Acc: (55.00%) (22244/39808)
Epoch: 8 | Batch_idx: 320 |  Loss: (1.2088) |  Loss2: (0.0000) | Acc: (55.00%) (22949/41088)
Epoch: 8 | Batch_idx: 330 |  Loss: (1.2087) |  Loss2: (0.0000) | Acc: (55.00%) (23670/42368)
Epoch: 8 | Batch_idx: 340 |  Loss: (1.2095) |  Loss2: (0.0000) | Acc: (55.00%) (24375/43648)
Epoch: 8 | Batch_idx: 350 |  Loss: (1.2103) |  Loss2: (0.0000) | Acc: (55.00%) (25088/44928)
Epoch: 8 | Batch_idx: 360 |  Loss: (1.2096) |  Loss2: (0.0000) | Acc: (55.00%) (25810/46208)
Epoch: 8 | Batch_idx: 370 |  Loss: (1.2097) |  Loss2: (0.0000) | Acc: (55.00%) (26531/47488)
Epoch: 8 | Batch_idx: 380 |  Loss: (1.2090) |  Loss2: (0.0000) | Acc: (55.00%) (27253/48768)
Epoch: 8 | Batch_idx: 390 |  Loss: (1.2093) |  Loss2: (0.0000) | Acc: (55.00%) (27915/50000)
# TEST : Loss: (1.1972) | Acc: (56.00%) (5649/10000)
percent tensor([0.4910, 0.5140, 0.4852, 0.5006, 0.4853, 0.4896, 0.5020, 0.5028, 0.4974,
        0.5011, 0.4999, 0.4834, 0.4954, 0.5243, 0.5019, 0.5035],
       device='cuda:0') torch.Size([16])
percent tensor([0.4910, 0.4888, 0.4799, 0.4868, 0.4805, 0.4904, 0.4838, 0.4807, 0.4880,
        0.4863, 0.4912, 0.4807, 0.4913, 0.4899, 0.4884, 0.4888],
       device='cuda:0') torch.Size([16])
percent tensor([0.4915, 0.5057, 0.4920, 0.4919, 0.4923, 0.4892, 0.4991, 0.4975, 0.4937,
        0.4989, 0.4953, 0.4930, 0.4933, 0.5082, 0.4973, 0.4934],
       device='cuda:0') torch.Size([16])
percent tensor([0.5015, 0.4837, 0.5092, 0.5192, 0.5036, 0.5099, 0.4851, 0.5136, 0.4909,
        0.4886, 0.4888, 0.4995, 0.4949, 0.4838, 0.4995, 0.5047],
       device='cuda:0') torch.Size([16])
percent tensor([0.5035, 0.5032, 0.4971, 0.4980, 0.4987, 0.5026, 0.5017, 0.5012, 0.5009,
        0.5025, 0.5022, 0.4970, 0.5029, 0.5015, 0.5033, 0.5039],
       device='cuda:0') torch.Size([16])
percent tensor([0.5208, 0.5155, 0.5360, 0.5329, 0.5317, 0.5344, 0.5210, 0.5453, 0.5191,
        0.5204, 0.5177, 0.5302, 0.5186, 0.5153, 0.5182, 0.5335],
       device='cuda:0') torch.Size([16])
percent tensor([0.5165, 0.5123, 0.5149, 0.5243, 0.5174, 0.5317, 0.5117, 0.5326, 0.5091,
        0.5150, 0.5105, 0.5095, 0.5131, 0.5096, 0.5120, 0.5380],
       device='cuda:0') torch.Size([16])
percent tensor([0.7088, 0.6860, 0.8277, 0.8446, 0.8466, 0.7913, 0.7134, 0.9051, 0.7326,
        0.7612, 0.7329, 0.7795, 0.7399, 0.6880, 0.7128, 0.8489],
       device='cuda:0') torch.Size([16])
Epoch: 9 | Batch_idx: 0 |  Loss: (1.2603) |  Loss2: (0.0000) | Acc: (55.00%) (71/128)
Epoch: 9 | Batch_idx: 10 |  Loss: (1.2283) |  Loss2: (0.0000) | Acc: (55.00%) (777/1408)
Epoch: 9 | Batch_idx: 20 |  Loss: (1.1985) |  Loss2: (0.0000) | Acc: (56.00%) (1523/2688)
Epoch: 9 | Batch_idx: 30 |  Loss: (1.2083) |  Loss2: (0.0000) | Acc: (55.00%) (2221/3968)
Epoch: 9 | Batch_idx: 40 |  Loss: (1.2046) |  Loss2: (0.0000) | Acc: (55.00%) (2935/5248)
Epoch: 9 | Batch_idx: 50 |  Loss: (1.1965) |  Loss2: (0.0000) | Acc: (56.00%) (3673/6528)
Epoch: 9 | Batch_idx: 60 |  Loss: (1.1921) |  Loss2: (0.0000) | Acc: (56.00%) (4398/7808)
Epoch: 9 | Batch_idx: 70 |  Loss: (1.1926) |  Loss2: (0.0000) | Acc: (56.00%) (5123/9088)
Epoch: 9 | Batch_idx: 80 |  Loss: (1.1888) |  Loss2: (0.0000) | Acc: (56.00%) (5829/10368)
Epoch: 9 | Batch_idx: 90 |  Loss: (1.1953) |  Loss2: (0.0000) | Acc: (55.00%) (6516/11648)
Epoch: 9 | Batch_idx: 100 |  Loss: (1.1975) |  Loss2: (0.0000) | Acc: (55.00%) (7224/12928)
Epoch: 9 | Batch_idx: 110 |  Loss: (1.1916) |  Loss2: (0.0000) | Acc: (56.00%) (7975/14208)
Epoch: 9 | Batch_idx: 120 |  Loss: (1.1930) |  Loss2: (0.0000) | Acc: (56.00%) (8681/15488)
Epoch: 9 | Batch_idx: 130 |  Loss: (1.1942) |  Loss2: (0.0000) | Acc: (56.00%) (9408/16768)
Epoch: 9 | Batch_idx: 140 |  Loss: (1.1968) |  Loss2: (0.0000) | Acc: (56.00%) (10139/18048)
Epoch: 9 | Batch_idx: 150 |  Loss: (1.1995) |  Loss2: (0.0000) | Acc: (56.00%) (10835/19328)
Epoch: 9 | Batch_idx: 160 |  Loss: (1.2006) |  Loss2: (0.0000) | Acc: (56.00%) (11542/20608)
Epoch: 9 | Batch_idx: 170 |  Loss: (1.2031) |  Loss2: (0.0000) | Acc: (55.00%) (12254/21888)
Epoch: 9 | Batch_idx: 180 |  Loss: (1.2012) |  Loss2: (0.0000) | Acc: (56.00%) (12975/23168)
Epoch: 9 | Batch_idx: 190 |  Loss: (1.1982) |  Loss2: (0.0000) | Acc: (56.00%) (13705/24448)
Epoch: 9 | Batch_idx: 200 |  Loss: (1.1992) |  Loss2: (0.0000) | Acc: (56.00%) (14418/25728)
Epoch: 9 | Batch_idx: 210 |  Loss: (1.1992) |  Loss2: (0.0000) | Acc: (56.00%) (15138/27008)
Epoch: 9 | Batch_idx: 220 |  Loss: (1.1983) |  Loss2: (0.0000) | Acc: (56.00%) (15871/28288)
Epoch: 9 | Batch_idx: 230 |  Loss: (1.1980) |  Loss2: (0.0000) | Acc: (56.00%) (16595/29568)
Epoch: 9 | Batch_idx: 240 |  Loss: (1.1991) |  Loss2: (0.0000) | Acc: (56.00%) (17319/30848)
Epoch: 9 | Batch_idx: 250 |  Loss: (1.1981) |  Loss2: (0.0000) | Acc: (56.00%) (18033/32128)
Epoch: 9 | Batch_idx: 260 |  Loss: (1.1983) |  Loss2: (0.0000) | Acc: (56.00%) (18751/33408)
Epoch: 9 | Batch_idx: 270 |  Loss: (1.1987) |  Loss2: (0.0000) | Acc: (56.00%) (19449/34688)
Epoch: 9 | Batch_idx: 280 |  Loss: (1.1979) |  Loss2: (0.0000) | Acc: (56.00%) (20179/35968)
Epoch: 9 | Batch_idx: 290 |  Loss: (1.1985) |  Loss2: (0.0000) | Acc: (56.00%) (20882/37248)
Epoch: 9 | Batch_idx: 300 |  Loss: (1.1968) |  Loss2: (0.0000) | Acc: (56.00%) (21619/38528)
Epoch: 9 | Batch_idx: 310 |  Loss: (1.1976) |  Loss2: (0.0000) | Acc: (56.00%) (22331/39808)
Epoch: 9 | Batch_idx: 320 |  Loss: (1.1973) |  Loss2: (0.0000) | Acc: (56.00%) (23056/41088)
Epoch: 9 | Batch_idx: 330 |  Loss: (1.1975) |  Loss2: (0.0000) | Acc: (56.00%) (23761/42368)
Epoch: 9 | Batch_idx: 340 |  Loss: (1.1963) |  Loss2: (0.0000) | Acc: (56.00%) (24503/43648)
Epoch: 9 | Batch_idx: 350 |  Loss: (1.1962) |  Loss2: (0.0000) | Acc: (56.00%) (25216/44928)
Epoch: 9 | Batch_idx: 360 |  Loss: (1.1955) |  Loss2: (0.0000) | Acc: (56.00%) (25933/46208)
Epoch: 9 | Batch_idx: 370 |  Loss: (1.1937) |  Loss2: (0.0000) | Acc: (56.00%) (26689/47488)
Epoch: 9 | Batch_idx: 380 |  Loss: (1.1940) |  Loss2: (0.0000) | Acc: (56.00%) (27421/48768)
Epoch: 9 | Batch_idx: 390 |  Loss: (1.1940) |  Loss2: (0.0000) | Acc: (56.00%) (28126/50000)
# TEST : Loss: (1.1893) | Acc: (57.00%) (5716/10000)
percent tensor([0.4937, 0.5176, 0.4860, 0.5024, 0.4870, 0.4925, 0.5050, 0.5046, 0.5006,
        0.5035, 0.5034, 0.4845, 0.4981, 0.5286, 0.5047, 0.5062],
       device='cuda:0') torch.Size([16])
percent tensor([0.4878, 0.4847, 0.4739, 0.4826, 0.4744, 0.4874, 0.4784, 0.4749, 0.4837,
        0.4817, 0.4878, 0.4748, 0.4880, 0.4862, 0.4846, 0.4850],
       device='cuda:0') torch.Size([16])
percent tensor([0.4922, 0.5097, 0.4917, 0.4927, 0.4921, 0.4903, 0.5012, 0.4997, 0.4946,
        0.5010, 0.4970, 0.4933, 0.4938, 0.5133, 0.4995, 0.4946],
       device='cuda:0') torch.Size([16])
percent tensor([0.5091, 0.4894, 0.5200, 0.5306, 0.5144, 0.5202, 0.4919, 0.5256, 0.4973,
        0.4953, 0.4940, 0.5088, 0.5008, 0.4886, 0.5082, 0.5148],
       device='cuda:0') torch.Size([16])
percent tensor([0.5067, 0.5062, 0.5008, 0.5014, 0.5032, 0.5060, 0.5059, 0.5060, 0.5035,
        0.5059, 0.5048, 0.5002, 0.5055, 0.5037, 0.5070, 0.5076],
       device='cuda:0') torch.Size([16])
percent tensor([0.5209, 0.5158, 0.5366, 0.5314, 0.5309, 0.5340, 0.5209, 0.5448, 0.5205,
        0.5201, 0.5186, 0.5309, 0.5198, 0.5162, 0.5167, 0.5331],
       device='cuda:0') torch.Size([16])
percent tensor([0.5160, 0.5122, 0.5181, 0.5269, 0.5204, 0.5309, 0.5132, 0.5384, 0.5098,
        0.5164, 0.5103, 0.5113, 0.5128, 0.5097, 0.5120, 0.5372],
       device='cuda:0') torch.Size([16])
percent tensor([0.7309, 0.7080, 0.8688, 0.8802, 0.8837, 0.8167, 0.7448, 0.9381, 0.7561,
        0.7896, 0.7565, 0.8159, 0.7608, 0.7090, 0.7435, 0.8704],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 10 | Batch_idx: 0 |  Loss: (1.1620) |  Loss2: (0.0000) | Acc: (56.00%) (72/128)
Epoch: 10 | Batch_idx: 10 |  Loss: (1.2125) |  Loss2: (0.0000) | Acc: (55.00%) (776/1408)
Epoch: 10 | Batch_idx: 20 |  Loss: (1.2171) |  Loss2: (0.0000) | Acc: (55.00%) (1485/2688)
Epoch: 10 | Batch_idx: 30 |  Loss: (1.2017) |  Loss2: (0.0000) | Acc: (56.00%) (2228/3968)
Epoch: 10 | Batch_idx: 40 |  Loss: (1.1968) |  Loss2: (0.0000) | Acc: (56.00%) (2955/5248)
Epoch: 10 | Batch_idx: 50 |  Loss: (1.2033) |  Loss2: (0.0000) | Acc: (56.00%) (3668/6528)
Epoch: 10 | Batch_idx: 60 |  Loss: (1.2041) |  Loss2: (0.0000) | Acc: (56.00%) (4387/7808)
Epoch: 10 | Batch_idx: 70 |  Loss: (1.1931) |  Loss2: (0.0000) | Acc: (56.00%) (5161/9088)
Epoch: 10 | Batch_idx: 80 |  Loss: (1.1888) |  Loss2: (0.0000) | Acc: (56.00%) (5909/10368)
Epoch: 10 | Batch_idx: 90 |  Loss: (1.1929) |  Loss2: (0.0000) | Acc: (56.00%) (6636/11648)
Epoch: 10 | Batch_idx: 100 |  Loss: (1.1858) |  Loss2: (0.0000) | Acc: (57.00%) (7389/12928)
Epoch: 10 | Batch_idx: 110 |  Loss: (1.1847) |  Loss2: (0.0000) | Acc: (57.00%) (8129/14208)
Epoch: 10 | Batch_idx: 120 |  Loss: (1.1813) |  Loss2: (0.0000) | Acc: (57.00%) (8880/15488)
Epoch: 10 | Batch_idx: 130 |  Loss: (1.1761) |  Loss2: (0.0000) | Acc: (57.00%) (9646/16768)
Epoch: 10 | Batch_idx: 140 |  Loss: (1.1736) |  Loss2: (0.0000) | Acc: (57.00%) (10420/18048)
Epoch: 10 | Batch_idx: 150 |  Loss: (1.1674) |  Loss2: (0.0000) | Acc: (57.00%) (11202/19328)
Epoch: 10 | Batch_idx: 160 |  Loss: (1.1668) |  Loss2: (0.0000) | Acc: (57.00%) (11949/20608)
Epoch: 10 | Batch_idx: 170 |  Loss: (1.1647) |  Loss2: (0.0000) | Acc: (58.00%) (12701/21888)
Epoch: 10 | Batch_idx: 180 |  Loss: (1.1622) |  Loss2: (0.0000) | Acc: (58.00%) (13455/23168)
Epoch: 10 | Batch_idx: 190 |  Loss: (1.1591) |  Loss2: (0.0000) | Acc: (58.00%) (14248/24448)
Epoch: 10 | Batch_idx: 200 |  Loss: (1.1570) |  Loss2: (0.0000) | Acc: (58.00%) (15015/25728)
Epoch: 10 | Batch_idx: 210 |  Loss: (1.1576) |  Loss2: (0.0000) | Acc: (58.00%) (15770/27008)
Epoch: 10 | Batch_idx: 220 |  Loss: (1.1552) |  Loss2: (0.0000) | Acc: (58.00%) (16546/28288)
Epoch: 10 | Batch_idx: 230 |  Loss: (1.1533) |  Loss2: (0.0000) | Acc: (58.00%) (17317/29568)
Epoch: 10 | Batch_idx: 240 |  Loss: (1.1492) |  Loss2: (0.0000) | Acc: (58.00%) (18118/30848)
Epoch: 10 | Batch_idx: 250 |  Loss: (1.1464) |  Loss2: (0.0000) | Acc: (58.00%) (18902/32128)
Epoch: 10 | Batch_idx: 260 |  Loss: (1.1452) |  Loss2: (0.0000) | Acc: (58.00%) (19653/33408)
Epoch: 10 | Batch_idx: 270 |  Loss: (1.1437) |  Loss2: (0.0000) | Acc: (58.00%) (20431/34688)
Epoch: 10 | Batch_idx: 280 |  Loss: (1.1423) |  Loss2: (0.0000) | Acc: (58.00%) (21204/35968)
Epoch: 10 | Batch_idx: 290 |  Loss: (1.1403) |  Loss2: (0.0000) | Acc: (59.00%) (21997/37248)
Epoch: 10 | Batch_idx: 300 |  Loss: (1.1392) |  Loss2: (0.0000) | Acc: (59.00%) (22769/38528)
Epoch: 10 | Batch_idx: 310 |  Loss: (1.1375) |  Loss2: (0.0000) | Acc: (59.00%) (23517/39808)
Epoch: 10 | Batch_idx: 320 |  Loss: (1.1375) |  Loss2: (0.0000) | Acc: (59.00%) (24267/41088)
Epoch: 10 | Batch_idx: 330 |  Loss: (1.1369) |  Loss2: (0.0000) | Acc: (59.00%) (25034/42368)
Epoch: 10 | Batch_idx: 340 |  Loss: (1.1357) |  Loss2: (0.0000) | Acc: (59.00%) (25787/43648)
Epoch: 10 | Batch_idx: 350 |  Loss: (1.1339) |  Loss2: (0.0000) | Acc: (59.00%) (26586/44928)
Epoch: 10 | Batch_idx: 360 |  Loss: (1.1320) |  Loss2: (0.0000) | Acc: (59.00%) (27380/46208)
Epoch: 10 | Batch_idx: 370 |  Loss: (1.1315) |  Loss2: (0.0000) | Acc: (59.00%) (28159/47488)
Epoch: 10 | Batch_idx: 380 |  Loss: (1.1290) |  Loss2: (0.0000) | Acc: (59.00%) (28964/48768)
Epoch: 10 | Batch_idx: 390 |  Loss: (1.1287) |  Loss2: (0.0000) | Acc: (59.00%) (29709/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_010.pth.tar'
# TEST : Loss: (1.1047) | Acc: (60.00%) (6004/10000)
percent tensor([0.4956, 0.5162, 0.4865, 0.5014, 0.4890, 0.4950, 0.5057, 0.5029, 0.5030,
        0.5031, 0.5053, 0.4866, 0.4995, 0.5267, 0.5049, 0.5057],
       device='cuda:0') torch.Size([16])
percent tensor([0.4860, 0.4850, 0.4716, 0.4823, 0.4743, 0.4854, 0.4787, 0.4742, 0.4824,
        0.4824, 0.4865, 0.4752, 0.4864, 0.4876, 0.4833, 0.4843],
       device='cuda:0') torch.Size([16])
percent tensor([0.4934, 0.5110, 0.4914, 0.4937, 0.4926, 0.4951, 0.5032, 0.4981, 0.4945,
        0.5023, 0.4993, 0.4949, 0.4959, 0.5130, 0.5022, 0.4963],
       device='cuda:0') torch.Size([16])
percent tensor([0.5094, 0.4874, 0.5229, 0.5291, 0.5174, 0.5175, 0.4931, 0.5233, 0.5009,
        0.4915, 0.4905, 0.5093, 0.4976, 0.4885, 0.5039, 0.5105],
       device='cuda:0') torch.Size([16])
percent tensor([0.5070, 0.5065, 0.5002, 0.5011, 0.5030, 0.5064, 0.5061, 0.5058, 0.5027,
        0.5055, 0.5050, 0.5004, 0.5060, 0.5044, 0.5079, 0.5079],
       device='cuda:0') torch.Size([16])
percent tensor([0.5230, 0.5177, 0.5378, 0.5308, 0.5273, 0.5273, 0.5214, 0.5400, 0.5239,
        0.5186, 0.5189, 0.5324, 0.5213, 0.5191, 0.5164, 0.5288],
       device='cuda:0') torch.Size([16])
percent tensor([0.5196, 0.5116, 0.5220, 0.5226, 0.5200, 0.5252, 0.5151, 0.5359, 0.5101,
        0.5130, 0.5086, 0.5116, 0.5127, 0.5104, 0.5083, 0.5291],
       device='cuda:0') torch.Size([16])
percent tensor([0.7633, 0.7137, 0.8581, 0.8679, 0.8679, 0.8026, 0.7457, 0.9137, 0.7437,
        0.7807, 0.7473, 0.8202, 0.7397, 0.7210, 0.7967, 0.8255],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(163.2643, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(776.4647, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(766.3617, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1531.8168, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(506.1415, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2162.4268, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4321.1919, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1447.1302, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6110.2568, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12232.6309, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4090.7856, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17275.9688, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 11 | Batch_idx: 0 |  Loss: (1.0691) |  Loss2: (0.0000) | Acc: (64.00%) (82/128)
Epoch: 11 | Batch_idx: 10 |  Loss: (1.1260) |  Loss2: (0.0000) | Acc: (59.00%) (835/1408)
Epoch: 11 | Batch_idx: 20 |  Loss: (1.0890) |  Loss2: (0.0000) | Acc: (60.00%) (1634/2688)
Epoch: 11 | Batch_idx: 30 |  Loss: (1.0743) |  Loss2: (0.0000) | Acc: (62.00%) (2461/3968)
Epoch: 11 | Batch_idx: 40 |  Loss: (1.0703) |  Loss2: (0.0000) | Acc: (61.00%) (3244/5248)
Epoch: 11 | Batch_idx: 50 |  Loss: (1.0649) |  Loss2: (0.0000) | Acc: (61.00%) (4027/6528)
Epoch: 11 | Batch_idx: 60 |  Loss: (1.0530) |  Loss2: (0.0000) | Acc: (62.00%) (4848/7808)
Epoch: 11 | Batch_idx: 70 |  Loss: (1.0495) |  Loss2: (0.0000) | Acc: (62.00%) (5648/9088)
Epoch: 11 | Batch_idx: 80 |  Loss: (1.0500) |  Loss2: (0.0000) | Acc: (62.00%) (6450/10368)
Epoch: 11 | Batch_idx: 90 |  Loss: (1.0467) |  Loss2: (0.0000) | Acc: (62.00%) (7269/11648)
Epoch: 11 | Batch_idx: 100 |  Loss: (1.0471) |  Loss2: (0.0000) | Acc: (62.00%) (8087/12928)
Epoch: 11 | Batch_idx: 110 |  Loss: (1.0457) |  Loss2: (0.0000) | Acc: (62.00%) (8889/14208)
Epoch: 11 | Batch_idx: 120 |  Loss: (1.0476) |  Loss2: (0.0000) | Acc: (62.00%) (9688/15488)
Epoch: 11 | Batch_idx: 130 |  Loss: (1.0444) |  Loss2: (0.0000) | Acc: (62.00%) (10505/16768)
Epoch: 11 | Batch_idx: 140 |  Loss: (1.0425) |  Loss2: (0.0000) | Acc: (62.00%) (11312/18048)
Epoch: 11 | Batch_idx: 150 |  Loss: (1.0422) |  Loss2: (0.0000) | Acc: (62.00%) (12119/19328)
Epoch: 11 | Batch_idx: 160 |  Loss: (1.0400) |  Loss2: (0.0000) | Acc: (62.00%) (12943/20608)
Epoch: 11 | Batch_idx: 170 |  Loss: (1.0399) |  Loss2: (0.0000) | Acc: (62.00%) (13746/21888)
Epoch: 11 | Batch_idx: 180 |  Loss: (1.0407) |  Loss2: (0.0000) | Acc: (62.00%) (14558/23168)
Epoch: 11 | Batch_idx: 190 |  Loss: (1.0412) |  Loss2: (0.0000) | Acc: (62.00%) (15361/24448)
Epoch: 11 | Batch_idx: 200 |  Loss: (1.0387) |  Loss2: (0.0000) | Acc: (63.00%) (16211/25728)
Epoch: 11 | Batch_idx: 210 |  Loss: (1.0404) |  Loss2: (0.0000) | Acc: (62.00%) (17000/27008)
Epoch: 11 | Batch_idx: 220 |  Loss: (1.0422) |  Loss2: (0.0000) | Acc: (62.00%) (17760/28288)
Epoch: 11 | Batch_idx: 230 |  Loss: (1.0412) |  Loss2: (0.0000) | Acc: (62.00%) (18573/29568)
Epoch: 11 | Batch_idx: 240 |  Loss: (1.0389) |  Loss2: (0.0000) | Acc: (62.00%) (19400/30848)
Epoch: 11 | Batch_idx: 250 |  Loss: (1.0364) |  Loss2: (0.0000) | Acc: (62.00%) (20221/32128)
Epoch: 11 | Batch_idx: 260 |  Loss: (1.0343) |  Loss2: (0.0000) | Acc: (63.00%) (21058/33408)
Epoch: 11 | Batch_idx: 270 |  Loss: (1.0341) |  Loss2: (0.0000) | Acc: (63.00%) (21855/34688)
Epoch: 11 | Batch_idx: 280 |  Loss: (1.0335) |  Loss2: (0.0000) | Acc: (63.00%) (22677/35968)
Epoch: 11 | Batch_idx: 290 |  Loss: (1.0325) |  Loss2: (0.0000) | Acc: (63.00%) (23504/37248)
Epoch: 11 | Batch_idx: 300 |  Loss: (1.0319) |  Loss2: (0.0000) | Acc: (63.00%) (24309/38528)
Epoch: 11 | Batch_idx: 310 |  Loss: (1.0307) |  Loss2: (0.0000) | Acc: (63.00%) (25156/39808)
Epoch: 11 | Batch_idx: 320 |  Loss: (1.0300) |  Loss2: (0.0000) | Acc: (63.00%) (25974/41088)
Epoch: 11 | Batch_idx: 330 |  Loss: (1.0285) |  Loss2: (0.0000) | Acc: (63.00%) (26787/42368)
Epoch: 11 | Batch_idx: 340 |  Loss: (1.0273) |  Loss2: (0.0000) | Acc: (63.00%) (27632/43648)
Epoch: 11 | Batch_idx: 350 |  Loss: (1.0257) |  Loss2: (0.0000) | Acc: (63.00%) (28457/44928)
Epoch: 11 | Batch_idx: 360 |  Loss: (1.0242) |  Loss2: (0.0000) | Acc: (63.00%) (29292/46208)
Epoch: 11 | Batch_idx: 370 |  Loss: (1.0237) |  Loss2: (0.0000) | Acc: (63.00%) (30116/47488)
Epoch: 11 | Batch_idx: 380 |  Loss: (1.0245) |  Loss2: (0.0000) | Acc: (63.00%) (30904/48768)
Epoch: 11 | Batch_idx: 390 |  Loss: (1.0238) |  Loss2: (0.0000) | Acc: (63.00%) (31705/50000)
# TEST : Loss: (1.0767) | Acc: (61.00%) (6148/10000)
percent tensor([0.4955, 0.5156, 0.4880, 0.5015, 0.4899, 0.4953, 0.5054, 0.5025, 0.5026,
        0.5034, 0.5046, 0.4879, 0.4990, 0.5265, 0.5047, 0.5052],
       device='cuda:0') torch.Size([16])
percent tensor([0.4856, 0.4855, 0.4740, 0.4811, 0.4751, 0.4842, 0.4797, 0.4753, 0.4836,
        0.4836, 0.4865, 0.4763, 0.4864, 0.4884, 0.4823, 0.4837],
       device='cuda:0') torch.Size([16])
percent tensor([0.4948, 0.5105, 0.4920, 0.4945, 0.4934, 0.4959, 0.5032, 0.4977, 0.4946,
        0.5024, 0.4997, 0.4942, 0.4973, 0.5118, 0.5027, 0.4973],
       device='cuda:0') torch.Size([16])
percent tensor([0.5093, 0.4867, 0.5226, 0.5327, 0.5181, 0.5197, 0.4923, 0.5222, 0.5021,
        0.4919, 0.4902, 0.5109, 0.4968, 0.4906, 0.5047, 0.5124],
       device='cuda:0') torch.Size([16])
percent tensor([0.5075, 0.5060, 0.5025, 0.5019, 0.5035, 0.5052, 0.5055, 0.5063, 0.5039,
        0.5062, 0.5049, 0.5020, 0.5068, 0.5028, 0.5079, 0.5084],
       device='cuda:0') torch.Size([16])
percent tensor([0.5235, 0.5173, 0.5344, 0.5340, 0.5297, 0.5263, 0.5233, 0.5359, 0.5241,
        0.5198, 0.5200, 0.5321, 0.5222, 0.5215, 0.5153, 0.5298],
       device='cuda:0') torch.Size([16])
percent tensor([0.5189, 0.5085, 0.5220, 0.5263, 0.5216, 0.5255, 0.5164, 0.5317, 0.5113,
        0.5154, 0.5074, 0.5158, 0.5141, 0.5104, 0.5080, 0.5288],
       device='cuda:0') torch.Size([16])
percent tensor([0.7956, 0.7302, 0.8404, 0.8483, 0.8587, 0.7972, 0.7944, 0.9072, 0.7552,
        0.7870, 0.7743, 0.8102, 0.7591, 0.7586, 0.8224, 0.8433],
       device='cuda:0') torch.Size([16])
Epoch: 12 | Batch_idx: 0 |  Loss: (1.0611) |  Loss2: (0.0000) | Acc: (60.00%) (77/128)
Epoch: 12 | Batch_idx: 10 |  Loss: (0.9523) |  Loss2: (0.0000) | Acc: (66.00%) (939/1408)
Epoch: 12 | Batch_idx: 20 |  Loss: (0.9725) |  Loss2: (0.0000) | Acc: (65.00%) (1762/2688)
Epoch: 12 | Batch_idx: 30 |  Loss: (0.9689) |  Loss2: (0.0000) | Acc: (65.00%) (2603/3968)
Epoch: 12 | Batch_idx: 40 |  Loss: (0.9696) |  Loss2: (0.0000) | Acc: (65.00%) (3444/5248)
Epoch: 12 | Batch_idx: 50 |  Loss: (0.9789) |  Loss2: (0.0000) | Acc: (65.00%) (4262/6528)
Epoch: 12 | Batch_idx: 60 |  Loss: (0.9721) |  Loss2: (0.0000) | Acc: (65.00%) (5119/7808)
Epoch: 12 | Batch_idx: 70 |  Loss: (0.9715) |  Loss2: (0.0000) | Acc: (65.00%) (5977/9088)
Epoch: 12 | Batch_idx: 80 |  Loss: (0.9728) |  Loss2: (0.0000) | Acc: (65.00%) (6818/10368)
Epoch: 12 | Batch_idx: 90 |  Loss: (0.9695) |  Loss2: (0.0000) | Acc: (65.00%) (7678/11648)
Epoch: 12 | Batch_idx: 100 |  Loss: (0.9666) |  Loss2: (0.0000) | Acc: (66.00%) (8541/12928)
Epoch: 12 | Batch_idx: 110 |  Loss: (0.9641) |  Loss2: (0.0000) | Acc: (66.00%) (9408/14208)
Epoch: 12 | Batch_idx: 120 |  Loss: (0.9659) |  Loss2: (0.0000) | Acc: (66.00%) (10243/15488)
Epoch: 12 | Batch_idx: 130 |  Loss: (0.9605) |  Loss2: (0.0000) | Acc: (66.00%) (11142/16768)
Epoch: 12 | Batch_idx: 140 |  Loss: (0.9610) |  Loss2: (0.0000) | Acc: (66.00%) (11982/18048)
Epoch: 12 | Batch_idx: 150 |  Loss: (0.9601) |  Loss2: (0.0000) | Acc: (66.00%) (12820/19328)
Epoch: 12 | Batch_idx: 160 |  Loss: (0.9594) |  Loss2: (0.0000) | Acc: (66.00%) (13679/20608)
Epoch: 12 | Batch_idx: 170 |  Loss: (0.9585) |  Loss2: (0.0000) | Acc: (66.00%) (14536/21888)
Epoch: 12 | Batch_idx: 180 |  Loss: (0.9592) |  Loss2: (0.0000) | Acc: (66.00%) (15368/23168)
Epoch: 12 | Batch_idx: 190 |  Loss: (0.9590) |  Loss2: (0.0000) | Acc: (66.00%) (16206/24448)
Epoch: 12 | Batch_idx: 200 |  Loss: (0.9566) |  Loss2: (0.0000) | Acc: (66.00%) (17063/25728)
Epoch: 12 | Batch_idx: 210 |  Loss: (0.9565) |  Loss2: (0.0000) | Acc: (66.00%) (17909/27008)
Epoch: 12 | Batch_idx: 220 |  Loss: (0.9573) |  Loss2: (0.0000) | Acc: (66.00%) (18742/28288)
Epoch: 12 | Batch_idx: 230 |  Loss: (0.9594) |  Loss2: (0.0000) | Acc: (66.00%) (19554/29568)
Epoch: 12 | Batch_idx: 240 |  Loss: (0.9590) |  Loss2: (0.0000) | Acc: (66.00%) (20413/30848)
Epoch: 12 | Batch_idx: 250 |  Loss: (0.9584) |  Loss2: (0.0000) | Acc: (66.00%) (21262/32128)
Epoch: 12 | Batch_idx: 260 |  Loss: (0.9570) |  Loss2: (0.0000) | Acc: (66.00%) (22139/33408)
Epoch: 12 | Batch_idx: 270 |  Loss: (0.9565) |  Loss2: (0.0000) | Acc: (66.00%) (22979/34688)
Epoch: 12 | Batch_idx: 280 |  Loss: (0.9575) |  Loss2: (0.0000) | Acc: (66.00%) (23808/35968)
Epoch: 12 | Batch_idx: 290 |  Loss: (0.9561) |  Loss2: (0.0000) | Acc: (66.00%) (24678/37248)
Epoch: 12 | Batch_idx: 300 |  Loss: (0.9549) |  Loss2: (0.0000) | Acc: (66.00%) (25552/38528)
Epoch: 12 | Batch_idx: 310 |  Loss: (0.9546) |  Loss2: (0.0000) | Acc: (66.00%) (26382/39808)
Epoch: 12 | Batch_idx: 320 |  Loss: (0.9530) |  Loss2: (0.0000) | Acc: (66.00%) (27267/41088)
Epoch: 12 | Batch_idx: 330 |  Loss: (0.9546) |  Loss2: (0.0000) | Acc: (66.00%) (28085/42368)
Epoch: 12 | Batch_idx: 340 |  Loss: (0.9535) |  Loss2: (0.0000) | Acc: (66.00%) (28927/43648)
Epoch: 12 | Batch_idx: 350 |  Loss: (0.9525) |  Loss2: (0.0000) | Acc: (66.00%) (29794/44928)
Epoch: 12 | Batch_idx: 360 |  Loss: (0.9524) |  Loss2: (0.0000) | Acc: (66.00%) (30653/46208)
Epoch: 12 | Batch_idx: 370 |  Loss: (0.9520) |  Loss2: (0.0000) | Acc: (66.00%) (31529/47488)
Epoch: 12 | Batch_idx: 380 |  Loss: (0.9508) |  Loss2: (0.0000) | Acc: (66.00%) (32390/48768)
Epoch: 12 | Batch_idx: 390 |  Loss: (0.9508) |  Loss2: (0.0000) | Acc: (66.00%) (33206/50000)
# TEST : Loss: (1.0392) | Acc: (63.00%) (6300/10000)
percent tensor([0.4956, 0.5150, 0.4866, 0.5011, 0.4888, 0.4954, 0.5049, 0.5016, 0.5032,
        0.5025, 0.5047, 0.4869, 0.4991, 0.5263, 0.5043, 0.5047],
       device='cuda:0') torch.Size([16])
percent tensor([0.4864, 0.4863, 0.4761, 0.4819, 0.4763, 0.4846, 0.4806, 0.4766, 0.4840,
        0.4847, 0.4865, 0.4773, 0.4867, 0.4887, 0.4829, 0.4843],
       device='cuda:0') torch.Size([16])
percent tensor([0.4943, 0.5104, 0.4911, 0.4941, 0.4930, 0.4960, 0.5035, 0.4964, 0.4944,
        0.5017, 0.4994, 0.4945, 0.4969, 0.5119, 0.5024, 0.4968],
       device='cuda:0') torch.Size([16])
percent tensor([0.5077, 0.4896, 0.5166, 0.5294, 0.5122, 0.5208, 0.4925, 0.5196, 0.5000,
        0.4900, 0.4903, 0.5055, 0.4969, 0.4975, 0.5049, 0.5120],
       device='cuda:0') torch.Size([16])
percent tensor([0.5063, 0.5063, 0.5028, 0.5021, 0.5032, 0.5042, 0.5059, 0.5063, 0.5033,
        0.5054, 0.5030, 0.5021, 0.5063, 0.5033, 0.5076, 0.5084],
       device='cuda:0') torch.Size([16])
percent tensor([0.5227, 0.5179, 0.5283, 0.5296, 0.5244, 0.5269, 0.5214, 0.5350, 0.5219,
        0.5198, 0.5217, 0.5275, 0.5216, 0.5252, 0.5148, 0.5292],
       device='cuda:0') torch.Size([16])
percent tensor([0.5199, 0.5097, 0.5193, 0.5228, 0.5175, 0.5275, 0.5182, 0.5307, 0.5135,
        0.5152, 0.5111, 0.5134, 0.5143, 0.5128, 0.5077, 0.5290],
       device='cuda:0') torch.Size([16])
percent tensor([0.7890, 0.7244, 0.8320, 0.8340, 0.8512, 0.8012, 0.7694, 0.8915, 0.7581,
        0.7957, 0.7622, 0.8233, 0.7560, 0.7742, 0.7868, 0.8329],
       device='cuda:0') torch.Size([16])
Epoch: 13 | Batch_idx: 0 |  Loss: (0.8618) |  Loss2: (0.0000) | Acc: (70.00%) (90/128)
Epoch: 13 | Batch_idx: 10 |  Loss: (0.9693) |  Loss2: (0.0000) | Acc: (64.00%) (914/1408)
Epoch: 13 | Batch_idx: 20 |  Loss: (0.9447) |  Loss2: (0.0000) | Acc: (66.00%) (1776/2688)
Epoch: 13 | Batch_idx: 30 |  Loss: (0.9417) |  Loss2: (0.0000) | Acc: (65.00%) (2613/3968)
Epoch: 13 | Batch_idx: 40 |  Loss: (0.9305) |  Loss2: (0.0000) | Acc: (66.00%) (3473/5248)
Epoch: 13 | Batch_idx: 50 |  Loss: (0.9271) |  Loss2: (0.0000) | Acc: (66.00%) (4342/6528)
Epoch: 13 | Batch_idx: 60 |  Loss: (0.9296) |  Loss2: (0.0000) | Acc: (66.00%) (5202/7808)
Epoch: 13 | Batch_idx: 70 |  Loss: (0.9242) |  Loss2: (0.0000) | Acc: (66.00%) (6072/9088)
Epoch: 13 | Batch_idx: 80 |  Loss: (0.9227) |  Loss2: (0.0000) | Acc: (67.00%) (6949/10368)
Epoch: 13 | Batch_idx: 90 |  Loss: (0.9244) |  Loss2: (0.0000) | Acc: (66.00%) (7788/11648)
Epoch: 13 | Batch_idx: 100 |  Loss: (0.9242) |  Loss2: (0.0000) | Acc: (66.00%) (8622/12928)
Epoch: 13 | Batch_idx: 110 |  Loss: (0.9208) |  Loss2: (0.0000) | Acc: (67.00%) (9524/14208)
Epoch: 13 | Batch_idx: 120 |  Loss: (0.9199) |  Loss2: (0.0000) | Acc: (67.00%) (10389/15488)
Epoch: 13 | Batch_idx: 130 |  Loss: (0.9236) |  Loss2: (0.0000) | Acc: (67.00%) (11246/16768)
Epoch: 13 | Batch_idx: 140 |  Loss: (0.9241) |  Loss2: (0.0000) | Acc: (67.00%) (12118/18048)
Epoch: 13 | Batch_idx: 150 |  Loss: (0.9219) |  Loss2: (0.0000) | Acc: (67.00%) (13004/19328)
Epoch: 13 | Batch_idx: 160 |  Loss: (0.9160) |  Loss2: (0.0000) | Acc: (67.00%) (13909/20608)
Epoch: 13 | Batch_idx: 170 |  Loss: (0.9154) |  Loss2: (0.0000) | Acc: (67.00%) (14774/21888)
Epoch: 13 | Batch_idx: 180 |  Loss: (0.9143) |  Loss2: (0.0000) | Acc: (67.00%) (15638/23168)
Epoch: 13 | Batch_idx: 190 |  Loss: (0.9131) |  Loss2: (0.0000) | Acc: (67.00%) (16513/24448)
Epoch: 13 | Batch_idx: 200 |  Loss: (0.9112) |  Loss2: (0.0000) | Acc: (67.00%) (17390/25728)
Epoch: 13 | Batch_idx: 210 |  Loss: (0.9093) |  Loss2: (0.0000) | Acc: (67.00%) (18274/27008)
Epoch: 13 | Batch_idx: 220 |  Loss: (0.9088) |  Loss2: (0.0000) | Acc: (67.00%) (19141/28288)
Epoch: 13 | Batch_idx: 230 |  Loss: (0.9081) |  Loss2: (0.0000) | Acc: (67.00%) (20023/29568)
Epoch: 13 | Batch_idx: 240 |  Loss: (0.9086) |  Loss2: (0.0000) | Acc: (67.00%) (20862/30848)
Epoch: 13 | Batch_idx: 250 |  Loss: (0.9081) |  Loss2: (0.0000) | Acc: (67.00%) (21733/32128)
Epoch: 13 | Batch_idx: 260 |  Loss: (0.9055) |  Loss2: (0.0000) | Acc: (67.00%) (22639/33408)
Epoch: 13 | Batch_idx: 270 |  Loss: (0.9033) |  Loss2: (0.0000) | Acc: (67.00%) (23529/34688)
Epoch: 13 | Batch_idx: 280 |  Loss: (0.9020) |  Loss2: (0.0000) | Acc: (67.00%) (24425/35968)
Epoch: 13 | Batch_idx: 290 |  Loss: (0.9009) |  Loss2: (0.0000) | Acc: (67.00%) (25298/37248)
Epoch: 13 | Batch_idx: 300 |  Loss: (0.8978) |  Loss2: (0.0000) | Acc: (68.00%) (26212/38528)
Epoch: 13 | Batch_idx: 310 |  Loss: (0.8971) |  Loss2: (0.0000) | Acc: (68.00%) (27092/39808)
Epoch: 13 | Batch_idx: 320 |  Loss: (0.8963) |  Loss2: (0.0000) | Acc: (68.00%) (27972/41088)
Epoch: 13 | Batch_idx: 330 |  Loss: (0.8958) |  Loss2: (0.0000) | Acc: (68.00%) (28856/42368)
Epoch: 13 | Batch_idx: 340 |  Loss: (0.8959) |  Loss2: (0.0000) | Acc: (68.00%) (29735/43648)
Epoch: 13 | Batch_idx: 350 |  Loss: (0.8947) |  Loss2: (0.0000) | Acc: (68.00%) (30628/44928)
Epoch: 13 | Batch_idx: 360 |  Loss: (0.8950) |  Loss2: (0.0000) | Acc: (68.00%) (31511/46208)
Epoch: 13 | Batch_idx: 370 |  Loss: (0.8940) |  Loss2: (0.0000) | Acc: (68.00%) (32412/47488)
Epoch: 13 | Batch_idx: 380 |  Loss: (0.8927) |  Loss2: (0.0000) | Acc: (68.00%) (33303/48768)
Epoch: 13 | Batch_idx: 390 |  Loss: (0.8909) |  Loss2: (0.0000) | Acc: (68.00%) (34184/50000)
# TEST : Loss: (0.9424) | Acc: (67.00%) (6702/10000)
percent tensor([0.4963, 0.5148, 0.4869, 0.5018, 0.4895, 0.4961, 0.5052, 0.5021, 0.5038,
        0.5029, 0.5053, 0.4871, 0.4994, 0.5253, 0.5046, 0.5051],
       device='cuda:0') torch.Size([16])
percent tensor([0.4861, 0.4856, 0.4760, 0.4819, 0.4767, 0.4850, 0.4808, 0.4769, 0.4840,
        0.4847, 0.4861, 0.4784, 0.4860, 0.4879, 0.4829, 0.4841],
       device='cuda:0') torch.Size([16])
percent tensor([0.4955, 0.5117, 0.4918, 0.4941, 0.4935, 0.4974, 0.5046, 0.4959, 0.4949,
        0.5030, 0.5009, 0.4953, 0.4978, 0.5132, 0.5035, 0.4980],
       device='cuda:0') torch.Size([16])
percent tensor([0.5097, 0.4871, 0.5223, 0.5293, 0.5174, 0.5219, 0.4911, 0.5221, 0.5046,
        0.4908, 0.4905, 0.5082, 0.4974, 0.4911, 0.5047, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5067, 0.5066, 0.5014, 0.5013, 0.5019, 0.5052, 0.5051, 0.5050, 0.5027,
        0.5061, 0.5042, 0.5020, 0.5067, 0.5027, 0.5081, 0.5087],
       device='cuda:0') torch.Size([16])
percent tensor([0.5248, 0.5163, 0.5334, 0.5351, 0.5274, 0.5319, 0.5206, 0.5354, 0.5246,
        0.5193, 0.5194, 0.5288, 0.5211, 0.5217, 0.5161, 0.5281],
       device='cuda:0') torch.Size([16])
percent tensor([0.5198, 0.5061, 0.5239, 0.5267, 0.5204, 0.5291, 0.5187, 0.5316, 0.5139,
        0.5144, 0.5080, 0.5174, 0.5127, 0.5092, 0.5074, 0.5263],
       device='cuda:0') torch.Size([16])
percent tensor([0.8082, 0.7416, 0.8591, 0.8486, 0.8627, 0.8114, 0.8064, 0.9121, 0.7633,
        0.7902, 0.7724, 0.8205, 0.7646, 0.7622, 0.8198, 0.8351],
       device='cuda:0') torch.Size([16])
Epoch: 14 | Batch_idx: 0 |  Loss: (0.8389) |  Loss2: (0.0000) | Acc: (64.00%) (83/128)
Epoch: 14 | Batch_idx: 10 |  Loss: (0.7865) |  Loss2: (0.0000) | Acc: (71.00%) (1013/1408)
Epoch: 14 | Batch_idx: 20 |  Loss: (0.8268) |  Loss2: (0.0000) | Acc: (70.00%) (1893/2688)
Epoch: 14 | Batch_idx: 30 |  Loss: (0.8395) |  Loss2: (0.0000) | Acc: (70.00%) (2786/3968)
Epoch: 14 | Batch_idx: 40 |  Loss: (0.8448) |  Loss2: (0.0000) | Acc: (69.00%) (3672/5248)
Epoch: 14 | Batch_idx: 50 |  Loss: (0.8376) |  Loss2: (0.0000) | Acc: (70.00%) (4597/6528)
Epoch: 14 | Batch_idx: 60 |  Loss: (0.8460) |  Loss2: (0.0000) | Acc: (70.00%) (5469/7808)
Epoch: 14 | Batch_idx: 70 |  Loss: (0.8447) |  Loss2: (0.0000) | Acc: (69.00%) (6361/9088)
Epoch: 14 | Batch_idx: 80 |  Loss: (0.8492) |  Loss2: (0.0000) | Acc: (69.00%) (7239/10368)
Epoch: 14 | Batch_idx: 90 |  Loss: (0.8454) |  Loss2: (0.0000) | Acc: (69.00%) (8152/11648)
Epoch: 14 | Batch_idx: 100 |  Loss: (0.8475) |  Loss2: (0.0000) | Acc: (69.00%) (9036/12928)
Epoch: 14 | Batch_idx: 110 |  Loss: (0.8456) |  Loss2: (0.0000) | Acc: (69.00%) (9935/14208)
Epoch: 14 | Batch_idx: 120 |  Loss: (0.8439) |  Loss2: (0.0000) | Acc: (70.00%) (10846/15488)
Epoch: 14 | Batch_idx: 130 |  Loss: (0.8459) |  Loss2: (0.0000) | Acc: (69.00%) (11735/16768)
Epoch: 14 | Batch_idx: 140 |  Loss: (0.8455) |  Loss2: (0.0000) | Acc: (69.00%) (12622/18048)
Epoch: 14 | Batch_idx: 150 |  Loss: (0.8479) |  Loss2: (0.0000) | Acc: (69.00%) (13515/19328)
Epoch: 14 | Batch_idx: 160 |  Loss: (0.8480) |  Loss2: (0.0000) | Acc: (69.00%) (14418/20608)
Epoch: 14 | Batch_idx: 170 |  Loss: (0.8492) |  Loss2: (0.0000) | Acc: (69.00%) (15308/21888)
Epoch: 14 | Batch_idx: 180 |  Loss: (0.8481) |  Loss2: (0.0000) | Acc: (70.00%) (16222/23168)
Epoch: 14 | Batch_idx: 190 |  Loss: (0.8464) |  Loss2: (0.0000) | Acc: (70.00%) (17138/24448)
Epoch: 14 | Batch_idx: 200 |  Loss: (0.8471) |  Loss2: (0.0000) | Acc: (70.00%) (18030/25728)
Epoch: 14 | Batch_idx: 210 |  Loss: (0.8460) |  Loss2: (0.0000) | Acc: (70.00%) (18937/27008)
Epoch: 14 | Batch_idx: 220 |  Loss: (0.8447) |  Loss2: (0.0000) | Acc: (70.00%) (19845/28288)
Epoch: 14 | Batch_idx: 230 |  Loss: (0.8455) |  Loss2: (0.0000) | Acc: (70.00%) (20748/29568)
Epoch: 14 | Batch_idx: 240 |  Loss: (0.8452) |  Loss2: (0.0000) | Acc: (70.00%) (21641/30848)
Epoch: 14 | Batch_idx: 250 |  Loss: (0.8441) |  Loss2: (0.0000) | Acc: (70.00%) (22532/32128)
Epoch: 14 | Batch_idx: 260 |  Loss: (0.8450) |  Loss2: (0.0000) | Acc: (70.00%) (23412/33408)
Epoch: 14 | Batch_idx: 270 |  Loss: (0.8452) |  Loss2: (0.0000) | Acc: (70.00%) (24301/34688)
Epoch: 14 | Batch_idx: 280 |  Loss: (0.8452) |  Loss2: (0.0000) | Acc: (70.00%) (25195/35968)
Epoch: 14 | Batch_idx: 290 |  Loss: (0.8459) |  Loss2: (0.0000) | Acc: (70.00%) (26093/37248)
Epoch: 14 | Batch_idx: 300 |  Loss: (0.8463) |  Loss2: (0.0000) | Acc: (70.00%) (26987/38528)
Epoch: 14 | Batch_idx: 310 |  Loss: (0.8462) |  Loss2: (0.0000) | Acc: (70.00%) (27891/39808)
Epoch: 14 | Batch_idx: 320 |  Loss: (0.8461) |  Loss2: (0.0000) | Acc: (70.00%) (28790/41088)
Epoch: 14 | Batch_idx: 330 |  Loss: (0.8447) |  Loss2: (0.0000) | Acc: (70.00%) (29712/42368)
Epoch: 14 | Batch_idx: 340 |  Loss: (0.8435) |  Loss2: (0.0000) | Acc: (70.00%) (30613/43648)
Epoch: 14 | Batch_idx: 350 |  Loss: (0.8416) |  Loss2: (0.0000) | Acc: (70.00%) (31535/44928)
Epoch: 14 | Batch_idx: 360 |  Loss: (0.8409) |  Loss2: (0.0000) | Acc: (70.00%) (32472/46208)
Epoch: 14 | Batch_idx: 370 |  Loss: (0.8406) |  Loss2: (0.0000) | Acc: (70.00%) (33372/47488)
Epoch: 14 | Batch_idx: 380 |  Loss: (0.8399) |  Loss2: (0.0000) | Acc: (70.00%) (34275/48768)
Epoch: 14 | Batch_idx: 390 |  Loss: (0.8393) |  Loss2: (0.0000) | Acc: (70.00%) (35143/50000)
# TEST : Loss: (0.9110) | Acc: (67.00%) (6732/10000)
percent tensor([0.4942, 0.5131, 0.4861, 0.5001, 0.4883, 0.4945, 0.5038, 0.5008, 0.5017,
        0.5014, 0.5035, 0.4862, 0.4975, 0.5233, 0.5029, 0.5033],
       device='cuda:0') torch.Size([16])
percent tensor([0.4862, 0.4851, 0.4760, 0.4803, 0.4766, 0.4856, 0.4808, 0.4766, 0.4847,
        0.4842, 0.4866, 0.4785, 0.4859, 0.4879, 0.4823, 0.4839],
       device='cuda:0') torch.Size([16])
percent tensor([0.4952, 0.5097, 0.4920, 0.4938, 0.4938, 0.4967, 0.5041, 0.4955, 0.4940,
        0.5023, 0.4997, 0.4964, 0.4973, 0.5123, 0.5023, 0.4974],
       device='cuda:0') torch.Size([16])
percent tensor([0.5074, 0.4856, 0.5228, 0.5306, 0.5178, 0.5190, 0.4912, 0.5222, 0.5041,
        0.4897, 0.4886, 0.5086, 0.4966, 0.4924, 0.5024, 0.5114],
       device='cuda:0') torch.Size([16])
percent tensor([0.5061, 0.5052, 0.5018, 0.5010, 0.5026, 0.5050, 0.5044, 0.5044, 0.5029,
        0.5050, 0.5028, 0.5019, 0.5063, 0.5024, 0.5073, 0.5074],
       device='cuda:0') torch.Size([16])
percent tensor([0.5245, 0.5193, 0.5332, 0.5352, 0.5282, 0.5290, 0.5221, 0.5360, 0.5252,
        0.5214, 0.5238, 0.5284, 0.5209, 0.5251, 0.5176, 0.5270],
       device='cuda:0') torch.Size([16])
percent tensor([0.5205, 0.5102, 0.5235, 0.5257, 0.5208, 0.5301, 0.5199, 0.5315, 0.5138,
        0.5153, 0.5115, 0.5160, 0.5125, 0.5124, 0.5088, 0.5270],
       device='cuda:0') torch.Size([16])
percent tensor([0.7907, 0.7596, 0.8693, 0.8487, 0.8509, 0.7944, 0.7971, 0.8996, 0.7673,
        0.8053, 0.8052, 0.8357, 0.7685, 0.7790, 0.7872, 0.8131],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 15 | Batch_idx: 0 |  Loss: (0.8598) |  Loss2: (0.0000) | Acc: (67.00%) (87/128)
Epoch: 15 | Batch_idx: 10 |  Loss: (0.8731) |  Loss2: (0.0000) | Acc: (68.00%) (966/1408)
Epoch: 15 | Batch_idx: 20 |  Loss: (0.8982) |  Loss2: (0.0000) | Acc: (68.00%) (1831/2688)
Epoch: 15 | Batch_idx: 30 |  Loss: (0.9338) |  Loss2: (0.0000) | Acc: (66.00%) (2648/3968)
Epoch: 15 | Batch_idx: 40 |  Loss: (0.9569) |  Loss2: (0.0000) | Acc: (65.00%) (3439/5248)
Epoch: 15 | Batch_idx: 50 |  Loss: (0.9784) |  Loss2: (0.0000) | Acc: (64.00%) (4229/6528)
Epoch: 15 | Batch_idx: 60 |  Loss: (0.9779) |  Loss2: (0.0000) | Acc: (64.00%) (5059/7808)
Epoch: 15 | Batch_idx: 70 |  Loss: (0.9706) |  Loss2: (0.0000) | Acc: (64.00%) (5905/9088)
Epoch: 15 | Batch_idx: 80 |  Loss: (0.9743) |  Loss2: (0.0000) | Acc: (64.00%) (6732/10368)
Epoch: 15 | Batch_idx: 90 |  Loss: (0.9784) |  Loss2: (0.0000) | Acc: (64.00%) (7543/11648)
Epoch: 15 | Batch_idx: 100 |  Loss: (0.9789) |  Loss2: (0.0000) | Acc: (64.00%) (8362/12928)
Epoch: 15 | Batch_idx: 110 |  Loss: (0.9790) |  Loss2: (0.0000) | Acc: (64.00%) (9198/14208)
Epoch: 15 | Batch_idx: 120 |  Loss: (0.9768) |  Loss2: (0.0000) | Acc: (64.00%) (10056/15488)
Epoch: 15 | Batch_idx: 130 |  Loss: (0.9739) |  Loss2: (0.0000) | Acc: (65.00%) (10915/16768)
Epoch: 15 | Batch_idx: 140 |  Loss: (0.9684) |  Loss2: (0.0000) | Acc: (65.00%) (11797/18048)
Epoch: 15 | Batch_idx: 150 |  Loss: (0.9630) |  Loss2: (0.0000) | Acc: (65.00%) (12683/19328)
Epoch: 15 | Batch_idx: 160 |  Loss: (0.9602) |  Loss2: (0.0000) | Acc: (65.00%) (13554/20608)
Epoch: 15 | Batch_idx: 170 |  Loss: (0.9554) |  Loss2: (0.0000) | Acc: (65.00%) (14431/21888)
Epoch: 15 | Batch_idx: 180 |  Loss: (0.9528) |  Loss2: (0.0000) | Acc: (66.00%) (15315/23168)
Epoch: 15 | Batch_idx: 190 |  Loss: (0.9527) |  Loss2: (0.0000) | Acc: (66.00%) (16156/24448)
Epoch: 15 | Batch_idx: 200 |  Loss: (0.9486) |  Loss2: (0.0000) | Acc: (66.00%) (17041/25728)
Epoch: 15 | Batch_idx: 210 |  Loss: (0.9471) |  Loss2: (0.0000) | Acc: (66.00%) (17902/27008)
Epoch: 15 | Batch_idx: 220 |  Loss: (0.9461) |  Loss2: (0.0000) | Acc: (66.00%) (18769/28288)
Epoch: 15 | Batch_idx: 230 |  Loss: (0.9421) |  Loss2: (0.0000) | Acc: (66.00%) (19666/29568)
Epoch: 15 | Batch_idx: 240 |  Loss: (0.9403) |  Loss2: (0.0000) | Acc: (66.00%) (20529/30848)
Epoch: 15 | Batch_idx: 250 |  Loss: (0.9396) |  Loss2: (0.0000) | Acc: (66.00%) (21385/32128)
Epoch: 15 | Batch_idx: 260 |  Loss: (0.9400) |  Loss2: (0.0000) | Acc: (66.00%) (22219/33408)
Epoch: 15 | Batch_idx: 270 |  Loss: (0.9361) |  Loss2: (0.0000) | Acc: (66.00%) (23112/34688)
Epoch: 15 | Batch_idx: 280 |  Loss: (0.9326) |  Loss2: (0.0000) | Acc: (66.00%) (24006/35968)
Epoch: 15 | Batch_idx: 290 |  Loss: (0.9313) |  Loss2: (0.0000) | Acc: (66.00%) (24883/37248)
Epoch: 15 | Batch_idx: 300 |  Loss: (0.9308) |  Loss2: (0.0000) | Acc: (66.00%) (25750/38528)
Epoch: 15 | Batch_idx: 310 |  Loss: (0.9289) |  Loss2: (0.0000) | Acc: (66.00%) (26628/39808)
Epoch: 15 | Batch_idx: 320 |  Loss: (0.9267) |  Loss2: (0.0000) | Acc: (66.00%) (27512/41088)
Epoch: 15 | Batch_idx: 330 |  Loss: (0.9249) |  Loss2: (0.0000) | Acc: (67.00%) (28395/42368)
Epoch: 15 | Batch_idx: 340 |  Loss: (0.9238) |  Loss2: (0.0000) | Acc: (67.00%) (29260/43648)
Epoch: 15 | Batch_idx: 350 |  Loss: (0.9210) |  Loss2: (0.0000) | Acc: (67.00%) (30166/44928)
Epoch: 15 | Batch_idx: 360 |  Loss: (0.9186) |  Loss2: (0.0000) | Acc: (67.00%) (31060/46208)
Epoch: 15 | Batch_idx: 370 |  Loss: (0.9174) |  Loss2: (0.0000) | Acc: (67.00%) (31934/47488)
Epoch: 15 | Batch_idx: 380 |  Loss: (0.9157) |  Loss2: (0.0000) | Acc: (67.00%) (32831/48768)
Epoch: 15 | Batch_idx: 390 |  Loss: (0.9141) |  Loss2: (0.0000) | Acc: (67.00%) (33706/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_015.pth.tar'
# TEST : Loss: (0.8711) | Acc: (69.00%) (6917/10000)
percent tensor([0.5101, 0.5283, 0.5051, 0.5153, 0.5097, 0.5090, 0.5223, 0.5190, 0.5186,
        0.5190, 0.5191, 0.5073, 0.5126, 0.5365, 0.5182, 0.5178],
       device='cuda:0') torch.Size([16])
percent tensor([0.4788, 0.4760, 0.4619, 0.4690, 0.4632, 0.4766, 0.4694, 0.4643, 0.4746,
        0.4746, 0.4779, 0.4666, 0.4777, 0.4791, 0.4729, 0.4749],
       device='cuda:0') torch.Size([16])
percent tensor([0.5033, 0.5241, 0.4994, 0.5016, 0.5041, 0.5036, 0.5197, 0.5074, 0.5050,
        0.5170, 0.5115, 0.5090, 0.5059, 0.5283, 0.5130, 0.5053],
       device='cuda:0') torch.Size([16])
percent tensor([0.5206, 0.5090, 0.5288, 0.5398, 0.5306, 0.5313, 0.5154, 0.5346, 0.5189,
        0.5096, 0.5082, 0.5193, 0.5108, 0.5158, 0.5210, 0.5257],
       device='cuda:0') torch.Size([16])
percent tensor([0.4986, 0.5011, 0.4915, 0.4891, 0.4914, 0.4929, 0.4979, 0.4927, 0.4977,
        0.5005, 0.5005, 0.4953, 0.5022, 0.4989, 0.4982, 0.4995],
       device='cuda:0') torch.Size([16])
percent tensor([0.5363, 0.5362, 0.5539, 0.5623, 0.5495, 0.5363, 0.5411, 0.5654, 0.5448,
        0.5419, 0.5425, 0.5531, 0.5333, 0.5487, 0.5332, 0.5381],
       device='cuda:0') torch.Size([16])
percent tensor([0.5103, 0.5046, 0.5158, 0.5202, 0.5156, 0.5088, 0.5158, 0.5282, 0.5092,
        0.5110, 0.5056, 0.5127, 0.5039, 0.5102, 0.5020, 0.5153],
       device='cuda:0') torch.Size([16])
percent tensor([0.8403, 0.8166, 0.9153, 0.8953, 0.9025, 0.8588, 0.8405, 0.9434, 0.8442,
        0.8604, 0.8499, 0.8965, 0.8359, 0.8359, 0.8398, 0.8777],
       device='cuda:0') torch.Size([16])
Epoch: 16 | Batch_idx: 0 |  Loss: (0.7377) |  Loss2: (0.0000) | Acc: (74.00%) (95/128)
Epoch: 16 | Batch_idx: 10 |  Loss: (0.8602) |  Loss2: (0.0000) | Acc: (69.00%) (972/1408)
Epoch: 16 | Batch_idx: 20 |  Loss: (0.8525) |  Loss2: (0.0000) | Acc: (69.00%) (1860/2688)
Epoch: 16 | Batch_idx: 30 |  Loss: (0.8408) |  Loss2: (0.0000) | Acc: (70.00%) (2779/3968)
Epoch: 16 | Batch_idx: 40 |  Loss: (0.8333) |  Loss2: (0.0000) | Acc: (70.00%) (3683/5248)
Epoch: 16 | Batch_idx: 50 |  Loss: (0.8463) |  Loss2: (0.0000) | Acc: (69.00%) (4550/6528)
Epoch: 16 | Batch_idx: 60 |  Loss: (0.8469) |  Loss2: (0.0000) | Acc: (69.00%) (5438/7808)
Epoch: 16 | Batch_idx: 70 |  Loss: (0.8380) |  Loss2: (0.0000) | Acc: (70.00%) (6383/9088)
Epoch: 16 | Batch_idx: 80 |  Loss: (0.8392) |  Loss2: (0.0000) | Acc: (70.00%) (7279/10368)
Epoch: 16 | Batch_idx: 90 |  Loss: (0.8360) |  Loss2: (0.0000) | Acc: (70.00%) (8189/11648)
Epoch: 16 | Batch_idx: 100 |  Loss: (0.8363) |  Loss2: (0.0000) | Acc: (70.00%) (9089/12928)
Epoch: 16 | Batch_idx: 110 |  Loss: (0.8346) |  Loss2: (0.0000) | Acc: (70.00%) (9986/14208)
Epoch: 16 | Batch_idx: 120 |  Loss: (0.8362) |  Loss2: (0.0000) | Acc: (70.00%) (10862/15488)
Epoch: 16 | Batch_idx: 130 |  Loss: (0.8351) |  Loss2: (0.0000) | Acc: (70.00%) (11763/16768)
Epoch: 16 | Batch_idx: 140 |  Loss: (0.8332) |  Loss2: (0.0000) | Acc: (70.00%) (12679/18048)
Epoch: 16 | Batch_idx: 150 |  Loss: (0.8346) |  Loss2: (0.0000) | Acc: (70.00%) (13563/19328)
Epoch: 16 | Batch_idx: 160 |  Loss: (0.8361) |  Loss2: (0.0000) | Acc: (70.00%) (14458/20608)
Epoch: 16 | Batch_idx: 170 |  Loss: (0.8360) |  Loss2: (0.0000) | Acc: (70.00%) (15370/21888)
Epoch: 16 | Batch_idx: 180 |  Loss: (0.8402) |  Loss2: (0.0000) | Acc: (70.00%) (16230/23168)
Epoch: 16 | Batch_idx: 190 |  Loss: (0.8408) |  Loss2: (0.0000) | Acc: (70.00%) (17122/24448)
Epoch: 16 | Batch_idx: 200 |  Loss: (0.8394) |  Loss2: (0.0000) | Acc: (70.00%) (18037/25728)
Epoch: 16 | Batch_idx: 210 |  Loss: (0.8364) |  Loss2: (0.0000) | Acc: (70.00%) (18968/27008)
Epoch: 16 | Batch_idx: 220 |  Loss: (0.8338) |  Loss2: (0.0000) | Acc: (70.00%) (19888/28288)
Epoch: 16 | Batch_idx: 230 |  Loss: (0.8352) |  Loss2: (0.0000) | Acc: (70.00%) (20794/29568)
Epoch: 16 | Batch_idx: 240 |  Loss: (0.8349) |  Loss2: (0.0000) | Acc: (70.00%) (21697/30848)
Epoch: 16 | Batch_idx: 250 |  Loss: (0.8341) |  Loss2: (0.0000) | Acc: (70.00%) (22601/32128)
Epoch: 16 | Batch_idx: 260 |  Loss: (0.8333) |  Loss2: (0.0000) | Acc: (70.00%) (23508/33408)
Epoch: 16 | Batch_idx: 270 |  Loss: (0.8332) |  Loss2: (0.0000) | Acc: (70.00%) (24405/34688)
Epoch: 16 | Batch_idx: 280 |  Loss: (0.8340) |  Loss2: (0.0000) | Acc: (70.00%) (25283/35968)
Epoch: 16 | Batch_idx: 290 |  Loss: (0.8362) |  Loss2: (0.0000) | Acc: (70.00%) (26150/37248)
Epoch: 16 | Batch_idx: 300 |  Loss: (0.8358) |  Loss2: (0.0000) | Acc: (70.00%) (27053/38528)
Epoch: 16 | Batch_idx: 310 |  Loss: (0.8358) |  Loss2: (0.0000) | Acc: (70.00%) (27945/39808)
Epoch: 16 | Batch_idx: 320 |  Loss: (0.8346) |  Loss2: (0.0000) | Acc: (70.00%) (28855/41088)
Epoch: 16 | Batch_idx: 330 |  Loss: (0.8346) |  Loss2: (0.0000) | Acc: (70.00%) (29765/42368)
Epoch: 16 | Batch_idx: 340 |  Loss: (0.8348) |  Loss2: (0.0000) | Acc: (70.00%) (30648/43648)
Epoch: 16 | Batch_idx: 350 |  Loss: (0.8335) |  Loss2: (0.0000) | Acc: (70.00%) (31567/44928)
Epoch: 16 | Batch_idx: 360 |  Loss: (0.8334) |  Loss2: (0.0000) | Acc: (70.00%) (32456/46208)
Epoch: 16 | Batch_idx: 370 |  Loss: (0.8334) |  Loss2: (0.0000) | Acc: (70.00%) (33350/47488)
Epoch: 16 | Batch_idx: 380 |  Loss: (0.8331) |  Loss2: (0.0000) | Acc: (70.00%) (34256/48768)
Epoch: 16 | Batch_idx: 390 |  Loss: (0.8328) |  Loss2: (0.0000) | Acc: (70.00%) (35127/50000)
# TEST : Loss: (0.8436) | Acc: (70.00%) (7024/10000)
percent tensor([0.5080, 0.5253, 0.5040, 0.5138, 0.5082, 0.5069, 0.5198, 0.5170, 0.5161,
        0.5166, 0.5164, 0.5061, 0.5104, 0.5334, 0.5158, 0.5154],
       device='cuda:0') torch.Size([16])
percent tensor([0.4813, 0.4792, 0.4625, 0.4697, 0.4648, 0.4792, 0.4723, 0.4659, 0.4774,
        0.4770, 0.4811, 0.4684, 0.4802, 0.4820, 0.4755, 0.4772],
       device='cuda:0') torch.Size([16])
percent tensor([0.5163, 0.5393, 0.5087, 0.5140, 0.5186, 0.5150, 0.5356, 0.5224, 0.5180,
        0.5320, 0.5254, 0.5222, 0.5171, 0.5456, 0.5273, 0.5181],
       device='cuda:0') torch.Size([16])
percent tensor([0.5241, 0.5140, 0.5297, 0.5411, 0.5330, 0.5343, 0.5213, 0.5369, 0.5219,
        0.5138, 0.5123, 0.5219, 0.5136, 0.5200, 0.5261, 0.5290],
       device='cuda:0') torch.Size([16])
percent tensor([0.4978, 0.5013, 0.4864, 0.4842, 0.4860, 0.4910, 0.4963, 0.4879, 0.4968,
        0.5003, 0.5016, 0.4926, 0.5031, 0.4992, 0.4970, 0.4983],
       device='cuda:0') torch.Size([16])
percent tensor([0.5467, 0.5488, 0.5721, 0.5825, 0.5650, 0.5399, 0.5551, 0.5846, 0.5619,
        0.5557, 0.5581, 0.5732, 0.5446, 0.5653, 0.5444, 0.5460],
       device='cuda:0') torch.Size([16])
percent tensor([0.5076, 0.5034, 0.5251, 0.5284, 0.5242, 0.5029, 0.5178, 0.5405, 0.5121,
        0.5137, 0.5052, 0.5195, 0.5019, 0.5098, 0.5025, 0.5129],
       device='cuda:0') torch.Size([16])
percent tensor([0.8852, 0.8623, 0.9463, 0.9315, 0.9413, 0.8961, 0.8853, 0.9705, 0.8914,
        0.9056, 0.8963, 0.9330, 0.8859, 0.8766, 0.8863, 0.9161],
       device='cuda:0') torch.Size([16])
Epoch: 17 | Batch_idx: 0 |  Loss: (0.8884) |  Loss2: (0.0000) | Acc: (61.00%) (79/128)
Epoch: 17 | Batch_idx: 10 |  Loss: (0.7682) |  Loss2: (0.0000) | Acc: (72.00%) (1019/1408)
Epoch: 17 | Batch_idx: 20 |  Loss: (0.8075) |  Loss2: (0.0000) | Acc: (71.00%) (1919/2688)
Epoch: 17 | Batch_idx: 30 |  Loss: (0.8052) |  Loss2: (0.0000) | Acc: (71.00%) (2833/3968)
Epoch: 17 | Batch_idx: 40 |  Loss: (0.7998) |  Loss2: (0.0000) | Acc: (71.00%) (3750/5248)
Epoch: 17 | Batch_idx: 50 |  Loss: (0.7943) |  Loss2: (0.0000) | Acc: (71.00%) (4670/6528)
Epoch: 17 | Batch_idx: 60 |  Loss: (0.8005) |  Loss2: (0.0000) | Acc: (71.00%) (5550/7808)
Epoch: 17 | Batch_idx: 70 |  Loss: (0.7995) |  Loss2: (0.0000) | Acc: (71.00%) (6457/9088)
Epoch: 17 | Batch_idx: 80 |  Loss: (0.8042) |  Loss2: (0.0000) | Acc: (70.00%) (7345/10368)
Epoch: 17 | Batch_idx: 90 |  Loss: (0.8092) |  Loss2: (0.0000) | Acc: (70.00%) (8251/11648)
Epoch: 17 | Batch_idx: 100 |  Loss: (0.8093) |  Loss2: (0.0000) | Acc: (70.00%) (9162/12928)
Epoch: 17 | Batch_idx: 110 |  Loss: (0.8072) |  Loss2: (0.0000) | Acc: (70.00%) (10072/14208)
Epoch: 17 | Batch_idx: 120 |  Loss: (0.8053) |  Loss2: (0.0000) | Acc: (71.00%) (11001/15488)
Epoch: 17 | Batch_idx: 130 |  Loss: (0.8043) |  Loss2: (0.0000) | Acc: (71.00%) (11914/16768)
Epoch: 17 | Batch_idx: 140 |  Loss: (0.8070) |  Loss2: (0.0000) | Acc: (71.00%) (12817/18048)
Epoch: 17 | Batch_idx: 150 |  Loss: (0.8084) |  Loss2: (0.0000) | Acc: (70.00%) (13711/19328)
Epoch: 17 | Batch_idx: 160 |  Loss: (0.8104) |  Loss2: (0.0000) | Acc: (70.00%) (14601/20608)
Epoch: 17 | Batch_idx: 170 |  Loss: (0.8087) |  Loss2: (0.0000) | Acc: (70.00%) (15536/21888)
Epoch: 17 | Batch_idx: 180 |  Loss: (0.8090) |  Loss2: (0.0000) | Acc: (71.00%) (16452/23168)
Epoch: 17 | Batch_idx: 190 |  Loss: (0.8111) |  Loss2: (0.0000) | Acc: (70.00%) (17336/24448)
Epoch: 17 | Batch_idx: 200 |  Loss: (0.8113) |  Loss2: (0.0000) | Acc: (70.00%) (18246/25728)
Epoch: 17 | Batch_idx: 210 |  Loss: (0.8106) |  Loss2: (0.0000) | Acc: (70.00%) (19167/27008)
Epoch: 17 | Batch_idx: 220 |  Loss: (0.8118) |  Loss2: (0.0000) | Acc: (70.00%) (20058/28288)
Epoch: 17 | Batch_idx: 230 |  Loss: (0.8127) |  Loss2: (0.0000) | Acc: (70.00%) (20954/29568)
Epoch: 17 | Batch_idx: 240 |  Loss: (0.8133) |  Loss2: (0.0000) | Acc: (70.00%) (21868/30848)
Epoch: 17 | Batch_idx: 250 |  Loss: (0.8134) |  Loss2: (0.0000) | Acc: (70.00%) (22774/32128)
Epoch: 17 | Batch_idx: 260 |  Loss: (0.8146) |  Loss2: (0.0000) | Acc: (70.00%) (23672/33408)
Epoch: 17 | Batch_idx: 270 |  Loss: (0.8143) |  Loss2: (0.0000) | Acc: (70.00%) (24584/34688)
Epoch: 17 | Batch_idx: 280 |  Loss: (0.8132) |  Loss2: (0.0000) | Acc: (70.00%) (25518/35968)
Epoch: 17 | Batch_idx: 290 |  Loss: (0.8148) |  Loss2: (0.0000) | Acc: (70.00%) (26422/37248)
Epoch: 17 | Batch_idx: 300 |  Loss: (0.8146) |  Loss2: (0.0000) | Acc: (70.00%) (27322/38528)
Epoch: 17 | Batch_idx: 310 |  Loss: (0.8138) |  Loss2: (0.0000) | Acc: (70.00%) (28248/39808)
Epoch: 17 | Batch_idx: 320 |  Loss: (0.8149) |  Loss2: (0.0000) | Acc: (70.00%) (29138/41088)
Epoch: 17 | Batch_idx: 330 |  Loss: (0.8157) |  Loss2: (0.0000) | Acc: (70.00%) (30044/42368)
Epoch: 17 | Batch_idx: 340 |  Loss: (0.8146) |  Loss2: (0.0000) | Acc: (70.00%) (30988/43648)
Epoch: 17 | Batch_idx: 350 |  Loss: (0.8145) |  Loss2: (0.0000) | Acc: (71.00%) (31912/44928)
Epoch: 17 | Batch_idx: 360 |  Loss: (0.8145) |  Loss2: (0.0000) | Acc: (71.00%) (32829/46208)
Epoch: 17 | Batch_idx: 370 |  Loss: (0.8133) |  Loss2: (0.0000) | Acc: (71.00%) (33759/47488)
Epoch: 17 | Batch_idx: 380 |  Loss: (0.8130) |  Loss2: (0.0000) | Acc: (71.00%) (34671/48768)
Epoch: 17 | Batch_idx: 390 |  Loss: (0.8123) |  Loss2: (0.0000) | Acc: (71.00%) (35555/50000)
# TEST : Loss: (0.8267) | Acc: (70.00%) (7069/10000)
percent tensor([0.5054, 0.5213, 0.5017, 0.5111, 0.5053, 0.5043, 0.5160, 0.5137, 0.5130,
        0.5133, 0.5132, 0.5034, 0.5076, 0.5294, 0.5126, 0.5124],
       device='cuda:0') torch.Size([16])
percent tensor([0.4835, 0.4820, 0.4635, 0.4703, 0.4664, 0.4809, 0.4751, 0.4676, 0.4798,
        0.4792, 0.4839, 0.4704, 0.4825, 0.4842, 0.4777, 0.4790],
       device='cuda:0') torch.Size([16])
percent tensor([0.5220, 0.5429, 0.5142, 0.5222, 0.5249, 0.5210, 0.5406, 0.5292, 0.5233,
        0.5359, 0.5296, 0.5273, 0.5204, 0.5515, 0.5328, 0.5235],
       device='cuda:0') torch.Size([16])
percent tensor([0.5252, 0.5145, 0.5284, 0.5403, 0.5325, 0.5355, 0.5224, 0.5361, 0.5220,
        0.5138, 0.5127, 0.5211, 0.5135, 0.5205, 0.5274, 0.5295],
       device='cuda:0') torch.Size([16])
percent tensor([0.4979, 0.5022, 0.4823, 0.4805, 0.4816, 0.4908, 0.4954, 0.4841, 0.4964,
        0.5007, 0.5031, 0.4904, 0.5046, 0.5000, 0.4965, 0.4980],
       device='cuda:0') torch.Size([16])
percent tensor([0.5532, 0.5562, 0.5845, 0.5979, 0.5751, 0.5438, 0.5624, 0.5970, 0.5751,
        0.5635, 0.5680, 0.5864, 0.5517, 0.5772, 0.5503, 0.5495],
       device='cuda:0') torch.Size([16])
percent tensor([0.5074, 0.5042, 0.5390, 0.5414, 0.5369, 0.5018, 0.5210, 0.5592, 0.5185,
        0.5185, 0.5077, 0.5292, 0.5025, 0.5112, 0.5053, 0.5125],
       device='cuda:0') torch.Size([16])
percent tensor([0.9045, 0.8855, 0.9614, 0.9482, 0.9579, 0.9175, 0.9058, 0.9818, 0.9138,
        0.9246, 0.9167, 0.9466, 0.9088, 0.8971, 0.9094, 0.9324],
       device='cuda:0') torch.Size([16])
Epoch: 18 | Batch_idx: 0 |  Loss: (0.8795) |  Loss2: (0.0000) | Acc: (66.00%) (85/128)
Epoch: 18 | Batch_idx: 10 |  Loss: (0.8481) |  Loss2: (0.0000) | Acc: (69.00%) (979/1408)
Epoch: 18 | Batch_idx: 20 |  Loss: (0.8305) |  Loss2: (0.0000) | Acc: (70.00%) (1882/2688)
Epoch: 18 | Batch_idx: 30 |  Loss: (0.8214) |  Loss2: (0.0000) | Acc: (70.00%) (2793/3968)
Epoch: 18 | Batch_idx: 40 |  Loss: (0.8192) |  Loss2: (0.0000) | Acc: (70.00%) (3702/5248)
Epoch: 18 | Batch_idx: 50 |  Loss: (0.8177) |  Loss2: (0.0000) | Acc: (70.00%) (4625/6528)
Epoch: 18 | Batch_idx: 60 |  Loss: (0.8084) |  Loss2: (0.0000) | Acc: (71.00%) (5551/7808)
Epoch: 18 | Batch_idx: 70 |  Loss: (0.8049) |  Loss2: (0.0000) | Acc: (71.00%) (6463/9088)
Epoch: 18 | Batch_idx: 80 |  Loss: (0.8007) |  Loss2: (0.0000) | Acc: (71.00%) (7398/10368)
Epoch: 18 | Batch_idx: 90 |  Loss: (0.7996) |  Loss2: (0.0000) | Acc: (71.00%) (8308/11648)
Epoch: 18 | Batch_idx: 100 |  Loss: (0.8006) |  Loss2: (0.0000) | Acc: (71.00%) (9213/12928)
Epoch: 18 | Batch_idx: 110 |  Loss: (0.8041) |  Loss2: (0.0000) | Acc: (71.00%) (10105/14208)
Epoch: 18 | Batch_idx: 120 |  Loss: (0.8013) |  Loss2: (0.0000) | Acc: (71.00%) (11044/15488)
Epoch: 18 | Batch_idx: 130 |  Loss: (0.7985) |  Loss2: (0.0000) | Acc: (71.00%) (11973/16768)
Epoch: 18 | Batch_idx: 140 |  Loss: (0.7990) |  Loss2: (0.0000) | Acc: (71.00%) (12871/18048)
Epoch: 18 | Batch_idx: 150 |  Loss: (0.8008) |  Loss2: (0.0000) | Acc: (71.00%) (13771/19328)
Epoch: 18 | Batch_idx: 160 |  Loss: (0.7988) |  Loss2: (0.0000) | Acc: (71.00%) (14697/20608)
Epoch: 18 | Batch_idx: 170 |  Loss: (0.8016) |  Loss2: (0.0000) | Acc: (71.00%) (15575/21888)
Epoch: 18 | Batch_idx: 180 |  Loss: (0.8012) |  Loss2: (0.0000) | Acc: (71.00%) (16506/23168)
Epoch: 18 | Batch_idx: 190 |  Loss: (0.8000) |  Loss2: (0.0000) | Acc: (71.00%) (17439/24448)
Epoch: 18 | Batch_idx: 200 |  Loss: (0.7967) |  Loss2: (0.0000) | Acc: (71.00%) (18390/25728)
Epoch: 18 | Batch_idx: 210 |  Loss: (0.7962) |  Loss2: (0.0000) | Acc: (71.00%) (19288/27008)
Epoch: 18 | Batch_idx: 220 |  Loss: (0.7985) |  Loss2: (0.0000) | Acc: (71.00%) (20176/28288)
Epoch: 18 | Batch_idx: 230 |  Loss: (0.7985) |  Loss2: (0.0000) | Acc: (71.00%) (21103/29568)
Epoch: 18 | Batch_idx: 240 |  Loss: (0.7981) |  Loss2: (0.0000) | Acc: (71.00%) (22017/30848)
Epoch: 18 | Batch_idx: 250 |  Loss: (0.7988) |  Loss2: (0.0000) | Acc: (71.00%) (22907/32128)
Epoch: 18 | Batch_idx: 260 |  Loss: (0.7979) |  Loss2: (0.0000) | Acc: (71.00%) (23832/33408)
Epoch: 18 | Batch_idx: 270 |  Loss: (0.7969) |  Loss2: (0.0000) | Acc: (71.00%) (24744/34688)
Epoch: 18 | Batch_idx: 280 |  Loss: (0.7978) |  Loss2: (0.0000) | Acc: (71.00%) (25650/35968)
Epoch: 18 | Batch_idx: 290 |  Loss: (0.7981) |  Loss2: (0.0000) | Acc: (71.00%) (26576/37248)
Epoch: 18 | Batch_idx: 300 |  Loss: (0.7997) |  Loss2: (0.0000) | Acc: (71.00%) (27490/38528)
Epoch: 18 | Batch_idx: 310 |  Loss: (0.7994) |  Loss2: (0.0000) | Acc: (71.00%) (28400/39808)
Epoch: 18 | Batch_idx: 320 |  Loss: (0.8004) |  Loss2: (0.0000) | Acc: (71.00%) (29296/41088)
Epoch: 18 | Batch_idx: 330 |  Loss: (0.7999) |  Loss2: (0.0000) | Acc: (71.00%) (30229/42368)
Epoch: 18 | Batch_idx: 340 |  Loss: (0.7995) |  Loss2: (0.0000) | Acc: (71.00%) (31146/43648)
Epoch: 18 | Batch_idx: 350 |  Loss: (0.8012) |  Loss2: (0.0000) | Acc: (71.00%) (32041/44928)
Epoch: 18 | Batch_idx: 360 |  Loss: (0.8019) |  Loss2: (0.0000) | Acc: (71.00%) (32935/46208)
Epoch: 18 | Batch_idx: 370 |  Loss: (0.8003) |  Loss2: (0.0000) | Acc: (71.00%) (33856/47488)
Epoch: 18 | Batch_idx: 380 |  Loss: (0.8000) |  Loss2: (0.0000) | Acc: (71.00%) (34785/48768)
Epoch: 18 | Batch_idx: 390 |  Loss: (0.8007) |  Loss2: (0.0000) | Acc: (71.00%) (35670/50000)
# TEST : Loss: (0.8202) | Acc: (71.00%) (7116/10000)
percent tensor([0.5019, 0.5176, 0.4981, 0.5078, 0.5013, 0.5009, 0.5121, 0.5099, 0.5094,
        0.5096, 0.5096, 0.4996, 0.5044, 0.5262, 0.5090, 0.5090],
       device='cuda:0') torch.Size([16])
percent tensor([0.4834, 0.4822, 0.4621, 0.4691, 0.4654, 0.4808, 0.4749, 0.4667, 0.4798,
        0.4789, 0.4842, 0.4697, 0.4825, 0.4841, 0.4776, 0.4786],
       device='cuda:0') torch.Size([16])
percent tensor([0.5276, 0.5483, 0.5201, 0.5298, 0.5318, 0.5259, 0.5471, 0.5364, 0.5289,
        0.5412, 0.5346, 0.5332, 0.5242, 0.5588, 0.5387, 0.5289],
       device='cuda:0') torch.Size([16])
percent tensor([0.5250, 0.5143, 0.5258, 0.5380, 0.5306, 0.5349, 0.5224, 0.5340, 0.5203,
        0.5132, 0.5121, 0.5196, 0.5127, 0.5199, 0.5270, 0.5288],
       device='cuda:0') torch.Size([16])
percent tensor([0.5003, 0.5047, 0.4814, 0.4801, 0.4805, 0.4932, 0.4967, 0.4836, 0.4983,
        0.5027, 0.5060, 0.4907, 0.5077, 0.5023, 0.4989, 0.5001],
       device='cuda:0') torch.Size([16])
percent tensor([0.5599, 0.5653, 0.5964, 0.6119, 0.5856, 0.5471, 0.5713, 0.6102, 0.5877,
        0.5726, 0.5788, 0.6005, 0.5605, 0.5898, 0.5580, 0.5541],
       device='cuda:0') torch.Size([16])
percent tensor([0.5069, 0.5068, 0.5534, 0.5543, 0.5504, 0.5012, 0.5246, 0.5787, 0.5261,
        0.5253, 0.5116, 0.5401, 0.5046, 0.5141, 0.5092, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.9229, 0.9045, 0.9708, 0.9585, 0.9679, 0.9340, 0.9231, 0.9880, 0.9344,
        0.9420, 0.9342, 0.9601, 0.9287, 0.9160, 0.9289, 0.9466],
       device='cuda:0') torch.Size([16])
Epoch: 19 | Batch_idx: 0 |  Loss: (0.7406) |  Loss2: (0.0000) | Acc: (68.00%) (88/128)
Epoch: 19 | Batch_idx: 10 |  Loss: (0.8107) |  Loss2: (0.0000) | Acc: (71.00%) (1003/1408)
Epoch: 19 | Batch_idx: 20 |  Loss: (0.8030) |  Loss2: (0.0000) | Acc: (71.00%) (1915/2688)
Epoch: 19 | Batch_idx: 30 |  Loss: (0.8032) |  Loss2: (0.0000) | Acc: (71.00%) (2846/3968)
Epoch: 19 | Batch_idx: 40 |  Loss: (0.8033) |  Loss2: (0.0000) | Acc: (71.00%) (3761/5248)
Epoch: 19 | Batch_idx: 50 |  Loss: (0.8088) |  Loss2: (0.0000) | Acc: (71.00%) (4643/6528)
Epoch: 19 | Batch_idx: 60 |  Loss: (0.8060) |  Loss2: (0.0000) | Acc: (71.00%) (5571/7808)
Epoch: 19 | Batch_idx: 70 |  Loss: (0.8079) |  Loss2: (0.0000) | Acc: (71.00%) (6480/9088)
Epoch: 19 | Batch_idx: 80 |  Loss: (0.8064) |  Loss2: (0.0000) | Acc: (71.00%) (7396/10368)
Epoch: 19 | Batch_idx: 90 |  Loss: (0.8050) |  Loss2: (0.0000) | Acc: (71.00%) (8316/11648)
Epoch: 19 | Batch_idx: 100 |  Loss: (0.8067) |  Loss2: (0.0000) | Acc: (71.00%) (9233/12928)
Epoch: 19 | Batch_idx: 110 |  Loss: (0.8061) |  Loss2: (0.0000) | Acc: (71.00%) (10146/14208)
Epoch: 19 | Batch_idx: 120 |  Loss: (0.8023) |  Loss2: (0.0000) | Acc: (71.00%) (11079/15488)
Epoch: 19 | Batch_idx: 130 |  Loss: (0.7990) |  Loss2: (0.0000) | Acc: (71.00%) (12039/16768)
Epoch: 19 | Batch_idx: 140 |  Loss: (0.7977) |  Loss2: (0.0000) | Acc: (71.00%) (12953/18048)
Epoch: 19 | Batch_idx: 150 |  Loss: (0.7958) |  Loss2: (0.0000) | Acc: (71.00%) (13882/19328)
Epoch: 19 | Batch_idx: 160 |  Loss: (0.7985) |  Loss2: (0.0000) | Acc: (71.00%) (14780/20608)
Epoch: 19 | Batch_idx: 170 |  Loss: (0.7972) |  Loss2: (0.0000) | Acc: (71.00%) (15702/21888)
Epoch: 19 | Batch_idx: 180 |  Loss: (0.7959) |  Loss2: (0.0000) | Acc: (71.00%) (16617/23168)
Epoch: 19 | Batch_idx: 190 |  Loss: (0.7969) |  Loss2: (0.0000) | Acc: (71.00%) (17511/24448)
Epoch: 19 | Batch_idx: 200 |  Loss: (0.7959) |  Loss2: (0.0000) | Acc: (71.00%) (18441/25728)
Epoch: 19 | Batch_idx: 210 |  Loss: (0.7950) |  Loss2: (0.0000) | Acc: (71.00%) (19360/27008)
Epoch: 19 | Batch_idx: 220 |  Loss: (0.7931) |  Loss2: (0.0000) | Acc: (71.00%) (20298/28288)
Epoch: 19 | Batch_idx: 230 |  Loss: (0.7949) |  Loss2: (0.0000) | Acc: (71.00%) (21208/29568)
Epoch: 19 | Batch_idx: 240 |  Loss: (0.7966) |  Loss2: (0.0000) | Acc: (71.00%) (22116/30848)
Epoch: 19 | Batch_idx: 250 |  Loss: (0.7967) |  Loss2: (0.0000) | Acc: (71.00%) (23037/32128)
Epoch: 19 | Batch_idx: 260 |  Loss: (0.7967) |  Loss2: (0.0000) | Acc: (71.00%) (23948/33408)
Epoch: 19 | Batch_idx: 270 |  Loss: (0.7968) |  Loss2: (0.0000) | Acc: (71.00%) (24855/34688)
Epoch: 19 | Batch_idx: 280 |  Loss: (0.7975) |  Loss2: (0.0000) | Acc: (71.00%) (25763/35968)
Epoch: 19 | Batch_idx: 290 |  Loss: (0.7981) |  Loss2: (0.0000) | Acc: (71.00%) (26681/37248)
Epoch: 19 | Batch_idx: 300 |  Loss: (0.7978) |  Loss2: (0.0000) | Acc: (71.00%) (27576/38528)
Epoch: 19 | Batch_idx: 310 |  Loss: (0.7973) |  Loss2: (0.0000) | Acc: (71.00%) (28485/39808)
Epoch: 19 | Batch_idx: 320 |  Loss: (0.7976) |  Loss2: (0.0000) | Acc: (71.00%) (29394/41088)
Epoch: 19 | Batch_idx: 330 |  Loss: (0.7989) |  Loss2: (0.0000) | Acc: (71.00%) (30308/42368)
Epoch: 19 | Batch_idx: 340 |  Loss: (0.7995) |  Loss2: (0.0000) | Acc: (71.00%) (31229/43648)
Epoch: 19 | Batch_idx: 350 |  Loss: (0.7982) |  Loss2: (0.0000) | Acc: (71.00%) (32158/44928)
Epoch: 19 | Batch_idx: 360 |  Loss: (0.7987) |  Loss2: (0.0000) | Acc: (71.00%) (33052/46208)
Epoch: 19 | Batch_idx: 370 |  Loss: (0.7982) |  Loss2: (0.0000) | Acc: (71.00%) (33954/47488)
Epoch: 19 | Batch_idx: 380 |  Loss: (0.7979) |  Loss2: (0.0000) | Acc: (71.00%) (34880/48768)
Epoch: 19 | Batch_idx: 390 |  Loss: (0.7975) |  Loss2: (0.0000) | Acc: (71.00%) (35758/50000)
# TEST : Loss: (0.8159) | Acc: (71.00%) (7129/10000)
percent tensor([0.4982, 0.5142, 0.4940, 0.5043, 0.4970, 0.4973, 0.5082, 0.5059, 0.5057,
        0.5059, 0.5061, 0.4955, 0.5009, 0.5236, 0.5055, 0.5055],
       device='cuda:0') torch.Size([16])
percent tensor([0.4855, 0.4848, 0.4645, 0.4710, 0.4681, 0.4826, 0.4779, 0.4693, 0.4824,
        0.4815, 0.4868, 0.4725, 0.4848, 0.4860, 0.4801, 0.4807],
       device='cuda:0') torch.Size([16])
percent tensor([0.5302, 0.5497, 0.5210, 0.5331, 0.5333, 0.5296, 0.5487, 0.5385, 0.5307,
        0.5422, 0.5361, 0.5343, 0.5253, 0.5623, 0.5412, 0.5313],
       device='cuda:0') torch.Size([16])
percent tensor([0.5263, 0.5152, 0.5253, 0.5382, 0.5305, 0.5365, 0.5233, 0.5340, 0.5207,
        0.5137, 0.5130, 0.5197, 0.5133, 0.5211, 0.5282, 0.5298],
       device='cuda:0') torch.Size([16])
percent tensor([0.5049, 0.5088, 0.4831, 0.4822, 0.4820, 0.4985, 0.5002, 0.4862, 0.5015,
        0.5067, 0.5103, 0.4931, 0.5124, 0.5059, 0.5039, 0.5046],
       device='cuda:0') torch.Size([16])
percent tensor([0.5625, 0.5690, 0.6023, 0.6198, 0.5894, 0.5468, 0.5740, 0.6146, 0.5957,
        0.5769, 0.5850, 0.6082, 0.5652, 0.5975, 0.5597, 0.5539],
       device='cuda:0') torch.Size([16])
percent tensor([0.5067, 0.5088, 0.5660, 0.5664, 0.5618, 0.5018, 0.5260, 0.5944, 0.5333,
        0.5298, 0.5147, 0.5493, 0.5065, 0.5168, 0.5118, 0.5110],
       device='cuda:0') torch.Size([16])
percent tensor([0.9336, 0.9164, 0.9751, 0.9644, 0.9735, 0.9425, 0.9325, 0.9906, 0.9446,
        0.9508, 0.9438, 0.9657, 0.9392, 0.9280, 0.9337, 0.9537],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 20 | Batch_idx: 0 |  Loss: (0.7374) |  Loss2: (0.0000) | Acc: (72.00%) (93/128)
Epoch: 20 | Batch_idx: 10 |  Loss: (0.7754) |  Loss2: (0.0000) | Acc: (72.00%) (1018/1408)
Epoch: 20 | Batch_idx: 20 |  Loss: (0.8398) |  Loss2: (0.0000) | Acc: (69.00%) (1874/2688)
Epoch: 20 | Batch_idx: 30 |  Loss: (0.8303) |  Loss2: (0.0000) | Acc: (70.00%) (2792/3968)
Epoch: 20 | Batch_idx: 40 |  Loss: (0.8167) |  Loss2: (0.0000) | Acc: (70.00%) (3721/5248)
Epoch: 20 | Batch_idx: 50 |  Loss: (0.8175) |  Loss2: (0.0000) | Acc: (70.00%) (4628/6528)
Epoch: 20 | Batch_idx: 60 |  Loss: (0.8155) |  Loss2: (0.0000) | Acc: (71.00%) (5549/7808)
Epoch: 20 | Batch_idx: 70 |  Loss: (0.8140) |  Loss2: (0.0000) | Acc: (71.00%) (6471/9088)
Epoch: 20 | Batch_idx: 80 |  Loss: (0.8186) |  Loss2: (0.0000) | Acc: (71.00%) (7368/10368)
Epoch: 20 | Batch_idx: 90 |  Loss: (0.8162) |  Loss2: (0.0000) | Acc: (71.00%) (8290/11648)
Epoch: 20 | Batch_idx: 100 |  Loss: (0.8172) |  Loss2: (0.0000) | Acc: (71.00%) (9202/12928)
Epoch: 20 | Batch_idx: 110 |  Loss: (0.8158) |  Loss2: (0.0000) | Acc: (71.00%) (10107/14208)
Epoch: 20 | Batch_idx: 120 |  Loss: (0.8178) |  Loss2: (0.0000) | Acc: (71.00%) (11008/15488)
Epoch: 20 | Batch_idx: 130 |  Loss: (0.8156) |  Loss2: (0.0000) | Acc: (71.00%) (11933/16768)
Epoch: 20 | Batch_idx: 140 |  Loss: (0.8180) |  Loss2: (0.0000) | Acc: (71.00%) (12829/18048)
Epoch: 20 | Batch_idx: 150 |  Loss: (0.8167) |  Loss2: (0.0000) | Acc: (71.00%) (13748/19328)
Epoch: 20 | Batch_idx: 160 |  Loss: (0.8160) |  Loss2: (0.0000) | Acc: (71.00%) (14656/20608)
Epoch: 20 | Batch_idx: 170 |  Loss: (0.8187) |  Loss2: (0.0000) | Acc: (71.00%) (15556/21888)
Epoch: 20 | Batch_idx: 180 |  Loss: (0.8146) |  Loss2: (0.0000) | Acc: (71.00%) (16507/23168)
Epoch: 20 | Batch_idx: 190 |  Loss: (0.8169) |  Loss2: (0.0000) | Acc: (71.00%) (17373/24448)
Epoch: 20 | Batch_idx: 200 |  Loss: (0.8141) |  Loss2: (0.0000) | Acc: (71.00%) (18319/25728)
Epoch: 20 | Batch_idx: 210 |  Loss: (0.8103) |  Loss2: (0.0000) | Acc: (71.00%) (19266/27008)
Epoch: 20 | Batch_idx: 220 |  Loss: (0.8103) |  Loss2: (0.0000) | Acc: (71.00%) (20184/28288)
Epoch: 20 | Batch_idx: 230 |  Loss: (0.8111) |  Loss2: (0.0000) | Acc: (71.00%) (21079/29568)
Epoch: 20 | Batch_idx: 240 |  Loss: (0.8085) |  Loss2: (0.0000) | Acc: (71.00%) (22025/30848)
Epoch: 20 | Batch_idx: 250 |  Loss: (0.8092) |  Loss2: (0.0000) | Acc: (71.00%) (22933/32128)
Epoch: 20 | Batch_idx: 260 |  Loss: (0.8082) |  Loss2: (0.0000) | Acc: (71.00%) (23844/33408)
Epoch: 20 | Batch_idx: 270 |  Loss: (0.8066) |  Loss2: (0.0000) | Acc: (71.00%) (24771/34688)
Epoch: 20 | Batch_idx: 280 |  Loss: (0.8047) |  Loss2: (0.0000) | Acc: (71.00%) (25705/35968)
Epoch: 20 | Batch_idx: 290 |  Loss: (0.8020) |  Loss2: (0.0000) | Acc: (71.00%) (26646/37248)
Epoch: 20 | Batch_idx: 300 |  Loss: (0.8007) |  Loss2: (0.0000) | Acc: (71.00%) (27572/38528)
Epoch: 20 | Batch_idx: 310 |  Loss: (0.8001) |  Loss2: (0.0000) | Acc: (71.00%) (28503/39808)
Epoch: 20 | Batch_idx: 320 |  Loss: (0.7989) |  Loss2: (0.0000) | Acc: (71.00%) (29451/41088)
Epoch: 20 | Batch_idx: 330 |  Loss: (0.7996) |  Loss2: (0.0000) | Acc: (71.00%) (30365/42368)
Epoch: 20 | Batch_idx: 340 |  Loss: (0.7971) |  Loss2: (0.0000) | Acc: (71.00%) (31317/43648)
Epoch: 20 | Batch_idx: 350 |  Loss: (0.7965) |  Loss2: (0.0000) | Acc: (71.00%) (32241/44928)
Epoch: 20 | Batch_idx: 360 |  Loss: (0.7965) |  Loss2: (0.0000) | Acc: (71.00%) (33149/46208)
Epoch: 20 | Batch_idx: 370 |  Loss: (0.7945) |  Loss2: (0.0000) | Acc: (71.00%) (34099/47488)
Epoch: 20 | Batch_idx: 380 |  Loss: (0.7939) |  Loss2: (0.0000) | Acc: (71.00%) (35048/48768)
Epoch: 20 | Batch_idx: 390 |  Loss: (0.7938) |  Loss2: (0.0000) | Acc: (71.00%) (35925/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_020.pth.tar'
# TEST : Loss: (0.9520) | Acc: (68.00%) (6806/10000)
percent tensor([0.4996, 0.5145, 0.4942, 0.5039, 0.4975, 0.4983, 0.5091, 0.5053, 0.5070,
        0.5062, 0.5072, 0.4960, 0.5019, 0.5244, 0.5059, 0.5058],
       device='cuda:0') torch.Size([16])
percent tensor([0.4858, 0.4844, 0.4686, 0.4725, 0.4703, 0.4829, 0.4782, 0.4715, 0.4827,
        0.4820, 0.4868, 0.4733, 0.4851, 0.4849, 0.4803, 0.4817],
       device='cuda:0') torch.Size([16])
percent tensor([0.5308, 0.5474, 0.5200, 0.5337, 0.5309, 0.5317, 0.5449, 0.5370, 0.5290,
        0.5393, 0.5356, 0.5297, 0.5236, 0.5611, 0.5423, 0.5310],
       device='cuda:0') torch.Size([16])
percent tensor([0.5276, 0.5150, 0.5283, 0.5394, 0.5337, 0.5371, 0.5248, 0.5349, 0.5211,
        0.5140, 0.5135, 0.5221, 0.5138, 0.5214, 0.5294, 0.5315],
       device='cuda:0') torch.Size([16])
percent tensor([0.5045, 0.5087, 0.4851, 0.4822, 0.4822, 0.4973, 0.5001, 0.4859, 0.5024,
        0.5060, 0.5093, 0.4931, 0.5123, 0.5074, 0.5030, 0.5034],
       device='cuda:0') torch.Size([16])
percent tensor([0.5543, 0.5542, 0.5908, 0.6010, 0.5696, 0.5546, 0.5609, 0.5966, 0.5900,
        0.5556, 0.5824, 0.5918, 0.5579, 0.5957, 0.5540, 0.5444],
       device='cuda:0') torch.Size([16])
percent tensor([0.5122, 0.5171, 0.5675, 0.5688, 0.5630, 0.5067, 0.5356, 0.5974, 0.5351,
        0.5379, 0.5255, 0.5559, 0.5084, 0.5221, 0.5239, 0.5159],
       device='cuda:0') torch.Size([16])
percent tensor([0.9368, 0.9231, 0.9752, 0.9627, 0.9778, 0.9371, 0.9410, 0.9913, 0.9396,
        0.9672, 0.9409, 0.9618, 0.9213, 0.9111, 0.9542, 0.9575],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(164.7200, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(784.7179, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(773.8922, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1530.8843, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(504.5586, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2168.4109, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4309.5986, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1441.6450, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6093.6001, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12182.7725, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4074.5090, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17195.3242, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 21 | Batch_idx: 0 |  Loss: (0.5849) |  Loss2: (0.0000) | Acc: (76.00%) (98/128)
Epoch: 21 | Batch_idx: 10 |  Loss: (0.7117) |  Loss2: (0.0000) | Acc: (74.00%) (1052/1408)
Epoch: 21 | Batch_idx: 20 |  Loss: (0.7286) |  Loss2: (0.0000) | Acc: (74.00%) (1998/2688)
Epoch: 21 | Batch_idx: 30 |  Loss: (0.7393) |  Loss2: (0.0000) | Acc: (73.00%) (2925/3968)
Epoch: 21 | Batch_idx: 40 |  Loss: (0.7412) |  Loss2: (0.0000) | Acc: (73.00%) (3872/5248)
Epoch: 21 | Batch_idx: 50 |  Loss: (0.7521) |  Loss2: (0.0000) | Acc: (73.00%) (4813/6528)
Epoch: 21 | Batch_idx: 60 |  Loss: (0.7483) |  Loss2: (0.0000) | Acc: (73.00%) (5758/7808)
Epoch: 21 | Batch_idx: 70 |  Loss: (0.7463) |  Loss2: (0.0000) | Acc: (73.00%) (6702/9088)
Epoch: 21 | Batch_idx: 80 |  Loss: (0.7489) |  Loss2: (0.0000) | Acc: (73.00%) (7622/10368)
Epoch: 21 | Batch_idx: 90 |  Loss: (0.7537) |  Loss2: (0.0000) | Acc: (73.00%) (8542/11648)
Epoch: 21 | Batch_idx: 100 |  Loss: (0.7484) |  Loss2: (0.0000) | Acc: (73.00%) (9506/12928)
Epoch: 21 | Batch_idx: 110 |  Loss: (0.7457) |  Loss2: (0.0000) | Acc: (73.00%) (10458/14208)
Epoch: 21 | Batch_idx: 120 |  Loss: (0.7470) |  Loss2: (0.0000) | Acc: (73.00%) (11393/15488)
Epoch: 21 | Batch_idx: 130 |  Loss: (0.7471) |  Loss2: (0.0000) | Acc: (73.00%) (12316/16768)
Epoch: 21 | Batch_idx: 140 |  Loss: (0.7485) |  Loss2: (0.0000) | Acc: (73.00%) (13241/18048)
Epoch: 21 | Batch_idx: 150 |  Loss: (0.7477) |  Loss2: (0.0000) | Acc: (73.00%) (14203/19328)
Epoch: 21 | Batch_idx: 160 |  Loss: (0.7485) |  Loss2: (0.0000) | Acc: (73.00%) (15133/20608)
Epoch: 21 | Batch_idx: 170 |  Loss: (0.7472) |  Loss2: (0.0000) | Acc: (73.00%) (16093/21888)
Epoch: 21 | Batch_idx: 180 |  Loss: (0.7486) |  Loss2: (0.0000) | Acc: (73.00%) (17009/23168)
Epoch: 21 | Batch_idx: 190 |  Loss: (0.7498) |  Loss2: (0.0000) | Acc: (73.00%) (17928/24448)
Epoch: 21 | Batch_idx: 200 |  Loss: (0.7501) |  Loss2: (0.0000) | Acc: (73.00%) (18867/25728)
Epoch: 21 | Batch_idx: 210 |  Loss: (0.7516) |  Loss2: (0.0000) | Acc: (73.00%) (19796/27008)
Epoch: 21 | Batch_idx: 220 |  Loss: (0.7505) |  Loss2: (0.0000) | Acc: (73.00%) (20758/28288)
Epoch: 21 | Batch_idx: 230 |  Loss: (0.7468) |  Loss2: (0.0000) | Acc: (73.00%) (21747/29568)
Epoch: 21 | Batch_idx: 240 |  Loss: (0.7444) |  Loss2: (0.0000) | Acc: (73.00%) (22718/30848)
Epoch: 21 | Batch_idx: 250 |  Loss: (0.7450) |  Loss2: (0.0000) | Acc: (73.00%) (23647/32128)
Epoch: 21 | Batch_idx: 260 |  Loss: (0.7440) |  Loss2: (0.0000) | Acc: (73.00%) (24627/33408)
Epoch: 21 | Batch_idx: 270 |  Loss: (0.7430) |  Loss2: (0.0000) | Acc: (73.00%) (25584/34688)
Epoch: 21 | Batch_idx: 280 |  Loss: (0.7429) |  Loss2: (0.0000) | Acc: (73.00%) (26530/35968)
Epoch: 21 | Batch_idx: 290 |  Loss: (0.7426) |  Loss2: (0.0000) | Acc: (73.00%) (27478/37248)
Epoch: 21 | Batch_idx: 300 |  Loss: (0.7426) |  Loss2: (0.0000) | Acc: (73.00%) (28410/38528)
Epoch: 21 | Batch_idx: 310 |  Loss: (0.7422) |  Loss2: (0.0000) | Acc: (73.00%) (29353/39808)
Epoch: 21 | Batch_idx: 320 |  Loss: (0.7432) |  Loss2: (0.0000) | Acc: (73.00%) (30280/41088)
Epoch: 21 | Batch_idx: 330 |  Loss: (0.7437) |  Loss2: (0.0000) | Acc: (73.00%) (31221/42368)
Epoch: 21 | Batch_idx: 340 |  Loss: (0.7430) |  Loss2: (0.0000) | Acc: (73.00%) (32173/43648)
Epoch: 21 | Batch_idx: 350 |  Loss: (0.7436) |  Loss2: (0.0000) | Acc: (73.00%) (33121/44928)
Epoch: 21 | Batch_idx: 360 |  Loss: (0.7421) |  Loss2: (0.0000) | Acc: (73.00%) (34090/46208)
Epoch: 21 | Batch_idx: 370 |  Loss: (0.7417) |  Loss2: (0.0000) | Acc: (73.00%) (35041/47488)
Epoch: 21 | Batch_idx: 380 |  Loss: (0.7421) |  Loss2: (0.0000) | Acc: (73.00%) (35981/48768)
Epoch: 21 | Batch_idx: 390 |  Loss: (0.7436) |  Loss2: (0.0000) | Acc: (73.00%) (36865/50000)
# TEST : Loss: (0.8549) | Acc: (69.00%) (6997/10000)
percent tensor([0.4994, 0.5142, 0.4948, 0.5034, 0.4977, 0.4979, 0.5089, 0.5053, 0.5069,
        0.5058, 0.5070, 0.4956, 0.5014, 0.5236, 0.5053, 0.5050],
       device='cuda:0') torch.Size([16])
percent tensor([0.4842, 0.4841, 0.4696, 0.4729, 0.4712, 0.4818, 0.4785, 0.4727, 0.4823,
        0.4821, 0.4855, 0.4750, 0.4841, 0.4844, 0.4794, 0.4811],
       device='cuda:0') torch.Size([16])
percent tensor([0.5324, 0.5498, 0.5253, 0.5356, 0.5350, 0.5300, 0.5500, 0.5388, 0.5330,
        0.5437, 0.5372, 0.5367, 0.5261, 0.5633, 0.5425, 0.5319],
       device='cuda:0') torch.Size([16])
percent tensor([0.5273, 0.5152, 0.5261, 0.5380, 0.5326, 0.5366, 0.5235, 0.5340, 0.5214,
        0.5134, 0.5130, 0.5217, 0.5130, 0.5226, 0.5287, 0.5306],
       device='cuda:0') torch.Size([16])
percent tensor([0.5046, 0.5086, 0.4877, 0.4848, 0.4846, 0.4972, 0.5010, 0.4868, 0.5014,
        0.5062, 0.5099, 0.4948, 0.5114, 0.5048, 0.5035, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.5648, 0.5687, 0.5960, 0.6136, 0.5835, 0.5628, 0.5768, 0.5978, 0.6030,
        0.5694, 0.5901, 0.6099, 0.5646, 0.6139, 0.5640, 0.5541],
       device='cuda:0') torch.Size([16])
percent tensor([0.5116, 0.5145, 0.5600, 0.5604, 0.5527, 0.5090, 0.5283, 0.5834, 0.5325,
        0.5338, 0.5195, 0.5508, 0.5067, 0.5252, 0.5180, 0.5125],
       device='cuda:0') torch.Size([16])
percent tensor([0.9420, 0.9374, 0.9698, 0.9562, 0.9637, 0.9495, 0.9442, 0.9852, 0.9343,
        0.9647, 0.9503, 0.9553, 0.9294, 0.9350, 0.9428, 0.9577],
       device='cuda:0') torch.Size([16])
Epoch: 22 | Batch_idx: 0 |  Loss: (0.7824) |  Loss2: (0.0000) | Acc: (70.00%) (90/128)
Epoch: 22 | Batch_idx: 10 |  Loss: (0.7203) |  Loss2: (0.0000) | Acc: (75.00%) (1062/1408)
Epoch: 22 | Batch_idx: 20 |  Loss: (0.7256) |  Loss2: (0.0000) | Acc: (75.00%) (2017/2688)
Epoch: 22 | Batch_idx: 30 |  Loss: (0.7111) |  Loss2: (0.0000) | Acc: (75.00%) (2993/3968)
Epoch: 22 | Batch_idx: 40 |  Loss: (0.7017) |  Loss2: (0.0000) | Acc: (75.00%) (3962/5248)
Epoch: 22 | Batch_idx: 50 |  Loss: (0.7060) |  Loss2: (0.0000) | Acc: (75.00%) (4903/6528)
Epoch: 22 | Batch_idx: 60 |  Loss: (0.7141) |  Loss2: (0.0000) | Acc: (74.00%) (5848/7808)
Epoch: 22 | Batch_idx: 70 |  Loss: (0.7171) |  Loss2: (0.0000) | Acc: (74.00%) (6793/9088)
Epoch: 22 | Batch_idx: 80 |  Loss: (0.7095) |  Loss2: (0.0000) | Acc: (75.00%) (7787/10368)
Epoch: 22 | Batch_idx: 90 |  Loss: (0.7098) |  Loss2: (0.0000) | Acc: (75.00%) (8740/11648)
Epoch: 22 | Batch_idx: 100 |  Loss: (0.7101) |  Loss2: (0.0000) | Acc: (74.00%) (9688/12928)
Epoch: 22 | Batch_idx: 110 |  Loss: (0.7076) |  Loss2: (0.0000) | Acc: (75.00%) (10658/14208)
Epoch: 22 | Batch_idx: 120 |  Loss: (0.7082) |  Loss2: (0.0000) | Acc: (75.00%) (11618/15488)
Epoch: 22 | Batch_idx: 130 |  Loss: (0.7063) |  Loss2: (0.0000) | Acc: (75.00%) (12595/16768)
Epoch: 22 | Batch_idx: 140 |  Loss: (0.7041) |  Loss2: (0.0000) | Acc: (75.00%) (13553/18048)
Epoch: 22 | Batch_idx: 150 |  Loss: (0.7045) |  Loss2: (0.0000) | Acc: (75.00%) (14499/19328)
Epoch: 22 | Batch_idx: 160 |  Loss: (0.7018) |  Loss2: (0.0000) | Acc: (75.00%) (15472/20608)
Epoch: 22 | Batch_idx: 170 |  Loss: (0.7013) |  Loss2: (0.0000) | Acc: (75.00%) (16439/21888)
Epoch: 22 | Batch_idx: 180 |  Loss: (0.7004) |  Loss2: (0.0000) | Acc: (75.00%) (17421/23168)
Epoch: 22 | Batch_idx: 190 |  Loss: (0.7009) |  Loss2: (0.0000) | Acc: (75.00%) (18375/24448)
Epoch: 22 | Batch_idx: 200 |  Loss: (0.7024) |  Loss2: (0.0000) | Acc: (75.00%) (19324/25728)
Epoch: 22 | Batch_idx: 210 |  Loss: (0.7030) |  Loss2: (0.0000) | Acc: (75.00%) (20285/27008)
Epoch: 22 | Batch_idx: 220 |  Loss: (0.7025) |  Loss2: (0.0000) | Acc: (75.00%) (21267/28288)
Epoch: 22 | Batch_idx: 230 |  Loss: (0.7041) |  Loss2: (0.0000) | Acc: (75.00%) (22219/29568)
Epoch: 22 | Batch_idx: 240 |  Loss: (0.7043) |  Loss2: (0.0000) | Acc: (75.00%) (23185/30848)
Epoch: 22 | Batch_idx: 250 |  Loss: (0.7043) |  Loss2: (0.0000) | Acc: (75.00%) (24140/32128)
Epoch: 22 | Batch_idx: 260 |  Loss: (0.7038) |  Loss2: (0.0000) | Acc: (75.00%) (25106/33408)
Epoch: 22 | Batch_idx: 270 |  Loss: (0.7043) |  Loss2: (0.0000) | Acc: (75.00%) (26070/34688)
Epoch: 22 | Batch_idx: 280 |  Loss: (0.7039) |  Loss2: (0.0000) | Acc: (75.00%) (27050/35968)
Epoch: 22 | Batch_idx: 290 |  Loss: (0.7040) |  Loss2: (0.0000) | Acc: (75.00%) (28015/37248)
Epoch: 22 | Batch_idx: 300 |  Loss: (0.7034) |  Loss2: (0.0000) | Acc: (75.00%) (28985/38528)
Epoch: 22 | Batch_idx: 310 |  Loss: (0.7040) |  Loss2: (0.0000) | Acc: (75.00%) (29938/39808)
Epoch: 22 | Batch_idx: 320 |  Loss: (0.7030) |  Loss2: (0.0000) | Acc: (75.00%) (30916/41088)
Epoch: 22 | Batch_idx: 330 |  Loss: (0.7019) |  Loss2: (0.0000) | Acc: (75.00%) (31903/42368)
Epoch: 22 | Batch_idx: 340 |  Loss: (0.7007) |  Loss2: (0.0000) | Acc: (75.00%) (32883/43648)
Epoch: 22 | Batch_idx: 350 |  Loss: (0.7009) |  Loss2: (0.0000) | Acc: (75.00%) (33831/44928)
Epoch: 22 | Batch_idx: 360 |  Loss: (0.7016) |  Loss2: (0.0000) | Acc: (75.00%) (34805/46208)
Epoch: 22 | Batch_idx: 370 |  Loss: (0.7016) |  Loss2: (0.0000) | Acc: (75.00%) (35755/47488)
Epoch: 22 | Batch_idx: 380 |  Loss: (0.7024) |  Loss2: (0.0000) | Acc: (75.00%) (36714/48768)
Epoch: 22 | Batch_idx: 390 |  Loss: (0.7029) |  Loss2: (0.0000) | Acc: (75.00%) (37644/50000)
# TEST : Loss: (0.7467) | Acc: (73.00%) (7356/10000)
percent tensor([0.4991, 0.5143, 0.4962, 0.5039, 0.4985, 0.4979, 0.5095, 0.5060, 0.5068,
        0.5064, 0.5068, 0.4968, 0.5015, 0.5237, 0.5055, 0.5051],
       device='cuda:0') torch.Size([16])
percent tensor([0.4852, 0.4843, 0.4698, 0.4726, 0.4716, 0.4813, 0.4789, 0.4721, 0.4822,
        0.4818, 0.4852, 0.4753, 0.4846, 0.4848, 0.4790, 0.4807],
       device='cuda:0') torch.Size([16])
percent tensor([0.5342, 0.5498, 0.5204, 0.5366, 0.5320, 0.5307, 0.5473, 0.5381, 0.5311,
        0.5432, 0.5395, 0.5327, 0.5281, 0.5624, 0.5441, 0.5343],
       device='cuda:0') torch.Size([16])
percent tensor([0.5267, 0.5182, 0.5254, 0.5375, 0.5310, 0.5367, 0.5258, 0.5348, 0.5212,
        0.5163, 0.5144, 0.5218, 0.5136, 0.5257, 0.5303, 0.5317],
       device='cuda:0') torch.Size([16])
percent tensor([0.5042, 0.5073, 0.4874, 0.4843, 0.4847, 0.4968, 0.4998, 0.4858, 0.5018,
        0.5055, 0.5086, 0.4936, 0.5115, 0.5040, 0.5017, 0.5035],
       device='cuda:0') torch.Size([16])
percent tensor([0.5667, 0.5649, 0.5983, 0.6268, 0.5864, 0.5680, 0.5784, 0.6092, 0.5971,
        0.5658, 0.5880, 0.6128, 0.5628, 0.6162, 0.5661, 0.5611],
       device='cuda:0') torch.Size([16])
percent tensor([0.5114, 0.5128, 0.5594, 0.5601, 0.5527, 0.5121, 0.5257, 0.5735, 0.5333,
        0.5268, 0.5199, 0.5564, 0.5081, 0.5350, 0.5196, 0.5094],
       device='cuda:0') torch.Size([16])
percent tensor([0.9439, 0.9278, 0.9719, 0.9572, 0.9625, 0.9425, 0.9418, 0.9792, 0.9438,
        0.9617, 0.9497, 0.9761, 0.9379, 0.9412, 0.9495, 0.9465],
       device='cuda:0') torch.Size([16])
Epoch: 23 | Batch_idx: 0 |  Loss: (0.6102) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 23 | Batch_idx: 10 |  Loss: (0.6859) |  Loss2: (0.0000) | Acc: (74.00%) (1053/1408)
Epoch: 23 | Batch_idx: 20 |  Loss: (0.6887) |  Loss2: (0.0000) | Acc: (75.00%) (2027/2688)
Epoch: 23 | Batch_idx: 30 |  Loss: (0.6827) |  Loss2: (0.0000) | Acc: (75.00%) (3005/3968)
Epoch: 23 | Batch_idx: 40 |  Loss: (0.6798) |  Loss2: (0.0000) | Acc: (75.00%) (3975/5248)
Epoch: 23 | Batch_idx: 50 |  Loss: (0.6832) |  Loss2: (0.0000) | Acc: (75.00%) (4944/6528)
Epoch: 23 | Batch_idx: 60 |  Loss: (0.6790) |  Loss2: (0.0000) | Acc: (75.00%) (5926/7808)
Epoch: 23 | Batch_idx: 70 |  Loss: (0.6769) |  Loss2: (0.0000) | Acc: (76.00%) (6917/9088)
Epoch: 23 | Batch_idx: 80 |  Loss: (0.6742) |  Loss2: (0.0000) | Acc: (76.00%) (7911/10368)
Epoch: 23 | Batch_idx: 90 |  Loss: (0.6695) |  Loss2: (0.0000) | Acc: (76.00%) (8906/11648)
Epoch: 23 | Batch_idx: 100 |  Loss: (0.6654) |  Loss2: (0.0000) | Acc: (76.00%) (9895/12928)
Epoch: 23 | Batch_idx: 110 |  Loss: (0.6646) |  Loss2: (0.0000) | Acc: (76.00%) (10872/14208)
Epoch: 23 | Batch_idx: 120 |  Loss: (0.6645) |  Loss2: (0.0000) | Acc: (76.00%) (11863/15488)
Epoch: 23 | Batch_idx: 130 |  Loss: (0.6651) |  Loss2: (0.0000) | Acc: (76.00%) (12818/16768)
Epoch: 23 | Batch_idx: 140 |  Loss: (0.6644) |  Loss2: (0.0000) | Acc: (76.00%) (13800/18048)
Epoch: 23 | Batch_idx: 150 |  Loss: (0.6654) |  Loss2: (0.0000) | Acc: (76.00%) (14775/19328)
Epoch: 23 | Batch_idx: 160 |  Loss: (0.6647) |  Loss2: (0.0000) | Acc: (76.00%) (15762/20608)
Epoch: 23 | Batch_idx: 170 |  Loss: (0.6661) |  Loss2: (0.0000) | Acc: (76.00%) (16729/21888)
Epoch: 23 | Batch_idx: 180 |  Loss: (0.6666) |  Loss2: (0.0000) | Acc: (76.00%) (17701/23168)
Epoch: 23 | Batch_idx: 190 |  Loss: (0.6662) |  Loss2: (0.0000) | Acc: (76.00%) (18684/24448)
Epoch: 23 | Batch_idx: 200 |  Loss: (0.6661) |  Loss2: (0.0000) | Acc: (76.00%) (19680/25728)
Epoch: 23 | Batch_idx: 210 |  Loss: (0.6686) |  Loss2: (0.0000) | Acc: (76.00%) (20630/27008)
Epoch: 23 | Batch_idx: 220 |  Loss: (0.6665) |  Loss2: (0.0000) | Acc: (76.00%) (21632/28288)
Epoch: 23 | Batch_idx: 230 |  Loss: (0.6664) |  Loss2: (0.0000) | Acc: (76.00%) (22609/29568)
Epoch: 23 | Batch_idx: 240 |  Loss: (0.6659) |  Loss2: (0.0000) | Acc: (76.00%) (23600/30848)
Epoch: 23 | Batch_idx: 250 |  Loss: (0.6681) |  Loss2: (0.0000) | Acc: (76.00%) (24554/32128)
Epoch: 23 | Batch_idx: 260 |  Loss: (0.6679) |  Loss2: (0.0000) | Acc: (76.00%) (25540/33408)
Epoch: 23 | Batch_idx: 270 |  Loss: (0.6679) |  Loss2: (0.0000) | Acc: (76.00%) (26520/34688)
Epoch: 23 | Batch_idx: 280 |  Loss: (0.6673) |  Loss2: (0.0000) | Acc: (76.00%) (27507/35968)
Epoch: 23 | Batch_idx: 290 |  Loss: (0.6671) |  Loss2: (0.0000) | Acc: (76.00%) (28493/37248)
Epoch: 23 | Batch_idx: 300 |  Loss: (0.6662) |  Loss2: (0.0000) | Acc: (76.00%) (29499/38528)
Epoch: 23 | Batch_idx: 310 |  Loss: (0.6675) |  Loss2: (0.0000) | Acc: (76.00%) (30463/39808)
Epoch: 23 | Batch_idx: 320 |  Loss: (0.6662) |  Loss2: (0.0000) | Acc: (76.00%) (31449/41088)
Epoch: 23 | Batch_idx: 330 |  Loss: (0.6646) |  Loss2: (0.0000) | Acc: (76.00%) (32457/42368)
Epoch: 23 | Batch_idx: 340 |  Loss: (0.6658) |  Loss2: (0.0000) | Acc: (76.00%) (33425/43648)
Epoch: 23 | Batch_idx: 350 |  Loss: (0.6659) |  Loss2: (0.0000) | Acc: (76.00%) (34407/44928)
Epoch: 23 | Batch_idx: 360 |  Loss: (0.6648) |  Loss2: (0.0000) | Acc: (76.00%) (35411/46208)
Epoch: 23 | Batch_idx: 370 |  Loss: (0.6641) |  Loss2: (0.0000) | Acc: (76.00%) (36401/47488)
Epoch: 23 | Batch_idx: 380 |  Loss: (0.6643) |  Loss2: (0.0000) | Acc: (76.00%) (37368/48768)
Epoch: 23 | Batch_idx: 390 |  Loss: (0.6642) |  Loss2: (0.0000) | Acc: (76.00%) (38313/50000)
# TEST : Loss: (0.8756) | Acc: (70.00%) (7031/10000)
percent tensor([0.4996, 0.5140, 0.4968, 0.5037, 0.4988, 0.4982, 0.5089, 0.5061, 0.5073,
        0.5065, 0.5071, 0.4969, 0.5017, 0.5237, 0.5053, 0.5052],
       device='cuda:0') torch.Size([16])
percent tensor([0.4855, 0.4838, 0.4714, 0.4732, 0.4732, 0.4818, 0.4796, 0.4728, 0.4826,
        0.4817, 0.4848, 0.4765, 0.4845, 0.4835, 0.4792, 0.4806],
       device='cuda:0') torch.Size([16])
percent tensor([0.5341, 0.5480, 0.5235, 0.5374, 0.5337, 0.5315, 0.5466, 0.5405, 0.5311,
        0.5429, 0.5379, 0.5345, 0.5260, 0.5609, 0.5432, 0.5335],
       device='cuda:0') torch.Size([16])
percent tensor([0.5262, 0.5153, 0.5262, 0.5349, 0.5305, 0.5347, 0.5233, 0.5328, 0.5212,
        0.5164, 0.5137, 0.5231, 0.5127, 0.5237, 0.5282, 0.5294],
       device='cuda:0') torch.Size([16])
percent tensor([0.5062, 0.5084, 0.4873, 0.4864, 0.4857, 0.4970, 0.5024, 0.4876, 0.5026,
        0.5058, 0.5085, 0.4946, 0.5119, 0.5050, 0.5029, 0.5048],
       device='cuda:0') torch.Size([16])
percent tensor([0.5660, 0.5660, 0.5998, 0.6176, 0.5845, 0.5696, 0.5728, 0.6030, 0.5953,
        0.5695, 0.5907, 0.6102, 0.5645, 0.6057, 0.5635, 0.5643],
       device='cuda:0') torch.Size([16])
percent tensor([0.5111, 0.5118, 0.5614, 0.5558, 0.5543, 0.5138, 0.5241, 0.5736, 0.5316,
        0.5272, 0.5187, 0.5528, 0.5040, 0.5211, 0.5175, 0.5052],
       device='cuda:0') torch.Size([16])
percent tensor([0.9451, 0.9504, 0.9740, 0.9549, 0.9689, 0.9456, 0.9440, 0.9811, 0.9533,
        0.9639, 0.9613, 0.9699, 0.9416, 0.9362, 0.9481, 0.9349],
       device='cuda:0') torch.Size([16])
Epoch: 24 | Batch_idx: 0 |  Loss: (0.6865) |  Loss2: (0.0000) | Acc: (76.00%) (98/128)
Epoch: 24 | Batch_idx: 10 |  Loss: (0.6653) |  Loss2: (0.0000) | Acc: (77.00%) (1096/1408)
Epoch: 24 | Batch_idx: 20 |  Loss: (0.6367) |  Loss2: (0.0000) | Acc: (78.00%) (2099/2688)
Epoch: 24 | Batch_idx: 30 |  Loss: (0.6340) |  Loss2: (0.0000) | Acc: (78.00%) (3110/3968)
Epoch: 24 | Batch_idx: 40 |  Loss: (0.6264) |  Loss2: (0.0000) | Acc: (78.00%) (4122/5248)
Epoch: 24 | Batch_idx: 50 |  Loss: (0.6244) |  Loss2: (0.0000) | Acc: (78.00%) (5138/6528)
Epoch: 24 | Batch_idx: 60 |  Loss: (0.6223) |  Loss2: (0.0000) | Acc: (78.00%) (6131/7808)
Epoch: 24 | Batch_idx: 70 |  Loss: (0.6256) |  Loss2: (0.0000) | Acc: (78.00%) (7126/9088)
Epoch: 24 | Batch_idx: 80 |  Loss: (0.6254) |  Loss2: (0.0000) | Acc: (78.00%) (8145/10368)
Epoch: 24 | Batch_idx: 90 |  Loss: (0.6283) |  Loss2: (0.0000) | Acc: (78.00%) (9124/11648)
Epoch: 24 | Batch_idx: 100 |  Loss: (0.6298) |  Loss2: (0.0000) | Acc: (78.00%) (10123/12928)
Epoch: 24 | Batch_idx: 110 |  Loss: (0.6299) |  Loss2: (0.0000) | Acc: (78.00%) (11112/14208)
Epoch: 24 | Batch_idx: 120 |  Loss: (0.6293) |  Loss2: (0.0000) | Acc: (78.00%) (12114/15488)
Epoch: 24 | Batch_idx: 130 |  Loss: (0.6300) |  Loss2: (0.0000) | Acc: (78.00%) (13117/16768)
Epoch: 24 | Batch_idx: 140 |  Loss: (0.6309) |  Loss2: (0.0000) | Acc: (78.00%) (14096/18048)
Epoch: 24 | Batch_idx: 150 |  Loss: (0.6346) |  Loss2: (0.0000) | Acc: (77.00%) (15055/19328)
Epoch: 24 | Batch_idx: 160 |  Loss: (0.6358) |  Loss2: (0.0000) | Acc: (77.00%) (16041/20608)
Epoch: 24 | Batch_idx: 170 |  Loss: (0.6338) |  Loss2: (0.0000) | Acc: (77.00%) (17055/21888)
Epoch: 24 | Batch_idx: 180 |  Loss: (0.6346) |  Loss2: (0.0000) | Acc: (77.00%) (18038/23168)
Epoch: 24 | Batch_idx: 190 |  Loss: (0.6356) |  Loss2: (0.0000) | Acc: (77.00%) (19019/24448)
Epoch: 24 | Batch_idx: 200 |  Loss: (0.6339) |  Loss2: (0.0000) | Acc: (77.00%) (20023/25728)
Epoch: 24 | Batch_idx: 210 |  Loss: (0.6345) |  Loss2: (0.0000) | Acc: (77.00%) (21019/27008)
Epoch: 24 | Batch_idx: 220 |  Loss: (0.6341) |  Loss2: (0.0000) | Acc: (77.00%) (22023/28288)
Epoch: 24 | Batch_idx: 230 |  Loss: (0.6339) |  Loss2: (0.0000) | Acc: (77.00%) (23029/29568)
Epoch: 24 | Batch_idx: 240 |  Loss: (0.6330) |  Loss2: (0.0000) | Acc: (77.00%) (24043/30848)
Epoch: 24 | Batch_idx: 250 |  Loss: (0.6326) |  Loss2: (0.0000) | Acc: (77.00%) (25043/32128)
Epoch: 24 | Batch_idx: 260 |  Loss: (0.6325) |  Loss2: (0.0000) | Acc: (77.00%) (26045/33408)
Epoch: 24 | Batch_idx: 270 |  Loss: (0.6328) |  Loss2: (0.0000) | Acc: (77.00%) (27048/34688)
Epoch: 24 | Batch_idx: 280 |  Loss: (0.6314) |  Loss2: (0.0000) | Acc: (78.00%) (28067/35968)
Epoch: 24 | Batch_idx: 290 |  Loss: (0.6319) |  Loss2: (0.0000) | Acc: (77.00%) (29052/37248)
Epoch: 24 | Batch_idx: 300 |  Loss: (0.6304) |  Loss2: (0.0000) | Acc: (78.00%) (30074/38528)
Epoch: 24 | Batch_idx: 310 |  Loss: (0.6287) |  Loss2: (0.0000) | Acc: (78.00%) (31100/39808)
Epoch: 24 | Batch_idx: 320 |  Loss: (0.6280) |  Loss2: (0.0000) | Acc: (78.00%) (32111/41088)
Epoch: 24 | Batch_idx: 330 |  Loss: (0.6272) |  Loss2: (0.0000) | Acc: (78.00%) (33131/42368)
Epoch: 24 | Batch_idx: 340 |  Loss: (0.6265) |  Loss2: (0.0000) | Acc: (78.00%) (34132/43648)
Epoch: 24 | Batch_idx: 350 |  Loss: (0.6276) |  Loss2: (0.0000) | Acc: (78.00%) (35121/44928)
Epoch: 24 | Batch_idx: 360 |  Loss: (0.6261) |  Loss2: (0.0000) | Acc: (78.00%) (36151/46208)
Epoch: 24 | Batch_idx: 370 |  Loss: (0.6263) |  Loss2: (0.0000) | Acc: (78.00%) (37150/47488)
Epoch: 24 | Batch_idx: 380 |  Loss: (0.6260) |  Loss2: (0.0000) | Acc: (78.00%) (38150/48768)
Epoch: 24 | Batch_idx: 390 |  Loss: (0.6262) |  Loss2: (0.0000) | Acc: (78.00%) (39110/50000)
# TEST : Loss: (0.7331) | Acc: (74.00%) (7491/10000)
percent tensor([0.4999, 0.5140, 0.4980, 0.5039, 0.4997, 0.4986, 0.5095, 0.5070, 0.5075,
        0.5065, 0.5070, 0.4976, 0.5018, 0.5228, 0.5055, 0.5050],
       device='cuda:0') torch.Size([16])
percent tensor([0.4851, 0.4851, 0.4691, 0.4732, 0.4710, 0.4821, 0.4798, 0.4728, 0.4830,
        0.4818, 0.4861, 0.4749, 0.4846, 0.4863, 0.4801, 0.4819],
       device='cuda:0') torch.Size([16])
percent tensor([0.5360, 0.5510, 0.5273, 0.5397, 0.5385, 0.5328, 0.5514, 0.5429, 0.5327,
        0.5454, 0.5399, 0.5379, 0.5269, 0.5643, 0.5470, 0.5361],
       device='cuda:0') torch.Size([16])
percent tensor([0.5262, 0.5164, 0.5272, 0.5362, 0.5325, 0.5356, 0.5254, 0.5339, 0.5206,
        0.5165, 0.5138, 0.5244, 0.5126, 0.5236, 0.5290, 0.5299],
       device='cuda:0') torch.Size([16])
percent tensor([0.5051, 0.5080, 0.4885, 0.4861, 0.4850, 0.4972, 0.5015, 0.4881, 0.5024,
        0.5067, 0.5093, 0.4952, 0.5120, 0.5044, 0.5035, 0.5047],
       device='cuda:0') torch.Size([16])
percent tensor([0.5645, 0.5569, 0.6047, 0.6212, 0.5975, 0.5731, 0.5778, 0.5976, 0.5934,
        0.5598, 0.5795, 0.6126, 0.5576, 0.6019, 0.5587, 0.5655],
       device='cuda:0') torch.Size([16])
percent tensor([0.5101, 0.5112, 0.5585, 0.5570, 0.5505, 0.5147, 0.5259, 0.5728, 0.5222,
        0.5221, 0.5149, 0.5442, 0.5007, 0.5196, 0.5187, 0.5076],
       device='cuda:0') torch.Size([16])
percent tensor([0.9473, 0.9422, 0.9704, 0.9565, 0.9599, 0.9487, 0.9403, 0.9794, 0.9357,
        0.9572, 0.9582, 0.9667, 0.9308, 0.9299, 0.9468, 0.9527],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 25 | Batch_idx: 0 |  Loss: (0.7400) |  Loss2: (0.0000) | Acc: (78.00%) (100/128)
Epoch: 25 | Batch_idx: 10 |  Loss: (0.6325) |  Loss2: (0.0000) | Acc: (79.00%) (1117/1408)
Epoch: 25 | Batch_idx: 20 |  Loss: (0.6646) |  Loss2: (0.0000) | Acc: (77.00%) (2082/2688)
Epoch: 25 | Batch_idx: 30 |  Loss: (0.7027) |  Loss2: (0.0000) | Acc: (76.00%) (3021/3968)
Epoch: 25 | Batch_idx: 40 |  Loss: (0.7158) |  Loss2: (0.0000) | Acc: (75.00%) (3960/5248)
Epoch: 25 | Batch_idx: 50 |  Loss: (0.7289) |  Loss2: (0.0000) | Acc: (74.00%) (4885/6528)
Epoch: 25 | Batch_idx: 60 |  Loss: (0.7377) |  Loss2: (0.0000) | Acc: (74.00%) (5806/7808)
Epoch: 25 | Batch_idx: 70 |  Loss: (0.7410) |  Loss2: (0.0000) | Acc: (74.00%) (6757/9088)
Epoch: 25 | Batch_idx: 80 |  Loss: (0.7449) |  Loss2: (0.0000) | Acc: (74.00%) (7686/10368)
Epoch: 25 | Batch_idx: 90 |  Loss: (0.7453) |  Loss2: (0.0000) | Acc: (74.00%) (8640/11648)
Epoch: 25 | Batch_idx: 100 |  Loss: (0.7464) |  Loss2: (0.0000) | Acc: (74.00%) (9581/12928)
Epoch: 25 | Batch_idx: 110 |  Loss: (0.7461) |  Loss2: (0.0000) | Acc: (74.00%) (10530/14208)
Epoch: 25 | Batch_idx: 120 |  Loss: (0.7447) |  Loss2: (0.0000) | Acc: (73.00%) (11452/15488)
Epoch: 25 | Batch_idx: 130 |  Loss: (0.7478) |  Loss2: (0.0000) | Acc: (73.00%) (12401/16768)
Epoch: 25 | Batch_idx: 140 |  Loss: (0.7443) |  Loss2: (0.0000) | Acc: (74.00%) (13361/18048)
Epoch: 25 | Batch_idx: 150 |  Loss: (0.7414) |  Loss2: (0.0000) | Acc: (74.00%) (14328/19328)
Epoch: 25 | Batch_idx: 160 |  Loss: (0.7425) |  Loss2: (0.0000) | Acc: (74.00%) (15250/20608)
Epoch: 25 | Batch_idx: 170 |  Loss: (0.7410) |  Loss2: (0.0000) | Acc: (74.00%) (16221/21888)
Epoch: 25 | Batch_idx: 180 |  Loss: (0.7390) |  Loss2: (0.0000) | Acc: (74.00%) (17181/23168)
Epoch: 25 | Batch_idx: 190 |  Loss: (0.7357) |  Loss2: (0.0000) | Acc: (74.00%) (18160/24448)
Epoch: 25 | Batch_idx: 200 |  Loss: (0.7334) |  Loss2: (0.0000) | Acc: (74.00%) (19146/25728)
Epoch: 25 | Batch_idx: 210 |  Loss: (0.7313) |  Loss2: (0.0000) | Acc: (74.00%) (20137/27008)
Epoch: 25 | Batch_idx: 220 |  Loss: (0.7310) |  Loss2: (0.0000) | Acc: (74.00%) (21112/28288)
Epoch: 25 | Batch_idx: 230 |  Loss: (0.7289) |  Loss2: (0.0000) | Acc: (74.00%) (22086/29568)
Epoch: 25 | Batch_idx: 240 |  Loss: (0.7280) |  Loss2: (0.0000) | Acc: (74.00%) (23049/30848)
Epoch: 25 | Batch_idx: 250 |  Loss: (0.7267) |  Loss2: (0.0000) | Acc: (74.00%) (24011/32128)
Epoch: 25 | Batch_idx: 260 |  Loss: (0.7245) |  Loss2: (0.0000) | Acc: (74.00%) (24988/33408)
Epoch: 25 | Batch_idx: 270 |  Loss: (0.7219) |  Loss2: (0.0000) | Acc: (74.00%) (25966/34688)
Epoch: 25 | Batch_idx: 280 |  Loss: (0.7191) |  Loss2: (0.0000) | Acc: (74.00%) (26961/35968)
Epoch: 25 | Batch_idx: 290 |  Loss: (0.7190) |  Loss2: (0.0000) | Acc: (74.00%) (27929/37248)
Epoch: 25 | Batch_idx: 300 |  Loss: (0.7178) |  Loss2: (0.0000) | Acc: (75.00%) (28899/38528)
Epoch: 25 | Batch_idx: 310 |  Loss: (0.7187) |  Loss2: (0.0000) | Acc: (75.00%) (29858/39808)
Epoch: 25 | Batch_idx: 320 |  Loss: (0.7173) |  Loss2: (0.0000) | Acc: (75.00%) (30824/41088)
Epoch: 25 | Batch_idx: 330 |  Loss: (0.7173) |  Loss2: (0.0000) | Acc: (75.00%) (31792/42368)
Epoch: 25 | Batch_idx: 340 |  Loss: (0.7168) |  Loss2: (0.0000) | Acc: (75.00%) (32753/43648)
Epoch: 25 | Batch_idx: 350 |  Loss: (0.7154) |  Loss2: (0.0000) | Acc: (75.00%) (33725/44928)
Epoch: 25 | Batch_idx: 360 |  Loss: (0.7147) |  Loss2: (0.0000) | Acc: (75.00%) (34709/46208)
Epoch: 25 | Batch_idx: 370 |  Loss: (0.7145) |  Loss2: (0.0000) | Acc: (75.00%) (35681/47488)
Epoch: 25 | Batch_idx: 380 |  Loss: (0.7119) |  Loss2: (0.0000) | Acc: (75.00%) (36701/48768)
Epoch: 25 | Batch_idx: 390 |  Loss: (0.7107) |  Loss2: (0.0000) | Acc: (75.00%) (37631/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_025.pth.tar'
# TEST : Loss: (0.7091) | Acc: (75.00%) (7576/10000)
percent tensor([0.5213, 0.5418, 0.5214, 0.5253, 0.5259, 0.5188, 0.5381, 0.5333, 0.5335,
        0.5319, 0.5318, 0.5226, 0.5237, 0.5514, 0.5294, 0.5272],
       device='cuda:0') torch.Size([16])
percent tensor([0.4943, 0.4949, 0.4818, 0.4855, 0.4837, 0.4909, 0.4905, 0.4845, 0.4937,
        0.4917, 0.4959, 0.4864, 0.4945, 0.4955, 0.4907, 0.4927],
       device='cuda:0') torch.Size([16])
percent tensor([0.5485, 0.5838, 0.5487, 0.5536, 0.5647, 0.5392, 0.5860, 0.5699, 0.5523,
        0.5747, 0.5616, 0.5663, 0.5404, 0.5999, 0.5709, 0.5510],
       device='cuda:0') torch.Size([16])
percent tensor([0.5471, 0.5407, 0.5375, 0.5507, 0.5504, 0.5581, 0.5521, 0.5520, 0.5372,
        0.5383, 0.5353, 0.5387, 0.5332, 0.5468, 0.5536, 0.5532],
       device='cuda:0') torch.Size([16])
percent tensor([0.4979, 0.4978, 0.4875, 0.4847, 0.4840, 0.4963, 0.4943, 0.4834, 0.4968,
        0.4970, 0.4995, 0.4898, 0.5000, 0.4975, 0.4931, 0.4972],
       device='cuda:0') torch.Size([16])
percent tensor([0.5685, 0.5674, 0.6130, 0.6310, 0.6049, 0.5805, 0.5916, 0.6095, 0.6038,
        0.5696, 0.5933, 0.6286, 0.5609, 0.6165, 0.5699, 0.5696],
       device='cuda:0') torch.Size([16])
percent tensor([0.5008, 0.4975, 0.5329, 0.5338, 0.5273, 0.5035, 0.5087, 0.5336, 0.5135,
        0.5077, 0.5045, 0.5267, 0.4927, 0.5125, 0.5007, 0.4987],
       device='cuda:0') torch.Size([16])
percent tensor([0.9597, 0.9620, 0.9752, 0.9637, 0.9750, 0.9611, 0.9621, 0.9861, 0.9564,
        0.9739, 0.9755, 0.9773, 0.9486, 0.9551, 0.9666, 0.9673],
       device='cuda:0') torch.Size([16])
Epoch: 26 | Batch_idx: 0 |  Loss: (0.6229) |  Loss2: (0.0000) | Acc: (78.00%) (100/128)
Epoch: 26 | Batch_idx: 10 |  Loss: (0.7087) |  Loss2: (0.0000) | Acc: (75.00%) (1066/1408)
Epoch: 26 | Batch_idx: 20 |  Loss: (0.6762) |  Loss2: (0.0000) | Acc: (76.00%) (2050/2688)
Epoch: 26 | Batch_idx: 30 |  Loss: (0.6646) |  Loss2: (0.0000) | Acc: (76.00%) (3050/3968)
Epoch: 26 | Batch_idx: 40 |  Loss: (0.6606) |  Loss2: (0.0000) | Acc: (76.00%) (4028/5248)
Epoch: 26 | Batch_idx: 50 |  Loss: (0.6609) |  Loss2: (0.0000) | Acc: (76.00%) (5001/6528)
Epoch: 26 | Batch_idx: 60 |  Loss: (0.6624) |  Loss2: (0.0000) | Acc: (76.00%) (5979/7808)
Epoch: 26 | Batch_idx: 70 |  Loss: (0.6619) |  Loss2: (0.0000) | Acc: (76.00%) (6963/9088)
Epoch: 26 | Batch_idx: 80 |  Loss: (0.6586) |  Loss2: (0.0000) | Acc: (76.00%) (7962/10368)
Epoch: 26 | Batch_idx: 90 |  Loss: (0.6568) |  Loss2: (0.0000) | Acc: (76.00%) (8966/11648)
Epoch: 26 | Batch_idx: 100 |  Loss: (0.6547) |  Loss2: (0.0000) | Acc: (77.00%) (9969/12928)
Epoch: 26 | Batch_idx: 110 |  Loss: (0.6566) |  Loss2: (0.0000) | Acc: (77.00%) (10951/14208)
Epoch: 26 | Batch_idx: 120 |  Loss: (0.6534) |  Loss2: (0.0000) | Acc: (77.00%) (11958/15488)
Epoch: 26 | Batch_idx: 130 |  Loss: (0.6507) |  Loss2: (0.0000) | Acc: (77.00%) (12974/16768)
Epoch: 26 | Batch_idx: 140 |  Loss: (0.6522) |  Loss2: (0.0000) | Acc: (77.00%) (13959/18048)
Epoch: 26 | Batch_idx: 150 |  Loss: (0.6514) |  Loss2: (0.0000) | Acc: (77.00%) (14957/19328)
Epoch: 26 | Batch_idx: 160 |  Loss: (0.6502) |  Loss2: (0.0000) | Acc: (77.00%) (15957/20608)
Epoch: 26 | Batch_idx: 170 |  Loss: (0.6497) |  Loss2: (0.0000) | Acc: (77.00%) (16941/21888)
Epoch: 26 | Batch_idx: 180 |  Loss: (0.6489) |  Loss2: (0.0000) | Acc: (77.00%) (17940/23168)
Epoch: 26 | Batch_idx: 190 |  Loss: (0.6480) |  Loss2: (0.0000) | Acc: (77.00%) (18937/24448)
Epoch: 26 | Batch_idx: 200 |  Loss: (0.6473) |  Loss2: (0.0000) | Acc: (77.00%) (19939/25728)
Epoch: 26 | Batch_idx: 210 |  Loss: (0.6490) |  Loss2: (0.0000) | Acc: (77.00%) (20912/27008)
Epoch: 26 | Batch_idx: 220 |  Loss: (0.6494) |  Loss2: (0.0000) | Acc: (77.00%) (21911/28288)
Epoch: 26 | Batch_idx: 230 |  Loss: (0.6475) |  Loss2: (0.0000) | Acc: (77.00%) (22903/29568)
Epoch: 26 | Batch_idx: 240 |  Loss: (0.6469) |  Loss2: (0.0000) | Acc: (77.00%) (23906/30848)
Epoch: 26 | Batch_idx: 250 |  Loss: (0.6479) |  Loss2: (0.0000) | Acc: (77.00%) (24890/32128)
Epoch: 26 | Batch_idx: 260 |  Loss: (0.6466) |  Loss2: (0.0000) | Acc: (77.00%) (25901/33408)
Epoch: 26 | Batch_idx: 270 |  Loss: (0.6465) |  Loss2: (0.0000) | Acc: (77.00%) (26909/34688)
Epoch: 26 | Batch_idx: 280 |  Loss: (0.6463) |  Loss2: (0.0000) | Acc: (77.00%) (27921/35968)
Epoch: 26 | Batch_idx: 290 |  Loss: (0.6457) |  Loss2: (0.0000) | Acc: (77.00%) (28914/37248)
Epoch: 26 | Batch_idx: 300 |  Loss: (0.6454) |  Loss2: (0.0000) | Acc: (77.00%) (29910/38528)
Epoch: 26 | Batch_idx: 310 |  Loss: (0.6447) |  Loss2: (0.0000) | Acc: (77.00%) (30912/39808)
Epoch: 26 | Batch_idx: 320 |  Loss: (0.6445) |  Loss2: (0.0000) | Acc: (77.00%) (31914/41088)
Epoch: 26 | Batch_idx: 330 |  Loss: (0.6441) |  Loss2: (0.0000) | Acc: (77.00%) (32918/42368)
Epoch: 26 | Batch_idx: 340 |  Loss: (0.6443) |  Loss2: (0.0000) | Acc: (77.00%) (33912/43648)
Epoch: 26 | Batch_idx: 350 |  Loss: (0.6433) |  Loss2: (0.0000) | Acc: (77.00%) (34922/44928)
Epoch: 26 | Batch_idx: 360 |  Loss: (0.6429) |  Loss2: (0.0000) | Acc: (77.00%) (35923/46208)
Epoch: 26 | Batch_idx: 370 |  Loss: (0.6416) |  Loss2: (0.0000) | Acc: (77.00%) (36935/47488)
Epoch: 26 | Batch_idx: 380 |  Loss: (0.6402) |  Loss2: (0.0000) | Acc: (77.00%) (37949/48768)
Epoch: 26 | Batch_idx: 390 |  Loss: (0.6408) |  Loss2: (0.0000) | Acc: (77.00%) (38887/50000)
# TEST : Loss: (0.6734) | Acc: (76.00%) (7687/10000)
percent tensor([0.5209, 0.5401, 0.5223, 0.5249, 0.5262, 0.5183, 0.5372, 0.5326, 0.5324,
        0.5313, 0.5306, 0.5235, 0.5232, 0.5488, 0.5284, 0.5262],
       device='cuda:0') torch.Size([16])
percent tensor([0.4957, 0.4954, 0.4833, 0.4870, 0.4850, 0.4925, 0.4910, 0.4856, 0.4947,
        0.4921, 0.4964, 0.4872, 0.4954, 0.4961, 0.4914, 0.4938],
       device='cuda:0') torch.Size([16])
percent tensor([0.5437, 0.5769, 0.5454, 0.5525, 0.5610, 0.5411, 0.5810, 0.5673, 0.5458,
        0.5671, 0.5526, 0.5608, 0.5341, 0.5936, 0.5681, 0.5480],
       device='cuda:0') torch.Size([16])
percent tensor([0.5580, 0.5509, 0.5437, 0.5570, 0.5600, 0.5709, 0.5636, 0.5598, 0.5436,
        0.5476, 0.5443, 0.5449, 0.5427, 0.5553, 0.5663, 0.5648],
       device='cuda:0') torch.Size([16])
percent tensor([0.4982, 0.4958, 0.4899, 0.4871, 0.4865, 0.4998, 0.4937, 0.4846, 0.4966,
        0.4954, 0.4976, 0.4894, 0.4978, 0.4969, 0.4921, 0.4978],
       device='cuda:0') torch.Size([16])
percent tensor([0.5877, 0.5838, 0.6246, 0.6516, 0.6201, 0.6029, 0.6109, 0.6247, 0.6218,
        0.5855, 0.6137, 0.6462, 0.5793, 0.6400, 0.5898, 0.5894],
       device='cuda:0') torch.Size([16])
percent tensor([0.5061, 0.5000, 0.5329, 0.5363, 0.5260, 0.5088, 0.5105, 0.5291, 0.5169,
        0.5096, 0.5083, 0.5274, 0.4954, 0.5195, 0.4997, 0.5019],
       device='cuda:0') torch.Size([16])
percent tensor([0.9773, 0.9755, 0.9848, 0.9777, 0.9845, 0.9764, 0.9779, 0.9917, 0.9718,
        0.9847, 0.9854, 0.9862, 0.9679, 0.9728, 0.9810, 0.9828],
       device='cuda:0') torch.Size([16])
Epoch: 27 | Batch_idx: 0 |  Loss: (0.6391) |  Loss2: (0.0000) | Acc: (74.00%) (95/128)
Epoch: 27 | Batch_idx: 10 |  Loss: (0.6023) |  Loss2: (0.0000) | Acc: (78.00%) (1112/1408)
Epoch: 27 | Batch_idx: 20 |  Loss: (0.6084) |  Loss2: (0.0000) | Acc: (78.00%) (2120/2688)
Epoch: 27 | Batch_idx: 30 |  Loss: (0.6281) |  Loss2: (0.0000) | Acc: (78.00%) (3107/3968)
Epoch: 27 | Batch_idx: 40 |  Loss: (0.6232) |  Loss2: (0.0000) | Acc: (78.00%) (4109/5248)
Epoch: 27 | Batch_idx: 50 |  Loss: (0.6248) |  Loss2: (0.0000) | Acc: (78.00%) (5121/6528)
Epoch: 27 | Batch_idx: 60 |  Loss: (0.6222) |  Loss2: (0.0000) | Acc: (78.00%) (6109/7808)
Epoch: 27 | Batch_idx: 70 |  Loss: (0.6258) |  Loss2: (0.0000) | Acc: (78.00%) (7108/9088)
Epoch: 27 | Batch_idx: 80 |  Loss: (0.6203) |  Loss2: (0.0000) | Acc: (78.00%) (8136/10368)
Epoch: 27 | Batch_idx: 90 |  Loss: (0.6246) |  Loss2: (0.0000) | Acc: (78.00%) (9119/11648)
Epoch: 27 | Batch_idx: 100 |  Loss: (0.6210) |  Loss2: (0.0000) | Acc: (78.00%) (10121/12928)
Epoch: 27 | Batch_idx: 110 |  Loss: (0.6245) |  Loss2: (0.0000) | Acc: (78.00%) (11109/14208)
Epoch: 27 | Batch_idx: 120 |  Loss: (0.6245) |  Loss2: (0.0000) | Acc: (78.00%) (12110/15488)
Epoch: 27 | Batch_idx: 130 |  Loss: (0.6220) |  Loss2: (0.0000) | Acc: (78.00%) (13132/16768)
Epoch: 27 | Batch_idx: 140 |  Loss: (0.6223) |  Loss2: (0.0000) | Acc: (78.00%) (14131/18048)
Epoch: 27 | Batch_idx: 150 |  Loss: (0.6230) |  Loss2: (0.0000) | Acc: (78.00%) (15138/19328)
Epoch: 27 | Batch_idx: 160 |  Loss: (0.6229) |  Loss2: (0.0000) | Acc: (78.00%) (16162/20608)
Epoch: 27 | Batch_idx: 170 |  Loss: (0.6237) |  Loss2: (0.0000) | Acc: (78.00%) (17151/21888)
Epoch: 27 | Batch_idx: 180 |  Loss: (0.6246) |  Loss2: (0.0000) | Acc: (78.00%) (18146/23168)
Epoch: 27 | Batch_idx: 190 |  Loss: (0.6246) |  Loss2: (0.0000) | Acc: (78.00%) (19140/24448)
Epoch: 27 | Batch_idx: 200 |  Loss: (0.6245) |  Loss2: (0.0000) | Acc: (78.00%) (20147/25728)
Epoch: 27 | Batch_idx: 210 |  Loss: (0.6228) |  Loss2: (0.0000) | Acc: (78.00%) (21157/27008)
Epoch: 27 | Batch_idx: 220 |  Loss: (0.6248) |  Loss2: (0.0000) | Acc: (78.00%) (22136/28288)
Epoch: 27 | Batch_idx: 230 |  Loss: (0.6237) |  Loss2: (0.0000) | Acc: (78.00%) (23155/29568)
Epoch: 27 | Batch_idx: 240 |  Loss: (0.6244) |  Loss2: (0.0000) | Acc: (78.00%) (24157/30848)
Epoch: 27 | Batch_idx: 250 |  Loss: (0.6243) |  Loss2: (0.0000) | Acc: (78.00%) (25154/32128)
Epoch: 27 | Batch_idx: 260 |  Loss: (0.6239) |  Loss2: (0.0000) | Acc: (78.00%) (26156/33408)
Epoch: 27 | Batch_idx: 270 |  Loss: (0.6229) |  Loss2: (0.0000) | Acc: (78.00%) (27174/34688)
Epoch: 27 | Batch_idx: 280 |  Loss: (0.6215) |  Loss2: (0.0000) | Acc: (78.00%) (28204/35968)
Epoch: 27 | Batch_idx: 290 |  Loss: (0.6217) |  Loss2: (0.0000) | Acc: (78.00%) (29199/37248)
Epoch: 27 | Batch_idx: 300 |  Loss: (0.6225) |  Loss2: (0.0000) | Acc: (78.00%) (30195/38528)
Epoch: 27 | Batch_idx: 310 |  Loss: (0.6226) |  Loss2: (0.0000) | Acc: (78.00%) (31180/39808)
Epoch: 27 | Batch_idx: 320 |  Loss: (0.6224) |  Loss2: (0.0000) | Acc: (78.00%) (32187/41088)
Epoch: 27 | Batch_idx: 330 |  Loss: (0.6221) |  Loss2: (0.0000) | Acc: (78.00%) (33196/42368)
Epoch: 27 | Batch_idx: 340 |  Loss: (0.6221) |  Loss2: (0.0000) | Acc: (78.00%) (34205/43648)
Epoch: 27 | Batch_idx: 350 |  Loss: (0.6229) |  Loss2: (0.0000) | Acc: (78.00%) (35189/44928)
Epoch: 27 | Batch_idx: 360 |  Loss: (0.6218) |  Loss2: (0.0000) | Acc: (78.00%) (36217/46208)
Epoch: 27 | Batch_idx: 370 |  Loss: (0.6207) |  Loss2: (0.0000) | Acc: (78.00%) (37251/47488)
Epoch: 27 | Batch_idx: 380 |  Loss: (0.6202) |  Loss2: (0.0000) | Acc: (78.00%) (38267/48768)
Epoch: 27 | Batch_idx: 390 |  Loss: (0.6211) |  Loss2: (0.0000) | Acc: (78.00%) (39213/50000)
# TEST : Loss: (0.6573) | Acc: (77.00%) (7751/10000)
percent tensor([0.5199, 0.5376, 0.5220, 0.5238, 0.5253, 0.5174, 0.5354, 0.5310, 0.5306,
        0.5298, 0.5288, 0.5231, 0.5221, 0.5456, 0.5269, 0.5248],
       device='cuda:0') torch.Size([16])
percent tensor([0.4957, 0.4946, 0.4830, 0.4871, 0.4846, 0.4927, 0.4901, 0.4852, 0.4941,
        0.4913, 0.4958, 0.4864, 0.4949, 0.4955, 0.4910, 0.4935],
       device='cuda:0') torch.Size([16])
percent tensor([0.5421, 0.5707, 0.5460, 0.5560, 0.5603, 0.5465, 0.5770, 0.5674, 0.5420,
        0.5608, 0.5454, 0.5579, 0.5297, 0.5889, 0.5672, 0.5477],
       device='cuda:0') torch.Size([16])
percent tensor([0.5600, 0.5521, 0.5423, 0.5548, 0.5602, 0.5750, 0.5648, 0.5587, 0.5423,
        0.5483, 0.5448, 0.5431, 0.5437, 0.5552, 0.5686, 0.5674],
       device='cuda:0') torch.Size([16])
percent tensor([0.4998, 0.4956, 0.4921, 0.4893, 0.4888, 0.5032, 0.4944, 0.4861, 0.4974,
        0.4953, 0.4974, 0.4895, 0.4976, 0.4974, 0.4927, 0.4996],
       device='cuda:0') torch.Size([16])
percent tensor([0.6019, 0.5966, 0.6364, 0.6674, 0.6320, 0.6195, 0.6242, 0.6348, 0.6364,
        0.5988, 0.6295, 0.6607, 0.5944, 0.6576, 0.6028, 0.6039],
       device='cuda:0') torch.Size([16])
percent tensor([0.5156, 0.5051, 0.5414, 0.5466, 0.5327, 0.5194, 0.5167, 0.5333, 0.5248,
        0.5157, 0.5164, 0.5355, 0.4998, 0.5293, 0.5028, 0.5088],
       device='cuda:0') torch.Size([16])
percent tensor([0.9862, 0.9837, 0.9899, 0.9851, 0.9896, 0.9848, 0.9858, 0.9947, 0.9815,
        0.9903, 0.9910, 0.9910, 0.9788, 0.9825, 0.9877, 0.9898],
       device='cuda:0') torch.Size([16])
Epoch: 28 | Batch_idx: 0 |  Loss: (0.4622) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 28 | Batch_idx: 10 |  Loss: (0.5925) |  Loss2: (0.0000) | Acc: (80.00%) (1128/1408)
Epoch: 28 | Batch_idx: 20 |  Loss: (0.6171) |  Loss2: (0.0000) | Acc: (78.00%) (2120/2688)
Epoch: 28 | Batch_idx: 30 |  Loss: (0.6118) |  Loss2: (0.0000) | Acc: (79.00%) (3141/3968)
Epoch: 28 | Batch_idx: 40 |  Loss: (0.6146) |  Loss2: (0.0000) | Acc: (78.00%) (4128/5248)
Epoch: 28 | Batch_idx: 50 |  Loss: (0.6137) |  Loss2: (0.0000) | Acc: (78.00%) (5130/6528)
Epoch: 28 | Batch_idx: 60 |  Loss: (0.6134) |  Loss2: (0.0000) | Acc: (78.00%) (6144/7808)
Epoch: 28 | Batch_idx: 70 |  Loss: (0.6106) |  Loss2: (0.0000) | Acc: (78.00%) (7166/9088)
Epoch: 28 | Batch_idx: 80 |  Loss: (0.6118) |  Loss2: (0.0000) | Acc: (78.00%) (8180/10368)
Epoch: 28 | Batch_idx: 90 |  Loss: (0.6125) |  Loss2: (0.0000) | Acc: (78.00%) (9178/11648)
Epoch: 28 | Batch_idx: 100 |  Loss: (0.6111) |  Loss2: (0.0000) | Acc: (78.00%) (10204/12928)
Epoch: 28 | Batch_idx: 110 |  Loss: (0.6132) |  Loss2: (0.0000) | Acc: (78.00%) (11190/14208)
Epoch: 28 | Batch_idx: 120 |  Loss: (0.6136) |  Loss2: (0.0000) | Acc: (78.00%) (12188/15488)
Epoch: 28 | Batch_idx: 130 |  Loss: (0.6131) |  Loss2: (0.0000) | Acc: (78.00%) (13202/16768)
Epoch: 28 | Batch_idx: 140 |  Loss: (0.6144) |  Loss2: (0.0000) | Acc: (78.00%) (14215/18048)
Epoch: 28 | Batch_idx: 150 |  Loss: (0.6160) |  Loss2: (0.0000) | Acc: (78.00%) (15219/19328)
Epoch: 28 | Batch_idx: 160 |  Loss: (0.6154) |  Loss2: (0.0000) | Acc: (78.00%) (16238/20608)
Epoch: 28 | Batch_idx: 170 |  Loss: (0.6151) |  Loss2: (0.0000) | Acc: (78.00%) (17232/21888)
Epoch: 28 | Batch_idx: 180 |  Loss: (0.6129) |  Loss2: (0.0000) | Acc: (78.00%) (18258/23168)
Epoch: 28 | Batch_idx: 190 |  Loss: (0.6119) |  Loss2: (0.0000) | Acc: (78.00%) (19281/24448)
Epoch: 28 | Batch_idx: 200 |  Loss: (0.6119) |  Loss2: (0.0000) | Acc: (78.00%) (20282/25728)
Epoch: 28 | Batch_idx: 210 |  Loss: (0.6115) |  Loss2: (0.0000) | Acc: (78.00%) (21298/27008)
Epoch: 28 | Batch_idx: 220 |  Loss: (0.6109) |  Loss2: (0.0000) | Acc: (78.00%) (22330/28288)
Epoch: 28 | Batch_idx: 230 |  Loss: (0.6112) |  Loss2: (0.0000) | Acc: (78.00%) (23332/29568)
Epoch: 28 | Batch_idx: 240 |  Loss: (0.6111) |  Loss2: (0.0000) | Acc: (78.00%) (24321/30848)
Epoch: 28 | Batch_idx: 250 |  Loss: (0.6109) |  Loss2: (0.0000) | Acc: (78.00%) (25321/32128)
Epoch: 28 | Batch_idx: 260 |  Loss: (0.6100) |  Loss2: (0.0000) | Acc: (78.00%) (26347/33408)
Epoch: 28 | Batch_idx: 270 |  Loss: (0.6109) |  Loss2: (0.0000) | Acc: (78.00%) (27343/34688)
Epoch: 28 | Batch_idx: 280 |  Loss: (0.6112) |  Loss2: (0.0000) | Acc: (78.00%) (28341/35968)
Epoch: 28 | Batch_idx: 290 |  Loss: (0.6112) |  Loss2: (0.0000) | Acc: (78.00%) (29340/37248)
Epoch: 28 | Batch_idx: 300 |  Loss: (0.6122) |  Loss2: (0.0000) | Acc: (78.00%) (30326/38528)
Epoch: 28 | Batch_idx: 310 |  Loss: (0.6121) |  Loss2: (0.0000) | Acc: (78.00%) (31331/39808)
Epoch: 28 | Batch_idx: 320 |  Loss: (0.6115) |  Loss2: (0.0000) | Acc: (78.00%) (32348/41088)
Epoch: 28 | Batch_idx: 330 |  Loss: (0.6116) |  Loss2: (0.0000) | Acc: (78.00%) (33359/42368)
Epoch: 28 | Batch_idx: 340 |  Loss: (0.6117) |  Loss2: (0.0000) | Acc: (78.00%) (34364/43648)
Epoch: 28 | Batch_idx: 350 |  Loss: (0.6108) |  Loss2: (0.0000) | Acc: (78.00%) (35394/44928)
Epoch: 28 | Batch_idx: 360 |  Loss: (0.6118) |  Loss2: (0.0000) | Acc: (78.00%) (36387/46208)
Epoch: 28 | Batch_idx: 370 |  Loss: (0.6119) |  Loss2: (0.0000) | Acc: (78.00%) (37385/47488)
Epoch: 28 | Batch_idx: 380 |  Loss: (0.6112) |  Loss2: (0.0000) | Acc: (78.00%) (38409/48768)
Epoch: 28 | Batch_idx: 390 |  Loss: (0.6105) |  Loss2: (0.0000) | Acc: (78.00%) (39396/50000)
# TEST : Loss: (0.6463) | Acc: (77.00%) (7776/10000)
percent tensor([0.5182, 0.5350, 0.5205, 0.5220, 0.5234, 0.5159, 0.5329, 0.5289, 0.5281,
        0.5278, 0.5265, 0.5217, 0.5204, 0.5423, 0.5250, 0.5230],
       device='cuda:0') torch.Size([16])
percent tensor([0.4949, 0.4933, 0.4818, 0.4862, 0.4833, 0.4920, 0.4886, 0.4839, 0.4929,
        0.4899, 0.4945, 0.4850, 0.4938, 0.4945, 0.4897, 0.4926],
       device='cuda:0') torch.Size([16])
percent tensor([0.5432, 0.5705, 0.5468, 0.5586, 0.5614, 0.5519, 0.5781, 0.5694, 0.5403,
        0.5592, 0.5427, 0.5572, 0.5288, 0.5890, 0.5699, 0.5501],
       device='cuda:0') torch.Size([16])
percent tensor([0.5657, 0.5571, 0.5456, 0.5575, 0.5653, 0.5826, 0.5704, 0.5628, 0.5449,
        0.5529, 0.5487, 0.5461, 0.5486, 0.5584, 0.5751, 0.5739],
       device='cuda:0') torch.Size([16])
percent tensor([0.5028, 0.4974, 0.4959, 0.4933, 0.4926, 0.5076, 0.4968, 0.4899, 0.4996,
        0.4970, 0.4986, 0.4916, 0.4993, 0.4991, 0.4957, 0.5030],
       device='cuda:0') torch.Size([16])
percent tensor([0.6083, 0.6019, 0.6387, 0.6711, 0.6358, 0.6276, 0.6296, 0.6370, 0.6420,
        0.6028, 0.6367, 0.6653, 0.6020, 0.6644, 0.6087, 0.6095],
       device='cuda:0') torch.Size([16])
percent tensor([0.5246, 0.5101, 0.5491, 0.5556, 0.5395, 0.5296, 0.5225, 0.5377, 0.5322,
        0.5217, 0.5234, 0.5427, 0.5045, 0.5385, 0.5054, 0.5152],
       device='cuda:0') torch.Size([16])
percent tensor([0.9899, 0.9876, 0.9927, 0.9886, 0.9925, 0.9885, 0.9896, 0.9963, 0.9863,
        0.9932, 0.9934, 0.9934, 0.9844, 0.9869, 0.9913, 0.9929],
       device='cuda:0') torch.Size([16])
Epoch: 29 | Batch_idx: 0 |  Loss: (0.6534) |  Loss2: (0.0000) | Acc: (74.00%) (95/128)
Epoch: 29 | Batch_idx: 10 |  Loss: (0.6021) |  Loss2: (0.0000) | Acc: (78.00%) (1105/1408)
Epoch: 29 | Batch_idx: 20 |  Loss: (0.6193) |  Loss2: (0.0000) | Acc: (78.00%) (2109/2688)
Epoch: 29 | Batch_idx: 30 |  Loss: (0.6150) |  Loss2: (0.0000) | Acc: (78.00%) (3116/3968)
Epoch: 29 | Batch_idx: 40 |  Loss: (0.6035) |  Loss2: (0.0000) | Acc: (78.00%) (4132/5248)
Epoch: 29 | Batch_idx: 50 |  Loss: (0.6067) |  Loss2: (0.0000) | Acc: (78.00%) (5145/6528)
Epoch: 29 | Batch_idx: 60 |  Loss: (0.6112) |  Loss2: (0.0000) | Acc: (78.00%) (6149/7808)
Epoch: 29 | Batch_idx: 70 |  Loss: (0.6060) |  Loss2: (0.0000) | Acc: (79.00%) (7184/9088)
Epoch: 29 | Batch_idx: 80 |  Loss: (0.6105) |  Loss2: (0.0000) | Acc: (79.00%) (8197/10368)
Epoch: 29 | Batch_idx: 90 |  Loss: (0.6122) |  Loss2: (0.0000) | Acc: (78.00%) (9195/11648)
Epoch: 29 | Batch_idx: 100 |  Loss: (0.6120) |  Loss2: (0.0000) | Acc: (78.00%) (10198/12928)
Epoch: 29 | Batch_idx: 110 |  Loss: (0.6098) |  Loss2: (0.0000) | Acc: (78.00%) (11210/14208)
Epoch: 29 | Batch_idx: 120 |  Loss: (0.6091) |  Loss2: (0.0000) | Acc: (78.00%) (12227/15488)
Epoch: 29 | Batch_idx: 130 |  Loss: (0.6107) |  Loss2: (0.0000) | Acc: (78.00%) (13225/16768)
Epoch: 29 | Batch_idx: 140 |  Loss: (0.6105) |  Loss2: (0.0000) | Acc: (78.00%) (14255/18048)
Epoch: 29 | Batch_idx: 150 |  Loss: (0.6102) |  Loss2: (0.0000) | Acc: (78.00%) (15260/19328)
Epoch: 29 | Batch_idx: 160 |  Loss: (0.6103) |  Loss2: (0.0000) | Acc: (78.00%) (16266/20608)
Epoch: 29 | Batch_idx: 170 |  Loss: (0.6094) |  Loss2: (0.0000) | Acc: (78.00%) (17282/21888)
Epoch: 29 | Batch_idx: 180 |  Loss: (0.6083) |  Loss2: (0.0000) | Acc: (78.00%) (18299/23168)
Epoch: 29 | Batch_idx: 190 |  Loss: (0.6078) |  Loss2: (0.0000) | Acc: (79.00%) (19319/24448)
Epoch: 29 | Batch_idx: 200 |  Loss: (0.6076) |  Loss2: (0.0000) | Acc: (79.00%) (20328/25728)
Epoch: 29 | Batch_idx: 210 |  Loss: (0.6080) |  Loss2: (0.0000) | Acc: (79.00%) (21340/27008)
Epoch: 29 | Batch_idx: 220 |  Loss: (0.6096) |  Loss2: (0.0000) | Acc: (78.00%) (22336/28288)
Epoch: 29 | Batch_idx: 230 |  Loss: (0.6108) |  Loss2: (0.0000) | Acc: (78.00%) (23326/29568)
Epoch: 29 | Batch_idx: 240 |  Loss: (0.6110) |  Loss2: (0.0000) | Acc: (78.00%) (24327/30848)
Epoch: 29 | Batch_idx: 250 |  Loss: (0.6108) |  Loss2: (0.0000) | Acc: (78.00%) (25334/32128)
Epoch: 29 | Batch_idx: 260 |  Loss: (0.6094) |  Loss2: (0.0000) | Acc: (78.00%) (26374/33408)
Epoch: 29 | Batch_idx: 270 |  Loss: (0.6083) |  Loss2: (0.0000) | Acc: (78.00%) (27402/34688)
Epoch: 29 | Batch_idx: 280 |  Loss: (0.6084) |  Loss2: (0.0000) | Acc: (78.00%) (28402/35968)
Epoch: 29 | Batch_idx: 290 |  Loss: (0.6086) |  Loss2: (0.0000) | Acc: (78.00%) (29403/37248)
Epoch: 29 | Batch_idx: 300 |  Loss: (0.6081) |  Loss2: (0.0000) | Acc: (78.00%) (30419/38528)
Epoch: 29 | Batch_idx: 310 |  Loss: (0.6070) |  Loss2: (0.0000) | Acc: (78.00%) (31435/39808)
Epoch: 29 | Batch_idx: 320 |  Loss: (0.6073) |  Loss2: (0.0000) | Acc: (78.00%) (32452/41088)
Epoch: 29 | Batch_idx: 330 |  Loss: (0.6071) |  Loss2: (0.0000) | Acc: (79.00%) (33471/42368)
Epoch: 29 | Batch_idx: 340 |  Loss: (0.6077) |  Loss2: (0.0000) | Acc: (78.00%) (34459/43648)
Epoch: 29 | Batch_idx: 350 |  Loss: (0.6059) |  Loss2: (0.0000) | Acc: (79.00%) (35499/44928)
Epoch: 29 | Batch_idx: 360 |  Loss: (0.6065) |  Loss2: (0.0000) | Acc: (78.00%) (36498/46208)
Epoch: 29 | Batch_idx: 370 |  Loss: (0.6060) |  Loss2: (0.0000) | Acc: (78.00%) (37511/47488)
Epoch: 29 | Batch_idx: 380 |  Loss: (0.6067) |  Loss2: (0.0000) | Acc: (78.00%) (38514/48768)
Epoch: 29 | Batch_idx: 390 |  Loss: (0.6064) |  Loss2: (0.0000) | Acc: (78.00%) (39478/50000)
# TEST : Loss: (0.6413) | Acc: (77.00%) (7789/10000)
percent tensor([0.5194, 0.5369, 0.5220, 0.5234, 0.5250, 0.5170, 0.5348, 0.5305, 0.5294,
        0.5294, 0.5279, 0.5234, 0.5217, 0.5441, 0.5266, 0.5243],
       device='cuda:0') torch.Size([16])
percent tensor([0.4944, 0.4925, 0.4809, 0.4858, 0.4823, 0.4916, 0.4875, 0.4830, 0.4922,
        0.4890, 0.4938, 0.4841, 0.4932, 0.4939, 0.4889, 0.4920],
       device='cuda:0') torch.Size([16])
percent tensor([0.5422, 0.5669, 0.5453, 0.5588, 0.5595, 0.5559, 0.5760, 0.5678, 0.5367,
        0.5545, 0.5381, 0.5537, 0.5256, 0.5867, 0.5693, 0.5498],
       device='cuda:0') torch.Size([16])
percent tensor([0.5672, 0.5575, 0.5450, 0.5562, 0.5659, 0.5857, 0.5714, 0.5626, 0.5439,
        0.5526, 0.5481, 0.5446, 0.5486, 0.5580, 0.5766, 0.5755],
       device='cuda:0') torch.Size([16])
percent tensor([0.5041, 0.4974, 0.4975, 0.4949, 0.4941, 0.5101, 0.4974, 0.4907, 0.5004,
        0.4972, 0.4988, 0.4916, 0.4993, 0.4997, 0.4960, 0.5044],
       device='cuda:0') torch.Size([16])
percent tensor([0.6110, 0.6038, 0.6403, 0.6743, 0.6382, 0.6324, 0.6319, 0.6371, 0.6457,
        0.6043, 0.6405, 0.6685, 0.6055, 0.6700, 0.6106, 0.6114],
       device='cuda:0') torch.Size([16])
percent tensor([0.5346, 0.5153, 0.5591, 0.5671, 0.5481, 0.5425, 0.5285, 0.5432, 0.5403,
        0.5279, 0.5316, 0.5506, 0.5091, 0.5484, 0.5090, 0.5226],
       device='cuda:0') torch.Size([16])
percent tensor([0.9925, 0.9902, 0.9946, 0.9913, 0.9946, 0.9908, 0.9922, 0.9973, 0.9896,
        0.9949, 0.9949, 0.9950, 0.9879, 0.9899, 0.9934, 0.9947],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 30 | Batch_idx: 0 |  Loss: (0.7189) |  Loss2: (0.0000) | Acc: (75.00%) (96/128)
Epoch: 30 | Batch_idx: 10 |  Loss: (0.5873) |  Loss2: (0.0000) | Acc: (79.00%) (1116/1408)
Epoch: 30 | Batch_idx: 20 |  Loss: (0.5983) |  Loss2: (0.0000) | Acc: (78.00%) (2116/2688)
Epoch: 30 | Batch_idx: 30 |  Loss: (0.6016) |  Loss2: (0.0000) | Acc: (79.00%) (3135/3968)
Epoch: 30 | Batch_idx: 40 |  Loss: (0.6047) |  Loss2: (0.0000) | Acc: (79.00%) (4162/5248)
Epoch: 30 | Batch_idx: 50 |  Loss: (0.6083) |  Loss2: (0.0000) | Acc: (79.00%) (5173/6528)
Epoch: 30 | Batch_idx: 60 |  Loss: (0.6066) |  Loss2: (0.0000) | Acc: (79.00%) (6186/7808)
Epoch: 30 | Batch_idx: 70 |  Loss: (0.6076) |  Loss2: (0.0000) | Acc: (79.00%) (7205/9088)
Epoch: 30 | Batch_idx: 80 |  Loss: (0.6057) |  Loss2: (0.0000) | Acc: (79.00%) (8216/10368)
Epoch: 30 | Batch_idx: 90 |  Loss: (0.6043) |  Loss2: (0.0000) | Acc: (79.00%) (9232/11648)
Epoch: 30 | Batch_idx: 100 |  Loss: (0.6067) |  Loss2: (0.0000) | Acc: (79.00%) (10223/12928)
Epoch: 30 | Batch_idx: 110 |  Loss: (0.6058) |  Loss2: (0.0000) | Acc: (78.00%) (11220/14208)
Epoch: 30 | Batch_idx: 120 |  Loss: (0.6073) |  Loss2: (0.0000) | Acc: (78.00%) (12210/15488)
Epoch: 30 | Batch_idx: 130 |  Loss: (0.6059) |  Loss2: (0.0000) | Acc: (78.00%) (13214/16768)
Epoch: 30 | Batch_idx: 140 |  Loss: (0.6056) |  Loss2: (0.0000) | Acc: (78.00%) (14224/18048)
Epoch: 30 | Batch_idx: 150 |  Loss: (0.6078) |  Loss2: (0.0000) | Acc: (78.00%) (15220/19328)
Epoch: 30 | Batch_idx: 160 |  Loss: (0.6082) |  Loss2: (0.0000) | Acc: (78.00%) (16222/20608)
Epoch: 30 | Batch_idx: 170 |  Loss: (0.6070) |  Loss2: (0.0000) | Acc: (78.00%) (17246/21888)
Epoch: 30 | Batch_idx: 180 |  Loss: (0.6087) |  Loss2: (0.0000) | Acc: (78.00%) (18225/23168)
Epoch: 30 | Batch_idx: 190 |  Loss: (0.6093) |  Loss2: (0.0000) | Acc: (78.00%) (19223/24448)
Epoch: 30 | Batch_idx: 200 |  Loss: (0.6093) |  Loss2: (0.0000) | Acc: (78.00%) (20243/25728)
Epoch: 30 | Batch_idx: 210 |  Loss: (0.6100) |  Loss2: (0.0000) | Acc: (78.00%) (21243/27008)
Epoch: 30 | Batch_idx: 220 |  Loss: (0.6102) |  Loss2: (0.0000) | Acc: (78.00%) (22250/28288)
Epoch: 30 | Batch_idx: 230 |  Loss: (0.6105) |  Loss2: (0.0000) | Acc: (78.00%) (23268/29568)
Epoch: 30 | Batch_idx: 240 |  Loss: (0.6094) |  Loss2: (0.0000) | Acc: (78.00%) (24290/30848)
Epoch: 30 | Batch_idx: 250 |  Loss: (0.6080) |  Loss2: (0.0000) | Acc: (78.00%) (25328/32128)
Epoch: 30 | Batch_idx: 260 |  Loss: (0.6080) |  Loss2: (0.0000) | Acc: (78.00%) (26324/33408)
Epoch: 30 | Batch_idx: 270 |  Loss: (0.6085) |  Loss2: (0.0000) | Acc: (78.00%) (27340/34688)
Epoch: 30 | Batch_idx: 280 |  Loss: (0.6085) |  Loss2: (0.0000) | Acc: (78.00%) (28341/35968)
Epoch: 30 | Batch_idx: 290 |  Loss: (0.6076) |  Loss2: (0.0000) | Acc: (78.00%) (29350/37248)
Epoch: 30 | Batch_idx: 300 |  Loss: (0.6057) |  Loss2: (0.0000) | Acc: (78.00%) (30392/38528)
Epoch: 30 | Batch_idx: 310 |  Loss: (0.6051) |  Loss2: (0.0000) | Acc: (78.00%) (31403/39808)
Epoch: 30 | Batch_idx: 320 |  Loss: (0.6044) |  Loss2: (0.0000) | Acc: (78.00%) (32416/41088)
Epoch: 30 | Batch_idx: 330 |  Loss: (0.6038) |  Loss2: (0.0000) | Acc: (78.00%) (33432/42368)
Epoch: 30 | Batch_idx: 340 |  Loss: (0.6051) |  Loss2: (0.0000) | Acc: (78.00%) (34429/43648)
Epoch: 30 | Batch_idx: 350 |  Loss: (0.6054) |  Loss2: (0.0000) | Acc: (78.00%) (35437/44928)
Epoch: 30 | Batch_idx: 360 |  Loss: (0.6050) |  Loss2: (0.0000) | Acc: (78.00%) (36467/46208)
Epoch: 30 | Batch_idx: 370 |  Loss: (0.6058) |  Loss2: (0.0000) | Acc: (78.00%) (37477/47488)
Epoch: 30 | Batch_idx: 380 |  Loss: (0.6046) |  Loss2: (0.0000) | Acc: (79.00%) (38532/48768)
Epoch: 30 | Batch_idx: 390 |  Loss: (0.6041) |  Loss2: (0.0000) | Acc: (79.00%) (39527/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_030.pth.tar'
# TEST : Loss: (0.6739) | Acc: (76.00%) (7696/10000)
percent tensor([0.5198, 0.5358, 0.5227, 0.5226, 0.5253, 0.5165, 0.5348, 0.5295, 0.5300,
        0.5296, 0.5281, 0.5251, 0.5222, 0.5426, 0.5260, 0.5236],
       device='cuda:0') torch.Size([16])
percent tensor([0.4952, 0.4926, 0.4832, 0.4878, 0.4845, 0.4921, 0.4882, 0.4849, 0.4915,
        0.4906, 0.4934, 0.4860, 0.4936, 0.4940, 0.4896, 0.4934],
       device='cuda:0') torch.Size([16])
percent tensor([0.5442, 0.5644, 0.5319, 0.5558, 0.5515, 0.5557, 0.5711, 0.5632, 0.5372,
        0.5520, 0.5412, 0.5473, 0.5265, 0.5871, 0.5684, 0.5515],
       device='cuda:0') torch.Size([16])
percent tensor([0.5656, 0.5562, 0.5440, 0.5564, 0.5623, 0.5820, 0.5690, 0.5620, 0.5419,
        0.5522, 0.5489, 0.5441, 0.5486, 0.5598, 0.5759, 0.5752],
       device='cuda:0') torch.Size([16])
percent tensor([0.5051, 0.5006, 0.4958, 0.4953, 0.4932, 0.5095, 0.5008, 0.4915, 0.5007,
        0.4982, 0.5003, 0.4928, 0.5008, 0.5055, 0.4975, 0.5059],
       device='cuda:0') torch.Size([16])
percent tensor([0.6110, 0.5941, 0.6482, 0.6779, 0.6420, 0.6373, 0.6124, 0.6508, 0.6455,
        0.6003, 0.6376, 0.6640, 0.6093, 0.6549, 0.6085, 0.6179],
       device='cuda:0') torch.Size([16])
percent tensor([0.5397, 0.5125, 0.5651, 0.5749, 0.5517, 0.5424, 0.5254, 0.5488, 0.5391,
        0.5269, 0.5266, 0.5530, 0.5085, 0.5473, 0.5086, 0.5219],
       device='cuda:0') torch.Size([16])
percent tensor([0.9930, 0.9909, 0.9954, 0.9917, 0.9951, 0.9888, 0.9887, 0.9979, 0.9912,
        0.9945, 0.9959, 0.9928, 0.9900, 0.9873, 0.9924, 0.9927],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(166.4515, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(790.3278, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(780.5632, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1531.3071, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(502.9077, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2176.6631, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4301.2373, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1436.5547, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6090.6216, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12136.7578, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4058.7117, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17118.9004, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 31 | Batch_idx: 0 |  Loss: (0.6258) |  Loss2: (0.0000) | Acc: (76.00%) (98/128)
Epoch: 31 | Batch_idx: 10 |  Loss: (0.6181) |  Loss2: (0.0000) | Acc: (78.00%) (1099/1408)
Epoch: 31 | Batch_idx: 20 |  Loss: (0.6095) |  Loss2: (0.0000) | Acc: (78.00%) (2109/2688)
Epoch: 31 | Batch_idx: 30 |  Loss: (0.5947) |  Loss2: (0.0000) | Acc: (79.00%) (3139/3968)
Epoch: 31 | Batch_idx: 40 |  Loss: (0.5742) |  Loss2: (0.0000) | Acc: (79.00%) (4188/5248)
Epoch: 31 | Batch_idx: 50 |  Loss: (0.5768) |  Loss2: (0.0000) | Acc: (79.00%) (5216/6528)
Epoch: 31 | Batch_idx: 60 |  Loss: (0.5785) |  Loss2: (0.0000) | Acc: (79.00%) (6239/7808)
Epoch: 31 | Batch_idx: 70 |  Loss: (0.5724) |  Loss2: (0.0000) | Acc: (80.00%) (7274/9088)
Epoch: 31 | Batch_idx: 80 |  Loss: (0.5698) |  Loss2: (0.0000) | Acc: (80.00%) (8300/10368)
Epoch: 31 | Batch_idx: 90 |  Loss: (0.5693) |  Loss2: (0.0000) | Acc: (80.00%) (9328/11648)
Epoch: 31 | Batch_idx: 100 |  Loss: (0.5696) |  Loss2: (0.0000) | Acc: (80.00%) (10345/12928)
Epoch: 31 | Batch_idx: 110 |  Loss: (0.5702) |  Loss2: (0.0000) | Acc: (80.00%) (11371/14208)
Epoch: 31 | Batch_idx: 120 |  Loss: (0.5667) |  Loss2: (0.0000) | Acc: (80.00%) (12431/15488)
Epoch: 31 | Batch_idx: 130 |  Loss: (0.5660) |  Loss2: (0.0000) | Acc: (80.00%) (13455/16768)
Epoch: 31 | Batch_idx: 140 |  Loss: (0.5679) |  Loss2: (0.0000) | Acc: (80.00%) (14478/18048)
Epoch: 31 | Batch_idx: 150 |  Loss: (0.5693) |  Loss2: (0.0000) | Acc: (80.00%) (15501/19328)
Epoch: 31 | Batch_idx: 160 |  Loss: (0.5681) |  Loss2: (0.0000) | Acc: (80.00%) (16535/20608)
Epoch: 31 | Batch_idx: 170 |  Loss: (0.5671) |  Loss2: (0.0000) | Acc: (80.00%) (17590/21888)
Epoch: 31 | Batch_idx: 180 |  Loss: (0.5672) |  Loss2: (0.0000) | Acc: (80.00%) (18623/23168)
Epoch: 31 | Batch_idx: 190 |  Loss: (0.5671) |  Loss2: (0.0000) | Acc: (80.00%) (19647/24448)
Epoch: 31 | Batch_idx: 200 |  Loss: (0.5675) |  Loss2: (0.0000) | Acc: (80.00%) (20659/25728)
Epoch: 31 | Batch_idx: 210 |  Loss: (0.5667) |  Loss2: (0.0000) | Acc: (80.00%) (21696/27008)
Epoch: 31 | Batch_idx: 220 |  Loss: (0.5662) |  Loss2: (0.0000) | Acc: (80.00%) (22736/28288)
Epoch: 31 | Batch_idx: 230 |  Loss: (0.5661) |  Loss2: (0.0000) | Acc: (80.00%) (23761/29568)
Epoch: 31 | Batch_idx: 240 |  Loss: (0.5665) |  Loss2: (0.0000) | Acc: (80.00%) (24775/30848)
Epoch: 31 | Batch_idx: 250 |  Loss: (0.5673) |  Loss2: (0.0000) | Acc: (80.00%) (25797/32128)
Epoch: 31 | Batch_idx: 260 |  Loss: (0.5671) |  Loss2: (0.0000) | Acc: (80.00%) (26831/33408)
Epoch: 31 | Batch_idx: 270 |  Loss: (0.5691) |  Loss2: (0.0000) | Acc: (80.00%) (27835/34688)
Epoch: 31 | Batch_idx: 280 |  Loss: (0.5688) |  Loss2: (0.0000) | Acc: (80.00%) (28861/35968)
Epoch: 31 | Batch_idx: 290 |  Loss: (0.5698) |  Loss2: (0.0000) | Acc: (80.00%) (29868/37248)
Epoch: 31 | Batch_idx: 300 |  Loss: (0.5700) |  Loss2: (0.0000) | Acc: (80.00%) (30898/38528)
Epoch: 31 | Batch_idx: 310 |  Loss: (0.5685) |  Loss2: (0.0000) | Acc: (80.00%) (31943/39808)
Epoch: 31 | Batch_idx: 320 |  Loss: (0.5703) |  Loss2: (0.0000) | Acc: (80.00%) (32931/41088)
Epoch: 31 | Batch_idx: 330 |  Loss: (0.5698) |  Loss2: (0.0000) | Acc: (80.00%) (33965/42368)
Epoch: 31 | Batch_idx: 340 |  Loss: (0.5695) |  Loss2: (0.0000) | Acc: (80.00%) (34994/43648)
Epoch: 31 | Batch_idx: 350 |  Loss: (0.5700) |  Loss2: (0.0000) | Acc: (80.00%) (36026/44928)
Epoch: 31 | Batch_idx: 360 |  Loss: (0.5688) |  Loss2: (0.0000) | Acc: (80.00%) (37069/46208)
Epoch: 31 | Batch_idx: 370 |  Loss: (0.5678) |  Loss2: (0.0000) | Acc: (80.00%) (38115/47488)
Epoch: 31 | Batch_idx: 380 |  Loss: (0.5675) |  Loss2: (0.0000) | Acc: (80.00%) (39151/48768)
Epoch: 31 | Batch_idx: 390 |  Loss: (0.5671) |  Loss2: (0.0000) | Acc: (80.00%) (40148/50000)
# TEST : Loss: (0.6209) | Acc: (78.00%) (7885/10000)
percent tensor([0.5198, 0.5360, 0.5225, 0.5232, 0.5252, 0.5164, 0.5347, 0.5296, 0.5294,
        0.5296, 0.5277, 0.5247, 0.5220, 0.5433, 0.5261, 0.5236],
       device='cuda:0') torch.Size([16])
percent tensor([0.4942, 0.4930, 0.4791, 0.4848, 0.4814, 0.4906, 0.4879, 0.4835, 0.4919,
        0.4895, 0.4936, 0.4836, 0.4927, 0.4954, 0.4884, 0.4917],
       device='cuda:0') torch.Size([16])
percent tensor([0.5488, 0.5644, 0.5446, 0.5610, 0.5610, 0.5571, 0.5755, 0.5664, 0.5437,
        0.5549, 0.5436, 0.5572, 0.5316, 0.5864, 0.5694, 0.5529],
       device='cuda:0') torch.Size([16])
percent tensor([0.5660, 0.5559, 0.5485, 0.5596, 0.5666, 0.5817, 0.5696, 0.5633, 0.5441,
        0.5540, 0.5490, 0.5478, 0.5506, 0.5581, 0.5765, 0.5752],
       device='cuda:0') torch.Size([16])
percent tensor([0.5013, 0.4963, 0.4955, 0.4947, 0.4923, 0.5085, 0.4965, 0.4909, 0.4980,
        0.4953, 0.4974, 0.4908, 0.4975, 0.4994, 0.4947, 0.5033],
       device='cuda:0') torch.Size([16])
percent tensor([0.6164, 0.6002, 0.6398, 0.6664, 0.6349, 0.6405, 0.6291, 0.6377, 0.6447,
        0.5981, 0.6428, 0.6617, 0.6062, 0.6659, 0.6174, 0.6225],
       device='cuda:0') torch.Size([16])
percent tensor([0.5428, 0.5115, 0.5601, 0.5644, 0.5473, 0.5464, 0.5280, 0.5429, 0.5377,
        0.5224, 0.5297, 0.5429, 0.5058, 0.5444, 0.5070, 0.5229],
       device='cuda:0') torch.Size([16])
percent tensor([0.9944, 0.9880, 0.9964, 0.9933, 0.9954, 0.9903, 0.9934, 0.9973, 0.9905,
        0.9934, 0.9943, 0.9939, 0.9828, 0.9898, 0.9949, 0.9943],
       device='cuda:0') torch.Size([16])
Epoch: 32 | Batch_idx: 0 |  Loss: (0.4384) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 32 | Batch_idx: 10 |  Loss: (0.5525) |  Loss2: (0.0000) | Acc: (82.00%) (1156/1408)
Epoch: 32 | Batch_idx: 20 |  Loss: (0.5302) |  Loss2: (0.0000) | Acc: (82.00%) (2211/2688)
Epoch: 32 | Batch_idx: 30 |  Loss: (0.5350) |  Loss2: (0.0000) | Acc: (81.00%) (3251/3968)
Epoch: 32 | Batch_idx: 40 |  Loss: (0.5366) |  Loss2: (0.0000) | Acc: (81.00%) (4301/5248)
Epoch: 32 | Batch_idx: 50 |  Loss: (0.5393) |  Loss2: (0.0000) | Acc: (81.00%) (5338/6528)
Epoch: 32 | Batch_idx: 60 |  Loss: (0.5329) |  Loss2: (0.0000) | Acc: (81.00%) (6396/7808)
Epoch: 32 | Batch_idx: 70 |  Loss: (0.5359) |  Loss2: (0.0000) | Acc: (81.00%) (7427/9088)
Epoch: 32 | Batch_idx: 80 |  Loss: (0.5388) |  Loss2: (0.0000) | Acc: (81.00%) (8457/10368)
Epoch: 32 | Batch_idx: 90 |  Loss: (0.5335) |  Loss2: (0.0000) | Acc: (81.00%) (9519/11648)
Epoch: 32 | Batch_idx: 100 |  Loss: (0.5345) |  Loss2: (0.0000) | Acc: (81.00%) (10547/12928)
Epoch: 32 | Batch_idx: 110 |  Loss: (0.5338) |  Loss2: (0.0000) | Acc: (81.00%) (11583/14208)
Epoch: 32 | Batch_idx: 120 |  Loss: (0.5385) |  Loss2: (0.0000) | Acc: (81.00%) (12608/15488)
Epoch: 32 | Batch_idx: 130 |  Loss: (0.5390) |  Loss2: (0.0000) | Acc: (81.00%) (13650/16768)
Epoch: 32 | Batch_idx: 140 |  Loss: (0.5401) |  Loss2: (0.0000) | Acc: (81.00%) (14675/18048)
Epoch: 32 | Batch_idx: 150 |  Loss: (0.5437) |  Loss2: (0.0000) | Acc: (81.00%) (15682/19328)
Epoch: 32 | Batch_idx: 160 |  Loss: (0.5438) |  Loss2: (0.0000) | Acc: (81.00%) (16730/20608)
Epoch: 32 | Batch_idx: 170 |  Loss: (0.5413) |  Loss2: (0.0000) | Acc: (81.00%) (17788/21888)
Epoch: 32 | Batch_idx: 180 |  Loss: (0.5447) |  Loss2: (0.0000) | Acc: (81.00%) (18800/23168)
Epoch: 32 | Batch_idx: 190 |  Loss: (0.5467) |  Loss2: (0.0000) | Acc: (81.00%) (19825/24448)
Epoch: 32 | Batch_idx: 200 |  Loss: (0.5437) |  Loss2: (0.0000) | Acc: (81.00%) (20892/25728)
Epoch: 32 | Batch_idx: 210 |  Loss: (0.5435) |  Loss2: (0.0000) | Acc: (81.00%) (21930/27008)
Epoch: 32 | Batch_idx: 220 |  Loss: (0.5446) |  Loss2: (0.0000) | Acc: (81.00%) (22954/28288)
Epoch: 32 | Batch_idx: 230 |  Loss: (0.5458) |  Loss2: (0.0000) | Acc: (81.00%) (23976/29568)
Epoch: 32 | Batch_idx: 240 |  Loss: (0.5460) |  Loss2: (0.0000) | Acc: (81.00%) (25040/30848)
Epoch: 32 | Batch_idx: 250 |  Loss: (0.5462) |  Loss2: (0.0000) | Acc: (81.00%) (26077/32128)
Epoch: 32 | Batch_idx: 260 |  Loss: (0.5468) |  Loss2: (0.0000) | Acc: (81.00%) (27106/33408)
Epoch: 32 | Batch_idx: 270 |  Loss: (0.5477) |  Loss2: (0.0000) | Acc: (81.00%) (28134/34688)
Epoch: 32 | Batch_idx: 280 |  Loss: (0.5476) |  Loss2: (0.0000) | Acc: (81.00%) (29170/35968)
Epoch: 32 | Batch_idx: 290 |  Loss: (0.5475) |  Loss2: (0.0000) | Acc: (81.00%) (30209/37248)
Epoch: 32 | Batch_idx: 300 |  Loss: (0.5466) |  Loss2: (0.0000) | Acc: (81.00%) (31260/38528)
Epoch: 32 | Batch_idx: 310 |  Loss: (0.5460) |  Loss2: (0.0000) | Acc: (81.00%) (32307/39808)
Epoch: 32 | Batch_idx: 320 |  Loss: (0.5461) |  Loss2: (0.0000) | Acc: (81.00%) (33356/41088)
Epoch: 32 | Batch_idx: 330 |  Loss: (0.5461) |  Loss2: (0.0000) | Acc: (81.00%) (34398/42368)
Epoch: 32 | Batch_idx: 340 |  Loss: (0.5460) |  Loss2: (0.0000) | Acc: (81.00%) (35422/43648)
Epoch: 32 | Batch_idx: 350 |  Loss: (0.5456) |  Loss2: (0.0000) | Acc: (81.00%) (36467/44928)
Epoch: 32 | Batch_idx: 360 |  Loss: (0.5452) |  Loss2: (0.0000) | Acc: (81.00%) (37522/46208)
Epoch: 32 | Batch_idx: 370 |  Loss: (0.5456) |  Loss2: (0.0000) | Acc: (81.00%) (38552/47488)
Epoch: 32 | Batch_idx: 380 |  Loss: (0.5455) |  Loss2: (0.0000) | Acc: (81.00%) (39606/48768)
Epoch: 32 | Batch_idx: 390 |  Loss: (0.5449) |  Loss2: (0.0000) | Acc: (81.00%) (40614/50000)
# TEST : Loss: (0.6718) | Acc: (77.00%) (7726/10000)
percent tensor([0.5194, 0.5364, 0.5213, 0.5232, 0.5244, 0.5154, 0.5346, 0.5299, 0.5294,
        0.5296, 0.5278, 0.5239, 0.5221, 0.5442, 0.5260, 0.5237],
       device='cuda:0') torch.Size([16])
percent tensor([0.4944, 0.4911, 0.4836, 0.4859, 0.4836, 0.4911, 0.4866, 0.4856, 0.4915,
        0.4890, 0.4926, 0.4853, 0.4926, 0.4921, 0.4881, 0.4913],
       device='cuda:0') torch.Size([16])
percent tensor([0.5478, 0.5698, 0.5308, 0.5618, 0.5513, 0.5541, 0.5757, 0.5655, 0.5365,
        0.5549, 0.5438, 0.5491, 0.5313, 0.5947, 0.5708, 0.5534],
       device='cuda:0') torch.Size([16])
percent tensor([0.5668, 0.5582, 0.5459, 0.5550, 0.5639, 0.5836, 0.5701, 0.5633, 0.5446,
        0.5528, 0.5507, 0.5463, 0.5508, 0.5591, 0.5782, 0.5755],
       device='cuda:0') torch.Size([16])
percent tensor([0.5015, 0.4961, 0.4964, 0.4962, 0.4933, 0.5082, 0.4950, 0.4908, 0.5000,
        0.4968, 0.4978, 0.4909, 0.4976, 0.5005, 0.4945, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.6107, 0.6069, 0.6603, 0.6772, 0.6522, 0.6309, 0.6372, 0.6571, 0.6417,
        0.6004, 0.6345, 0.6722, 0.6071, 0.6652, 0.6160, 0.6254],
       device='cuda:0') torch.Size([16])
percent tensor([0.5371, 0.5168, 0.5651, 0.5675, 0.5534, 0.5394, 0.5340, 0.5485, 0.5368,
        0.5293, 0.5282, 0.5575, 0.5072, 0.5525, 0.5072, 0.5221],
       device='cuda:0') torch.Size([16])
percent tensor([0.9925, 0.9884, 0.9954, 0.9911, 0.9952, 0.9870, 0.9933, 0.9981, 0.9905,
        0.9936, 0.9934, 0.9960, 0.9878, 0.9910, 0.9956, 0.9952],
       device='cuda:0') torch.Size([16])
Epoch: 33 | Batch_idx: 0 |  Loss: (0.6921) |  Loss2: (0.0000) | Acc: (73.00%) (94/128)
Epoch: 33 | Batch_idx: 10 |  Loss: (0.5507) |  Loss2: (0.0000) | Acc: (80.00%) (1127/1408)
Epoch: 33 | Batch_idx: 20 |  Loss: (0.5440) |  Loss2: (0.0000) | Acc: (80.00%) (2162/2688)
Epoch: 33 | Batch_idx: 30 |  Loss: (0.5355) |  Loss2: (0.0000) | Acc: (80.00%) (3208/3968)
Epoch: 33 | Batch_idx: 40 |  Loss: (0.5186) |  Loss2: (0.0000) | Acc: (81.00%) (4283/5248)
Epoch: 33 | Batch_idx: 50 |  Loss: (0.5264) |  Loss2: (0.0000) | Acc: (81.00%) (5317/6528)
Epoch: 33 | Batch_idx: 60 |  Loss: (0.5318) |  Loss2: (0.0000) | Acc: (81.00%) (6349/7808)
Epoch: 33 | Batch_idx: 70 |  Loss: (0.5268) |  Loss2: (0.0000) | Acc: (81.00%) (7416/9088)
Epoch: 33 | Batch_idx: 80 |  Loss: (0.5237) |  Loss2: (0.0000) | Acc: (81.00%) (8474/10368)
Epoch: 33 | Batch_idx: 90 |  Loss: (0.5215) |  Loss2: (0.0000) | Acc: (81.00%) (9528/11648)
Epoch: 33 | Batch_idx: 100 |  Loss: (0.5192) |  Loss2: (0.0000) | Acc: (81.00%) (10576/12928)
Epoch: 33 | Batch_idx: 110 |  Loss: (0.5205) |  Loss2: (0.0000) | Acc: (81.00%) (11627/14208)
Epoch: 33 | Batch_idx: 120 |  Loss: (0.5210) |  Loss2: (0.0000) | Acc: (81.00%) (12667/15488)
Epoch: 33 | Batch_idx: 130 |  Loss: (0.5190) |  Loss2: (0.0000) | Acc: (81.00%) (13736/16768)
Epoch: 33 | Batch_idx: 140 |  Loss: (0.5179) |  Loss2: (0.0000) | Acc: (82.00%) (14804/18048)
Epoch: 33 | Batch_idx: 150 |  Loss: (0.5178) |  Loss2: (0.0000) | Acc: (82.00%) (15860/19328)
Epoch: 33 | Batch_idx: 160 |  Loss: (0.5179) |  Loss2: (0.0000) | Acc: (82.00%) (16910/20608)
Epoch: 33 | Batch_idx: 170 |  Loss: (0.5173) |  Loss2: (0.0000) | Acc: (82.00%) (17958/21888)
Epoch: 33 | Batch_idx: 180 |  Loss: (0.5171) |  Loss2: (0.0000) | Acc: (82.00%) (19015/23168)
Epoch: 33 | Batch_idx: 190 |  Loss: (0.5178) |  Loss2: (0.0000) | Acc: (82.00%) (20062/24448)
Epoch: 33 | Batch_idx: 200 |  Loss: (0.5189) |  Loss2: (0.0000) | Acc: (82.00%) (21099/25728)
Epoch: 33 | Batch_idx: 210 |  Loss: (0.5164) |  Loss2: (0.0000) | Acc: (82.00%) (22174/27008)
Epoch: 33 | Batch_idx: 220 |  Loss: (0.5153) |  Loss2: (0.0000) | Acc: (82.00%) (23243/28288)
Epoch: 33 | Batch_idx: 230 |  Loss: (0.5165) |  Loss2: (0.0000) | Acc: (82.00%) (24290/29568)
Epoch: 33 | Batch_idx: 240 |  Loss: (0.5182) |  Loss2: (0.0000) | Acc: (82.00%) (25328/30848)
Epoch: 33 | Batch_idx: 250 |  Loss: (0.5189) |  Loss2: (0.0000) | Acc: (82.00%) (26372/32128)
Epoch: 33 | Batch_idx: 260 |  Loss: (0.5203) |  Loss2: (0.0000) | Acc: (82.00%) (27405/33408)
Epoch: 33 | Batch_idx: 270 |  Loss: (0.5206) |  Loss2: (0.0000) | Acc: (82.00%) (28455/34688)
Epoch: 33 | Batch_idx: 280 |  Loss: (0.5209) |  Loss2: (0.0000) | Acc: (82.00%) (29512/35968)
Epoch: 33 | Batch_idx: 290 |  Loss: (0.5212) |  Loss2: (0.0000) | Acc: (82.00%) (30560/37248)
Epoch: 33 | Batch_idx: 300 |  Loss: (0.5206) |  Loss2: (0.0000) | Acc: (82.00%) (31613/38528)
Epoch: 33 | Batch_idx: 310 |  Loss: (0.5199) |  Loss2: (0.0000) | Acc: (82.00%) (32667/39808)
Epoch: 33 | Batch_idx: 320 |  Loss: (0.5193) |  Loss2: (0.0000) | Acc: (82.00%) (33731/41088)
Epoch: 33 | Batch_idx: 330 |  Loss: (0.5199) |  Loss2: (0.0000) | Acc: (82.00%) (34775/42368)
Epoch: 33 | Batch_idx: 340 |  Loss: (0.5201) |  Loss2: (0.0000) | Acc: (82.00%) (35818/43648)
Epoch: 33 | Batch_idx: 350 |  Loss: (0.5204) |  Loss2: (0.0000) | Acc: (82.00%) (36851/44928)
Epoch: 33 | Batch_idx: 360 |  Loss: (0.5201) |  Loss2: (0.0000) | Acc: (82.00%) (37908/46208)
Epoch: 33 | Batch_idx: 370 |  Loss: (0.5200) |  Loss2: (0.0000) | Acc: (82.00%) (38966/47488)
Epoch: 33 | Batch_idx: 380 |  Loss: (0.5206) |  Loss2: (0.0000) | Acc: (82.00%) (40004/48768)
Epoch: 33 | Batch_idx: 390 |  Loss: (0.5198) |  Loss2: (0.0000) | Acc: (82.00%) (41024/50000)
# TEST : Loss: (0.6184) | Acc: (79.00%) (7921/10000)
percent tensor([0.5204, 0.5350, 0.5227, 0.5227, 0.5253, 0.5168, 0.5342, 0.5292, 0.5298,
        0.5290, 0.5281, 0.5245, 0.5225, 0.5415, 0.5255, 0.5235],
       device='cuda:0') torch.Size([16])
percent tensor([0.4944, 0.4912, 0.4832, 0.4856, 0.4835, 0.4917, 0.4872, 0.4847, 0.4909,
        0.4894, 0.4928, 0.4856, 0.4926, 0.4919, 0.4885, 0.4912],
       device='cuda:0') torch.Size([16])
percent tensor([0.5495, 0.5653, 0.5425, 0.5611, 0.5582, 0.5629, 0.5741, 0.5626, 0.5431,
        0.5547, 0.5446, 0.5570, 0.5298, 0.5907, 0.5704, 0.5534],
       device='cuda:0') torch.Size([16])
percent tensor([0.5703, 0.5600, 0.5444, 0.5588, 0.5638, 0.5890, 0.5724, 0.5642, 0.5442,
        0.5562, 0.5536, 0.5478, 0.5534, 0.5619, 0.5814, 0.5801],
       device='cuda:0') torch.Size([16])
percent tensor([0.5037, 0.4984, 0.4976, 0.4968, 0.4956, 0.5091, 0.4985, 0.4932, 0.5004,
        0.4973, 0.4985, 0.4921, 0.4988, 0.5014, 0.4964, 0.5045],
       device='cuda:0') torch.Size([16])
percent tensor([0.6029, 0.5875, 0.6404, 0.6772, 0.6373, 0.6413, 0.6169, 0.6366, 0.6368,
        0.5837, 0.6218, 0.6608, 0.5955, 0.6550, 0.6050, 0.6204],
       device='cuda:0') torch.Size([16])
percent tensor([0.5398, 0.5111, 0.5622, 0.5729, 0.5515, 0.5487, 0.5298, 0.5441, 0.5400,
        0.5258, 0.5231, 0.5520, 0.5106, 0.5499, 0.5093, 0.5274],
       device='cuda:0') torch.Size([16])
percent tensor([0.9909, 0.9889, 0.9966, 0.9940, 0.9946, 0.9877, 0.9940, 0.9987, 0.9917,
        0.9946, 0.9917, 0.9969, 0.9850, 0.9914, 0.9950, 0.9933],
       device='cuda:0') torch.Size([16])
Epoch: 34 | Batch_idx: 0 |  Loss: (0.5918) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 34 | Batch_idx: 10 |  Loss: (0.5323) |  Loss2: (0.0000) | Acc: (80.00%) (1139/1408)
Epoch: 34 | Batch_idx: 20 |  Loss: (0.5059) |  Loss2: (0.0000) | Acc: (82.00%) (2213/2688)
Epoch: 34 | Batch_idx: 30 |  Loss: (0.5136) |  Loss2: (0.0000) | Acc: (82.00%) (3254/3968)
Epoch: 34 | Batch_idx: 40 |  Loss: (0.5045) |  Loss2: (0.0000) | Acc: (82.00%) (4320/5248)
Epoch: 34 | Batch_idx: 50 |  Loss: (0.5061) |  Loss2: (0.0000) | Acc: (82.00%) (5355/6528)
Epoch: 34 | Batch_idx: 60 |  Loss: (0.4998) |  Loss2: (0.0000) | Acc: (82.00%) (6428/7808)
Epoch: 34 | Batch_idx: 70 |  Loss: (0.5056) |  Loss2: (0.0000) | Acc: (82.00%) (7465/9088)
Epoch: 34 | Batch_idx: 80 |  Loss: (0.5059) |  Loss2: (0.0000) | Acc: (82.00%) (8534/10368)
Epoch: 34 | Batch_idx: 90 |  Loss: (0.5040) |  Loss2: (0.0000) | Acc: (82.00%) (9594/11648)
Epoch: 34 | Batch_idx: 100 |  Loss: (0.4992) |  Loss2: (0.0000) | Acc: (82.00%) (10667/12928)
Epoch: 34 | Batch_idx: 110 |  Loss: (0.4989) |  Loss2: (0.0000) | Acc: (82.00%) (11728/14208)
Epoch: 34 | Batch_idx: 120 |  Loss: (0.4979) |  Loss2: (0.0000) | Acc: (82.00%) (12795/15488)
Epoch: 34 | Batch_idx: 130 |  Loss: (0.5001) |  Loss2: (0.0000) | Acc: (82.00%) (13838/16768)
Epoch: 34 | Batch_idx: 140 |  Loss: (0.4986) |  Loss2: (0.0000) | Acc: (82.00%) (14893/18048)
Epoch: 34 | Batch_idx: 150 |  Loss: (0.4984) |  Loss2: (0.0000) | Acc: (82.00%) (15963/19328)
Epoch: 34 | Batch_idx: 160 |  Loss: (0.4986) |  Loss2: (0.0000) | Acc: (82.00%) (17030/20608)
Epoch: 34 | Batch_idx: 170 |  Loss: (0.4960) |  Loss2: (0.0000) | Acc: (82.00%) (18104/21888)
Epoch: 34 | Batch_idx: 180 |  Loss: (0.4959) |  Loss2: (0.0000) | Acc: (82.00%) (19155/23168)
Epoch: 34 | Batch_idx: 190 |  Loss: (0.4959) |  Loss2: (0.0000) | Acc: (82.00%) (20217/24448)
Epoch: 34 | Batch_idx: 200 |  Loss: (0.4961) |  Loss2: (0.0000) | Acc: (82.00%) (21261/25728)
Epoch: 34 | Batch_idx: 210 |  Loss: (0.4962) |  Loss2: (0.0000) | Acc: (82.00%) (22331/27008)
Epoch: 34 | Batch_idx: 220 |  Loss: (0.4965) |  Loss2: (0.0000) | Acc: (82.00%) (23383/28288)
Epoch: 34 | Batch_idx: 230 |  Loss: (0.4964) |  Loss2: (0.0000) | Acc: (82.00%) (24450/29568)
Epoch: 34 | Batch_idx: 240 |  Loss: (0.4961) |  Loss2: (0.0000) | Acc: (82.00%) (25505/30848)
Epoch: 34 | Batch_idx: 250 |  Loss: (0.4976) |  Loss2: (0.0000) | Acc: (82.00%) (26550/32128)
Epoch: 34 | Batch_idx: 260 |  Loss: (0.4973) |  Loss2: (0.0000) | Acc: (82.00%) (27618/33408)
Epoch: 34 | Batch_idx: 270 |  Loss: (0.4984) |  Loss2: (0.0000) | Acc: (82.00%) (28662/34688)
Epoch: 34 | Batch_idx: 280 |  Loss: (0.4977) |  Loss2: (0.0000) | Acc: (82.00%) (29729/35968)
Epoch: 34 | Batch_idx: 290 |  Loss: (0.4992) |  Loss2: (0.0000) | Acc: (82.00%) (30767/37248)
Epoch: 34 | Batch_idx: 300 |  Loss: (0.4998) |  Loss2: (0.0000) | Acc: (82.00%) (31810/38528)
Epoch: 34 | Batch_idx: 310 |  Loss: (0.5001) |  Loss2: (0.0000) | Acc: (82.00%) (32886/39808)
Epoch: 34 | Batch_idx: 320 |  Loss: (0.4994) |  Loss2: (0.0000) | Acc: (82.00%) (33960/41088)
Epoch: 34 | Batch_idx: 330 |  Loss: (0.4996) |  Loss2: (0.0000) | Acc: (82.00%) (35012/42368)
Epoch: 34 | Batch_idx: 340 |  Loss: (0.5002) |  Loss2: (0.0000) | Acc: (82.00%) (36064/43648)
Epoch: 34 | Batch_idx: 350 |  Loss: (0.5005) |  Loss2: (0.0000) | Acc: (82.00%) (37113/44928)
Epoch: 34 | Batch_idx: 360 |  Loss: (0.4994) |  Loss2: (0.0000) | Acc: (82.00%) (38185/46208)
Epoch: 34 | Batch_idx: 370 |  Loss: (0.4989) |  Loss2: (0.0000) | Acc: (82.00%) (39251/47488)
Epoch: 34 | Batch_idx: 380 |  Loss: (0.4991) |  Loss2: (0.0000) | Acc: (82.00%) (40309/48768)
Epoch: 34 | Batch_idx: 390 |  Loss: (0.4986) |  Loss2: (0.0000) | Acc: (82.00%) (41337/50000)
# TEST : Loss: (0.6422) | Acc: (78.00%) (7849/10000)
percent tensor([0.5204, 0.5353, 0.5225, 0.5224, 0.5252, 0.5170, 0.5345, 0.5290, 0.5295,
        0.5289, 0.5282, 0.5245, 0.5225, 0.5420, 0.5257, 0.5233],
       device='cuda:0') torch.Size([16])
percent tensor([0.4952, 0.4939, 0.4830, 0.4864, 0.4845, 0.4920, 0.4894, 0.4855, 0.4924,
        0.4912, 0.4946, 0.4864, 0.4939, 0.4947, 0.4899, 0.4933],
       device='cuda:0') torch.Size([16])
percent tensor([0.5468, 0.5633, 0.5351, 0.5569, 0.5543, 0.5627, 0.5699, 0.5627, 0.5355,
        0.5518, 0.5408, 0.5527, 0.5273, 0.5850, 0.5708, 0.5507],
       device='cuda:0') torch.Size([16])
percent tensor([0.5680, 0.5546, 0.5486, 0.5588, 0.5636, 0.5845, 0.5673, 0.5662, 0.5458,
        0.5521, 0.5493, 0.5442, 0.5503, 0.5552, 0.5781, 0.5763],
       device='cuda:0') torch.Size([16])
percent tensor([0.5017, 0.4964, 0.4961, 0.4963, 0.4938, 0.5085, 0.4980, 0.4928, 0.5000,
        0.4957, 0.4976, 0.4911, 0.4975, 0.5009, 0.4950, 0.5034],
       device='cuda:0') torch.Size([16])
percent tensor([0.6060, 0.6080, 0.6439, 0.6730, 0.6422, 0.6386, 0.6240, 0.6394, 0.6375,
        0.6029, 0.6321, 0.6626, 0.6063, 0.6593, 0.6129, 0.6244],
       device='cuda:0') torch.Size([16])
percent tensor([0.5362, 0.5132, 0.5591, 0.5694, 0.5524, 0.5472, 0.5289, 0.5462, 0.5342,
        0.5238, 0.5283, 0.5485, 0.5090, 0.5468, 0.5067, 0.5193],
       device='cuda:0') torch.Size([16])
percent tensor([0.9919, 0.9881, 0.9963, 0.9934, 0.9957, 0.9859, 0.9937, 0.9971, 0.9876,
        0.9941, 0.9920, 0.9961, 0.9846, 0.9893, 0.9938, 0.9942],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 35 | Batch_idx: 0 |  Loss: (0.4220) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 35 | Batch_idx: 10 |  Loss: (0.5032) |  Loss2: (0.0000) | Acc: (82.00%) (1166/1408)
Epoch: 35 | Batch_idx: 20 |  Loss: (0.5551) |  Loss2: (0.0000) | Acc: (80.00%) (2171/2688)
Epoch: 35 | Batch_idx: 30 |  Loss: (0.5703) |  Loss2: (0.0000) | Acc: (80.00%) (3186/3968)
Epoch: 35 | Batch_idx: 40 |  Loss: (0.5836) |  Loss2: (0.0000) | Acc: (79.00%) (4190/5248)
Epoch: 35 | Batch_idx: 50 |  Loss: (0.5907) |  Loss2: (0.0000) | Acc: (79.00%) (5189/6528)
Epoch: 35 | Batch_idx: 60 |  Loss: (0.5937) |  Loss2: (0.0000) | Acc: (79.00%) (6215/7808)
Epoch: 35 | Batch_idx: 70 |  Loss: (0.5926) |  Loss2: (0.0000) | Acc: (79.00%) (7221/9088)
Epoch: 35 | Batch_idx: 80 |  Loss: (0.5935) |  Loss2: (0.0000) | Acc: (79.00%) (8233/10368)
Epoch: 35 | Batch_idx: 90 |  Loss: (0.5938) |  Loss2: (0.0000) | Acc: (79.00%) (9242/11648)
Epoch: 35 | Batch_idx: 100 |  Loss: (0.5966) |  Loss2: (0.0000) | Acc: (79.00%) (10244/12928)
Epoch: 35 | Batch_idx: 110 |  Loss: (0.5954) |  Loss2: (0.0000) | Acc: (79.00%) (11252/14208)
Epoch: 35 | Batch_idx: 120 |  Loss: (0.5942) |  Loss2: (0.0000) | Acc: (79.00%) (12274/15488)
Epoch: 35 | Batch_idx: 130 |  Loss: (0.5939) |  Loss2: (0.0000) | Acc: (79.00%) (13284/16768)
Epoch: 35 | Batch_idx: 140 |  Loss: (0.5949) |  Loss2: (0.0000) | Acc: (79.00%) (14303/18048)
Epoch: 35 | Batch_idx: 150 |  Loss: (0.5942) |  Loss2: (0.0000) | Acc: (79.00%) (15326/19328)
Epoch: 35 | Batch_idx: 160 |  Loss: (0.5919) |  Loss2: (0.0000) | Acc: (79.00%) (16372/20608)
Epoch: 35 | Batch_idx: 170 |  Loss: (0.5892) |  Loss2: (0.0000) | Acc: (79.00%) (17415/21888)
Epoch: 35 | Batch_idx: 180 |  Loss: (0.5893) |  Loss2: (0.0000) | Acc: (79.00%) (18435/23168)
Epoch: 35 | Batch_idx: 190 |  Loss: (0.5911) |  Loss2: (0.0000) | Acc: (79.00%) (19436/24448)
Epoch: 35 | Batch_idx: 200 |  Loss: (0.5900) |  Loss2: (0.0000) | Acc: (79.00%) (20456/25728)
Epoch: 35 | Batch_idx: 210 |  Loss: (0.5892) |  Loss2: (0.0000) | Acc: (79.00%) (21486/27008)
Epoch: 35 | Batch_idx: 220 |  Loss: (0.5887) |  Loss2: (0.0000) | Acc: (79.00%) (22518/28288)
Epoch: 35 | Batch_idx: 230 |  Loss: (0.5868) |  Loss2: (0.0000) | Acc: (79.00%) (23551/29568)
Epoch: 35 | Batch_idx: 240 |  Loss: (0.5856) |  Loss2: (0.0000) | Acc: (79.00%) (24589/30848)
Epoch: 35 | Batch_idx: 250 |  Loss: (0.5839) |  Loss2: (0.0000) | Acc: (79.00%) (25636/32128)
Epoch: 35 | Batch_idx: 260 |  Loss: (0.5827) |  Loss2: (0.0000) | Acc: (79.00%) (26683/33408)
Epoch: 35 | Batch_idx: 270 |  Loss: (0.5829) |  Loss2: (0.0000) | Acc: (79.00%) (27714/34688)
Epoch: 35 | Batch_idx: 280 |  Loss: (0.5811) |  Loss2: (0.0000) | Acc: (79.00%) (28750/35968)
Epoch: 35 | Batch_idx: 290 |  Loss: (0.5794) |  Loss2: (0.0000) | Acc: (80.00%) (29806/37248)
Epoch: 35 | Batch_idx: 300 |  Loss: (0.5787) |  Loss2: (0.0000) | Acc: (80.00%) (30848/38528)
Epoch: 35 | Batch_idx: 310 |  Loss: (0.5791) |  Loss2: (0.0000) | Acc: (80.00%) (31867/39808)
Epoch: 35 | Batch_idx: 320 |  Loss: (0.5784) |  Loss2: (0.0000) | Acc: (80.00%) (32886/41088)
Epoch: 35 | Batch_idx: 330 |  Loss: (0.5768) |  Loss2: (0.0000) | Acc: (80.00%) (33923/42368)
Epoch: 35 | Batch_idx: 340 |  Loss: (0.5755) |  Loss2: (0.0000) | Acc: (80.00%) (34968/43648)
Epoch: 35 | Batch_idx: 350 |  Loss: (0.5744) |  Loss2: (0.0000) | Acc: (80.00%) (36011/44928)
Epoch: 35 | Batch_idx: 360 |  Loss: (0.5746) |  Loss2: (0.0000) | Acc: (80.00%) (37039/46208)
Epoch: 35 | Batch_idx: 370 |  Loss: (0.5730) |  Loss2: (0.0000) | Acc: (80.00%) (38077/47488)
Epoch: 35 | Batch_idx: 380 |  Loss: (0.5724) |  Loss2: (0.0000) | Acc: (80.00%) (39108/48768)
Epoch: 35 | Batch_idx: 390 |  Loss: (0.5724) |  Loss2: (0.0000) | Acc: (80.00%) (40089/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_035.pth.tar'
# TEST : Loss: (0.5976) | Acc: (79.00%) (7925/10000)
percent tensor([0.5242, 0.5405, 0.5271, 0.5269, 0.5300, 0.5204, 0.5400, 0.5335, 0.5337,
        0.5337, 0.5323, 0.5295, 0.5266, 0.5468, 0.5301, 0.5272],
       device='cuda:0') torch.Size([16])
percent tensor([0.4988, 0.4998, 0.4865, 0.4893, 0.4889, 0.4947, 0.4951, 0.4904, 0.4972,
        0.4952, 0.4996, 0.4901, 0.4989, 0.4989, 0.4949, 0.4970],
       device='cuda:0') torch.Size([16])
percent tensor([0.5379, 0.5477, 0.5392, 0.5682, 0.5608, 0.5747, 0.5637, 0.5703, 0.5296,
        0.5361, 0.5227, 0.5481, 0.5101, 0.5794, 0.5704, 0.5450],
       device='cuda:0') torch.Size([16])
percent tensor([0.6099, 0.5845, 0.5894, 0.6064, 0.6136, 0.6376, 0.6088, 0.6154, 0.5800,
        0.5839, 0.5789, 0.5823, 0.5748, 0.5908, 0.6261, 0.6220],
       device='cuda:0') torch.Size([16])
percent tensor([0.4878, 0.4824, 0.4856, 0.4874, 0.4848, 0.4971, 0.4836, 0.4793, 0.4895,
        0.4843, 0.4874, 0.4809, 0.4835, 0.4928, 0.4763, 0.4903],
       device='cuda:0') torch.Size([16])
percent tensor([0.5530, 0.5500, 0.6040, 0.6546, 0.6045, 0.6011, 0.5748, 0.5902, 0.5994,
        0.5483, 0.5854, 0.6199, 0.5442, 0.6196, 0.5563, 0.5694],
       device='cuda:0') torch.Size([16])
percent tensor([0.5377, 0.5141, 0.5492, 0.5634, 0.5375, 0.5445, 0.5213, 0.5281, 0.5388,
        0.5283, 0.5301, 0.5434, 0.5168, 0.5548, 0.4938, 0.5165],
       device='cuda:0') torch.Size([16])
percent tensor([0.9913, 0.9919, 0.9961, 0.9939, 0.9959, 0.9889, 0.9940, 0.9979, 0.9914,
        0.9949, 0.9940, 0.9951, 0.9886, 0.9930, 0.9952, 0.9947],
       device='cuda:0') torch.Size([16])
Epoch: 36 | Batch_idx: 0 |  Loss: (0.5026) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 36 | Batch_idx: 10 |  Loss: (0.5246) |  Loss2: (0.0000) | Acc: (81.00%) (1142/1408)
Epoch: 36 | Batch_idx: 20 |  Loss: (0.5269) |  Loss2: (0.0000) | Acc: (81.00%) (2186/2688)
Epoch: 36 | Batch_idx: 30 |  Loss: (0.5202) |  Loss2: (0.0000) | Acc: (81.00%) (3237/3968)
Epoch: 36 | Batch_idx: 40 |  Loss: (0.5228) |  Loss2: (0.0000) | Acc: (81.00%) (4270/5248)
Epoch: 36 | Batch_idx: 50 |  Loss: (0.5246) |  Loss2: (0.0000) | Acc: (81.00%) (5320/6528)
Epoch: 36 | Batch_idx: 60 |  Loss: (0.5225) |  Loss2: (0.0000) | Acc: (81.00%) (6376/7808)
Epoch: 36 | Batch_idx: 70 |  Loss: (0.5223) |  Loss2: (0.0000) | Acc: (81.00%) (7421/9088)
Epoch: 36 | Batch_idx: 80 |  Loss: (0.5239) |  Loss2: (0.0000) | Acc: (81.00%) (8465/10368)
Epoch: 36 | Batch_idx: 90 |  Loss: (0.5255) |  Loss2: (0.0000) | Acc: (81.00%) (9507/11648)
Epoch: 36 | Batch_idx: 100 |  Loss: (0.5294) |  Loss2: (0.0000) | Acc: (81.00%) (10526/12928)
Epoch: 36 | Batch_idx: 110 |  Loss: (0.5291) |  Loss2: (0.0000) | Acc: (81.00%) (11577/14208)
Epoch: 36 | Batch_idx: 120 |  Loss: (0.5281) |  Loss2: (0.0000) | Acc: (81.00%) (12629/15488)
Epoch: 36 | Batch_idx: 130 |  Loss: (0.5265) |  Loss2: (0.0000) | Acc: (81.00%) (13697/16768)
Epoch: 36 | Batch_idx: 140 |  Loss: (0.5272) |  Loss2: (0.0000) | Acc: (81.00%) (14739/18048)
Epoch: 36 | Batch_idx: 150 |  Loss: (0.5283) |  Loss2: (0.0000) | Acc: (81.00%) (15781/19328)
Epoch: 36 | Batch_idx: 160 |  Loss: (0.5288) |  Loss2: (0.0000) | Acc: (81.00%) (16833/20608)
Epoch: 36 | Batch_idx: 170 |  Loss: (0.5272) |  Loss2: (0.0000) | Acc: (81.00%) (17888/21888)
Epoch: 36 | Batch_idx: 180 |  Loss: (0.5262) |  Loss2: (0.0000) | Acc: (81.00%) (18954/23168)
Epoch: 36 | Batch_idx: 190 |  Loss: (0.5274) |  Loss2: (0.0000) | Acc: (81.00%) (19982/24448)
Epoch: 36 | Batch_idx: 200 |  Loss: (0.5293) |  Loss2: (0.0000) | Acc: (81.00%) (20998/25728)
Epoch: 36 | Batch_idx: 210 |  Loss: (0.5302) |  Loss2: (0.0000) | Acc: (81.00%) (22037/27008)
Epoch: 36 | Batch_idx: 220 |  Loss: (0.5310) |  Loss2: (0.0000) | Acc: (81.00%) (23081/28288)
Epoch: 36 | Batch_idx: 230 |  Loss: (0.5298) |  Loss2: (0.0000) | Acc: (81.00%) (24138/29568)
Epoch: 36 | Batch_idx: 240 |  Loss: (0.5278) |  Loss2: (0.0000) | Acc: (81.00%) (25208/30848)
Epoch: 36 | Batch_idx: 250 |  Loss: (0.5270) |  Loss2: (0.0000) | Acc: (81.00%) (26264/32128)
Epoch: 36 | Batch_idx: 260 |  Loss: (0.5268) |  Loss2: (0.0000) | Acc: (81.00%) (27311/33408)
Epoch: 36 | Batch_idx: 270 |  Loss: (0.5269) |  Loss2: (0.0000) | Acc: (81.00%) (28355/34688)
Epoch: 36 | Batch_idx: 280 |  Loss: (0.5272) |  Loss2: (0.0000) | Acc: (81.00%) (29399/35968)
Epoch: 36 | Batch_idx: 290 |  Loss: (0.5273) |  Loss2: (0.0000) | Acc: (81.00%) (30450/37248)
Epoch: 36 | Batch_idx: 300 |  Loss: (0.5263) |  Loss2: (0.0000) | Acc: (81.00%) (31500/38528)
Epoch: 36 | Batch_idx: 310 |  Loss: (0.5249) |  Loss2: (0.0000) | Acc: (81.00%) (32570/39808)
Epoch: 36 | Batch_idx: 320 |  Loss: (0.5241) |  Loss2: (0.0000) | Acc: (81.00%) (33645/41088)
Epoch: 36 | Batch_idx: 330 |  Loss: (0.5242) |  Loss2: (0.0000) | Acc: (81.00%) (34681/42368)
Epoch: 36 | Batch_idx: 340 |  Loss: (0.5236) |  Loss2: (0.0000) | Acc: (81.00%) (35739/43648)
Epoch: 36 | Batch_idx: 350 |  Loss: (0.5223) |  Loss2: (0.0000) | Acc: (81.00%) (36804/44928)
Epoch: 36 | Batch_idx: 360 |  Loss: (0.5220) |  Loss2: (0.0000) | Acc: (81.00%) (37860/46208)
Epoch: 36 | Batch_idx: 370 |  Loss: (0.5219) |  Loss2: (0.0000) | Acc: (81.00%) (38927/47488)
Epoch: 36 | Batch_idx: 380 |  Loss: (0.5220) |  Loss2: (0.0000) | Acc: (81.00%) (39968/48768)
Epoch: 36 | Batch_idx: 390 |  Loss: (0.5215) |  Loss2: (0.0000) | Acc: (81.00%) (40998/50000)
# TEST : Loss: (0.5679) | Acc: (80.00%) (8019/10000)
percent tensor([0.5201, 0.5355, 0.5227, 0.5227, 0.5251, 0.5165, 0.5348, 0.5287, 0.5289,
        0.5291, 0.5276, 0.5250, 0.5223, 0.5414, 0.5258, 0.5229],
       device='cuda:0') torch.Size([16])
percent tensor([0.4999, 0.5012, 0.4872, 0.4897, 0.4898, 0.4958, 0.4964, 0.4915, 0.4981,
        0.4960, 0.5004, 0.4908, 0.5001, 0.4995, 0.4963, 0.4978],
       device='cuda:0') torch.Size([16])
percent tensor([0.5388, 0.5473, 0.5412, 0.5778, 0.5682, 0.5886, 0.5674, 0.5803, 0.5289,
        0.5321, 0.5174, 0.5468, 0.5037, 0.5852, 0.5786, 0.5479],
       device='cuda:0') torch.Size([16])
percent tensor([0.6197, 0.5873, 0.6007, 0.6215, 0.6291, 0.6553, 0.6175, 0.6308, 0.5844,
        0.5862, 0.5801, 0.5885, 0.5741, 0.5975, 0.6362, 0.6315],
       device='cuda:0') torch.Size([16])
percent tensor([0.4847, 0.4798, 0.4843, 0.4861, 0.4830, 0.4936, 0.4806, 0.4767, 0.4880,
        0.4829, 0.4861, 0.4796, 0.4807, 0.4918, 0.4720, 0.4881],
       device='cuda:0') torch.Size([16])
percent tensor([0.5767, 0.5739, 0.6272, 0.6810, 0.6299, 0.6261, 0.6005, 0.6182, 0.6229,
        0.5704, 0.6086, 0.6438, 0.5611, 0.6501, 0.5847, 0.5941],
       device='cuda:0') torch.Size([16])
percent tensor([0.5494, 0.5256, 0.5582, 0.5715, 0.5435, 0.5546, 0.5280, 0.5306, 0.5510,
        0.5441, 0.5420, 0.5543, 0.5273, 0.5725, 0.4947, 0.5241],
       device='cuda:0') torch.Size([16])
percent tensor([0.9928, 0.9930, 0.9969, 0.9944, 0.9968, 0.9900, 0.9950, 0.9982, 0.9925,
        0.9959, 0.9947, 0.9957, 0.9894, 0.9943, 0.9960, 0.9958],
       device='cuda:0') torch.Size([16])
Epoch: 37 | Batch_idx: 0 |  Loss: (0.5804) |  Loss2: (0.0000) | Acc: (76.00%) (98/128)
Epoch: 37 | Batch_idx: 10 |  Loss: (0.5396) |  Loss2: (0.0000) | Acc: (81.00%) (1146/1408)
Epoch: 37 | Batch_idx: 20 |  Loss: (0.5085) |  Loss2: (0.0000) | Acc: (82.00%) (2222/2688)
Epoch: 37 | Batch_idx: 30 |  Loss: (0.4995) |  Loss2: (0.0000) | Acc: (82.00%) (3282/3968)
Epoch: 37 | Batch_idx: 40 |  Loss: (0.5052) |  Loss2: (0.0000) | Acc: (82.00%) (4315/5248)
Epoch: 37 | Batch_idx: 50 |  Loss: (0.5019) |  Loss2: (0.0000) | Acc: (82.00%) (5380/6528)
Epoch: 37 | Batch_idx: 60 |  Loss: (0.4984) |  Loss2: (0.0000) | Acc: (82.00%) (6451/7808)
Epoch: 37 | Batch_idx: 70 |  Loss: (0.4954) |  Loss2: (0.0000) | Acc: (82.00%) (7527/9088)
Epoch: 37 | Batch_idx: 80 |  Loss: (0.4945) |  Loss2: (0.0000) | Acc: (82.00%) (8575/10368)
Epoch: 37 | Batch_idx: 90 |  Loss: (0.4966) |  Loss2: (0.0000) | Acc: (82.00%) (9638/11648)
Epoch: 37 | Batch_idx: 100 |  Loss: (0.4960) |  Loss2: (0.0000) | Acc: (82.00%) (10716/12928)
Epoch: 37 | Batch_idx: 110 |  Loss: (0.4940) |  Loss2: (0.0000) | Acc: (82.00%) (11788/14208)
Epoch: 37 | Batch_idx: 120 |  Loss: (0.4993) |  Loss2: (0.0000) | Acc: (82.00%) (12819/15488)
Epoch: 37 | Batch_idx: 130 |  Loss: (0.4973) |  Loss2: (0.0000) | Acc: (82.00%) (13884/16768)
Epoch: 37 | Batch_idx: 140 |  Loss: (0.4999) |  Loss2: (0.0000) | Acc: (82.00%) (14917/18048)
Epoch: 37 | Batch_idx: 150 |  Loss: (0.5015) |  Loss2: (0.0000) | Acc: (82.00%) (15962/19328)
Epoch: 37 | Batch_idx: 160 |  Loss: (0.5043) |  Loss2: (0.0000) | Acc: (82.00%) (17013/20608)
Epoch: 37 | Batch_idx: 170 |  Loss: (0.5042) |  Loss2: (0.0000) | Acc: (82.00%) (18071/21888)
Epoch: 37 | Batch_idx: 180 |  Loss: (0.5053) |  Loss2: (0.0000) | Acc: (82.00%) (19113/23168)
Epoch: 37 | Batch_idx: 190 |  Loss: (0.5055) |  Loss2: (0.0000) | Acc: (82.00%) (20171/24448)
Epoch: 37 | Batch_idx: 200 |  Loss: (0.5055) |  Loss2: (0.0000) | Acc: (82.00%) (21232/25728)
Epoch: 37 | Batch_idx: 210 |  Loss: (0.5074) |  Loss2: (0.0000) | Acc: (82.00%) (22272/27008)
Epoch: 37 | Batch_idx: 220 |  Loss: (0.5067) |  Loss2: (0.0000) | Acc: (82.00%) (23341/28288)
Epoch: 37 | Batch_idx: 230 |  Loss: (0.5059) |  Loss2: (0.0000) | Acc: (82.00%) (24408/29568)
Epoch: 37 | Batch_idx: 240 |  Loss: (0.5051) |  Loss2: (0.0000) | Acc: (82.00%) (25475/30848)
Epoch: 37 | Batch_idx: 250 |  Loss: (0.5055) |  Loss2: (0.0000) | Acc: (82.00%) (26523/32128)
Epoch: 37 | Batch_idx: 260 |  Loss: (0.5054) |  Loss2: (0.0000) | Acc: (82.00%) (27583/33408)
Epoch: 37 | Batch_idx: 270 |  Loss: (0.5055) |  Loss2: (0.0000) | Acc: (82.00%) (28631/34688)
Epoch: 37 | Batch_idx: 280 |  Loss: (0.5049) |  Loss2: (0.0000) | Acc: (82.00%) (29697/35968)
Epoch: 37 | Batch_idx: 290 |  Loss: (0.5056) |  Loss2: (0.0000) | Acc: (82.00%) (30757/37248)
Epoch: 37 | Batch_idx: 300 |  Loss: (0.5048) |  Loss2: (0.0000) | Acc: (82.00%) (31820/38528)
Epoch: 37 | Batch_idx: 310 |  Loss: (0.5040) |  Loss2: (0.0000) | Acc: (82.00%) (32887/39808)
Epoch: 37 | Batch_idx: 320 |  Loss: (0.5042) |  Loss2: (0.0000) | Acc: (82.00%) (33941/41088)
Epoch: 37 | Batch_idx: 330 |  Loss: (0.5034) |  Loss2: (0.0000) | Acc: (82.00%) (35011/42368)
Epoch: 37 | Batch_idx: 340 |  Loss: (0.5033) |  Loss2: (0.0000) | Acc: (82.00%) (36075/43648)
Epoch: 37 | Batch_idx: 350 |  Loss: (0.5029) |  Loss2: (0.0000) | Acc: (82.00%) (37150/44928)
Epoch: 37 | Batch_idx: 360 |  Loss: (0.5034) |  Loss2: (0.0000) | Acc: (82.00%) (38208/46208)
Epoch: 37 | Batch_idx: 370 |  Loss: (0.5029) |  Loss2: (0.0000) | Acc: (82.00%) (39273/47488)
Epoch: 37 | Batch_idx: 380 |  Loss: (0.5025) |  Loss2: (0.0000) | Acc: (82.00%) (40343/48768)
Epoch: 37 | Batch_idx: 390 |  Loss: (0.5022) |  Loss2: (0.0000) | Acc: (82.00%) (41379/50000)
# TEST : Loss: (0.5517) | Acc: (81.00%) (8110/10000)
percent tensor([0.5207, 0.5360, 0.5240, 0.5235, 0.5262, 0.5171, 0.5357, 0.5296, 0.5294,
        0.5299, 0.5280, 0.5264, 0.5230, 0.5413, 0.5265, 0.5234],
       device='cuda:0') torch.Size([16])
percent tensor([0.4996, 0.5005, 0.4858, 0.4882, 0.4885, 0.4954, 0.4956, 0.4906, 0.4971,
        0.4951, 0.4997, 0.4896, 0.4996, 0.4984, 0.4957, 0.4970],
       device='cuda:0') torch.Size([16])
percent tensor([0.5409, 0.5465, 0.5440, 0.5846, 0.5737, 0.6007, 0.5697, 0.5871, 0.5288,
        0.5296, 0.5140, 0.5464, 0.5005, 0.5876, 0.5849, 0.5513],
       device='cuda:0') torch.Size([16])
percent tensor([0.6209, 0.5842, 0.6014, 0.6248, 0.6315, 0.6613, 0.6177, 0.6338, 0.5829,
        0.5823, 0.5761, 0.5871, 0.5690, 0.5966, 0.6375, 0.6321],
       device='cuda:0') torch.Size([16])
percent tensor([0.4853, 0.4809, 0.4841, 0.4855, 0.4827, 0.4938, 0.4811, 0.4764, 0.4888,
        0.4843, 0.4873, 0.4799, 0.4818, 0.4927, 0.4719, 0.4895],
       device='cuda:0') torch.Size([16])
percent tensor([0.5916, 0.5872, 0.6396, 0.6935, 0.6418, 0.6401, 0.6135, 0.6290, 0.6355,
        0.5834, 0.6215, 0.6541, 0.5731, 0.6660, 0.5962, 0.6087],
       device='cuda:0') torch.Size([16])
percent tensor([0.5565, 0.5326, 0.5631, 0.5758, 0.5450, 0.5625, 0.5294, 0.5267, 0.5606,
        0.5545, 0.5506, 0.5603, 0.5348, 0.5860, 0.4898, 0.5271],
       device='cuda:0') torch.Size([16])
percent tensor([0.9940, 0.9944, 0.9976, 0.9956, 0.9975, 0.9917, 0.9960, 0.9987, 0.9936,
        0.9968, 0.9957, 0.9967, 0.9907, 0.9956, 0.9970, 0.9966],
       device='cuda:0') torch.Size([16])
Epoch: 38 | Batch_idx: 0 |  Loss: (0.4917) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 38 | Batch_idx: 10 |  Loss: (0.4821) |  Loss2: (0.0000) | Acc: (83.00%) (1171/1408)
Epoch: 38 | Batch_idx: 20 |  Loss: (0.5015) |  Loss2: (0.0000) | Acc: (82.00%) (2218/2688)
Epoch: 38 | Batch_idx: 30 |  Loss: (0.4962) |  Loss2: (0.0000) | Acc: (82.00%) (3276/3968)
Epoch: 38 | Batch_idx: 40 |  Loss: (0.5066) |  Loss2: (0.0000) | Acc: (82.00%) (4322/5248)
Epoch: 38 | Batch_idx: 50 |  Loss: (0.5025) |  Loss2: (0.0000) | Acc: (82.00%) (5387/6528)
Epoch: 38 | Batch_idx: 60 |  Loss: (0.5015) |  Loss2: (0.0000) | Acc: (82.00%) (6443/7808)
Epoch: 38 | Batch_idx: 70 |  Loss: (0.4996) |  Loss2: (0.0000) | Acc: (82.00%) (7513/9088)
Epoch: 38 | Batch_idx: 80 |  Loss: (0.4973) |  Loss2: (0.0000) | Acc: (82.00%) (8588/10368)
Epoch: 38 | Batch_idx: 90 |  Loss: (0.4992) |  Loss2: (0.0000) | Acc: (82.00%) (9653/11648)
Epoch: 38 | Batch_idx: 100 |  Loss: (0.4966) |  Loss2: (0.0000) | Acc: (82.00%) (10727/12928)
Epoch: 38 | Batch_idx: 110 |  Loss: (0.4995) |  Loss2: (0.0000) | Acc: (82.00%) (11768/14208)
Epoch: 38 | Batch_idx: 120 |  Loss: (0.4939) |  Loss2: (0.0000) | Acc: (82.00%) (12854/15488)
Epoch: 38 | Batch_idx: 130 |  Loss: (0.4936) |  Loss2: (0.0000) | Acc: (82.00%) (13913/16768)
Epoch: 38 | Batch_idx: 140 |  Loss: (0.4913) |  Loss2: (0.0000) | Acc: (83.00%) (14990/18048)
Epoch: 38 | Batch_idx: 150 |  Loss: (0.4916) |  Loss2: (0.0000) | Acc: (83.00%) (16053/19328)
Epoch: 38 | Batch_idx: 160 |  Loss: (0.4876) |  Loss2: (0.0000) | Acc: (83.00%) (17154/20608)
Epoch: 38 | Batch_idx: 170 |  Loss: (0.4888) |  Loss2: (0.0000) | Acc: (83.00%) (18217/21888)
Epoch: 38 | Batch_idx: 180 |  Loss: (0.4876) |  Loss2: (0.0000) | Acc: (83.00%) (19292/23168)
Epoch: 38 | Batch_idx: 190 |  Loss: (0.4878) |  Loss2: (0.0000) | Acc: (83.00%) (20356/24448)
Epoch: 38 | Batch_idx: 200 |  Loss: (0.4894) |  Loss2: (0.0000) | Acc: (83.00%) (21408/25728)
Epoch: 38 | Batch_idx: 210 |  Loss: (0.4897) |  Loss2: (0.0000) | Acc: (83.00%) (22466/27008)
Epoch: 38 | Batch_idx: 220 |  Loss: (0.4909) |  Loss2: (0.0000) | Acc: (83.00%) (23514/28288)
Epoch: 38 | Batch_idx: 230 |  Loss: (0.4915) |  Loss2: (0.0000) | Acc: (83.00%) (24577/29568)
Epoch: 38 | Batch_idx: 240 |  Loss: (0.4916) |  Loss2: (0.0000) | Acc: (83.00%) (25644/30848)
Epoch: 38 | Batch_idx: 250 |  Loss: (0.4919) |  Loss2: (0.0000) | Acc: (83.00%) (26688/32128)
Epoch: 38 | Batch_idx: 260 |  Loss: (0.4942) |  Loss2: (0.0000) | Acc: (82.00%) (27714/33408)
Epoch: 38 | Batch_idx: 270 |  Loss: (0.4925) |  Loss2: (0.0000) | Acc: (83.00%) (28803/34688)
Epoch: 38 | Batch_idx: 280 |  Loss: (0.4927) |  Loss2: (0.0000) | Acc: (83.00%) (29870/35968)
Epoch: 38 | Batch_idx: 290 |  Loss: (0.4925) |  Loss2: (0.0000) | Acc: (83.00%) (30930/37248)
Epoch: 38 | Batch_idx: 300 |  Loss: (0.4923) |  Loss2: (0.0000) | Acc: (83.00%) (31992/38528)
Epoch: 38 | Batch_idx: 310 |  Loss: (0.4930) |  Loss2: (0.0000) | Acc: (83.00%) (33052/39808)
Epoch: 38 | Batch_idx: 320 |  Loss: (0.4935) |  Loss2: (0.0000) | Acc: (83.00%) (34117/41088)
Epoch: 38 | Batch_idx: 330 |  Loss: (0.4930) |  Loss2: (0.0000) | Acc: (83.00%) (35178/42368)
Epoch: 38 | Batch_idx: 340 |  Loss: (0.4939) |  Loss2: (0.0000) | Acc: (83.00%) (36242/43648)
Epoch: 38 | Batch_idx: 350 |  Loss: (0.4930) |  Loss2: (0.0000) | Acc: (83.00%) (37325/44928)
Epoch: 38 | Batch_idx: 360 |  Loss: (0.4933) |  Loss2: (0.0000) | Acc: (83.00%) (38383/46208)
Epoch: 38 | Batch_idx: 370 |  Loss: (0.4931) |  Loss2: (0.0000) | Acc: (83.00%) (39446/47488)
Epoch: 38 | Batch_idx: 380 |  Loss: (0.4938) |  Loss2: (0.0000) | Acc: (83.00%) (40490/48768)
Epoch: 38 | Batch_idx: 390 |  Loss: (0.4926) |  Loss2: (0.0000) | Acc: (83.00%) (41510/50000)
# TEST : Loss: (0.5430) | Acc: (81.00%) (8128/10000)
percent tensor([0.5210, 0.5366, 0.5243, 0.5236, 0.5264, 0.5173, 0.5363, 0.5298, 0.5297,
        0.5304, 0.5284, 0.5269, 0.5233, 0.5416, 0.5270, 0.5236],
       device='cuda:0') torch.Size([16])
percent tensor([0.5001, 0.5007, 0.4860, 0.4883, 0.4888, 0.4959, 0.4960, 0.4911, 0.4973,
        0.4953, 0.4998, 0.4899, 0.5000, 0.4983, 0.4963, 0.4973],
       device='cuda:0') torch.Size([16])
percent tensor([0.5347, 0.5409, 0.5378, 0.5783, 0.5686, 0.5950, 0.5647, 0.5834, 0.5222,
        0.5224, 0.5069, 0.5386, 0.4973, 0.5796, 0.5807, 0.5449],
       device='cuda:0') torch.Size([16])
percent tensor([0.6182, 0.5780, 0.5995, 0.6238, 0.6303, 0.6612, 0.6135, 0.6319, 0.5784,
        0.5762, 0.5691, 0.5826, 0.5621, 0.5910, 0.6339, 0.6282],
       device='cuda:0') torch.Size([16])
percent tensor([0.4867, 0.4822, 0.4859, 0.4875, 0.4847, 0.4944, 0.4827, 0.4780, 0.4902,
        0.4862, 0.4887, 0.4819, 0.4828, 0.4941, 0.4732, 0.4911],
       device='cuda:0') torch.Size([16])
percent tensor([0.5974, 0.5946, 0.6442, 0.6970, 0.6472, 0.6473, 0.6183, 0.6335, 0.6403,
        0.5900, 0.6269, 0.6567, 0.5774, 0.6727, 0.6022, 0.6135],
       device='cuda:0') torch.Size([16])
percent tensor([0.5685, 0.5449, 0.5731, 0.5849, 0.5538, 0.5755, 0.5376, 0.5306, 0.5742,
        0.5701, 0.5646, 0.5710, 0.5468, 0.6032, 0.4922, 0.5348],
       device='cuda:0') torch.Size([16])
percent tensor([0.9951, 0.9952, 0.9979, 0.9961, 0.9977, 0.9929, 0.9967, 0.9988, 0.9946,
        0.9974, 0.9965, 0.9972, 0.9921, 0.9964, 0.9975, 0.9972],
       device='cuda:0') torch.Size([16])
Epoch: 39 | Batch_idx: 0 |  Loss: (0.4884) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 39 | Batch_idx: 10 |  Loss: (0.4973) |  Loss2: (0.0000) | Acc: (83.00%) (1171/1408)
Epoch: 39 | Batch_idx: 20 |  Loss: (0.4906) |  Loss2: (0.0000) | Acc: (83.00%) (2236/2688)
Epoch: 39 | Batch_idx: 30 |  Loss: (0.4977) |  Loss2: (0.0000) | Acc: (82.00%) (3288/3968)
Epoch: 39 | Batch_idx: 40 |  Loss: (0.4887) |  Loss2: (0.0000) | Acc: (83.00%) (4373/5248)
Epoch: 39 | Batch_idx: 50 |  Loss: (0.4937) |  Loss2: (0.0000) | Acc: (83.00%) (5433/6528)
Epoch: 39 | Batch_idx: 60 |  Loss: (0.4832) |  Loss2: (0.0000) | Acc: (83.00%) (6518/7808)
Epoch: 39 | Batch_idx: 70 |  Loss: (0.4858) |  Loss2: (0.0000) | Acc: (83.00%) (7579/9088)
Epoch: 39 | Batch_idx: 80 |  Loss: (0.4825) |  Loss2: (0.0000) | Acc: (83.00%) (8649/10368)
Epoch: 39 | Batch_idx: 90 |  Loss: (0.4808) |  Loss2: (0.0000) | Acc: (83.00%) (9720/11648)
Epoch: 39 | Batch_idx: 100 |  Loss: (0.4790) |  Loss2: (0.0000) | Acc: (83.00%) (10792/12928)
Epoch: 39 | Batch_idx: 110 |  Loss: (0.4818) |  Loss2: (0.0000) | Acc: (83.00%) (11832/14208)
Epoch: 39 | Batch_idx: 120 |  Loss: (0.4847) |  Loss2: (0.0000) | Acc: (83.00%) (12897/15488)
Epoch: 39 | Batch_idx: 130 |  Loss: (0.4854) |  Loss2: (0.0000) | Acc: (83.00%) (13952/16768)
Epoch: 39 | Batch_idx: 140 |  Loss: (0.4835) |  Loss2: (0.0000) | Acc: (83.00%) (15040/18048)
Epoch: 39 | Batch_idx: 150 |  Loss: (0.4842) |  Loss2: (0.0000) | Acc: (83.00%) (16103/19328)
Epoch: 39 | Batch_idx: 160 |  Loss: (0.4817) |  Loss2: (0.0000) | Acc: (83.00%) (17180/20608)
Epoch: 39 | Batch_idx: 170 |  Loss: (0.4796) |  Loss2: (0.0000) | Acc: (83.00%) (18268/21888)
Epoch: 39 | Batch_idx: 180 |  Loss: (0.4799) |  Loss2: (0.0000) | Acc: (83.00%) (19332/23168)
Epoch: 39 | Batch_idx: 190 |  Loss: (0.4801) |  Loss2: (0.0000) | Acc: (83.00%) (20393/24448)
Epoch: 39 | Batch_idx: 200 |  Loss: (0.4800) |  Loss2: (0.0000) | Acc: (83.00%) (21464/25728)
Epoch: 39 | Batch_idx: 210 |  Loss: (0.4780) |  Loss2: (0.0000) | Acc: (83.00%) (22550/27008)
Epoch: 39 | Batch_idx: 220 |  Loss: (0.4801) |  Loss2: (0.0000) | Acc: (83.00%) (23597/28288)
Epoch: 39 | Batch_idx: 230 |  Loss: (0.4810) |  Loss2: (0.0000) | Acc: (83.00%) (24661/29568)
Epoch: 39 | Batch_idx: 240 |  Loss: (0.4821) |  Loss2: (0.0000) | Acc: (83.00%) (25714/30848)
Epoch: 39 | Batch_idx: 250 |  Loss: (0.4831) |  Loss2: (0.0000) | Acc: (83.00%) (26782/32128)
Epoch: 39 | Batch_idx: 260 |  Loss: (0.4835) |  Loss2: (0.0000) | Acc: (83.00%) (27844/33408)
Epoch: 39 | Batch_idx: 270 |  Loss: (0.4825) |  Loss2: (0.0000) | Acc: (83.00%) (28925/34688)
Epoch: 39 | Batch_idx: 280 |  Loss: (0.4826) |  Loss2: (0.0000) | Acc: (83.00%) (30008/35968)
Epoch: 39 | Batch_idx: 290 |  Loss: (0.4827) |  Loss2: (0.0000) | Acc: (83.00%) (31062/37248)
Epoch: 39 | Batch_idx: 300 |  Loss: (0.4835) |  Loss2: (0.0000) | Acc: (83.00%) (32110/38528)
Epoch: 39 | Batch_idx: 310 |  Loss: (0.4827) |  Loss2: (0.0000) | Acc: (83.00%) (33181/39808)
Epoch: 39 | Batch_idx: 320 |  Loss: (0.4840) |  Loss2: (0.0000) | Acc: (83.00%) (34224/41088)
Epoch: 39 | Batch_idx: 330 |  Loss: (0.4842) |  Loss2: (0.0000) | Acc: (83.00%) (35307/42368)
Epoch: 39 | Batch_idx: 340 |  Loss: (0.4846) |  Loss2: (0.0000) | Acc: (83.00%) (36360/43648)
Epoch: 39 | Batch_idx: 350 |  Loss: (0.4847) |  Loss2: (0.0000) | Acc: (83.00%) (37427/44928)
Epoch: 39 | Batch_idx: 360 |  Loss: (0.4856) |  Loss2: (0.0000) | Acc: (83.00%) (38470/46208)
Epoch: 39 | Batch_idx: 370 |  Loss: (0.4857) |  Loss2: (0.0000) | Acc: (83.00%) (39536/47488)
Epoch: 39 | Batch_idx: 380 |  Loss: (0.4849) |  Loss2: (0.0000) | Acc: (83.00%) (40631/48768)
Epoch: 39 | Batch_idx: 390 |  Loss: (0.4859) |  Loss2: (0.0000) | Acc: (83.00%) (41637/50000)
# TEST : Loss: (0.5400) | Acc: (81.00%) (8127/10000)
percent tensor([0.5211, 0.5365, 0.5248, 0.5238, 0.5268, 0.5174, 0.5365, 0.5300, 0.5296,
        0.5306, 0.5283, 0.5275, 0.5234, 0.5411, 0.5272, 0.5236],
       device='cuda:0') torch.Size([16])
percent tensor([0.5022, 0.5033, 0.4878, 0.4900, 0.4908, 0.4977, 0.4986, 0.4934, 0.4995,
        0.4976, 0.5020, 0.4920, 0.5023, 0.5003, 0.4987, 0.4995],
       device='cuda:0') torch.Size([16])
percent tensor([0.5410, 0.5465, 0.5419, 0.5836, 0.5740, 0.6026, 0.5707, 0.5895, 0.5257,
        0.5271, 0.5114, 0.5426, 0.5002, 0.5840, 0.5882, 0.5515],
       device='cuda:0') torch.Size([16])
percent tensor([0.6172, 0.5744, 0.5987, 0.6235, 0.6301, 0.6613, 0.6122, 0.6320, 0.5752,
        0.5729, 0.5651, 0.5805, 0.5577, 0.5880, 0.6321, 0.6260],
       device='cuda:0') torch.Size([16])
percent tensor([0.4863, 0.4813, 0.4858, 0.4876, 0.4850, 0.4948, 0.4819, 0.4777, 0.4897,
        0.4856, 0.4878, 0.4811, 0.4817, 0.4937, 0.4718, 0.4915],
       device='cuda:0') torch.Size([16])
percent tensor([0.6042, 0.6015, 0.6492, 0.7018, 0.6520, 0.6538, 0.6240, 0.6385, 0.6458,
        0.5964, 0.6338, 0.6608, 0.5842, 0.6790, 0.6079, 0.6199],
       device='cuda:0') torch.Size([16])
percent tensor([0.5712, 0.5457, 0.5797, 0.5924, 0.5581, 0.5817, 0.5363, 0.5336, 0.5793,
        0.5748, 0.5680, 0.5764, 0.5483, 0.6110, 0.4894, 0.5364],
       device='cuda:0') torch.Size([16])
percent tensor([0.9961, 0.9961, 0.9984, 0.9969, 0.9982, 0.9940, 0.9973, 0.9991, 0.9956,
        0.9980, 0.9972, 0.9977, 0.9933, 0.9972, 0.9981, 0.9978],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 40 | Batch_idx: 0 |  Loss: (0.3507) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 40 | Batch_idx: 10 |  Loss: (0.4694) |  Loss2: (0.0000) | Acc: (84.00%) (1193/1408)
Epoch: 40 | Batch_idx: 20 |  Loss: (0.4760) |  Loss2: (0.0000) | Acc: (84.00%) (2263/2688)
Epoch: 40 | Batch_idx: 30 |  Loss: (0.4795) |  Loss2: (0.0000) | Acc: (83.00%) (3327/3968)
Epoch: 40 | Batch_idx: 40 |  Loss: (0.4731) |  Loss2: (0.0000) | Acc: (83.00%) (4408/5248)
Epoch: 40 | Batch_idx: 50 |  Loss: (0.4773) |  Loss2: (0.0000) | Acc: (83.00%) (5476/6528)
Epoch: 40 | Batch_idx: 60 |  Loss: (0.4766) |  Loss2: (0.0000) | Acc: (83.00%) (6550/7808)
Epoch: 40 | Batch_idx: 70 |  Loss: (0.4802) |  Loss2: (0.0000) | Acc: (83.00%) (7605/9088)
Epoch: 40 | Batch_idx: 80 |  Loss: (0.4832) |  Loss2: (0.0000) | Acc: (83.00%) (8660/10368)
Epoch: 40 | Batch_idx: 90 |  Loss: (0.4842) |  Loss2: (0.0000) | Acc: (83.00%) (9707/11648)
Epoch: 40 | Batch_idx: 100 |  Loss: (0.4817) |  Loss2: (0.0000) | Acc: (83.00%) (10797/12928)
Epoch: 40 | Batch_idx: 110 |  Loss: (0.4844) |  Loss2: (0.0000) | Acc: (83.00%) (11852/14208)
Epoch: 40 | Batch_idx: 120 |  Loss: (0.4808) |  Loss2: (0.0000) | Acc: (83.00%) (12942/15488)
Epoch: 40 | Batch_idx: 130 |  Loss: (0.4822) |  Loss2: (0.0000) | Acc: (83.00%) (14004/16768)
Epoch: 40 | Batch_idx: 140 |  Loss: (0.4820) |  Loss2: (0.0000) | Acc: (83.00%) (15065/18048)
Epoch: 40 | Batch_idx: 150 |  Loss: (0.4812) |  Loss2: (0.0000) | Acc: (83.00%) (16147/19328)
Epoch: 40 | Batch_idx: 160 |  Loss: (0.4819) |  Loss2: (0.0000) | Acc: (83.00%) (17207/20608)
Epoch: 40 | Batch_idx: 170 |  Loss: (0.4819) |  Loss2: (0.0000) | Acc: (83.00%) (18274/21888)
Epoch: 40 | Batch_idx: 180 |  Loss: (0.4818) |  Loss2: (0.0000) | Acc: (83.00%) (19330/23168)
Epoch: 40 | Batch_idx: 190 |  Loss: (0.4800) |  Loss2: (0.0000) | Acc: (83.00%) (20423/24448)
Epoch: 40 | Batch_idx: 200 |  Loss: (0.4824) |  Loss2: (0.0000) | Acc: (83.00%) (21455/25728)
Epoch: 40 | Batch_idx: 210 |  Loss: (0.4813) |  Loss2: (0.0000) | Acc: (83.00%) (22537/27008)
Epoch: 40 | Batch_idx: 220 |  Loss: (0.4810) |  Loss2: (0.0000) | Acc: (83.00%) (23603/28288)
Epoch: 40 | Batch_idx: 230 |  Loss: (0.4793) |  Loss2: (0.0000) | Acc: (83.00%) (24690/29568)
Epoch: 40 | Batch_idx: 240 |  Loss: (0.4777) |  Loss2: (0.0000) | Acc: (83.00%) (25770/30848)
Epoch: 40 | Batch_idx: 250 |  Loss: (0.4796) |  Loss2: (0.0000) | Acc: (83.00%) (26824/32128)
Epoch: 40 | Batch_idx: 260 |  Loss: (0.4805) |  Loss2: (0.0000) | Acc: (83.00%) (27859/33408)
Epoch: 40 | Batch_idx: 270 |  Loss: (0.4809) |  Loss2: (0.0000) | Acc: (83.00%) (28916/34688)
Epoch: 40 | Batch_idx: 280 |  Loss: (0.4808) |  Loss2: (0.0000) | Acc: (83.00%) (29983/35968)
Epoch: 40 | Batch_idx: 290 |  Loss: (0.4812) |  Loss2: (0.0000) | Acc: (83.00%) (31046/37248)
Epoch: 40 | Batch_idx: 300 |  Loss: (0.4830) |  Loss2: (0.0000) | Acc: (83.00%) (32085/38528)
Epoch: 40 | Batch_idx: 310 |  Loss: (0.4835) |  Loss2: (0.0000) | Acc: (83.00%) (33158/39808)
Epoch: 40 | Batch_idx: 320 |  Loss: (0.4842) |  Loss2: (0.0000) | Acc: (83.00%) (34215/41088)
Epoch: 40 | Batch_idx: 330 |  Loss: (0.4852) |  Loss2: (0.0000) | Acc: (83.00%) (35269/42368)
Epoch: 40 | Batch_idx: 340 |  Loss: (0.4852) |  Loss2: (0.0000) | Acc: (83.00%) (36336/43648)
Epoch: 40 | Batch_idx: 350 |  Loss: (0.4853) |  Loss2: (0.0000) | Acc: (83.00%) (37408/44928)
Epoch: 40 | Batch_idx: 360 |  Loss: (0.4866) |  Loss2: (0.0000) | Acc: (83.00%) (38461/46208)
Epoch: 40 | Batch_idx: 370 |  Loss: (0.4873) |  Loss2: (0.0000) | Acc: (83.00%) (39511/47488)
Epoch: 40 | Batch_idx: 380 |  Loss: (0.4880) |  Loss2: (0.0000) | Acc: (83.00%) (40559/48768)
Epoch: 40 | Batch_idx: 390 |  Loss: (0.4880) |  Loss2: (0.0000) | Acc: (83.00%) (41585/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_040.pth.tar'
# TEST : Loss: (0.5717) | Acc: (80.00%) (8093/10000)
percent tensor([0.5203, 0.5361, 0.5233, 0.5227, 0.5253, 0.5160, 0.5358, 0.5297, 0.5290,
        0.5297, 0.5276, 0.5258, 0.5225, 0.5406, 0.5266, 0.5230],
       device='cuda:0') torch.Size([16])
percent tensor([0.5007, 0.5013, 0.4888, 0.4893, 0.4906, 0.4965, 0.4977, 0.4939, 0.4979,
        0.4971, 0.5005, 0.4938, 0.5009, 0.4989, 0.4980, 0.4981],
       device='cuda:0') torch.Size([16])
percent tensor([0.5407, 0.5404, 0.5475, 0.5771, 0.5771, 0.5902, 0.5684, 0.5865, 0.5257,
        0.5228, 0.5115, 0.5418, 0.4998, 0.5776, 0.5794, 0.5468],
       device='cuda:0') torch.Size([16])
percent tensor([0.6177, 0.5741, 0.6068, 0.6241, 0.6331, 0.6578, 0.6115, 0.6312, 0.5752,
        0.5746, 0.5662, 0.5783, 0.5584, 0.5892, 0.6296, 0.6245],
       device='cuda:0') torch.Size([16])
percent tensor([0.4860, 0.4835, 0.4832, 0.4862, 0.4823, 0.4940, 0.4846, 0.4778, 0.4914,
        0.4872, 0.4887, 0.4778, 0.4828, 0.4955, 0.4728, 0.4934],
       device='cuda:0') torch.Size([16])
percent tensor([0.6015, 0.6022, 0.6329, 0.6821, 0.6506, 0.6492, 0.6190, 0.6351, 0.6503,
        0.5947, 0.6373, 0.6494, 0.5856, 0.6797, 0.6027, 0.6186],
       device='cuda:0') torch.Size([16])
percent tensor([0.5648, 0.5448, 0.5701, 0.5835, 0.5587, 0.5744, 0.5462, 0.5326, 0.5887,
        0.5695, 0.5685, 0.5723, 0.5493, 0.6038, 0.4944, 0.5389],
       device='cuda:0') torch.Size([16])
percent tensor([0.9959, 0.9958, 0.9982, 0.9959, 0.9980, 0.9933, 0.9971, 0.9989, 0.9963,
        0.9980, 0.9970, 0.9988, 0.9952, 0.9956, 0.9977, 0.9973],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(167.8977, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(794.7140, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(786.0654, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1531.4362, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(501.1927, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2184.4902, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4293.6421, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1431.5570, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6095.7607, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12093.4199, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4042.9517, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17045.5801, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 41 | Batch_idx: 0 |  Loss: (0.3431) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 41 | Batch_idx: 10 |  Loss: (0.4736) |  Loss2: (0.0000) | Acc: (83.00%) (1181/1408)
Epoch: 41 | Batch_idx: 20 |  Loss: (0.4698) |  Loss2: (0.0000) | Acc: (84.00%) (2259/2688)
Epoch: 41 | Batch_idx: 30 |  Loss: (0.4740) |  Loss2: (0.0000) | Acc: (83.00%) (3318/3968)
Epoch: 41 | Batch_idx: 40 |  Loss: (0.4675) |  Loss2: (0.0000) | Acc: (83.00%) (4393/5248)
Epoch: 41 | Batch_idx: 50 |  Loss: (0.4734) |  Loss2: (0.0000) | Acc: (83.00%) (5453/6528)
Epoch: 41 | Batch_idx: 60 |  Loss: (0.4735) |  Loss2: (0.0000) | Acc: (83.00%) (6534/7808)
Epoch: 41 | Batch_idx: 70 |  Loss: (0.4697) |  Loss2: (0.0000) | Acc: (83.00%) (7615/9088)
Epoch: 41 | Batch_idx: 80 |  Loss: (0.4704) |  Loss2: (0.0000) | Acc: (83.00%) (8692/10368)
Epoch: 41 | Batch_idx: 90 |  Loss: (0.4681) |  Loss2: (0.0000) | Acc: (83.00%) (9762/11648)
Epoch: 41 | Batch_idx: 100 |  Loss: (0.4683) |  Loss2: (0.0000) | Acc: (83.00%) (10824/12928)
Epoch: 41 | Batch_idx: 110 |  Loss: (0.4710) |  Loss2: (0.0000) | Acc: (83.00%) (11878/14208)
Epoch: 41 | Batch_idx: 120 |  Loss: (0.4713) |  Loss2: (0.0000) | Acc: (83.00%) (12938/15488)
Epoch: 41 | Batch_idx: 130 |  Loss: (0.4720) |  Loss2: (0.0000) | Acc: (83.00%) (14004/16768)
Epoch: 41 | Batch_idx: 140 |  Loss: (0.4696) |  Loss2: (0.0000) | Acc: (83.00%) (15093/18048)
Epoch: 41 | Batch_idx: 150 |  Loss: (0.4680) |  Loss2: (0.0000) | Acc: (83.00%) (16187/19328)
Epoch: 41 | Batch_idx: 160 |  Loss: (0.4669) |  Loss2: (0.0000) | Acc: (83.00%) (17255/20608)
Epoch: 41 | Batch_idx: 170 |  Loss: (0.4649) |  Loss2: (0.0000) | Acc: (83.00%) (18351/21888)
Epoch: 41 | Batch_idx: 180 |  Loss: (0.4646) |  Loss2: (0.0000) | Acc: (83.00%) (19427/23168)
Epoch: 41 | Batch_idx: 190 |  Loss: (0.4643) |  Loss2: (0.0000) | Acc: (83.00%) (20493/24448)
Epoch: 41 | Batch_idx: 200 |  Loss: (0.4650) |  Loss2: (0.0000) | Acc: (83.00%) (21567/25728)
Epoch: 41 | Batch_idx: 210 |  Loss: (0.4652) |  Loss2: (0.0000) | Acc: (83.00%) (22652/27008)
Epoch: 41 | Batch_idx: 220 |  Loss: (0.4650) |  Loss2: (0.0000) | Acc: (83.00%) (23734/28288)
Epoch: 41 | Batch_idx: 230 |  Loss: (0.4650) |  Loss2: (0.0000) | Acc: (83.00%) (24813/29568)
Epoch: 41 | Batch_idx: 240 |  Loss: (0.4641) |  Loss2: (0.0000) | Acc: (83.00%) (25905/30848)
Epoch: 41 | Batch_idx: 250 |  Loss: (0.4645) |  Loss2: (0.0000) | Acc: (83.00%) (26979/32128)
Epoch: 41 | Batch_idx: 260 |  Loss: (0.4649) |  Loss2: (0.0000) | Acc: (83.00%) (28057/33408)
Epoch: 41 | Batch_idx: 270 |  Loss: (0.4645) |  Loss2: (0.0000) | Acc: (83.00%) (29134/34688)
Epoch: 41 | Batch_idx: 280 |  Loss: (0.4657) |  Loss2: (0.0000) | Acc: (83.00%) (30184/35968)
Epoch: 41 | Batch_idx: 290 |  Loss: (0.4640) |  Loss2: (0.0000) | Acc: (83.00%) (31277/37248)
Epoch: 41 | Batch_idx: 300 |  Loss: (0.4643) |  Loss2: (0.0000) | Acc: (83.00%) (32351/38528)
Epoch: 41 | Batch_idx: 310 |  Loss: (0.4647) |  Loss2: (0.0000) | Acc: (83.00%) (33425/39808)
Epoch: 41 | Batch_idx: 320 |  Loss: (0.4643) |  Loss2: (0.0000) | Acc: (83.00%) (34496/41088)
Epoch: 41 | Batch_idx: 330 |  Loss: (0.4643) |  Loss2: (0.0000) | Acc: (84.00%) (35594/42368)
Epoch: 41 | Batch_idx: 340 |  Loss: (0.4657) |  Loss2: (0.0000) | Acc: (83.00%) (36643/43648)
Epoch: 41 | Batch_idx: 350 |  Loss: (0.4660) |  Loss2: (0.0000) | Acc: (83.00%) (37709/44928)
Epoch: 41 | Batch_idx: 360 |  Loss: (0.4661) |  Loss2: (0.0000) | Acc: (83.00%) (38780/46208)
Epoch: 41 | Batch_idx: 370 |  Loss: (0.4659) |  Loss2: (0.0000) | Acc: (83.00%) (39846/47488)
Epoch: 41 | Batch_idx: 380 |  Loss: (0.4649) |  Loss2: (0.0000) | Acc: (83.00%) (40940/48768)
Epoch: 41 | Batch_idx: 390 |  Loss: (0.4646) |  Loss2: (0.0000) | Acc: (83.00%) (41989/50000)
# TEST : Loss: (0.6413) | Acc: (78.00%) (7863/10000)
percent tensor([0.5203, 0.5355, 0.5239, 0.5228, 0.5260, 0.5163, 0.5354, 0.5300, 0.5288,
        0.5297, 0.5273, 0.5262, 0.5223, 0.5403, 0.5264, 0.5228],
       device='cuda:0') torch.Size([16])
percent tensor([0.5017, 0.5017, 0.4917, 0.4905, 0.4930, 0.4964, 0.4987, 0.4952, 0.4995,
        0.4980, 0.5008, 0.4950, 0.5015, 0.4990, 0.4979, 0.4988],
       device='cuda:0') torch.Size([16])
percent tensor([0.5415, 0.5436, 0.5494, 0.5776, 0.5762, 0.5825, 0.5720, 0.5935, 0.5285,
        0.5291, 0.5132, 0.5482, 0.5019, 0.5783, 0.5831, 0.5493],
       device='cuda:0') torch.Size([16])
percent tensor([0.6148, 0.5720, 0.6063, 0.6165, 0.6341, 0.6398, 0.6121, 0.6282, 0.5770,
        0.5751, 0.5657, 0.5847, 0.5604, 0.5856, 0.6247, 0.6165],
       device='cuda:0') torch.Size([16])
percent tensor([0.4864, 0.4820, 0.4871, 0.4883, 0.4857, 0.4958, 0.4834, 0.4772, 0.4882,
        0.4862, 0.4875, 0.4803, 0.4812, 0.4921, 0.4725, 0.4925],
       device='cuda:0') torch.Size([16])
percent tensor([0.6117, 0.5986, 0.6540, 0.6922, 0.6597, 0.6544, 0.6352, 0.6392, 0.6403,
        0.5943, 0.6355, 0.6605, 0.5934, 0.6772, 0.6115, 0.6331],
       device='cuda:0') torch.Size([16])
percent tensor([0.5719, 0.5482, 0.5852, 0.5932, 0.5730, 0.5888, 0.5525, 0.5269, 0.5871,
        0.5691, 0.5737, 0.5822, 0.5506, 0.5993, 0.4982, 0.5475],
       device='cuda:0') torch.Size([16])
percent tensor([0.9970, 0.9971, 0.9982, 0.9963, 0.9982, 0.9943, 0.9969, 0.9990, 0.9978,
        0.9977, 0.9978, 0.9987, 0.9955, 0.9979, 0.9976, 0.9973],
       device='cuda:0') torch.Size([16])
Epoch: 42 | Batch_idx: 0 |  Loss: (0.4232) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 42 | Batch_idx: 10 |  Loss: (0.4278) |  Loss2: (0.0000) | Acc: (85.00%) (1197/1408)
Epoch: 42 | Batch_idx: 20 |  Loss: (0.4301) |  Loss2: (0.0000) | Acc: (85.00%) (2289/2688)
Epoch: 42 | Batch_idx: 30 |  Loss: (0.4426) |  Loss2: (0.0000) | Acc: (84.00%) (3347/3968)
Epoch: 42 | Batch_idx: 40 |  Loss: (0.4417) |  Loss2: (0.0000) | Acc: (84.00%) (4431/5248)
Epoch: 42 | Batch_idx: 50 |  Loss: (0.4397) |  Loss2: (0.0000) | Acc: (84.00%) (5524/6528)
Epoch: 42 | Batch_idx: 60 |  Loss: (0.4434) |  Loss2: (0.0000) | Acc: (84.00%) (6614/7808)
Epoch: 42 | Batch_idx: 70 |  Loss: (0.4479) |  Loss2: (0.0000) | Acc: (84.00%) (7670/9088)
Epoch: 42 | Batch_idx: 80 |  Loss: (0.4487) |  Loss2: (0.0000) | Acc: (84.00%) (8750/10368)
Epoch: 42 | Batch_idx: 90 |  Loss: (0.4467) |  Loss2: (0.0000) | Acc: (84.00%) (9843/11648)
Epoch: 42 | Batch_idx: 100 |  Loss: (0.4477) |  Loss2: (0.0000) | Acc: (84.00%) (10916/12928)
Epoch: 42 | Batch_idx: 110 |  Loss: (0.4470) |  Loss2: (0.0000) | Acc: (84.00%) (11994/14208)
Epoch: 42 | Batch_idx: 120 |  Loss: (0.4514) |  Loss2: (0.0000) | Acc: (84.00%) (13062/15488)
Epoch: 42 | Batch_idx: 130 |  Loss: (0.4503) |  Loss2: (0.0000) | Acc: (84.00%) (14152/16768)
Epoch: 42 | Batch_idx: 140 |  Loss: (0.4504) |  Loss2: (0.0000) | Acc: (84.00%) (15235/18048)
Epoch: 42 | Batch_idx: 150 |  Loss: (0.4494) |  Loss2: (0.0000) | Acc: (84.00%) (16321/19328)
Epoch: 42 | Batch_idx: 160 |  Loss: (0.4495) |  Loss2: (0.0000) | Acc: (84.00%) (17400/20608)
Epoch: 42 | Batch_idx: 170 |  Loss: (0.4500) |  Loss2: (0.0000) | Acc: (84.00%) (18473/21888)
Epoch: 42 | Batch_idx: 180 |  Loss: (0.4500) |  Loss2: (0.0000) | Acc: (84.00%) (19558/23168)
Epoch: 42 | Batch_idx: 190 |  Loss: (0.4523) |  Loss2: (0.0000) | Acc: (84.00%) (20626/24448)
Epoch: 42 | Batch_idx: 200 |  Loss: (0.4524) |  Loss2: (0.0000) | Acc: (84.00%) (21712/25728)
Epoch: 42 | Batch_idx: 210 |  Loss: (0.4512) |  Loss2: (0.0000) | Acc: (84.00%) (22802/27008)
Epoch: 42 | Batch_idx: 220 |  Loss: (0.4522) |  Loss2: (0.0000) | Acc: (84.00%) (23867/28288)
Epoch: 42 | Batch_idx: 230 |  Loss: (0.4523) |  Loss2: (0.0000) | Acc: (84.00%) (24951/29568)
Epoch: 42 | Batch_idx: 240 |  Loss: (0.4533) |  Loss2: (0.0000) | Acc: (84.00%) (26029/30848)
Epoch: 42 | Batch_idx: 250 |  Loss: (0.4519) |  Loss2: (0.0000) | Acc: (84.00%) (27135/32128)
Epoch: 42 | Batch_idx: 260 |  Loss: (0.4515) |  Loss2: (0.0000) | Acc: (84.00%) (28220/33408)
Epoch: 42 | Batch_idx: 270 |  Loss: (0.4511) |  Loss2: (0.0000) | Acc: (84.00%) (29304/34688)
Epoch: 42 | Batch_idx: 280 |  Loss: (0.4511) |  Loss2: (0.0000) | Acc: (84.00%) (30378/35968)
Epoch: 42 | Batch_idx: 290 |  Loss: (0.4496) |  Loss2: (0.0000) | Acc: (84.00%) (31490/37248)
Epoch: 42 | Batch_idx: 300 |  Loss: (0.4499) |  Loss2: (0.0000) | Acc: (84.00%) (32571/38528)
Epoch: 42 | Batch_idx: 310 |  Loss: (0.4492) |  Loss2: (0.0000) | Acc: (84.00%) (33671/39808)
Epoch: 42 | Batch_idx: 320 |  Loss: (0.4486) |  Loss2: (0.0000) | Acc: (84.00%) (34767/41088)
Epoch: 42 | Batch_idx: 330 |  Loss: (0.4474) |  Loss2: (0.0000) | Acc: (84.00%) (35867/42368)
Epoch: 42 | Batch_idx: 340 |  Loss: (0.4481) |  Loss2: (0.0000) | Acc: (84.00%) (36941/43648)
Epoch: 42 | Batch_idx: 350 |  Loss: (0.4487) |  Loss2: (0.0000) | Acc: (84.00%) (38027/44928)
Epoch: 42 | Batch_idx: 360 |  Loss: (0.4498) |  Loss2: (0.0000) | Acc: (84.00%) (39076/46208)
Epoch: 42 | Batch_idx: 370 |  Loss: (0.4500) |  Loss2: (0.0000) | Acc: (84.00%) (40148/47488)
Epoch: 42 | Batch_idx: 380 |  Loss: (0.4502) |  Loss2: (0.0000) | Acc: (84.00%) (41229/48768)
Epoch: 42 | Batch_idx: 390 |  Loss: (0.4498) |  Loss2: (0.0000) | Acc: (84.00%) (42280/50000)
# TEST : Loss: (0.5113) | Acc: (82.00%) (8273/10000)
percent tensor([0.5198, 0.5357, 0.5239, 0.5219, 0.5257, 0.5157, 0.5360, 0.5293, 0.5292,
        0.5298, 0.5275, 0.5267, 0.5221, 0.5403, 0.5261, 0.5225],
       device='cuda:0') torch.Size([16])
percent tensor([0.5011, 0.5033, 0.4894, 0.4901, 0.4918, 0.4963, 0.4996, 0.4944, 0.4982,
        0.4990, 0.5010, 0.4943, 0.5015, 0.5017, 0.4981, 0.4989],
       device='cuda:0') torch.Size([16])
percent tensor([0.5494, 0.5480, 0.5546, 0.5805, 0.5842, 0.5960, 0.5761, 0.5941, 0.5378,
        0.5331, 0.5289, 0.5500, 0.5101, 0.5711, 0.5877, 0.5577],
       device='cuda:0') torch.Size([16])
percent tensor([0.6311, 0.5789, 0.6149, 0.6296, 0.6426, 0.6655, 0.6168, 0.6364, 0.5822,
        0.5808, 0.5740, 0.5842, 0.5713, 0.5844, 0.6353, 0.6352],
       device='cuda:0') torch.Size([16])
percent tensor([0.4880, 0.4802, 0.4867, 0.4898, 0.4856, 0.4963, 0.4812, 0.4772, 0.4900,
        0.4852, 0.4867, 0.4801, 0.4815, 0.4919, 0.4732, 0.4935],
       device='cuda:0') torch.Size([16])
percent tensor([0.6011, 0.5869, 0.6538, 0.6986, 0.6702, 0.6605, 0.6216, 0.6423, 0.6380,
        0.5882, 0.6186, 0.6540, 0.5886, 0.6529, 0.6033, 0.6349],
       device='cuda:0') torch.Size([16])
percent tensor([0.5530, 0.5321, 0.5750, 0.5884, 0.5726, 0.5928, 0.5291, 0.5186, 0.5754,
        0.5629, 0.5577, 0.5674, 0.5410, 0.5827, 0.4910, 0.5439],
       device='cuda:0') torch.Size([16])
percent tensor([0.9962, 0.9948, 0.9981, 0.9977, 0.9985, 0.9944, 0.9966, 0.9991, 0.9951,
        0.9970, 0.9967, 0.9981, 0.9939, 0.9951, 0.9980, 0.9979],
       device='cuda:0') torch.Size([16])
Epoch: 43 | Batch_idx: 0 |  Loss: (0.3696) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 43 | Batch_idx: 10 |  Loss: (0.4325) |  Loss2: (0.0000) | Acc: (85.00%) (1202/1408)
Epoch: 43 | Batch_idx: 20 |  Loss: (0.4316) |  Loss2: (0.0000) | Acc: (85.00%) (2286/2688)
Epoch: 43 | Batch_idx: 30 |  Loss: (0.4212) |  Loss2: (0.0000) | Acc: (85.00%) (3388/3968)
Epoch: 43 | Batch_idx: 40 |  Loss: (0.4123) |  Loss2: (0.0000) | Acc: (85.00%) (4504/5248)
Epoch: 43 | Batch_idx: 50 |  Loss: (0.4208) |  Loss2: (0.0000) | Acc: (85.00%) (5587/6528)
Epoch: 43 | Batch_idx: 60 |  Loss: (0.4226) |  Loss2: (0.0000) | Acc: (85.00%) (6675/7808)
Epoch: 43 | Batch_idx: 70 |  Loss: (0.4208) |  Loss2: (0.0000) | Acc: (85.00%) (7777/9088)
Epoch: 43 | Batch_idx: 80 |  Loss: (0.4206) |  Loss2: (0.0000) | Acc: (85.00%) (8872/10368)
Epoch: 43 | Batch_idx: 90 |  Loss: (0.4213) |  Loss2: (0.0000) | Acc: (85.00%) (9957/11648)
Epoch: 43 | Batch_idx: 100 |  Loss: (0.4224) |  Loss2: (0.0000) | Acc: (85.00%) (11033/12928)
Epoch: 43 | Batch_idx: 110 |  Loss: (0.4245) |  Loss2: (0.0000) | Acc: (85.00%) (12118/14208)
Epoch: 43 | Batch_idx: 120 |  Loss: (0.4270) |  Loss2: (0.0000) | Acc: (85.00%) (13184/15488)
Epoch: 43 | Batch_idx: 130 |  Loss: (0.4284) |  Loss2: (0.0000) | Acc: (85.00%) (14262/16768)
Epoch: 43 | Batch_idx: 140 |  Loss: (0.4267) |  Loss2: (0.0000) | Acc: (85.00%) (15357/18048)
Epoch: 43 | Batch_idx: 150 |  Loss: (0.4279) |  Loss2: (0.0000) | Acc: (85.00%) (16446/19328)
Epoch: 43 | Batch_idx: 160 |  Loss: (0.4277) |  Loss2: (0.0000) | Acc: (85.00%) (17551/20608)
Epoch: 43 | Batch_idx: 170 |  Loss: (0.4294) |  Loss2: (0.0000) | Acc: (85.00%) (18633/21888)
Epoch: 43 | Batch_idx: 180 |  Loss: (0.4302) |  Loss2: (0.0000) | Acc: (85.00%) (19721/23168)
Epoch: 43 | Batch_idx: 190 |  Loss: (0.4305) |  Loss2: (0.0000) | Acc: (85.00%) (20799/24448)
Epoch: 43 | Batch_idx: 200 |  Loss: (0.4315) |  Loss2: (0.0000) | Acc: (85.00%) (21884/25728)
Epoch: 43 | Batch_idx: 210 |  Loss: (0.4304) |  Loss2: (0.0000) | Acc: (85.00%) (22983/27008)
Epoch: 43 | Batch_idx: 220 |  Loss: (0.4306) |  Loss2: (0.0000) | Acc: (85.00%) (24086/28288)
Epoch: 43 | Batch_idx: 230 |  Loss: (0.4294) |  Loss2: (0.0000) | Acc: (85.00%) (25188/29568)
Epoch: 43 | Batch_idx: 240 |  Loss: (0.4315) |  Loss2: (0.0000) | Acc: (85.00%) (26263/30848)
Epoch: 43 | Batch_idx: 250 |  Loss: (0.4318) |  Loss2: (0.0000) | Acc: (85.00%) (27342/32128)
Epoch: 43 | Batch_idx: 260 |  Loss: (0.4310) |  Loss2: (0.0000) | Acc: (85.00%) (28449/33408)
Epoch: 43 | Batch_idx: 270 |  Loss: (0.4301) |  Loss2: (0.0000) | Acc: (85.00%) (29554/34688)
Epoch: 43 | Batch_idx: 280 |  Loss: (0.4301) |  Loss2: (0.0000) | Acc: (85.00%) (30652/35968)
Epoch: 43 | Batch_idx: 290 |  Loss: (0.4311) |  Loss2: (0.0000) | Acc: (85.00%) (31724/37248)
Epoch: 43 | Batch_idx: 300 |  Loss: (0.4307) |  Loss2: (0.0000) | Acc: (85.00%) (32828/38528)
Epoch: 43 | Batch_idx: 310 |  Loss: (0.4304) |  Loss2: (0.0000) | Acc: (85.00%) (33907/39808)
Epoch: 43 | Batch_idx: 320 |  Loss: (0.4311) |  Loss2: (0.0000) | Acc: (85.00%) (34983/41088)
Epoch: 43 | Batch_idx: 330 |  Loss: (0.4314) |  Loss2: (0.0000) | Acc: (85.00%) (36073/42368)
Epoch: 43 | Batch_idx: 340 |  Loss: (0.4322) |  Loss2: (0.0000) | Acc: (85.00%) (37143/43648)
Epoch: 43 | Batch_idx: 350 |  Loss: (0.4334) |  Loss2: (0.0000) | Acc: (85.00%) (38219/44928)
Epoch: 43 | Batch_idx: 360 |  Loss: (0.4333) |  Loss2: (0.0000) | Acc: (85.00%) (39302/46208)
Epoch: 43 | Batch_idx: 370 |  Loss: (0.4337) |  Loss2: (0.0000) | Acc: (85.00%) (40390/47488)
Epoch: 43 | Batch_idx: 380 |  Loss: (0.4341) |  Loss2: (0.0000) | Acc: (85.00%) (41471/48768)
Epoch: 43 | Batch_idx: 390 |  Loss: (0.4348) |  Loss2: (0.0000) | Acc: (85.00%) (42501/50000)
# TEST : Loss: (0.7895) | Acc: (74.00%) (7481/10000)
percent tensor([0.5197, 0.5347, 0.5244, 0.5218, 0.5257, 0.5156, 0.5353, 0.5294, 0.5288,
        0.5292, 0.5270, 0.5266, 0.5218, 0.5391, 0.5255, 0.5220],
       device='cuda:0') torch.Size([16])
percent tensor([0.5008, 0.5034, 0.4874, 0.4897, 0.4907, 0.4975, 0.4989, 0.4932, 0.4984,
        0.4984, 0.5013, 0.4937, 0.5014, 0.5018, 0.4987, 0.4993],
       device='cuda:0') torch.Size([16])
percent tensor([0.5345, 0.5318, 0.5404, 0.5742, 0.5700, 0.5749, 0.5642, 0.5801, 0.5264,
        0.5160, 0.5081, 0.5336, 0.4965, 0.5768, 0.5720, 0.5431],
       device='cuda:0') torch.Size([16])
percent tensor([0.6212, 0.5709, 0.6052, 0.6207, 0.6342, 0.6569, 0.6112, 0.6284, 0.5774,
        0.5754, 0.5628, 0.5775, 0.5667, 0.5805, 0.6306, 0.6272],
       device='cuda:0') torch.Size([16])
percent tensor([0.4915, 0.4867, 0.4902, 0.4931, 0.4876, 0.4974, 0.4888, 0.4807, 0.4945,
        0.4908, 0.4913, 0.4853, 0.4859, 0.4996, 0.4777, 0.4963],
       device='cuda:0') torch.Size([16])
percent tensor([0.5902, 0.5868, 0.6374, 0.6881, 0.6472, 0.6575, 0.6190, 0.6211, 0.6454,
        0.5880, 0.6241, 0.6546, 0.5851, 0.6681, 0.5902, 0.6223],
       device='cuda:0') torch.Size([16])
percent tensor([0.5664, 0.5481, 0.5800, 0.5944, 0.5730, 0.5959, 0.5428, 0.5270, 0.5931,
        0.5656, 0.5663, 0.5837, 0.5568, 0.5997, 0.5040, 0.5548],
       device='cuda:0') torch.Size([16])
percent tensor([0.9964, 0.9953, 0.9984, 0.9977, 0.9981, 0.9950, 0.9963, 0.9989, 0.9955,
        0.9969, 0.9969, 0.9984, 0.9948, 0.9946, 0.9973, 0.9975],
       device='cuda:0') torch.Size([16])
Epoch: 44 | Batch_idx: 0 |  Loss: (0.3710) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 44 | Batch_idx: 10 |  Loss: (0.4105) |  Loss2: (0.0000) | Acc: (85.00%) (1209/1408)
Epoch: 44 | Batch_idx: 20 |  Loss: (0.4095) |  Loss2: (0.0000) | Acc: (85.00%) (2308/2688)
Epoch: 44 | Batch_idx: 30 |  Loss: (0.4194) |  Loss2: (0.0000) | Acc: (85.00%) (3390/3968)
Epoch: 44 | Batch_idx: 40 |  Loss: (0.4196) |  Loss2: (0.0000) | Acc: (85.00%) (4477/5248)
Epoch: 44 | Batch_idx: 50 |  Loss: (0.4216) |  Loss2: (0.0000) | Acc: (85.00%) (5567/6528)
Epoch: 44 | Batch_idx: 60 |  Loss: (0.4153) |  Loss2: (0.0000) | Acc: (85.00%) (6677/7808)
Epoch: 44 | Batch_idx: 70 |  Loss: (0.4164) |  Loss2: (0.0000) | Acc: (85.00%) (7762/9088)
Epoch: 44 | Batch_idx: 80 |  Loss: (0.4187) |  Loss2: (0.0000) | Acc: (85.00%) (8843/10368)
Epoch: 44 | Batch_idx: 90 |  Loss: (0.4194) |  Loss2: (0.0000) | Acc: (85.00%) (9933/11648)
Epoch: 44 | Batch_idx: 100 |  Loss: (0.4175) |  Loss2: (0.0000) | Acc: (85.00%) (11041/12928)
Epoch: 44 | Batch_idx: 110 |  Loss: (0.4176) |  Loss2: (0.0000) | Acc: (85.00%) (12139/14208)
Epoch: 44 | Batch_idx: 120 |  Loss: (0.4162) |  Loss2: (0.0000) | Acc: (85.00%) (13235/15488)
Epoch: 44 | Batch_idx: 130 |  Loss: (0.4195) |  Loss2: (0.0000) | Acc: (85.00%) (14325/16768)
Epoch: 44 | Batch_idx: 140 |  Loss: (0.4207) |  Loss2: (0.0000) | Acc: (85.00%) (15406/18048)
Epoch: 44 | Batch_idx: 150 |  Loss: (0.4212) |  Loss2: (0.0000) | Acc: (85.00%) (16502/19328)
Epoch: 44 | Batch_idx: 160 |  Loss: (0.4212) |  Loss2: (0.0000) | Acc: (85.00%) (17597/20608)
Epoch: 44 | Batch_idx: 170 |  Loss: (0.4242) |  Loss2: (0.0000) | Acc: (85.00%) (18669/21888)
Epoch: 44 | Batch_idx: 180 |  Loss: (0.4237) |  Loss2: (0.0000) | Acc: (85.00%) (19757/23168)
Epoch: 44 | Batch_idx: 190 |  Loss: (0.4221) |  Loss2: (0.0000) | Acc: (85.00%) (20858/24448)
Epoch: 44 | Batch_idx: 200 |  Loss: (0.4211) |  Loss2: (0.0000) | Acc: (85.00%) (21959/25728)
Epoch: 44 | Batch_idx: 210 |  Loss: (0.4219) |  Loss2: (0.0000) | Acc: (85.00%) (23056/27008)
Epoch: 44 | Batch_idx: 220 |  Loss: (0.4214) |  Loss2: (0.0000) | Acc: (85.00%) (24164/28288)
Epoch: 44 | Batch_idx: 230 |  Loss: (0.4203) |  Loss2: (0.0000) | Acc: (85.00%) (25270/29568)
Epoch: 44 | Batch_idx: 240 |  Loss: (0.4201) |  Loss2: (0.0000) | Acc: (85.00%) (26371/30848)
Epoch: 44 | Batch_idx: 250 |  Loss: (0.4202) |  Loss2: (0.0000) | Acc: (85.00%) (27467/32128)
Epoch: 44 | Batch_idx: 260 |  Loss: (0.4189) |  Loss2: (0.0000) | Acc: (85.00%) (28586/33408)
Epoch: 44 | Batch_idx: 270 |  Loss: (0.4201) |  Loss2: (0.0000) | Acc: (85.00%) (29665/34688)
Epoch: 44 | Batch_idx: 280 |  Loss: (0.4208) |  Loss2: (0.0000) | Acc: (85.00%) (30756/35968)
Epoch: 44 | Batch_idx: 290 |  Loss: (0.4199) |  Loss2: (0.0000) | Acc: (85.00%) (31856/37248)
Epoch: 44 | Batch_idx: 300 |  Loss: (0.4215) |  Loss2: (0.0000) | Acc: (85.00%) (32922/38528)
Epoch: 44 | Batch_idx: 310 |  Loss: (0.4223) |  Loss2: (0.0000) | Acc: (85.00%) (33998/39808)
Epoch: 44 | Batch_idx: 320 |  Loss: (0.4220) |  Loss2: (0.0000) | Acc: (85.00%) (35088/41088)
Epoch: 44 | Batch_idx: 330 |  Loss: (0.4224) |  Loss2: (0.0000) | Acc: (85.00%) (36184/42368)
Epoch: 44 | Batch_idx: 340 |  Loss: (0.4230) |  Loss2: (0.0000) | Acc: (85.00%) (37269/43648)
Epoch: 44 | Batch_idx: 350 |  Loss: (0.4227) |  Loss2: (0.0000) | Acc: (85.00%) (38364/44928)
Epoch: 44 | Batch_idx: 360 |  Loss: (0.4233) |  Loss2: (0.0000) | Acc: (85.00%) (39456/46208)
Epoch: 44 | Batch_idx: 370 |  Loss: (0.4229) |  Loss2: (0.0000) | Acc: (85.00%) (40549/47488)
Epoch: 44 | Batch_idx: 380 |  Loss: (0.4227) |  Loss2: (0.0000) | Acc: (85.00%) (41649/48768)
Epoch: 44 | Batch_idx: 390 |  Loss: (0.4215) |  Loss2: (0.0000) | Acc: (85.00%) (42714/50000)
# TEST : Loss: (0.5073) | Acc: (82.00%) (8273/10000)
percent tensor([0.5198, 0.5352, 0.5233, 0.5224, 0.5251, 0.5160, 0.5352, 0.5295, 0.5287,
        0.5290, 0.5271, 0.5253, 0.5220, 0.5402, 0.5259, 0.5225],
       device='cuda:0') torch.Size([16])
percent tensor([0.5010, 0.5029, 0.4890, 0.4904, 0.4913, 0.4969, 0.4988, 0.4948, 0.4986,
        0.4987, 0.5009, 0.4943, 0.5017, 0.5003, 0.4985, 0.4992],
       device='cuda:0') torch.Size([16])
percent tensor([0.5395, 0.5404, 0.5511, 0.5778, 0.5818, 0.5833, 0.5717, 0.5924, 0.5323,
        0.5252, 0.5157, 0.5476, 0.5009, 0.5841, 0.5795, 0.5471],
       device='cuda:0') torch.Size([16])
percent tensor([0.6215, 0.5759, 0.6046, 0.6213, 0.6319, 0.6583, 0.6120, 0.6276, 0.5778,
        0.5763, 0.5692, 0.5811, 0.5656, 0.5917, 0.6336, 0.6289],
       device='cuda:0') torch.Size([16])
percent tensor([0.4876, 0.4808, 0.4882, 0.4919, 0.4859, 0.4973, 0.4839, 0.4780, 0.4902,
        0.4860, 0.4878, 0.4820, 0.4815, 0.4938, 0.4726, 0.4941],
       device='cuda:0') torch.Size([16])
percent tensor([0.5998, 0.5878, 0.6505, 0.6981, 0.6690, 0.6670, 0.6249, 0.6409, 0.6381,
        0.5884, 0.6221, 0.6683, 0.5821, 0.6610, 0.6090, 0.6399],
       device='cuda:0') torch.Size([16])
percent tensor([0.5602, 0.5417, 0.5825, 0.5958, 0.5809, 0.5949, 0.5467, 0.5314, 0.5805,
        0.5734, 0.5735, 0.5860, 0.5446, 0.5925, 0.4966, 0.5515],
       device='cuda:0') torch.Size([16])
percent tensor([0.9957, 0.9962, 0.9979, 0.9966, 0.9980, 0.9947, 0.9965, 0.9987, 0.9958,
        0.9977, 0.9970, 0.9988, 0.9936, 0.9965, 0.9980, 0.9979],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 45 | Batch_idx: 0 |  Loss: (0.3546) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 45 | Batch_idx: 10 |  Loss: (0.4117) |  Loss2: (0.0000) | Acc: (86.00%) (1215/1408)
Epoch: 45 | Batch_idx: 20 |  Loss: (0.4252) |  Loss2: (0.0000) | Acc: (85.00%) (2302/2688)
Epoch: 45 | Batch_idx: 30 |  Loss: (0.4452) |  Loss2: (0.0000) | Acc: (84.00%) (3368/3968)
Epoch: 45 | Batch_idx: 40 |  Loss: (0.4627) |  Loss2: (0.0000) | Acc: (84.00%) (4416/5248)
Epoch: 45 | Batch_idx: 50 |  Loss: (0.4658) |  Loss2: (0.0000) | Acc: (84.00%) (5485/6528)
Epoch: 45 | Batch_idx: 60 |  Loss: (0.4636) |  Loss2: (0.0000) | Acc: (84.00%) (6568/7808)
Epoch: 45 | Batch_idx: 70 |  Loss: (0.4634) |  Loss2: (0.0000) | Acc: (84.00%) (7636/9088)
Epoch: 45 | Batch_idx: 80 |  Loss: (0.4606) |  Loss2: (0.0000) | Acc: (84.00%) (8723/10368)
Epoch: 45 | Batch_idx: 90 |  Loss: (0.4573) |  Loss2: (0.0000) | Acc: (84.00%) (9813/11648)
Epoch: 45 | Batch_idx: 100 |  Loss: (0.4606) |  Loss2: (0.0000) | Acc: (84.00%) (10881/12928)
Epoch: 45 | Batch_idx: 110 |  Loss: (0.4586) |  Loss2: (0.0000) | Acc: (84.00%) (11975/14208)
Epoch: 45 | Batch_idx: 120 |  Loss: (0.4599) |  Loss2: (0.0000) | Acc: (84.00%) (13041/15488)
Epoch: 45 | Batch_idx: 130 |  Loss: (0.4615) |  Loss2: (0.0000) | Acc: (84.00%) (14109/16768)
Epoch: 45 | Batch_idx: 140 |  Loss: (0.4626) |  Loss2: (0.0000) | Acc: (84.00%) (15196/18048)
Epoch: 45 | Batch_idx: 150 |  Loss: (0.4611) |  Loss2: (0.0000) | Acc: (84.00%) (16288/19328)
Epoch: 45 | Batch_idx: 160 |  Loss: (0.4620) |  Loss2: (0.0000) | Acc: (84.00%) (17353/20608)
Epoch: 45 | Batch_idx: 170 |  Loss: (0.4616) |  Loss2: (0.0000) | Acc: (84.00%) (18435/21888)
Epoch: 45 | Batch_idx: 180 |  Loss: (0.4596) |  Loss2: (0.0000) | Acc: (84.00%) (19536/23168)
Epoch: 45 | Batch_idx: 190 |  Loss: (0.4580) |  Loss2: (0.0000) | Acc: (84.00%) (20633/24448)
Epoch: 45 | Batch_idx: 200 |  Loss: (0.4578) |  Loss2: (0.0000) | Acc: (84.00%) (21727/25728)
Epoch: 45 | Batch_idx: 210 |  Loss: (0.4571) |  Loss2: (0.0000) | Acc: (84.00%) (22806/27008)
Epoch: 45 | Batch_idx: 220 |  Loss: (0.4556) |  Loss2: (0.0000) | Acc: (84.00%) (23899/28288)
Epoch: 45 | Batch_idx: 230 |  Loss: (0.4549) |  Loss2: (0.0000) | Acc: (84.00%) (24985/29568)
Epoch: 45 | Batch_idx: 240 |  Loss: (0.4528) |  Loss2: (0.0000) | Acc: (84.00%) (26096/30848)
Epoch: 45 | Batch_idx: 250 |  Loss: (0.4529) |  Loss2: (0.0000) | Acc: (84.00%) (27188/32128)
Epoch: 45 | Batch_idx: 260 |  Loss: (0.4531) |  Loss2: (0.0000) | Acc: (84.00%) (28239/33408)
Epoch: 45 | Batch_idx: 270 |  Loss: (0.4520) |  Loss2: (0.0000) | Acc: (84.00%) (29345/34688)
Epoch: 45 | Batch_idx: 280 |  Loss: (0.4496) |  Loss2: (0.0000) | Acc: (84.00%) (30449/35968)
Epoch: 45 | Batch_idx: 290 |  Loss: (0.4499) |  Loss2: (0.0000) | Acc: (84.00%) (31515/37248)
Epoch: 45 | Batch_idx: 300 |  Loss: (0.4487) |  Loss2: (0.0000) | Acc: (84.00%) (32603/38528)
Epoch: 45 | Batch_idx: 310 |  Loss: (0.4473) |  Loss2: (0.0000) | Acc: (84.00%) (33692/39808)
Epoch: 45 | Batch_idx: 320 |  Loss: (0.4478) |  Loss2: (0.0000) | Acc: (84.00%) (34777/41088)
Epoch: 45 | Batch_idx: 330 |  Loss: (0.4471) |  Loss2: (0.0000) | Acc: (84.00%) (35863/42368)
Epoch: 45 | Batch_idx: 340 |  Loss: (0.4473) |  Loss2: (0.0000) | Acc: (84.00%) (36941/43648)
Epoch: 45 | Batch_idx: 350 |  Loss: (0.4458) |  Loss2: (0.0000) | Acc: (84.00%) (38057/44928)
Epoch: 45 | Batch_idx: 360 |  Loss: (0.4458) |  Loss2: (0.0000) | Acc: (84.00%) (39131/46208)
Epoch: 45 | Batch_idx: 370 |  Loss: (0.4438) |  Loss2: (0.0000) | Acc: (84.00%) (40259/47488)
Epoch: 45 | Batch_idx: 380 |  Loss: (0.4437) |  Loss2: (0.0000) | Acc: (84.00%) (41334/48768)
Epoch: 45 | Batch_idx: 390 |  Loss: (0.4429) |  Loss2: (0.0000) | Acc: (84.00%) (42384/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_045.pth.tar'
# TEST : Loss: (0.5124) | Acc: (82.00%) (8279/10000)
percent tensor([0.5301, 0.5507, 0.5350, 0.5337, 0.5384, 0.5252, 0.5507, 0.5435, 0.5418,
        0.5425, 0.5395, 0.5383, 0.5331, 0.5567, 0.5383, 0.5339],
       device='cuda:0') torch.Size([16])
percent tensor([0.5078, 0.5104, 0.4964, 0.4970, 0.4995, 0.5028, 0.5077, 0.5022, 0.5061,
        0.5062, 0.5083, 0.5024, 0.5090, 0.5073, 0.5058, 0.5066],
       device='cuda:0') torch.Size([16])
percent tensor([0.5602, 0.5582, 0.5720, 0.6014, 0.6036, 0.6094, 0.5914, 0.6164, 0.5557,
        0.5410, 0.5366, 0.5642, 0.5175, 0.6084, 0.6014, 0.5675],
       device='cuda:0') torch.Size([16])
percent tensor([0.6137, 0.5744, 0.5897, 0.6052, 0.6175, 0.6403, 0.6100, 0.6141, 0.5747,
        0.5728, 0.5726, 0.5745, 0.5631, 0.5953, 0.6240, 0.6168],
       device='cuda:0') torch.Size([16])
percent tensor([0.4934, 0.4927, 0.4923, 0.4933, 0.4879, 0.4974, 0.4916, 0.4825, 0.4987,
        0.4970, 0.5001, 0.4930, 0.4946, 0.5009, 0.4832, 0.4995],
       device='cuda:0') torch.Size([16])
percent tensor([0.6440, 0.6331, 0.6830, 0.7347, 0.6964, 0.7120, 0.6676, 0.6687, 0.6839,
        0.6417, 0.6774, 0.7229, 0.6385, 0.7159, 0.6553, 0.6796],
       device='cuda:0') torch.Size([16])
percent tensor([0.5324, 0.5089, 0.5765, 0.5935, 0.5754, 0.6018, 0.5260, 0.5298, 0.5555,
        0.5476, 0.5489, 0.5811, 0.5136, 0.5692, 0.4903, 0.5387],
       device='cuda:0') torch.Size([16])
percent tensor([0.9955, 0.9966, 0.9980, 0.9969, 0.9980, 0.9944, 0.9965, 0.9986, 0.9962,
        0.9981, 0.9975, 0.9991, 0.9934, 0.9962, 0.9985, 0.9983],
       device='cuda:0') torch.Size([16])
Epoch: 46 | Batch_idx: 0 |  Loss: (0.4404) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 46 | Batch_idx: 10 |  Loss: (0.4173) |  Loss2: (0.0000) | Acc: (86.00%) (1213/1408)
Epoch: 46 | Batch_idx: 20 |  Loss: (0.4043) |  Loss2: (0.0000) | Acc: (86.00%) (2317/2688)
Epoch: 46 | Batch_idx: 30 |  Loss: (0.4075) |  Loss2: (0.0000) | Acc: (86.00%) (3421/3968)
Epoch: 46 | Batch_idx: 40 |  Loss: (0.4127) |  Loss2: (0.0000) | Acc: (86.00%) (4514/5248)
Epoch: 46 | Batch_idx: 50 |  Loss: (0.4242) |  Loss2: (0.0000) | Acc: (85.00%) (5588/6528)
Epoch: 46 | Batch_idx: 60 |  Loss: (0.4254) |  Loss2: (0.0000) | Acc: (85.00%) (6662/7808)
Epoch: 46 | Batch_idx: 70 |  Loss: (0.4283) |  Loss2: (0.0000) | Acc: (85.00%) (7742/9088)
Epoch: 46 | Batch_idx: 80 |  Loss: (0.4267) |  Loss2: (0.0000) | Acc: (85.00%) (8849/10368)
Epoch: 46 | Batch_idx: 90 |  Loss: (0.4263) |  Loss2: (0.0000) | Acc: (85.00%) (9955/11648)
Epoch: 46 | Batch_idx: 100 |  Loss: (0.4287) |  Loss2: (0.0000) | Acc: (85.00%) (11035/12928)
Epoch: 46 | Batch_idx: 110 |  Loss: (0.4294) |  Loss2: (0.0000) | Acc: (85.00%) (12121/14208)
Epoch: 46 | Batch_idx: 120 |  Loss: (0.4284) |  Loss2: (0.0000) | Acc: (85.00%) (13217/15488)
Epoch: 46 | Batch_idx: 130 |  Loss: (0.4251) |  Loss2: (0.0000) | Acc: (85.00%) (14315/16768)
Epoch: 46 | Batch_idx: 140 |  Loss: (0.4239) |  Loss2: (0.0000) | Acc: (85.00%) (15415/18048)
Epoch: 46 | Batch_idx: 150 |  Loss: (0.4254) |  Loss2: (0.0000) | Acc: (85.00%) (16495/19328)
Epoch: 46 | Batch_idx: 160 |  Loss: (0.4254) |  Loss2: (0.0000) | Acc: (85.00%) (17592/20608)
Epoch: 46 | Batch_idx: 170 |  Loss: (0.4256) |  Loss2: (0.0000) | Acc: (85.00%) (18675/21888)
Epoch: 46 | Batch_idx: 180 |  Loss: (0.4287) |  Loss2: (0.0000) | Acc: (85.00%) (19737/23168)
Epoch: 46 | Batch_idx: 190 |  Loss: (0.4276) |  Loss2: (0.0000) | Acc: (85.00%) (20835/24448)
Epoch: 46 | Batch_idx: 200 |  Loss: (0.4276) |  Loss2: (0.0000) | Acc: (85.00%) (21930/25728)
Epoch: 46 | Batch_idx: 210 |  Loss: (0.4292) |  Loss2: (0.0000) | Acc: (85.00%) (23005/27008)
Epoch: 46 | Batch_idx: 220 |  Loss: (0.4295) |  Loss2: (0.0000) | Acc: (85.00%) (24083/28288)
Epoch: 46 | Batch_idx: 230 |  Loss: (0.4285) |  Loss2: (0.0000) | Acc: (85.00%) (25183/29568)
Epoch: 46 | Batch_idx: 240 |  Loss: (0.4285) |  Loss2: (0.0000) | Acc: (85.00%) (26276/30848)
Epoch: 46 | Batch_idx: 250 |  Loss: (0.4264) |  Loss2: (0.0000) | Acc: (85.00%) (27390/32128)
Epoch: 46 | Batch_idx: 260 |  Loss: (0.4250) |  Loss2: (0.0000) | Acc: (85.00%) (28498/33408)
Epoch: 46 | Batch_idx: 270 |  Loss: (0.4244) |  Loss2: (0.0000) | Acc: (85.00%) (29599/34688)
Epoch: 46 | Batch_idx: 280 |  Loss: (0.4237) |  Loss2: (0.0000) | Acc: (85.00%) (30696/35968)
Epoch: 46 | Batch_idx: 290 |  Loss: (0.4239) |  Loss2: (0.0000) | Acc: (85.00%) (31781/37248)
Epoch: 46 | Batch_idx: 300 |  Loss: (0.4244) |  Loss2: (0.0000) | Acc: (85.00%) (32864/38528)
Epoch: 46 | Batch_idx: 310 |  Loss: (0.4248) |  Loss2: (0.0000) | Acc: (85.00%) (33948/39808)
Epoch: 46 | Batch_idx: 320 |  Loss: (0.4237) |  Loss2: (0.0000) | Acc: (85.00%) (35049/41088)
Epoch: 46 | Batch_idx: 330 |  Loss: (0.4227) |  Loss2: (0.0000) | Acc: (85.00%) (36159/42368)
Epoch: 46 | Batch_idx: 340 |  Loss: (0.4231) |  Loss2: (0.0000) | Acc: (85.00%) (37244/43648)
Epoch: 46 | Batch_idx: 350 |  Loss: (0.4221) |  Loss2: (0.0000) | Acc: (85.00%) (38354/44928)
Epoch: 46 | Batch_idx: 360 |  Loss: (0.4230) |  Loss2: (0.0000) | Acc: (85.00%) (39441/46208)
Epoch: 46 | Batch_idx: 370 |  Loss: (0.4228) |  Loss2: (0.0000) | Acc: (85.00%) (40535/47488)
Epoch: 46 | Batch_idx: 380 |  Loss: (0.4222) |  Loss2: (0.0000) | Acc: (85.00%) (41631/48768)
Epoch: 46 | Batch_idx: 390 |  Loss: (0.4226) |  Loss2: (0.0000) | Acc: (85.00%) (42676/50000)
# TEST : Loss: (0.4937) | Acc: (83.00%) (8324/10000)
percent tensor([0.5302, 0.5522, 0.5348, 0.5337, 0.5385, 0.5250, 0.5518, 0.5441, 0.5423,
        0.5433, 0.5400, 0.5385, 0.5335, 0.5587, 0.5388, 0.5343],
       device='cuda:0') torch.Size([16])
percent tensor([0.5118, 0.5146, 0.5003, 0.5002, 0.5036, 0.5062, 0.5124, 0.5061, 0.5101,
        0.5104, 0.5125, 0.5066, 0.5130, 0.5111, 0.5097, 0.5105],
       device='cuda:0') torch.Size([16])
percent tensor([0.5512, 0.5540, 0.5674, 0.5947, 0.5989, 0.5967, 0.5871, 0.6136, 0.5503,
        0.5351, 0.5291, 0.5599, 0.5122, 0.6029, 0.5948, 0.5581],
       device='cuda:0') torch.Size([16])
percent tensor([0.6078, 0.5705, 0.5849, 0.5985, 0.6113, 0.6284, 0.6065, 0.6068, 0.5698,
        0.5697, 0.5695, 0.5716, 0.5587, 0.5916, 0.6171, 0.6083],
       device='cuda:0') torch.Size([16])
percent tensor([0.4989, 0.5016, 0.4975, 0.4984, 0.4905, 0.4993, 0.4985, 0.4882, 0.5069,
        0.5057, 0.5096, 0.5019, 0.5046, 0.5089, 0.4913, 0.5049],
       device='cuda:0') torch.Size([16])
percent tensor([0.6462, 0.6432, 0.6794, 0.7351, 0.6905, 0.7162, 0.6729, 0.6604, 0.6914,
        0.6484, 0.6890, 0.7280, 0.6503, 0.7301, 0.6573, 0.6824],
       device='cuda:0') torch.Size([16])
percent tensor([0.5307, 0.5048, 0.5849, 0.6066, 0.5839, 0.6195, 0.5262, 0.5392, 0.5551,
        0.5465, 0.5467, 0.5877, 0.5102, 0.5695, 0.4935, 0.5453],
       device='cuda:0') torch.Size([16])
percent tensor([0.9959, 0.9969, 0.9983, 0.9975, 0.9981, 0.9950, 0.9969, 0.9987, 0.9968,
        0.9983, 0.9978, 0.9993, 0.9941, 0.9969, 0.9987, 0.9984],
       device='cuda:0') torch.Size([16])
Epoch: 47 | Batch_idx: 0 |  Loss: (0.4180) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 47 | Batch_idx: 10 |  Loss: (0.4323) |  Loss2: (0.0000) | Acc: (84.00%) (1196/1408)
Epoch: 47 | Batch_idx: 20 |  Loss: (0.4237) |  Loss2: (0.0000) | Acc: (85.00%) (2292/2688)
Epoch: 47 | Batch_idx: 30 |  Loss: (0.4076) |  Loss2: (0.0000) | Acc: (85.00%) (3411/3968)
Epoch: 47 | Batch_idx: 40 |  Loss: (0.4153) |  Loss2: (0.0000) | Acc: (85.00%) (4488/5248)
Epoch: 47 | Batch_idx: 50 |  Loss: (0.4134) |  Loss2: (0.0000) | Acc: (85.00%) (5582/6528)
Epoch: 47 | Batch_idx: 60 |  Loss: (0.4096) |  Loss2: (0.0000) | Acc: (85.00%) (6691/7808)
Epoch: 47 | Batch_idx: 70 |  Loss: (0.4083) |  Loss2: (0.0000) | Acc: (85.00%) (7789/9088)
Epoch: 47 | Batch_idx: 80 |  Loss: (0.4147) |  Loss2: (0.0000) | Acc: (85.00%) (8867/10368)
Epoch: 47 | Batch_idx: 90 |  Loss: (0.4145) |  Loss2: (0.0000) | Acc: (85.00%) (9972/11648)
Epoch: 47 | Batch_idx: 100 |  Loss: (0.4120) |  Loss2: (0.0000) | Acc: (85.00%) (11088/12928)
Epoch: 47 | Batch_idx: 110 |  Loss: (0.4124) |  Loss2: (0.0000) | Acc: (85.00%) (12190/14208)
Epoch: 47 | Batch_idx: 120 |  Loss: (0.4122) |  Loss2: (0.0000) | Acc: (85.00%) (13283/15488)
Epoch: 47 | Batch_idx: 130 |  Loss: (0.4107) |  Loss2: (0.0000) | Acc: (85.00%) (14398/16768)
Epoch: 47 | Batch_idx: 140 |  Loss: (0.4119) |  Loss2: (0.0000) | Acc: (85.00%) (15491/18048)
Epoch: 47 | Batch_idx: 150 |  Loss: (0.4109) |  Loss2: (0.0000) | Acc: (85.00%) (16588/19328)
Epoch: 47 | Batch_idx: 160 |  Loss: (0.4114) |  Loss2: (0.0000) | Acc: (85.00%) (17674/20608)
Epoch: 47 | Batch_idx: 170 |  Loss: (0.4117) |  Loss2: (0.0000) | Acc: (85.00%) (18782/21888)
Epoch: 47 | Batch_idx: 180 |  Loss: (0.4119) |  Loss2: (0.0000) | Acc: (85.00%) (19880/23168)
Epoch: 47 | Batch_idx: 190 |  Loss: (0.4128) |  Loss2: (0.0000) | Acc: (85.00%) (20958/24448)
Epoch: 47 | Batch_idx: 200 |  Loss: (0.4127) |  Loss2: (0.0000) | Acc: (85.00%) (22067/25728)
Epoch: 47 | Batch_idx: 210 |  Loss: (0.4126) |  Loss2: (0.0000) | Acc: (85.00%) (23173/27008)
Epoch: 47 | Batch_idx: 220 |  Loss: (0.4126) |  Loss2: (0.0000) | Acc: (85.00%) (24267/28288)
Epoch: 47 | Batch_idx: 230 |  Loss: (0.4134) |  Loss2: (0.0000) | Acc: (85.00%) (25363/29568)
Epoch: 47 | Batch_idx: 240 |  Loss: (0.4138) |  Loss2: (0.0000) | Acc: (85.00%) (26452/30848)
Epoch: 47 | Batch_idx: 250 |  Loss: (0.4134) |  Loss2: (0.0000) | Acc: (85.00%) (27565/32128)
Epoch: 47 | Batch_idx: 260 |  Loss: (0.4134) |  Loss2: (0.0000) | Acc: (85.00%) (28668/33408)
Epoch: 47 | Batch_idx: 270 |  Loss: (0.4132) |  Loss2: (0.0000) | Acc: (85.00%) (29768/34688)
Epoch: 47 | Batch_idx: 280 |  Loss: (0.4133) |  Loss2: (0.0000) | Acc: (85.00%) (30870/35968)
Epoch: 47 | Batch_idx: 290 |  Loss: (0.4115) |  Loss2: (0.0000) | Acc: (85.00%) (31991/37248)
Epoch: 47 | Batch_idx: 300 |  Loss: (0.4107) |  Loss2: (0.0000) | Acc: (85.00%) (33082/38528)
Epoch: 47 | Batch_idx: 310 |  Loss: (0.4115) |  Loss2: (0.0000) | Acc: (85.00%) (34171/39808)
Epoch: 47 | Batch_idx: 320 |  Loss: (0.4127) |  Loss2: (0.0000) | Acc: (85.00%) (35263/41088)
Epoch: 47 | Batch_idx: 330 |  Loss: (0.4121) |  Loss2: (0.0000) | Acc: (85.00%) (36367/42368)
Epoch: 47 | Batch_idx: 340 |  Loss: (0.4138) |  Loss2: (0.0000) | Acc: (85.00%) (37442/43648)
Epoch: 47 | Batch_idx: 350 |  Loss: (0.4136) |  Loss2: (0.0000) | Acc: (85.00%) (38536/44928)
Epoch: 47 | Batch_idx: 360 |  Loss: (0.4139) |  Loss2: (0.0000) | Acc: (85.00%) (39629/46208)
Epoch: 47 | Batch_idx: 370 |  Loss: (0.4121) |  Loss2: (0.0000) | Acc: (85.00%) (40772/47488)
Epoch: 47 | Batch_idx: 380 |  Loss: (0.4122) |  Loss2: (0.0000) | Acc: (85.00%) (41865/48768)
Epoch: 47 | Batch_idx: 390 |  Loss: (0.4108) |  Loss2: (0.0000) | Acc: (85.00%) (42940/50000)
# TEST : Loss: (0.4865) | Acc: (83.00%) (8346/10000)
percent tensor([0.5302, 0.5533, 0.5352, 0.5342, 0.5390, 0.5246, 0.5528, 0.5450, 0.5427,
        0.5441, 0.5404, 0.5390, 0.5339, 0.5601, 0.5393, 0.5346],
       device='cuda:0') torch.Size([16])
percent tensor([0.5142, 0.5172, 0.5017, 0.5016, 0.5054, 0.5084, 0.5149, 0.5080, 0.5121,
        0.5126, 0.5149, 0.5085, 0.5154, 0.5133, 0.5121, 0.5128],
       device='cuda:0') torch.Size([16])
percent tensor([0.5527, 0.5574, 0.5724, 0.6001, 0.6037, 0.5985, 0.5908, 0.6199, 0.5534,
        0.5368, 0.5305, 0.5645, 0.5136, 0.6072, 0.5988, 0.5601],
       device='cuda:0') torch.Size([16])
percent tensor([0.6068, 0.5700, 0.5818, 0.5949, 0.6072, 0.6226, 0.6069, 0.6039, 0.5681,
        0.5692, 0.5699, 0.5712, 0.5575, 0.5924, 0.6153, 0.6055],
       device='cuda:0') torch.Size([16])
percent tensor([0.5032, 0.5094, 0.5016, 0.5020, 0.4920, 0.5004, 0.5041, 0.4918, 0.5139,
        0.5134, 0.5184, 0.5096, 0.5133, 0.5158, 0.4976, 0.5091],
       device='cuda:0') torch.Size([16])
percent tensor([0.6388, 0.6413, 0.6700, 0.7280, 0.6786, 0.7081, 0.6682, 0.6459, 0.6889,
        0.6435, 0.6893, 0.7242, 0.6498, 0.7309, 0.6477, 0.6754],
       device='cuda:0') torch.Size([16])
percent tensor([0.5322, 0.5059, 0.5929, 0.6169, 0.5899, 0.6340, 0.5293, 0.5452, 0.5587,
        0.5483, 0.5498, 0.5963, 0.5120, 0.5734, 0.4981, 0.5538],
       device='cuda:0') torch.Size([16])
percent tensor([0.9962, 0.9973, 0.9984, 0.9976, 0.9982, 0.9954, 0.9973, 0.9987, 0.9972,
        0.9984, 0.9980, 0.9994, 0.9948, 0.9973, 0.9989, 0.9986],
       device='cuda:0') torch.Size([16])
Epoch: 48 | Batch_idx: 0 |  Loss: (0.3166) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 48 | Batch_idx: 10 |  Loss: (0.3823) |  Loss2: (0.0000) | Acc: (87.00%) (1233/1408)
Epoch: 48 | Batch_idx: 20 |  Loss: (0.3929) |  Loss2: (0.0000) | Acc: (87.00%) (2340/2688)
Epoch: 48 | Batch_idx: 30 |  Loss: (0.4086) |  Loss2: (0.0000) | Acc: (86.00%) (3415/3968)
Epoch: 48 | Batch_idx: 40 |  Loss: (0.4081) |  Loss2: (0.0000) | Acc: (86.00%) (4524/5248)
Epoch: 48 | Batch_idx: 50 |  Loss: (0.4155) |  Loss2: (0.0000) | Acc: (85.00%) (5604/6528)
Epoch: 48 | Batch_idx: 60 |  Loss: (0.4096) |  Loss2: (0.0000) | Acc: (85.00%) (6714/7808)
Epoch: 48 | Batch_idx: 70 |  Loss: (0.4139) |  Loss2: (0.0000) | Acc: (85.00%) (7804/9088)
Epoch: 48 | Batch_idx: 80 |  Loss: (0.4133) |  Loss2: (0.0000) | Acc: (85.00%) (8898/10368)
Epoch: 48 | Batch_idx: 90 |  Loss: (0.4114) |  Loss2: (0.0000) | Acc: (85.00%) (9996/11648)
Epoch: 48 | Batch_idx: 100 |  Loss: (0.4088) |  Loss2: (0.0000) | Acc: (85.00%) (11111/12928)
Epoch: 48 | Batch_idx: 110 |  Loss: (0.4114) |  Loss2: (0.0000) | Acc: (85.00%) (12203/14208)
Epoch: 48 | Batch_idx: 120 |  Loss: (0.4138) |  Loss2: (0.0000) | Acc: (85.00%) (13285/15488)
Epoch: 48 | Batch_idx: 130 |  Loss: (0.4123) |  Loss2: (0.0000) | Acc: (85.00%) (14395/16768)
Epoch: 48 | Batch_idx: 140 |  Loss: (0.4105) |  Loss2: (0.0000) | Acc: (85.00%) (15507/18048)
Epoch: 48 | Batch_idx: 150 |  Loss: (0.4110) |  Loss2: (0.0000) | Acc: (85.00%) (16599/19328)
Epoch: 48 | Batch_idx: 160 |  Loss: (0.4097) |  Loss2: (0.0000) | Acc: (85.00%) (17704/20608)
Epoch: 48 | Batch_idx: 170 |  Loss: (0.4091) |  Loss2: (0.0000) | Acc: (85.00%) (18804/21888)
Epoch: 48 | Batch_idx: 180 |  Loss: (0.4084) |  Loss2: (0.0000) | Acc: (85.00%) (19912/23168)
Epoch: 48 | Batch_idx: 190 |  Loss: (0.4084) |  Loss2: (0.0000) | Acc: (85.00%) (21022/24448)
Epoch: 48 | Batch_idx: 200 |  Loss: (0.4094) |  Loss2: (0.0000) | Acc: (85.00%) (22114/25728)
Epoch: 48 | Batch_idx: 210 |  Loss: (0.4096) |  Loss2: (0.0000) | Acc: (85.00%) (23202/27008)
Epoch: 48 | Batch_idx: 220 |  Loss: (0.4092) |  Loss2: (0.0000) | Acc: (85.00%) (24305/28288)
Epoch: 48 | Batch_idx: 230 |  Loss: (0.4091) |  Loss2: (0.0000) | Acc: (85.00%) (25405/29568)
Epoch: 48 | Batch_idx: 240 |  Loss: (0.4089) |  Loss2: (0.0000) | Acc: (85.00%) (26514/30848)
Epoch: 48 | Batch_idx: 250 |  Loss: (0.4095) |  Loss2: (0.0000) | Acc: (85.00%) (27605/32128)
Epoch: 48 | Batch_idx: 260 |  Loss: (0.4092) |  Loss2: (0.0000) | Acc: (85.00%) (28701/33408)
Epoch: 48 | Batch_idx: 270 |  Loss: (0.4090) |  Loss2: (0.0000) | Acc: (85.00%) (29798/34688)
Epoch: 48 | Batch_idx: 280 |  Loss: (0.4079) |  Loss2: (0.0000) | Acc: (85.00%) (30917/35968)
Epoch: 48 | Batch_idx: 290 |  Loss: (0.4076) |  Loss2: (0.0000) | Acc: (85.00%) (32019/37248)
Epoch: 48 | Batch_idx: 300 |  Loss: (0.4064) |  Loss2: (0.0000) | Acc: (86.00%) (33139/38528)
Epoch: 48 | Batch_idx: 310 |  Loss: (0.4059) |  Loss2: (0.0000) | Acc: (86.00%) (34248/39808)
Epoch: 48 | Batch_idx: 320 |  Loss: (0.4061) |  Loss2: (0.0000) | Acc: (86.00%) (35342/41088)
Epoch: 48 | Batch_idx: 330 |  Loss: (0.4061) |  Loss2: (0.0000) | Acc: (86.00%) (36441/42368)
Epoch: 48 | Batch_idx: 340 |  Loss: (0.4059) |  Loss2: (0.0000) | Acc: (86.00%) (37542/43648)
Epoch: 48 | Batch_idx: 350 |  Loss: (0.4055) |  Loss2: (0.0000) | Acc: (85.00%) (38638/44928)
Epoch: 48 | Batch_idx: 360 |  Loss: (0.4062) |  Loss2: (0.0000) | Acc: (85.00%) (39727/46208)
Epoch: 48 | Batch_idx: 370 |  Loss: (0.4060) |  Loss2: (0.0000) | Acc: (86.00%) (40842/47488)
Epoch: 48 | Batch_idx: 380 |  Loss: (0.4056) |  Loss2: (0.0000) | Acc: (86.00%) (41948/48768)
Epoch: 48 | Batch_idx: 390 |  Loss: (0.4049) |  Loss2: (0.0000) | Acc: (86.00%) (43024/50000)
# TEST : Loss: (0.4776) | Acc: (83.00%) (8360/10000)
percent tensor([0.5277, 0.5506, 0.5327, 0.5316, 0.5363, 0.5222, 0.5500, 0.5422, 0.5401,
        0.5415, 0.5378, 0.5365, 0.5314, 0.5575, 0.5367, 0.5320],
       device='cuda:0') torch.Size([16])
percent tensor([0.5152, 0.5180, 0.5018, 0.5017, 0.5055, 0.5094, 0.5155, 0.5083, 0.5125,
        0.5131, 0.5154, 0.5088, 0.5162, 0.5139, 0.5130, 0.5134],
       device='cuda:0') torch.Size([16])
percent tensor([0.5461, 0.5528, 0.5689, 0.5952, 0.5982, 0.5882, 0.5851, 0.6144, 0.5479,
        0.5321, 0.5244, 0.5616, 0.5104, 0.6007, 0.5921, 0.5529],
       device='cuda:0') torch.Size([16])
percent tensor([0.6077, 0.5712, 0.5819, 0.5952, 0.6066, 0.6197, 0.6086, 0.6038, 0.5688,
        0.5710, 0.5721, 0.5735, 0.5585, 0.5949, 0.6158, 0.6051],
       device='cuda:0') torch.Size([16])
percent tensor([0.5087, 0.5174, 0.5064, 0.5063, 0.4947, 0.5031, 0.5105, 0.4963, 0.5213,
        0.5217, 0.5273, 0.5175, 0.5224, 0.5232, 0.5045, 0.5148],
       device='cuda:0') torch.Size([16])
percent tensor([0.6340, 0.6393, 0.6623, 0.7213, 0.6685, 0.7028, 0.6632, 0.6323, 0.6857,
        0.6399, 0.6870, 0.7192, 0.6497, 0.7298, 0.6389, 0.6701],
       device='cuda:0') torch.Size([16])
percent tensor([0.5419, 0.5128, 0.6050, 0.6316, 0.5997, 0.6553, 0.5386, 0.5551, 0.5685,
        0.5568, 0.5590, 0.6107, 0.5205, 0.5835, 0.5079, 0.5692],
       device='cuda:0') torch.Size([16])
percent tensor([0.9968, 0.9977, 0.9986, 0.9979, 0.9984, 0.9961, 0.9977, 0.9988, 0.9976,
        0.9987, 0.9983, 0.9995, 0.9956, 0.9977, 0.9990, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 49 | Batch_idx: 0 |  Loss: (0.3114) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 49 | Batch_idx: 10 |  Loss: (0.4256) |  Loss2: (0.0000) | Acc: (85.00%) (1208/1408)
Epoch: 49 | Batch_idx: 20 |  Loss: (0.4145) |  Loss2: (0.0000) | Acc: (85.00%) (2311/2688)
Epoch: 49 | Batch_idx: 30 |  Loss: (0.4261) |  Loss2: (0.0000) | Acc: (85.00%) (3402/3968)
Epoch: 49 | Batch_idx: 40 |  Loss: (0.4064) |  Loss2: (0.0000) | Acc: (86.00%) (4540/5248)
Epoch: 49 | Batch_idx: 50 |  Loss: (0.4054) |  Loss2: (0.0000) | Acc: (86.00%) (5636/6528)
Epoch: 49 | Batch_idx: 60 |  Loss: (0.3998) |  Loss2: (0.0000) | Acc: (86.00%) (6742/7808)
Epoch: 49 | Batch_idx: 70 |  Loss: (0.3984) |  Loss2: (0.0000) | Acc: (86.00%) (7858/9088)
Epoch: 49 | Batch_idx: 80 |  Loss: (0.4030) |  Loss2: (0.0000) | Acc: (86.00%) (8940/10368)
Epoch: 49 | Batch_idx: 90 |  Loss: (0.4046) |  Loss2: (0.0000) | Acc: (86.00%) (10035/11648)
Epoch: 49 | Batch_idx: 100 |  Loss: (0.4075) |  Loss2: (0.0000) | Acc: (86.00%) (11126/12928)
Epoch: 49 | Batch_idx: 110 |  Loss: (0.4032) |  Loss2: (0.0000) | Acc: (86.00%) (12237/14208)
Epoch: 49 | Batch_idx: 120 |  Loss: (0.4020) |  Loss2: (0.0000) | Acc: (86.00%) (13342/15488)
Epoch: 49 | Batch_idx: 130 |  Loss: (0.4028) |  Loss2: (0.0000) | Acc: (86.00%) (14441/16768)
Epoch: 49 | Batch_idx: 140 |  Loss: (0.4026) |  Loss2: (0.0000) | Acc: (86.00%) (15550/18048)
Epoch: 49 | Batch_idx: 150 |  Loss: (0.4037) |  Loss2: (0.0000) | Acc: (86.00%) (16640/19328)
Epoch: 49 | Batch_idx: 160 |  Loss: (0.4033) |  Loss2: (0.0000) | Acc: (86.00%) (17747/20608)
Epoch: 49 | Batch_idx: 170 |  Loss: (0.4045) |  Loss2: (0.0000) | Acc: (86.00%) (18836/21888)
Epoch: 49 | Batch_idx: 180 |  Loss: (0.4030) |  Loss2: (0.0000) | Acc: (86.00%) (19947/23168)
Epoch: 49 | Batch_idx: 190 |  Loss: (0.4014) |  Loss2: (0.0000) | Acc: (86.00%) (21072/24448)
Epoch: 49 | Batch_idx: 200 |  Loss: (0.4014) |  Loss2: (0.0000) | Acc: (86.00%) (22169/25728)
Epoch: 49 | Batch_idx: 210 |  Loss: (0.3998) |  Loss2: (0.0000) | Acc: (86.00%) (23296/27008)
Epoch: 49 | Batch_idx: 220 |  Loss: (0.4011) |  Loss2: (0.0000) | Acc: (86.00%) (24381/28288)
Epoch: 49 | Batch_idx: 230 |  Loss: (0.4019) |  Loss2: (0.0000) | Acc: (86.00%) (25474/29568)
Epoch: 49 | Batch_idx: 240 |  Loss: (0.4005) |  Loss2: (0.0000) | Acc: (86.00%) (26590/30848)
Epoch: 49 | Batch_idx: 250 |  Loss: (0.4003) |  Loss2: (0.0000) | Acc: (86.00%) (27682/32128)
Epoch: 49 | Batch_idx: 260 |  Loss: (0.4001) |  Loss2: (0.0000) | Acc: (86.00%) (28797/33408)
Epoch: 49 | Batch_idx: 270 |  Loss: (0.3996) |  Loss2: (0.0000) | Acc: (86.00%) (29919/34688)
Epoch: 49 | Batch_idx: 280 |  Loss: (0.3989) |  Loss2: (0.0000) | Acc: (86.00%) (31037/35968)
Epoch: 49 | Batch_idx: 290 |  Loss: (0.3991) |  Loss2: (0.0000) | Acc: (86.00%) (32140/37248)
Epoch: 49 | Batch_idx: 300 |  Loss: (0.3998) |  Loss2: (0.0000) | Acc: (86.00%) (33235/38528)
Epoch: 49 | Batch_idx: 310 |  Loss: (0.3998) |  Loss2: (0.0000) | Acc: (86.00%) (34332/39808)
Epoch: 49 | Batch_idx: 320 |  Loss: (0.3997) |  Loss2: (0.0000) | Acc: (86.00%) (35449/41088)
Epoch: 49 | Batch_idx: 330 |  Loss: (0.3992) |  Loss2: (0.0000) | Acc: (86.00%) (36572/42368)
Epoch: 49 | Batch_idx: 340 |  Loss: (0.3992) |  Loss2: (0.0000) | Acc: (86.00%) (37674/43648)
Epoch: 49 | Batch_idx: 350 |  Loss: (0.3998) |  Loss2: (0.0000) | Acc: (86.00%) (38766/44928)
Epoch: 49 | Batch_idx: 360 |  Loss: (0.3995) |  Loss2: (0.0000) | Acc: (86.00%) (39880/46208)
Epoch: 49 | Batch_idx: 370 |  Loss: (0.3994) |  Loss2: (0.0000) | Acc: (86.00%) (40991/47488)
Epoch: 49 | Batch_idx: 380 |  Loss: (0.4001) |  Loss2: (0.0000) | Acc: (86.00%) (42086/48768)
Epoch: 49 | Batch_idx: 390 |  Loss: (0.3997) |  Loss2: (0.0000) | Acc: (86.00%) (43151/50000)
# TEST : Loss: (0.4721) | Acc: (83.00%) (8388/10000)
percent tensor([0.5280, 0.5520, 0.5326, 0.5319, 0.5365, 0.5223, 0.5511, 0.5426, 0.5407,
        0.5422, 0.5385, 0.5367, 0.5319, 0.5593, 0.5374, 0.5324],
       device='cuda:0') torch.Size([16])
percent tensor([0.5164, 0.5194, 0.5029, 0.5026, 0.5066, 0.5105, 0.5168, 0.5092, 0.5137,
        0.5143, 0.5166, 0.5100, 0.5176, 0.5150, 0.5142, 0.5145],
       device='cuda:0') torch.Size([16])
percent tensor([0.5453, 0.5544, 0.5680, 0.5947, 0.5981, 0.5851, 0.5865, 0.6149, 0.5482,
        0.5319, 0.5240, 0.5613, 0.5101, 0.6030, 0.5922, 0.5512],
       device='cuda:0') torch.Size([16])
percent tensor([0.6107, 0.5735, 0.5844, 0.5976, 0.6088, 0.6197, 0.6125, 0.6063, 0.5713,
        0.5739, 0.5753, 0.5766, 0.5606, 0.5988, 0.6184, 0.6071],
       device='cuda:0') torch.Size([16])
percent tensor([0.5115, 0.5232, 0.5096, 0.5089, 0.4956, 0.5038, 0.5144, 0.4987, 0.5268,
        0.5276, 0.5338, 0.5232, 0.5288, 0.5288, 0.5082, 0.5177],
       device='cuda:0') torch.Size([16])
percent tensor([0.6346, 0.6434, 0.6588, 0.7165, 0.6635, 0.7006, 0.6634, 0.6280, 0.6854,
        0.6421, 0.6879, 0.7163, 0.6528, 0.7319, 0.6376, 0.6690],
       device='cuda:0') torch.Size([16])
percent tensor([0.5407, 0.5102, 0.6065, 0.6341, 0.6004, 0.6635, 0.5387, 0.5578, 0.5660,
        0.5543, 0.5563, 0.6104, 0.5182, 0.5810, 0.5091, 0.5734],
       device='cuda:0') torch.Size([16])
percent tensor([0.9971, 0.9979, 0.9987, 0.9980, 0.9985, 0.9964, 0.9979, 0.9988, 0.9979,
        0.9988, 0.9985, 0.9995, 0.9961, 0.9980, 0.9991, 0.9989],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 50 | Batch_idx: 0 |  Loss: (0.3782) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 50 | Batch_idx: 10 |  Loss: (0.3828) |  Loss2: (0.0000) | Acc: (86.00%) (1218/1408)
Epoch: 50 | Batch_idx: 20 |  Loss: (0.3902) |  Loss2: (0.0000) | Acc: (86.00%) (2324/2688)
Epoch: 50 | Batch_idx: 30 |  Loss: (0.3962) |  Loss2: (0.0000) | Acc: (86.00%) (3426/3968)
Epoch: 50 | Batch_idx: 40 |  Loss: (0.3988) |  Loss2: (0.0000) | Acc: (86.00%) (4529/5248)
Epoch: 50 | Batch_idx: 50 |  Loss: (0.4054) |  Loss2: (0.0000) | Acc: (85.00%) (5613/6528)
Epoch: 50 | Batch_idx: 60 |  Loss: (0.4114) |  Loss2: (0.0000) | Acc: (85.00%) (6704/7808)
Epoch: 50 | Batch_idx: 70 |  Loss: (0.4106) |  Loss2: (0.0000) | Acc: (85.00%) (7799/9088)
Epoch: 50 | Batch_idx: 80 |  Loss: (0.4101) |  Loss2: (0.0000) | Acc: (85.00%) (8898/10368)
Epoch: 50 | Batch_idx: 90 |  Loss: (0.4063) |  Loss2: (0.0000) | Acc: (85.00%) (10013/11648)
Epoch: 50 | Batch_idx: 100 |  Loss: (0.4064) |  Loss2: (0.0000) | Acc: (85.00%) (11115/12928)
Epoch: 50 | Batch_idx: 110 |  Loss: (0.4080) |  Loss2: (0.0000) | Acc: (85.00%) (12206/14208)
Epoch: 50 | Batch_idx: 120 |  Loss: (0.4052) |  Loss2: (0.0000) | Acc: (86.00%) (13329/15488)
Epoch: 50 | Batch_idx: 130 |  Loss: (0.4030) |  Loss2: (0.0000) | Acc: (86.00%) (14445/16768)
Epoch: 50 | Batch_idx: 140 |  Loss: (0.4058) |  Loss2: (0.0000) | Acc: (85.00%) (15515/18048)
Epoch: 50 | Batch_idx: 150 |  Loss: (0.4054) |  Loss2: (0.0000) | Acc: (85.00%) (16615/19328)
Epoch: 50 | Batch_idx: 160 |  Loss: (0.4075) |  Loss2: (0.0000) | Acc: (85.00%) (17691/20608)
Epoch: 50 | Batch_idx: 170 |  Loss: (0.4072) |  Loss2: (0.0000) | Acc: (85.00%) (18797/21888)
Epoch: 50 | Batch_idx: 180 |  Loss: (0.4068) |  Loss2: (0.0000) | Acc: (85.00%) (19899/23168)
Epoch: 50 | Batch_idx: 190 |  Loss: (0.4075) |  Loss2: (0.0000) | Acc: (85.00%) (20973/24448)
Epoch: 50 | Batch_idx: 200 |  Loss: (0.4083) |  Loss2: (0.0000) | Acc: (85.00%) (22050/25728)
Epoch: 50 | Batch_idx: 210 |  Loss: (0.4088) |  Loss2: (0.0000) | Acc: (85.00%) (23139/27008)
Epoch: 50 | Batch_idx: 220 |  Loss: (0.4101) |  Loss2: (0.0000) | Acc: (85.00%) (24225/28288)
Epoch: 50 | Batch_idx: 230 |  Loss: (0.4081) |  Loss2: (0.0000) | Acc: (85.00%) (25363/29568)
Epoch: 50 | Batch_idx: 240 |  Loss: (0.4065) |  Loss2: (0.0000) | Acc: (85.00%) (26482/30848)
Epoch: 50 | Batch_idx: 250 |  Loss: (0.4075) |  Loss2: (0.0000) | Acc: (85.00%) (27574/32128)
Epoch: 50 | Batch_idx: 260 |  Loss: (0.4074) |  Loss2: (0.0000) | Acc: (85.00%) (28673/33408)
Epoch: 50 | Batch_idx: 270 |  Loss: (0.4087) |  Loss2: (0.0000) | Acc: (85.00%) (29766/34688)
Epoch: 50 | Batch_idx: 280 |  Loss: (0.4082) |  Loss2: (0.0000) | Acc: (85.00%) (30866/35968)
Epoch: 50 | Batch_idx: 290 |  Loss: (0.4073) |  Loss2: (0.0000) | Acc: (85.00%) (31985/37248)
Epoch: 50 | Batch_idx: 300 |  Loss: (0.4072) |  Loss2: (0.0000) | Acc: (85.00%) (33087/38528)
Epoch: 50 | Batch_idx: 310 |  Loss: (0.4056) |  Loss2: (0.0000) | Acc: (85.00%) (34215/39808)
Epoch: 50 | Batch_idx: 320 |  Loss: (0.4063) |  Loss2: (0.0000) | Acc: (85.00%) (35292/41088)
Epoch: 50 | Batch_idx: 330 |  Loss: (0.4072) |  Loss2: (0.0000) | Acc: (85.00%) (36395/42368)
Epoch: 50 | Batch_idx: 340 |  Loss: (0.4065) |  Loss2: (0.0000) | Acc: (85.00%) (37508/43648)
Epoch: 50 | Batch_idx: 350 |  Loss: (0.4067) |  Loss2: (0.0000) | Acc: (85.00%) (38610/44928)
Epoch: 50 | Batch_idx: 360 |  Loss: (0.4075) |  Loss2: (0.0000) | Acc: (85.00%) (39701/46208)
Epoch: 50 | Batch_idx: 370 |  Loss: (0.4087) |  Loss2: (0.0000) | Acc: (85.00%) (40785/47488)
Epoch: 50 | Batch_idx: 380 |  Loss: (0.4088) |  Loss2: (0.0000) | Acc: (85.00%) (41888/48768)
Epoch: 50 | Batch_idx: 390 |  Loss: (0.4092) |  Loss2: (0.0000) | Acc: (85.00%) (42927/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_050.pth.tar'
# TEST : Loss: (0.5626) | Acc: (81.00%) (8117/10000)
percent tensor([0.5286, 0.5512, 0.5338, 0.5323, 0.5373, 0.5230, 0.5509, 0.5426, 0.5406,
        0.5426, 0.5385, 0.5379, 0.5323, 0.5573, 0.5376, 0.5323],
       device='cuda:0') torch.Size([16])
percent tensor([0.5163, 0.5185, 0.5044, 0.5031, 0.5069, 0.5100, 0.5160, 0.5095, 0.5139,
        0.5133, 0.5164, 0.5097, 0.5173, 0.5145, 0.5127, 0.5139],
       device='cuda:0') torch.Size([16])
percent tensor([0.5475, 0.5591, 0.5602, 0.5925, 0.5976, 0.5827, 0.5878, 0.6105, 0.5472,
        0.5322, 0.5242, 0.5600, 0.5102, 0.5992, 0.5974, 0.5525],
       device='cuda:0') torch.Size([16])
percent tensor([0.6123, 0.5778, 0.5955, 0.6039, 0.6141, 0.6145, 0.6172, 0.6116, 0.5763,
        0.5785, 0.5777, 0.5838, 0.5640, 0.5985, 0.6195, 0.6083],
       device='cuda:0') torch.Size([16])
percent tensor([0.5097, 0.5231, 0.5046, 0.5049, 0.4938, 0.5031, 0.5128, 0.4965, 0.5255,
        0.5255, 0.5329, 0.5164, 0.5265, 0.5302, 0.5059, 0.5144],
       device='cuda:0') torch.Size([16])
percent tensor([0.6242, 0.6442, 0.6679, 0.7079, 0.6802, 0.6858, 0.6573, 0.6319, 0.6811,
        0.6280, 0.6776, 0.6928, 0.6367, 0.7206, 0.6265, 0.6629],
       device='cuda:0') torch.Size([16])
percent tensor([0.5454, 0.5210, 0.6224, 0.6465, 0.6214, 0.6591, 0.5421, 0.5684, 0.5651,
        0.5540, 0.5469, 0.5942, 0.5202, 0.5763, 0.5160, 0.5888],
       device='cuda:0') torch.Size([16])
percent tensor([0.9968, 0.9972, 0.9989, 0.9982, 0.9987, 0.9949, 0.9981, 0.9994, 0.9971,
        0.9973, 0.9978, 0.9990, 0.9944, 0.9956, 0.9989, 0.9982],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(169.3514, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(798.1794, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(790.7377, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1531.2194, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(499.4007, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2192.4023, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4287.5132, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1426.5389, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6104.6099, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12052.4951, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4027.3315, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16974.4648, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 51 | Batch_idx: 0 |  Loss: (0.3318) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 51 | Batch_idx: 10 |  Loss: (0.4132) |  Loss2: (0.0000) | Acc: (85.00%) (1199/1408)
Epoch: 51 | Batch_idx: 20 |  Loss: (0.4130) |  Loss2: (0.0000) | Acc: (85.00%) (2287/2688)
Epoch: 51 | Batch_idx: 30 |  Loss: (0.4060) |  Loss2: (0.0000) | Acc: (85.00%) (3386/3968)
Epoch: 51 | Batch_idx: 40 |  Loss: (0.4083) |  Loss2: (0.0000) | Acc: (85.00%) (4485/5248)
Epoch: 51 | Batch_idx: 50 |  Loss: (0.4037) |  Loss2: (0.0000) | Acc: (85.00%) (5603/6528)
Epoch: 51 | Batch_idx: 60 |  Loss: (0.3996) |  Loss2: (0.0000) | Acc: (85.00%) (6713/7808)
Epoch: 51 | Batch_idx: 70 |  Loss: (0.3983) |  Loss2: (0.0000) | Acc: (86.00%) (7829/9088)
Epoch: 51 | Batch_idx: 80 |  Loss: (0.4022) |  Loss2: (0.0000) | Acc: (86.00%) (8921/10368)
Epoch: 51 | Batch_idx: 90 |  Loss: (0.4012) |  Loss2: (0.0000) | Acc: (86.00%) (10021/11648)
Epoch: 51 | Batch_idx: 100 |  Loss: (0.3999) |  Loss2: (0.0000) | Acc: (86.00%) (11123/12928)
Epoch: 51 | Batch_idx: 110 |  Loss: (0.4007) |  Loss2: (0.0000) | Acc: (85.00%) (12214/14208)
Epoch: 51 | Batch_idx: 120 |  Loss: (0.4003) |  Loss2: (0.0000) | Acc: (86.00%) (13325/15488)
Epoch: 51 | Batch_idx: 130 |  Loss: (0.4010) |  Loss2: (0.0000) | Acc: (86.00%) (14422/16768)
Epoch: 51 | Batch_idx: 140 |  Loss: (0.4020) |  Loss2: (0.0000) | Acc: (85.00%) (15521/18048)
Epoch: 51 | Batch_idx: 150 |  Loss: (0.4011) |  Loss2: (0.0000) | Acc: (86.00%) (16627/19328)
Epoch: 51 | Batch_idx: 160 |  Loss: (0.4013) |  Loss2: (0.0000) | Acc: (86.00%) (17738/20608)
Epoch: 51 | Batch_idx: 170 |  Loss: (0.4003) |  Loss2: (0.0000) | Acc: (86.00%) (18850/21888)
Epoch: 51 | Batch_idx: 180 |  Loss: (0.4002) |  Loss2: (0.0000) | Acc: (86.00%) (19964/23168)
Epoch: 51 | Batch_idx: 190 |  Loss: (0.3997) |  Loss2: (0.0000) | Acc: (86.00%) (21099/24448)
Epoch: 51 | Batch_idx: 200 |  Loss: (0.3991) |  Loss2: (0.0000) | Acc: (86.00%) (22202/25728)
Epoch: 51 | Batch_idx: 210 |  Loss: (0.3976) |  Loss2: (0.0000) | Acc: (86.00%) (23327/27008)
Epoch: 51 | Batch_idx: 220 |  Loss: (0.3969) |  Loss2: (0.0000) | Acc: (86.00%) (24437/28288)
Epoch: 51 | Batch_idx: 230 |  Loss: (0.3967) |  Loss2: (0.0000) | Acc: (86.00%) (25546/29568)
Epoch: 51 | Batch_idx: 240 |  Loss: (0.3978) |  Loss2: (0.0000) | Acc: (86.00%) (26631/30848)
Epoch: 51 | Batch_idx: 250 |  Loss: (0.3993) |  Loss2: (0.0000) | Acc: (86.00%) (27726/32128)
Epoch: 51 | Batch_idx: 260 |  Loss: (0.3982) |  Loss2: (0.0000) | Acc: (86.00%) (28845/33408)
Epoch: 51 | Batch_idx: 270 |  Loss: (0.3983) |  Loss2: (0.0000) | Acc: (86.00%) (29941/34688)
Epoch: 51 | Batch_idx: 280 |  Loss: (0.3988) |  Loss2: (0.0000) | Acc: (86.00%) (31031/35968)
Epoch: 51 | Batch_idx: 290 |  Loss: (0.3982) |  Loss2: (0.0000) | Acc: (86.00%) (32152/37248)
Epoch: 51 | Batch_idx: 300 |  Loss: (0.3981) |  Loss2: (0.0000) | Acc: (86.00%) (33267/38528)
Epoch: 51 | Batch_idx: 310 |  Loss: (0.3982) |  Loss2: (0.0000) | Acc: (86.00%) (34372/39808)
Epoch: 51 | Batch_idx: 320 |  Loss: (0.3981) |  Loss2: (0.0000) | Acc: (86.00%) (35474/41088)
Epoch: 51 | Batch_idx: 330 |  Loss: (0.3987) |  Loss2: (0.0000) | Acc: (86.00%) (36568/42368)
Epoch: 51 | Batch_idx: 340 |  Loss: (0.3993) |  Loss2: (0.0000) | Acc: (86.00%) (37668/43648)
Epoch: 51 | Batch_idx: 350 |  Loss: (0.4005) |  Loss2: (0.0000) | Acc: (86.00%) (38759/44928)
Epoch: 51 | Batch_idx: 360 |  Loss: (0.3993) |  Loss2: (0.0000) | Acc: (86.00%) (39877/46208)
Epoch: 51 | Batch_idx: 370 |  Loss: (0.3998) |  Loss2: (0.0000) | Acc: (86.00%) (40970/47488)
Epoch: 51 | Batch_idx: 380 |  Loss: (0.4002) |  Loss2: (0.0000) | Acc: (86.00%) (42063/48768)
Epoch: 51 | Batch_idx: 390 |  Loss: (0.4003) |  Loss2: (0.0000) | Acc: (86.00%) (43121/50000)
# TEST : Loss: (0.4795) | Acc: (83.00%) (8378/10000)
percent tensor([0.5291, 0.5512, 0.5343, 0.5324, 0.5375, 0.5229, 0.5513, 0.5426, 0.5411,
        0.5428, 0.5391, 0.5385, 0.5327, 0.5570, 0.5376, 0.5324],
       device='cuda:0') torch.Size([16])
percent tensor([0.5158, 0.5196, 0.5030, 0.5029, 0.5060, 0.5105, 0.5173, 0.5096, 0.5140,
        0.5138, 0.5169, 0.5097, 0.5175, 0.5175, 0.5137, 0.5142],
       device='cuda:0') torch.Size([16])
percent tensor([0.5473, 0.5525, 0.5578, 0.5905, 0.5942, 0.5813, 0.5808, 0.6046, 0.5484,
        0.5279, 0.5227, 0.5604, 0.5107, 0.5920, 0.5904, 0.5481],
       device='cuda:0') torch.Size([16])
percent tensor([0.6110, 0.5691, 0.5944, 0.6008, 0.6108, 0.6180, 0.6081, 0.6103, 0.5733,
        0.5738, 0.5738, 0.5760, 0.5621, 0.5897, 0.6140, 0.6045],
       device='cuda:0') torch.Size([16])
percent tensor([0.5116, 0.5277, 0.5027, 0.5054, 0.4933, 0.5064, 0.5178, 0.4981, 0.5278,
        0.5292, 0.5340, 0.5183, 0.5278, 0.5353, 0.5094, 0.5202],
       device='cuda:0') torch.Size([16])
percent tensor([0.6311, 0.6570, 0.6599, 0.7196, 0.6674, 0.6797, 0.6627, 0.6331, 0.6899,
        0.6444, 0.6842, 0.6951, 0.6536, 0.7428, 0.6237, 0.6677],
       device='cuda:0') torch.Size([16])
percent tensor([0.5499, 0.5218, 0.6152, 0.6502, 0.6102, 0.6476, 0.5376, 0.5635, 0.5706,
        0.5577, 0.5451, 0.5902, 0.5278, 0.5856, 0.5031, 0.5784],
       device='cuda:0') torch.Size([16])
percent tensor([0.9971, 0.9979, 0.9988, 0.9990, 0.9986, 0.9962, 0.9979, 0.9993, 0.9973,
        0.9980, 0.9980, 0.9992, 0.9959, 0.9973, 0.9988, 0.9987],
       device='cuda:0') torch.Size([16])
Epoch: 52 | Batch_idx: 0 |  Loss: (0.4030) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 52 | Batch_idx: 10 |  Loss: (0.3751) |  Loss2: (0.0000) | Acc: (87.00%) (1225/1408)
Epoch: 52 | Batch_idx: 20 |  Loss: (0.3599) |  Loss2: (0.0000) | Acc: (87.00%) (2357/2688)
Epoch: 52 | Batch_idx: 30 |  Loss: (0.3631) |  Loss2: (0.0000) | Acc: (87.00%) (3485/3968)
Epoch: 52 | Batch_idx: 40 |  Loss: (0.3631) |  Loss2: (0.0000) | Acc: (87.00%) (4615/5248)
Epoch: 52 | Batch_idx: 50 |  Loss: (0.3634) |  Loss2: (0.0000) | Acc: (87.00%) (5728/6528)
Epoch: 52 | Batch_idx: 60 |  Loss: (0.3674) |  Loss2: (0.0000) | Acc: (87.00%) (6823/7808)
Epoch: 52 | Batch_idx: 70 |  Loss: (0.3699) |  Loss2: (0.0000) | Acc: (87.00%) (7943/9088)
Epoch: 52 | Batch_idx: 80 |  Loss: (0.3742) |  Loss2: (0.0000) | Acc: (87.00%) (9046/10368)
Epoch: 52 | Batch_idx: 90 |  Loss: (0.3756) |  Loss2: (0.0000) | Acc: (87.00%) (10159/11648)
Epoch: 52 | Batch_idx: 100 |  Loss: (0.3788) |  Loss2: (0.0000) | Acc: (87.00%) (11252/12928)
Epoch: 52 | Batch_idx: 110 |  Loss: (0.3764) |  Loss2: (0.0000) | Acc: (87.00%) (12366/14208)
Epoch: 52 | Batch_idx: 120 |  Loss: (0.3754) |  Loss2: (0.0000) | Acc: (87.00%) (13492/15488)
Epoch: 52 | Batch_idx: 130 |  Loss: (0.3758) |  Loss2: (0.0000) | Acc: (87.00%) (14607/16768)
Epoch: 52 | Batch_idx: 140 |  Loss: (0.3768) |  Loss2: (0.0000) | Acc: (87.00%) (15721/18048)
Epoch: 52 | Batch_idx: 150 |  Loss: (0.3775) |  Loss2: (0.0000) | Acc: (87.00%) (16819/19328)
Epoch: 52 | Batch_idx: 160 |  Loss: (0.3759) |  Loss2: (0.0000) | Acc: (87.00%) (17937/20608)
Epoch: 52 | Batch_idx: 170 |  Loss: (0.3769) |  Loss2: (0.0000) | Acc: (87.00%) (19051/21888)
Epoch: 52 | Batch_idx: 180 |  Loss: (0.3773) |  Loss2: (0.0000) | Acc: (87.00%) (20165/23168)
Epoch: 52 | Batch_idx: 190 |  Loss: (0.3797) |  Loss2: (0.0000) | Acc: (86.00%) (21260/24448)
Epoch: 52 | Batch_idx: 200 |  Loss: (0.3799) |  Loss2: (0.0000) | Acc: (86.00%) (22375/25728)
Epoch: 52 | Batch_idx: 210 |  Loss: (0.3800) |  Loss2: (0.0000) | Acc: (86.00%) (23496/27008)
Epoch: 52 | Batch_idx: 220 |  Loss: (0.3790) |  Loss2: (0.0000) | Acc: (87.00%) (24629/28288)
Epoch: 52 | Batch_idx: 230 |  Loss: (0.3805) |  Loss2: (0.0000) | Acc: (87.00%) (25737/29568)
Epoch: 52 | Batch_idx: 240 |  Loss: (0.3802) |  Loss2: (0.0000) | Acc: (87.00%) (26850/30848)
Epoch: 52 | Batch_idx: 250 |  Loss: (0.3797) |  Loss2: (0.0000) | Acc: (87.00%) (27969/32128)
Epoch: 52 | Batch_idx: 260 |  Loss: (0.3789) |  Loss2: (0.0000) | Acc: (87.00%) (29080/33408)
Epoch: 52 | Batch_idx: 270 |  Loss: (0.3798) |  Loss2: (0.0000) | Acc: (87.00%) (30187/34688)
Epoch: 52 | Batch_idx: 280 |  Loss: (0.3792) |  Loss2: (0.0000) | Acc: (87.00%) (31306/35968)
Epoch: 52 | Batch_idx: 290 |  Loss: (0.3786) |  Loss2: (0.0000) | Acc: (87.00%) (32428/37248)
Epoch: 52 | Batch_idx: 300 |  Loss: (0.3799) |  Loss2: (0.0000) | Acc: (87.00%) (33537/38528)
Epoch: 52 | Batch_idx: 310 |  Loss: (0.3818) |  Loss2: (0.0000) | Acc: (86.00%) (34624/39808)
Epoch: 52 | Batch_idx: 320 |  Loss: (0.3813) |  Loss2: (0.0000) | Acc: (87.00%) (35755/41088)
Epoch: 52 | Batch_idx: 330 |  Loss: (0.3823) |  Loss2: (0.0000) | Acc: (86.00%) (36853/42368)
Epoch: 52 | Batch_idx: 340 |  Loss: (0.3824) |  Loss2: (0.0000) | Acc: (86.00%) (37948/43648)
Epoch: 52 | Batch_idx: 350 |  Loss: (0.3819) |  Loss2: (0.0000) | Acc: (86.00%) (39064/44928)
Epoch: 52 | Batch_idx: 360 |  Loss: (0.3824) |  Loss2: (0.0000) | Acc: (86.00%) (40168/46208)
Epoch: 52 | Batch_idx: 370 |  Loss: (0.3814) |  Loss2: (0.0000) | Acc: (86.00%) (41299/47488)
Epoch: 52 | Batch_idx: 380 |  Loss: (0.3819) |  Loss2: (0.0000) | Acc: (86.00%) (42405/48768)
Epoch: 52 | Batch_idx: 390 |  Loss: (0.3812) |  Loss2: (0.0000) | Acc: (86.00%) (43478/50000)
# TEST : Loss: (0.6465) | Acc: (78.00%) (7851/10000)
percent tensor([0.5287, 0.5522, 0.5326, 0.5328, 0.5364, 0.5226, 0.5513, 0.5429, 0.5410,
        0.5427, 0.5390, 0.5367, 0.5326, 0.5581, 0.5380, 0.5327],
       device='cuda:0') torch.Size([16])
percent tensor([0.5175, 0.5215, 0.5064, 0.5045, 0.5080, 0.5106, 0.5196, 0.5114, 0.5161,
        0.5172, 0.5190, 0.5126, 0.5191, 0.5183, 0.5155, 0.5157],
       device='cuda:0') torch.Size([16])
percent tensor([0.5461, 0.5596, 0.5569, 0.5949, 0.5942, 0.5875, 0.5856, 0.6057, 0.5448,
        0.5329, 0.5204, 0.5613, 0.5103, 0.5992, 0.5969, 0.5513],
       device='cuda:0') torch.Size([16])
percent tensor([0.6121, 0.5777, 0.5913, 0.6010, 0.6137, 0.6216, 0.6127, 0.6089, 0.5733,
        0.5794, 0.5736, 0.5779, 0.5611, 0.5967, 0.6210, 0.6103],
       device='cuda:0') torch.Size([16])
percent tensor([0.5098, 0.5208, 0.5035, 0.5066, 0.4907, 0.5001, 0.5127, 0.4988, 0.5264,
        0.5240, 0.5335, 0.5163, 0.5257, 0.5291, 0.5034, 0.5147],
       device='cuda:0') torch.Size([16])
percent tensor([0.6293, 0.6454, 0.6581, 0.7047, 0.6697, 0.6857, 0.6587, 0.6508, 0.6893,
        0.6254, 0.6697, 0.6822, 0.6409, 0.7272, 0.6226, 0.6658],
       device='cuda:0') torch.Size([16])
percent tensor([0.5481, 0.5104, 0.6127, 0.6389, 0.6114, 0.6594, 0.5398, 0.5759, 0.5682,
        0.5464, 0.5337, 0.5831, 0.5213, 0.5749, 0.5036, 0.5892],
       device='cuda:0') torch.Size([16])
percent tensor([0.9980, 0.9970, 0.9989, 0.9986, 0.9989, 0.9961, 0.9975, 0.9988, 0.9972,
        0.9984, 0.9979, 0.9993, 0.9968, 0.9970, 0.9991, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 53 | Batch_idx: 0 |  Loss: (0.3303) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 53 | Batch_idx: 10 |  Loss: (0.3600) |  Loss2: (0.0000) | Acc: (88.00%) (1247/1408)
Epoch: 53 | Batch_idx: 20 |  Loss: (0.3824) |  Loss2: (0.0000) | Acc: (87.00%) (2348/2688)
Epoch: 53 | Batch_idx: 30 |  Loss: (0.3694) |  Loss2: (0.0000) | Acc: (87.00%) (3482/3968)
Epoch: 53 | Batch_idx: 40 |  Loss: (0.3618) |  Loss2: (0.0000) | Acc: (87.00%) (4604/5248)
Epoch: 53 | Batch_idx: 50 |  Loss: (0.3667) |  Loss2: (0.0000) | Acc: (87.00%) (5718/6528)
Epoch: 53 | Batch_idx: 60 |  Loss: (0.3661) |  Loss2: (0.0000) | Acc: (87.00%) (6837/7808)
Epoch: 53 | Batch_idx: 70 |  Loss: (0.3661) |  Loss2: (0.0000) | Acc: (87.00%) (7958/9088)
Epoch: 53 | Batch_idx: 80 |  Loss: (0.3639) |  Loss2: (0.0000) | Acc: (87.00%) (9085/10368)
Epoch: 53 | Batch_idx: 90 |  Loss: (0.3667) |  Loss2: (0.0000) | Acc: (87.00%) (10202/11648)
Epoch: 53 | Batch_idx: 100 |  Loss: (0.3682) |  Loss2: (0.0000) | Acc: (87.00%) (11316/12928)
Epoch: 53 | Batch_idx: 110 |  Loss: (0.3692) |  Loss2: (0.0000) | Acc: (87.00%) (12415/14208)
Epoch: 53 | Batch_idx: 120 |  Loss: (0.3682) |  Loss2: (0.0000) | Acc: (87.00%) (13548/15488)
Epoch: 53 | Batch_idx: 130 |  Loss: (0.3680) |  Loss2: (0.0000) | Acc: (87.00%) (14670/16768)
Epoch: 53 | Batch_idx: 140 |  Loss: (0.3671) |  Loss2: (0.0000) | Acc: (87.00%) (15792/18048)
Epoch: 53 | Batch_idx: 150 |  Loss: (0.3690) |  Loss2: (0.0000) | Acc: (87.00%) (16898/19328)
Epoch: 53 | Batch_idx: 160 |  Loss: (0.3702) |  Loss2: (0.0000) | Acc: (87.00%) (17999/20608)
Epoch: 53 | Batch_idx: 170 |  Loss: (0.3713) |  Loss2: (0.0000) | Acc: (87.00%) (19108/21888)
Epoch: 53 | Batch_idx: 180 |  Loss: (0.3703) |  Loss2: (0.0000) | Acc: (87.00%) (20235/23168)
Epoch: 53 | Batch_idx: 190 |  Loss: (0.3697) |  Loss2: (0.0000) | Acc: (87.00%) (21359/24448)
Epoch: 53 | Batch_idx: 200 |  Loss: (0.3701) |  Loss2: (0.0000) | Acc: (87.00%) (22479/25728)
Epoch: 53 | Batch_idx: 210 |  Loss: (0.3697) |  Loss2: (0.0000) | Acc: (87.00%) (23610/27008)
Epoch: 53 | Batch_idx: 220 |  Loss: (0.3705) |  Loss2: (0.0000) | Acc: (87.00%) (24713/28288)
Epoch: 53 | Batch_idx: 230 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (87.00%) (25800/29568)
Epoch: 53 | Batch_idx: 240 |  Loss: (0.3724) |  Loss2: (0.0000) | Acc: (87.00%) (26914/30848)
Epoch: 53 | Batch_idx: 250 |  Loss: (0.3734) |  Loss2: (0.0000) | Acc: (87.00%) (28013/32128)
Epoch: 53 | Batch_idx: 260 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (87.00%) (29125/33408)
Epoch: 53 | Batch_idx: 270 |  Loss: (0.3717) |  Loss2: (0.0000) | Acc: (87.00%) (30254/34688)
Epoch: 53 | Batch_idx: 280 |  Loss: (0.3707) |  Loss2: (0.0000) | Acc: (87.00%) (31388/35968)
Epoch: 53 | Batch_idx: 290 |  Loss: (0.3718) |  Loss2: (0.0000) | Acc: (87.00%) (32488/37248)
Epoch: 53 | Batch_idx: 300 |  Loss: (0.3720) |  Loss2: (0.0000) | Acc: (87.00%) (33594/38528)
Epoch: 53 | Batch_idx: 310 |  Loss: (0.3721) |  Loss2: (0.0000) | Acc: (87.00%) (34705/39808)
Epoch: 53 | Batch_idx: 320 |  Loss: (0.3717) |  Loss2: (0.0000) | Acc: (87.00%) (35822/41088)
Epoch: 53 | Batch_idx: 330 |  Loss: (0.3731) |  Loss2: (0.0000) | Acc: (87.00%) (36910/42368)
Epoch: 53 | Batch_idx: 340 |  Loss: (0.3736) |  Loss2: (0.0000) | Acc: (87.00%) (38011/43648)
Epoch: 53 | Batch_idx: 350 |  Loss: (0.3740) |  Loss2: (0.0000) | Acc: (87.00%) (39116/44928)
Epoch: 53 | Batch_idx: 360 |  Loss: (0.3738) |  Loss2: (0.0000) | Acc: (87.00%) (40239/46208)
Epoch: 53 | Batch_idx: 370 |  Loss: (0.3727) |  Loss2: (0.0000) | Acc: (87.00%) (41372/47488)
Epoch: 53 | Batch_idx: 380 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (87.00%) (42483/48768)
Epoch: 53 | Batch_idx: 390 |  Loss: (0.3735) |  Loss2: (0.0000) | Acc: (87.00%) (43547/50000)
# TEST : Loss: (0.5063) | Acc: (82.00%) (8299/10000)
percent tensor([0.5287, 0.5514, 0.5334, 0.5327, 0.5366, 0.5221, 0.5508, 0.5431, 0.5411,
        0.5428, 0.5394, 0.5376, 0.5329, 0.5568, 0.5377, 0.5326],
       device='cuda:0') torch.Size([16])
percent tensor([0.5173, 0.5196, 0.5051, 0.5039, 0.5073, 0.5113, 0.5172, 0.5106, 0.5145,
        0.5148, 0.5172, 0.5113, 0.5187, 0.5146, 0.5147, 0.5151],
       device='cuda:0') torch.Size([16])
percent tensor([0.5555, 0.5623, 0.5572, 0.6057, 0.5954, 0.5911, 0.5925, 0.6143, 0.5535,
        0.5401, 0.5372, 0.5699, 0.5173, 0.6104, 0.6048, 0.5627],
       device='cuda:0') torch.Size([16])
percent tensor([0.6112, 0.5731, 0.5834, 0.6015, 0.6072, 0.6177, 0.6096, 0.6113, 0.5791,
        0.5775, 0.5799, 0.5737, 0.5608, 0.6021, 0.6201, 0.6104],
       device='cuda:0') torch.Size([16])
percent tensor([0.5118, 0.5265, 0.5052, 0.5035, 0.4937, 0.5050, 0.5175, 0.4977, 0.5246,
        0.5258, 0.5329, 0.5172, 0.5266, 0.5323, 0.5085, 0.5182],
       device='cuda:0') torch.Size([16])
percent tensor([0.6381, 0.6554, 0.6448, 0.7150, 0.6592, 0.6828, 0.6724, 0.6453, 0.6865,
        0.6413, 0.6889, 0.6940, 0.6441, 0.7423, 0.6354, 0.6705],
       device='cuda:0') torch.Size([16])
percent tensor([0.5419, 0.5152, 0.5978, 0.6364, 0.5953, 0.6408, 0.5276, 0.5640, 0.5703,
        0.5410, 0.5534, 0.5911, 0.5139, 0.5922, 0.5025, 0.5694],
       device='cuda:0') torch.Size([16])
percent tensor([0.9972, 0.9983, 0.9991, 0.9985, 0.9992, 0.9974, 0.9983, 0.9990, 0.9988,
        0.9992, 0.9988, 0.9997, 0.9979, 0.9982, 0.9992, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 54 | Batch_idx: 0 |  Loss: (0.2502) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 54 | Batch_idx: 10 |  Loss: (0.3648) |  Loss2: (0.0000) | Acc: (87.00%) (1232/1408)
Epoch: 54 | Batch_idx: 20 |  Loss: (0.3607) |  Loss2: (0.0000) | Acc: (87.00%) (2352/2688)
Epoch: 54 | Batch_idx: 30 |  Loss: (0.3586) |  Loss2: (0.0000) | Acc: (87.00%) (3484/3968)
Epoch: 54 | Batch_idx: 40 |  Loss: (0.3529) |  Loss2: (0.0000) | Acc: (88.00%) (4621/5248)
Epoch: 54 | Batch_idx: 50 |  Loss: (0.3558) |  Loss2: (0.0000) | Acc: (87.00%) (5740/6528)
Epoch: 54 | Batch_idx: 60 |  Loss: (0.3582) |  Loss2: (0.0000) | Acc: (87.00%) (6866/7808)
Epoch: 54 | Batch_idx: 70 |  Loss: (0.3578) |  Loss2: (0.0000) | Acc: (87.00%) (7986/9088)
Epoch: 54 | Batch_idx: 80 |  Loss: (0.3556) |  Loss2: (0.0000) | Acc: (87.00%) (9116/10368)
Epoch: 54 | Batch_idx: 90 |  Loss: (0.3546) |  Loss2: (0.0000) | Acc: (87.00%) (10239/11648)
Epoch: 54 | Batch_idx: 100 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (11346/12928)
Epoch: 54 | Batch_idx: 110 |  Loss: (0.3588) |  Loss2: (0.0000) | Acc: (87.00%) (12460/14208)
Epoch: 54 | Batch_idx: 120 |  Loss: (0.3586) |  Loss2: (0.0000) | Acc: (87.00%) (13577/15488)
Epoch: 54 | Batch_idx: 130 |  Loss: (0.3553) |  Loss2: (0.0000) | Acc: (87.00%) (14719/16768)
Epoch: 54 | Batch_idx: 140 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (15832/18048)
Epoch: 54 | Batch_idx: 150 |  Loss: (0.3583) |  Loss2: (0.0000) | Acc: (87.00%) (16938/19328)
Epoch: 54 | Batch_idx: 160 |  Loss: (0.3580) |  Loss2: (0.0000) | Acc: (87.00%) (18056/20608)
Epoch: 54 | Batch_idx: 170 |  Loss: (0.3606) |  Loss2: (0.0000) | Acc: (87.00%) (19156/21888)
Epoch: 54 | Batch_idx: 180 |  Loss: (0.3616) |  Loss2: (0.0000) | Acc: (87.00%) (20272/23168)
Epoch: 54 | Batch_idx: 190 |  Loss: (0.3638) |  Loss2: (0.0000) | Acc: (87.00%) (21372/24448)
Epoch: 54 | Batch_idx: 200 |  Loss: (0.3640) |  Loss2: (0.0000) | Acc: (87.00%) (22478/25728)
Epoch: 54 | Batch_idx: 210 |  Loss: (0.3650) |  Loss2: (0.0000) | Acc: (87.00%) (23595/27008)
Epoch: 54 | Batch_idx: 220 |  Loss: (0.3652) |  Loss2: (0.0000) | Acc: (87.00%) (24712/28288)
Epoch: 54 | Batch_idx: 230 |  Loss: (0.3662) |  Loss2: (0.0000) | Acc: (87.00%) (25815/29568)
Epoch: 54 | Batch_idx: 240 |  Loss: (0.3663) |  Loss2: (0.0000) | Acc: (87.00%) (26938/30848)
Epoch: 54 | Batch_idx: 250 |  Loss: (0.3671) |  Loss2: (0.0000) | Acc: (87.00%) (28042/32128)
Epoch: 54 | Batch_idx: 260 |  Loss: (0.3683) |  Loss2: (0.0000) | Acc: (87.00%) (29150/33408)
Epoch: 54 | Batch_idx: 270 |  Loss: (0.3671) |  Loss2: (0.0000) | Acc: (87.00%) (30270/34688)
Epoch: 54 | Batch_idx: 280 |  Loss: (0.3673) |  Loss2: (0.0000) | Acc: (87.00%) (31383/35968)
Epoch: 54 | Batch_idx: 290 |  Loss: (0.3669) |  Loss2: (0.0000) | Acc: (87.00%) (32503/37248)
Epoch: 54 | Batch_idx: 300 |  Loss: (0.3653) |  Loss2: (0.0000) | Acc: (87.00%) (33632/38528)
Epoch: 54 | Batch_idx: 310 |  Loss: (0.3650) |  Loss2: (0.0000) | Acc: (87.00%) (34738/39808)
Epoch: 54 | Batch_idx: 320 |  Loss: (0.3650) |  Loss2: (0.0000) | Acc: (87.00%) (35863/41088)
Epoch: 54 | Batch_idx: 330 |  Loss: (0.3651) |  Loss2: (0.0000) | Acc: (87.00%) (36974/42368)
Epoch: 54 | Batch_idx: 340 |  Loss: (0.3655) |  Loss2: (0.0000) | Acc: (87.00%) (38084/43648)
Epoch: 54 | Batch_idx: 350 |  Loss: (0.3663) |  Loss2: (0.0000) | Acc: (87.00%) (39189/44928)
Epoch: 54 | Batch_idx: 360 |  Loss: (0.3649) |  Loss2: (0.0000) | Acc: (87.00%) (40331/46208)
Epoch: 54 | Batch_idx: 370 |  Loss: (0.3647) |  Loss2: (0.0000) | Acc: (87.00%) (41458/47488)
Epoch: 54 | Batch_idx: 380 |  Loss: (0.3649) |  Loss2: (0.0000) | Acc: (87.00%) (42571/48768)
Epoch: 54 | Batch_idx: 390 |  Loss: (0.3650) |  Loss2: (0.0000) | Acc: (87.00%) (43635/50000)
# TEST : Loss: (0.4548) | Acc: (84.00%) (8495/10000)
percent tensor([0.5295, 0.5517, 0.5349, 0.5331, 0.5380, 0.5231, 0.5517, 0.5428, 0.5419,
        0.5432, 0.5394, 0.5392, 0.5332, 0.5571, 0.5379, 0.5327],
       device='cuda:0') torch.Size([16])
percent tensor([0.5169, 0.5188, 0.5048, 0.5044, 0.5069, 0.5111, 0.5172, 0.5094, 0.5145,
        0.5144, 0.5171, 0.5114, 0.5184, 0.5162, 0.5142, 0.5146],
       device='cuda:0') torch.Size([16])
percent tensor([0.5540, 0.5639, 0.5535, 0.5965, 0.5919, 0.5881, 0.5889, 0.6102, 0.5524,
        0.5382, 0.5308, 0.5623, 0.5192, 0.6098, 0.6004, 0.5589],
       device='cuda:0') torch.Size([16])
percent tensor([0.6173, 0.5752, 0.5933, 0.5995, 0.6164, 0.6287, 0.6113, 0.6132, 0.5794,
        0.5800, 0.5817, 0.5744, 0.5668, 0.5958, 0.6218, 0.6147],
       device='cuda:0') torch.Size([16])
percent tensor([0.5100, 0.5249, 0.5042, 0.5061, 0.4924, 0.5004, 0.5164, 0.4990, 0.5229,
        0.5251, 0.5306, 0.5175, 0.5237, 0.5328, 0.5065, 0.5166],
       device='cuda:0') torch.Size([16])
percent tensor([0.6234, 0.6595, 0.6521, 0.6992, 0.6711, 0.6689, 0.6661, 0.6422, 0.6854,
        0.6410, 0.6855, 0.6776, 0.6379, 0.7494, 0.6225, 0.6637],
       device='cuda:0') torch.Size([16])
percent tensor([0.5468, 0.5246, 0.6060, 0.6258, 0.6047, 0.6380, 0.5436, 0.5735, 0.5712,
        0.5606, 0.5557, 0.5700, 0.5244, 0.5925, 0.5096, 0.5829],
       device='cuda:0') torch.Size([16])
percent tensor([0.9982, 0.9981, 0.9988, 0.9987, 0.9989, 0.9967, 0.9983, 0.9989, 0.9983,
        0.9987, 0.9983, 0.9991, 0.9973, 0.9979, 0.9988, 0.9987],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 55 | Batch_idx: 0 |  Loss: (0.2720) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 55 | Batch_idx: 10 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (87.00%) (1231/1408)
Epoch: 55 | Batch_idx: 20 |  Loss: (0.3921) |  Loss2: (0.0000) | Acc: (86.00%) (2328/2688)
Epoch: 55 | Batch_idx: 30 |  Loss: (0.3955) |  Loss2: (0.0000) | Acc: (86.00%) (3444/3968)
Epoch: 55 | Batch_idx: 40 |  Loss: (0.4141) |  Loss2: (0.0000) | Acc: (86.00%) (4515/5248)
Epoch: 55 | Batch_idx: 50 |  Loss: (0.4246) |  Loss2: (0.0000) | Acc: (85.00%) (5600/6528)
Epoch: 55 | Batch_idx: 60 |  Loss: (0.4297) |  Loss2: (0.0000) | Acc: (85.00%) (6669/7808)
Epoch: 55 | Batch_idx: 70 |  Loss: (0.4286) |  Loss2: (0.0000) | Acc: (85.00%) (7766/9088)
Epoch: 55 | Batch_idx: 80 |  Loss: (0.4258) |  Loss2: (0.0000) | Acc: (85.00%) (8872/10368)
Epoch: 55 | Batch_idx: 90 |  Loss: (0.4282) |  Loss2: (0.0000) | Acc: (85.00%) (9939/11648)
Epoch: 55 | Batch_idx: 100 |  Loss: (0.4302) |  Loss2: (0.0000) | Acc: (85.00%) (11009/12928)
Epoch: 55 | Batch_idx: 110 |  Loss: (0.4288) |  Loss2: (0.0000) | Acc: (85.00%) (12100/14208)
Epoch: 55 | Batch_idx: 120 |  Loss: (0.4266) |  Loss2: (0.0000) | Acc: (85.00%) (13198/15488)
Epoch: 55 | Batch_idx: 130 |  Loss: (0.4266) |  Loss2: (0.0000) | Acc: (85.00%) (14289/16768)
Epoch: 55 | Batch_idx: 140 |  Loss: (0.4270) |  Loss2: (0.0000) | Acc: (85.00%) (15375/18048)
Epoch: 55 | Batch_idx: 150 |  Loss: (0.4247) |  Loss2: (0.0000) | Acc: (85.00%) (16475/19328)
Epoch: 55 | Batch_idx: 160 |  Loss: (0.4224) |  Loss2: (0.0000) | Acc: (85.00%) (17590/20608)
Epoch: 55 | Batch_idx: 170 |  Loss: (0.4240) |  Loss2: (0.0000) | Acc: (85.00%) (18694/21888)
Epoch: 55 | Batch_idx: 180 |  Loss: (0.4232) |  Loss2: (0.0000) | Acc: (85.00%) (19788/23168)
Epoch: 55 | Batch_idx: 190 |  Loss: (0.4223) |  Loss2: (0.0000) | Acc: (85.00%) (20883/24448)
Epoch: 55 | Batch_idx: 200 |  Loss: (0.4226) |  Loss2: (0.0000) | Acc: (85.00%) (21970/25728)
Epoch: 55 | Batch_idx: 210 |  Loss: (0.4211) |  Loss2: (0.0000) | Acc: (85.00%) (23071/27008)
Epoch: 55 | Batch_idx: 220 |  Loss: (0.4215) |  Loss2: (0.0000) | Acc: (85.00%) (24176/28288)
Epoch: 55 | Batch_idx: 230 |  Loss: (0.4213) |  Loss2: (0.0000) | Acc: (85.00%) (25261/29568)
Epoch: 55 | Batch_idx: 240 |  Loss: (0.4209) |  Loss2: (0.0000) | Acc: (85.00%) (26371/30848)
Epoch: 55 | Batch_idx: 250 |  Loss: (0.4189) |  Loss2: (0.0000) | Acc: (85.00%) (27492/32128)
Epoch: 55 | Batch_idx: 260 |  Loss: (0.4179) |  Loss2: (0.0000) | Acc: (85.00%) (28597/33408)
Epoch: 55 | Batch_idx: 270 |  Loss: (0.4168) |  Loss2: (0.0000) | Acc: (85.00%) (29711/34688)
Epoch: 55 | Batch_idx: 280 |  Loss: (0.4156) |  Loss2: (0.0000) | Acc: (85.00%) (30818/35968)
Epoch: 55 | Batch_idx: 290 |  Loss: (0.4157) |  Loss2: (0.0000) | Acc: (85.00%) (31902/37248)
Epoch: 55 | Batch_idx: 300 |  Loss: (0.4142) |  Loss2: (0.0000) | Acc: (85.00%) (33017/38528)
Epoch: 55 | Batch_idx: 310 |  Loss: (0.4137) |  Loss2: (0.0000) | Acc: (85.00%) (34115/39808)
Epoch: 55 | Batch_idx: 320 |  Loss: (0.4134) |  Loss2: (0.0000) | Acc: (85.00%) (35216/41088)
Epoch: 55 | Batch_idx: 330 |  Loss: (0.4129) |  Loss2: (0.0000) | Acc: (85.00%) (36319/42368)
Epoch: 55 | Batch_idx: 340 |  Loss: (0.4132) |  Loss2: (0.0000) | Acc: (85.00%) (37409/43648)
Epoch: 55 | Batch_idx: 350 |  Loss: (0.4132) |  Loss2: (0.0000) | Acc: (85.00%) (38515/44928)
Epoch: 55 | Batch_idx: 360 |  Loss: (0.4117) |  Loss2: (0.0000) | Acc: (85.00%) (39623/46208)
Epoch: 55 | Batch_idx: 370 |  Loss: (0.4108) |  Loss2: (0.0000) | Acc: (85.00%) (40735/47488)
Epoch: 55 | Batch_idx: 380 |  Loss: (0.4098) |  Loss2: (0.0000) | Acc: (85.00%) (41851/48768)
Epoch: 55 | Batch_idx: 390 |  Loss: (0.4090) |  Loss2: (0.0000) | Acc: (85.00%) (42930/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_055.pth.tar'
# TEST : Loss: (0.4841) | Acc: (83.00%) (8364/10000)
percent tensor([0.5283, 0.5488, 0.5356, 0.5321, 0.5383, 0.5211, 0.5503, 0.5416, 0.5403,
        0.5419, 0.5372, 0.5399, 0.5320, 0.5536, 0.5358, 0.5309],
       device='cuda:0') torch.Size([16])
percent tensor([0.5129, 0.5141, 0.5039, 0.5030, 0.5050, 0.5064, 0.5140, 0.5075, 0.5127,
        0.5115, 0.5135, 0.5096, 0.5148, 0.5128, 0.5092, 0.5105],
       device='cuda:0') torch.Size([16])
percent tensor([0.5544, 0.5708, 0.5432, 0.5795, 0.5867, 0.5887, 0.5935, 0.6088, 0.5490,
        0.5370, 0.5335, 0.5553, 0.5292, 0.5933, 0.6040, 0.5608],
       device='cuda:0') torch.Size([16])
percent tensor([0.6363, 0.5963, 0.6035, 0.6110, 0.6303, 0.6417, 0.6319, 0.6308, 0.5966,
        0.5992, 0.5998, 0.5926, 0.5880, 0.6137, 0.6421, 0.6300],
       device='cuda:0') torch.Size([16])
percent tensor([0.5070, 0.5235, 0.5037, 0.5033, 0.4904, 0.4960, 0.5140, 0.4972, 0.5215,
        0.5228, 0.5286, 0.5172, 0.5230, 0.5297, 0.5056, 0.5142],
       device='cuda:0') torch.Size([16])
percent tensor([0.6106, 0.6410, 0.6303, 0.6723, 0.6399, 0.6411, 0.6461, 0.6204, 0.6643,
        0.6232, 0.6635, 0.6549, 0.6276, 0.7213, 0.6087, 0.6427],
       device='cuda:0') torch.Size([16])
percent tensor([0.5311, 0.5043, 0.6204, 0.6449, 0.6111, 0.6604, 0.5309, 0.5810, 0.5632,
        0.5472, 0.5347, 0.5624, 0.5006, 0.5813, 0.4993, 0.5793],
       device='cuda:0') torch.Size([16])
percent tensor([0.9980, 0.9982, 0.9989, 0.9990, 0.9994, 0.9979, 0.9984, 0.9989, 0.9974,
        0.9986, 0.9982, 0.9991, 0.9968, 0.9979, 0.9991, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 56 | Batch_idx: 0 |  Loss: (0.4013) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 56 | Batch_idx: 10 |  Loss: (0.4118) |  Loss2: (0.0000) | Acc: (85.00%) (1210/1408)
Epoch: 56 | Batch_idx: 20 |  Loss: (0.3993) |  Loss2: (0.0000) | Acc: (86.00%) (2317/2688)
Epoch: 56 | Batch_idx: 30 |  Loss: (0.4000) |  Loss2: (0.0000) | Acc: (86.00%) (3429/3968)
Epoch: 56 | Batch_idx: 40 |  Loss: (0.3969) |  Loss2: (0.0000) | Acc: (86.00%) (4543/5248)
Epoch: 56 | Batch_idx: 50 |  Loss: (0.3903) |  Loss2: (0.0000) | Acc: (86.00%) (5651/6528)
Epoch: 56 | Batch_idx: 60 |  Loss: (0.3922) |  Loss2: (0.0000) | Acc: (86.00%) (6756/7808)
Epoch: 56 | Batch_idx: 70 |  Loss: (0.3887) |  Loss2: (0.0000) | Acc: (86.00%) (7868/9088)
Epoch: 56 | Batch_idx: 80 |  Loss: (0.3941) |  Loss2: (0.0000) | Acc: (86.00%) (8954/10368)
Epoch: 56 | Batch_idx: 90 |  Loss: (0.3936) |  Loss2: (0.0000) | Acc: (86.00%) (10076/11648)
Epoch: 56 | Batch_idx: 100 |  Loss: (0.3922) |  Loss2: (0.0000) | Acc: (86.00%) (11188/12928)
Epoch: 56 | Batch_idx: 110 |  Loss: (0.3922) |  Loss2: (0.0000) | Acc: (86.00%) (12287/14208)
Epoch: 56 | Batch_idx: 120 |  Loss: (0.3951) |  Loss2: (0.0000) | Acc: (86.00%) (13360/15488)
Epoch: 56 | Batch_idx: 130 |  Loss: (0.3939) |  Loss2: (0.0000) | Acc: (86.00%) (14471/16768)
Epoch: 56 | Batch_idx: 140 |  Loss: (0.3923) |  Loss2: (0.0000) | Acc: (86.00%) (15580/18048)
Epoch: 56 | Batch_idx: 150 |  Loss: (0.3909) |  Loss2: (0.0000) | Acc: (86.00%) (16703/19328)
Epoch: 56 | Batch_idx: 160 |  Loss: (0.3899) |  Loss2: (0.0000) | Acc: (86.00%) (17820/20608)
Epoch: 56 | Batch_idx: 170 |  Loss: (0.3907) |  Loss2: (0.0000) | Acc: (86.00%) (18922/21888)
Epoch: 56 | Batch_idx: 180 |  Loss: (0.3897) |  Loss2: (0.0000) | Acc: (86.00%) (20042/23168)
Epoch: 56 | Batch_idx: 190 |  Loss: (0.3895) |  Loss2: (0.0000) | Acc: (86.00%) (21154/24448)
Epoch: 56 | Batch_idx: 200 |  Loss: (0.3897) |  Loss2: (0.0000) | Acc: (86.00%) (22251/25728)
Epoch: 56 | Batch_idx: 210 |  Loss: (0.3891) |  Loss2: (0.0000) | Acc: (86.00%) (23362/27008)
Epoch: 56 | Batch_idx: 220 |  Loss: (0.3907) |  Loss2: (0.0000) | Acc: (86.00%) (24449/28288)
Epoch: 56 | Batch_idx: 230 |  Loss: (0.3913) |  Loss2: (0.0000) | Acc: (86.00%) (25549/29568)
Epoch: 56 | Batch_idx: 240 |  Loss: (0.3911) |  Loss2: (0.0000) | Acc: (86.00%) (26666/30848)
Epoch: 56 | Batch_idx: 250 |  Loss: (0.3912) |  Loss2: (0.0000) | Acc: (86.00%) (27762/32128)
Epoch: 56 | Batch_idx: 260 |  Loss: (0.3914) |  Loss2: (0.0000) | Acc: (86.00%) (28859/33408)
Epoch: 56 | Batch_idx: 270 |  Loss: (0.3899) |  Loss2: (0.0000) | Acc: (86.00%) (29980/34688)
Epoch: 56 | Batch_idx: 280 |  Loss: (0.3889) |  Loss2: (0.0000) | Acc: (86.00%) (31098/35968)
Epoch: 56 | Batch_idx: 290 |  Loss: (0.3882) |  Loss2: (0.0000) | Acc: (86.00%) (32217/37248)
Epoch: 56 | Batch_idx: 300 |  Loss: (0.3879) |  Loss2: (0.0000) | Acc: (86.00%) (33326/38528)
Epoch: 56 | Batch_idx: 310 |  Loss: (0.3864) |  Loss2: (0.0000) | Acc: (86.00%) (34457/39808)
Epoch: 56 | Batch_idx: 320 |  Loss: (0.3851) |  Loss2: (0.0000) | Acc: (86.00%) (35588/41088)
Epoch: 56 | Batch_idx: 330 |  Loss: (0.3849) |  Loss2: (0.0000) | Acc: (86.00%) (36699/42368)
Epoch: 56 | Batch_idx: 340 |  Loss: (0.3839) |  Loss2: (0.0000) | Acc: (86.00%) (37831/43648)
Epoch: 56 | Batch_idx: 350 |  Loss: (0.3837) |  Loss2: (0.0000) | Acc: (86.00%) (38946/44928)
Epoch: 56 | Batch_idx: 360 |  Loss: (0.3839) |  Loss2: (0.0000) | Acc: (86.00%) (40053/46208)
Epoch: 56 | Batch_idx: 370 |  Loss: (0.3820) |  Loss2: (0.0000) | Acc: (86.00%) (41197/47488)
Epoch: 56 | Batch_idx: 380 |  Loss: (0.3811) |  Loss2: (0.0000) | Acc: (86.00%) (42329/48768)
Epoch: 56 | Batch_idx: 390 |  Loss: (0.3803) |  Loss2: (0.0000) | Acc: (86.00%) (43404/50000)
# TEST : Loss: (0.4601) | Acc: (84.00%) (8449/10000)
percent tensor([0.5266, 0.5466, 0.5344, 0.5304, 0.5369, 0.5189, 0.5483, 0.5402, 0.5383,
        0.5403, 0.5350, 0.5387, 0.5303, 0.5510, 0.5338, 0.5291],
       device='cuda:0') torch.Size([16])
percent tensor([0.5111, 0.5125, 0.5044, 0.5025, 0.5051, 0.5041, 0.5125, 0.5075, 0.5119,
        0.5102, 0.5120, 0.5097, 0.5134, 0.5114, 0.5071, 0.5085],
       device='cuda:0') torch.Size([16])
percent tensor([0.5576, 0.5689, 0.5486, 0.5833, 0.5942, 0.5990, 0.5951, 0.6158, 0.5481,
        0.5339, 0.5317, 0.5553, 0.5282, 0.5867, 0.6090, 0.5650],
       device='cuda:0') torch.Size([16])
percent tensor([0.6467, 0.6053, 0.6121, 0.6186, 0.6399, 0.6473, 0.6433, 0.6406, 0.6035,
        0.6088, 0.6083, 0.6018, 0.5977, 0.6215, 0.6526, 0.6390],
       device='cuda:0') torch.Size([16])
percent tensor([0.5092, 0.5256, 0.5060, 0.5064, 0.4915, 0.4973, 0.5163, 0.4993, 0.5251,
        0.5239, 0.5313, 0.5214, 0.5258, 0.5335, 0.5085, 0.5158],
       device='cuda:0') torch.Size([16])
percent tensor([0.6171, 0.6443, 0.6311, 0.6703, 0.6407, 0.6395, 0.6490, 0.6201, 0.6657,
        0.6278, 0.6648, 0.6587, 0.6327, 0.7211, 0.6122, 0.6480],
       device='cuda:0') torch.Size([16])
percent tensor([0.5248, 0.4949, 0.6393, 0.6654, 0.6294, 0.6735, 0.5270, 0.5918, 0.5645,
        0.5427, 0.5247, 0.5675, 0.4927, 0.5775, 0.4908, 0.5839],
       device='cuda:0') torch.Size([16])
percent tensor([0.9982, 0.9983, 0.9990, 0.9990, 0.9994, 0.9980, 0.9985, 0.9990, 0.9976,
        0.9987, 0.9984, 0.9992, 0.9971, 0.9979, 0.9991, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 57 | Batch_idx: 0 |  Loss: (0.3653) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 57 | Batch_idx: 10 |  Loss: (0.3365) |  Loss2: (0.0000) | Acc: (88.00%) (1250/1408)
Epoch: 57 | Batch_idx: 20 |  Loss: (0.3519) |  Loss2: (0.0000) | Acc: (87.00%) (2363/2688)
Epoch: 57 | Batch_idx: 30 |  Loss: (0.3566) |  Loss2: (0.0000) | Acc: (87.00%) (3476/3968)
Epoch: 57 | Batch_idx: 40 |  Loss: (0.3561) |  Loss2: (0.0000) | Acc: (87.00%) (4597/5248)
Epoch: 57 | Batch_idx: 50 |  Loss: (0.3578) |  Loss2: (0.0000) | Acc: (87.00%) (5710/6528)
Epoch: 57 | Batch_idx: 60 |  Loss: (0.3634) |  Loss2: (0.0000) | Acc: (87.00%) (6831/7808)
Epoch: 57 | Batch_idx: 70 |  Loss: (0.3677) |  Loss2: (0.0000) | Acc: (87.00%) (7937/9088)
Epoch: 57 | Batch_idx: 80 |  Loss: (0.3715) |  Loss2: (0.0000) | Acc: (87.00%) (9038/10368)
Epoch: 57 | Batch_idx: 90 |  Loss: (0.3767) |  Loss2: (0.0000) | Acc: (87.00%) (10135/11648)
Epoch: 57 | Batch_idx: 100 |  Loss: (0.3750) |  Loss2: (0.0000) | Acc: (87.00%) (11263/12928)
Epoch: 57 | Batch_idx: 110 |  Loss: (0.3755) |  Loss2: (0.0000) | Acc: (87.00%) (12384/14208)
Epoch: 57 | Batch_idx: 120 |  Loss: (0.3743) |  Loss2: (0.0000) | Acc: (87.00%) (13515/15488)
Epoch: 57 | Batch_idx: 130 |  Loss: (0.3727) |  Loss2: (0.0000) | Acc: (87.00%) (14638/16768)
Epoch: 57 | Batch_idx: 140 |  Loss: (0.3718) |  Loss2: (0.0000) | Acc: (87.00%) (15759/18048)
Epoch: 57 | Batch_idx: 150 |  Loss: (0.3716) |  Loss2: (0.0000) | Acc: (87.00%) (16869/19328)
Epoch: 57 | Batch_idx: 160 |  Loss: (0.3703) |  Loss2: (0.0000) | Acc: (87.00%) (17988/20608)
Epoch: 57 | Batch_idx: 170 |  Loss: (0.3694) |  Loss2: (0.0000) | Acc: (87.00%) (19111/21888)
Epoch: 57 | Batch_idx: 180 |  Loss: (0.3693) |  Loss2: (0.0000) | Acc: (87.00%) (20235/23168)
Epoch: 57 | Batch_idx: 190 |  Loss: (0.3687) |  Loss2: (0.0000) | Acc: (87.00%) (21351/24448)
Epoch: 57 | Batch_idx: 200 |  Loss: (0.3673) |  Loss2: (0.0000) | Acc: (87.00%) (22472/25728)
Epoch: 57 | Batch_idx: 210 |  Loss: (0.3674) |  Loss2: (0.0000) | Acc: (87.00%) (23604/27008)
Epoch: 57 | Batch_idx: 220 |  Loss: (0.3672) |  Loss2: (0.0000) | Acc: (87.00%) (24725/28288)
Epoch: 57 | Batch_idx: 230 |  Loss: (0.3676) |  Loss2: (0.0000) | Acc: (87.00%) (25839/29568)
Epoch: 57 | Batch_idx: 240 |  Loss: (0.3663) |  Loss2: (0.0000) | Acc: (87.00%) (26974/30848)
Epoch: 57 | Batch_idx: 250 |  Loss: (0.3663) |  Loss2: (0.0000) | Acc: (87.00%) (28081/32128)
Epoch: 57 | Batch_idx: 260 |  Loss: (0.3660) |  Loss2: (0.0000) | Acc: (87.00%) (29197/33408)
Epoch: 57 | Batch_idx: 270 |  Loss: (0.3653) |  Loss2: (0.0000) | Acc: (87.00%) (30311/34688)
Epoch: 57 | Batch_idx: 280 |  Loss: (0.3643) |  Loss2: (0.0000) | Acc: (87.00%) (31439/35968)
Epoch: 57 | Batch_idx: 290 |  Loss: (0.3647) |  Loss2: (0.0000) | Acc: (87.00%) (32561/37248)
Epoch: 57 | Batch_idx: 300 |  Loss: (0.3645) |  Loss2: (0.0000) | Acc: (87.00%) (33695/38528)
Epoch: 57 | Batch_idx: 310 |  Loss: (0.3645) |  Loss2: (0.0000) | Acc: (87.00%) (34822/39808)
Epoch: 57 | Batch_idx: 320 |  Loss: (0.3642) |  Loss2: (0.0000) | Acc: (87.00%) (35952/41088)
Epoch: 57 | Batch_idx: 330 |  Loss: (0.3648) |  Loss2: (0.0000) | Acc: (87.00%) (37056/42368)
Epoch: 57 | Batch_idx: 340 |  Loss: (0.3644) |  Loss2: (0.0000) | Acc: (87.00%) (38190/43648)
Epoch: 57 | Batch_idx: 350 |  Loss: (0.3644) |  Loss2: (0.0000) | Acc: (87.00%) (39312/44928)
Epoch: 57 | Batch_idx: 360 |  Loss: (0.3635) |  Loss2: (0.0000) | Acc: (87.00%) (40439/46208)
Epoch: 57 | Batch_idx: 370 |  Loss: (0.3630) |  Loss2: (0.0000) | Acc: (87.00%) (41569/47488)
Epoch: 57 | Batch_idx: 380 |  Loss: (0.3636) |  Loss2: (0.0000) | Acc: (87.00%) (42666/48768)
Epoch: 57 | Batch_idx: 390 |  Loss: (0.3631) |  Loss2: (0.0000) | Acc: (87.00%) (43751/50000)
# TEST : Loss: (0.4478) | Acc: (84.00%) (8479/10000)
percent tensor([0.5287, 0.5485, 0.5381, 0.5325, 0.5403, 0.5202, 0.5511, 0.5430, 0.5404,
        0.5428, 0.5367, 0.5424, 0.5323, 0.5523, 0.5357, 0.5308],
       device='cuda:0') torch.Size([16])
percent tensor([0.5116, 0.5129, 0.5066, 0.5036, 0.5069, 0.5040, 0.5132, 0.5089, 0.5130,
        0.5108, 0.5127, 0.5114, 0.5142, 0.5118, 0.5073, 0.5088],
       device='cuda:0') torch.Size([16])
percent tensor([0.5521, 0.5584, 0.5482, 0.5820, 0.5929, 0.5973, 0.5873, 0.6146, 0.5432,
        0.5247, 0.5231, 0.5504, 0.5196, 0.5785, 0.6020, 0.5590],
       device='cuda:0') torch.Size([16])
percent tensor([0.6403, 0.5989, 0.6055, 0.6117, 0.6318, 0.6386, 0.6373, 0.6341, 0.5965,
        0.6024, 0.6017, 0.5953, 0.5919, 0.6150, 0.6454, 0.6311],
       device='cuda:0') torch.Size([16])
percent tensor([0.5143, 0.5303, 0.5117, 0.5129, 0.4958, 0.5018, 0.5212, 0.5042, 0.5304,
        0.5281, 0.5359, 0.5284, 0.5307, 0.5391, 0.5143, 0.5209],
       device='cuda:0') torch.Size([16])
percent tensor([0.6214, 0.6472, 0.6303, 0.6685, 0.6370, 0.6367, 0.6505, 0.6170, 0.6671,
        0.6330, 0.6677, 0.6630, 0.6378, 0.7225, 0.6144, 0.6501],
       device='cuda:0') torch.Size([16])
percent tensor([0.5262, 0.4979, 0.6475, 0.6741, 0.6359, 0.6814, 0.5298, 0.5945, 0.5700,
        0.5479, 0.5273, 0.5779, 0.4963, 0.5819, 0.4891, 0.5879],
       device='cuda:0') torch.Size([16])
percent tensor([0.9984, 0.9985, 0.9991, 0.9991, 0.9994, 0.9981, 0.9987, 0.9991, 0.9979,
        0.9989, 0.9985, 0.9993, 0.9974, 0.9981, 0.9992, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 58 | Batch_idx: 0 |  Loss: (0.3644) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 58 | Batch_idx: 10 |  Loss: (0.3748) |  Loss2: (0.0000) | Acc: (87.00%) (1232/1408)
Epoch: 58 | Batch_idx: 20 |  Loss: (0.3701) |  Loss2: (0.0000) | Acc: (87.00%) (2344/2688)
Epoch: 58 | Batch_idx: 30 |  Loss: (0.3707) |  Loss2: (0.0000) | Acc: (87.00%) (3454/3968)
Epoch: 58 | Batch_idx: 40 |  Loss: (0.3612) |  Loss2: (0.0000) | Acc: (87.00%) (4587/5248)
Epoch: 58 | Batch_idx: 50 |  Loss: (0.3575) |  Loss2: (0.0000) | Acc: (87.00%) (5716/6528)
Epoch: 58 | Batch_idx: 60 |  Loss: (0.3639) |  Loss2: (0.0000) | Acc: (87.00%) (6820/7808)
Epoch: 58 | Batch_idx: 70 |  Loss: (0.3647) |  Loss2: (0.0000) | Acc: (87.00%) (7936/9088)
Epoch: 58 | Batch_idx: 80 |  Loss: (0.3598) |  Loss2: (0.0000) | Acc: (87.00%) (9079/10368)
Epoch: 58 | Batch_idx: 90 |  Loss: (0.3563) |  Loss2: (0.0000) | Acc: (87.00%) (10196/11648)
Epoch: 58 | Batch_idx: 100 |  Loss: (0.3563) |  Loss2: (0.0000) | Acc: (87.00%) (11330/12928)
Epoch: 58 | Batch_idx: 110 |  Loss: (0.3548) |  Loss2: (0.0000) | Acc: (87.00%) (12464/14208)
Epoch: 58 | Batch_idx: 120 |  Loss: (0.3549) |  Loss2: (0.0000) | Acc: (87.00%) (13583/15488)
Epoch: 58 | Batch_idx: 130 |  Loss: (0.3531) |  Loss2: (0.0000) | Acc: (87.00%) (14718/16768)
Epoch: 58 | Batch_idx: 140 |  Loss: (0.3507) |  Loss2: (0.0000) | Acc: (87.00%) (15870/18048)
Epoch: 58 | Batch_idx: 150 |  Loss: (0.3533) |  Loss2: (0.0000) | Acc: (87.00%) (16980/19328)
Epoch: 58 | Batch_idx: 160 |  Loss: (0.3529) |  Loss2: (0.0000) | Acc: (87.00%) (18120/20608)
Epoch: 58 | Batch_idx: 170 |  Loss: (0.3550) |  Loss2: (0.0000) | Acc: (87.00%) (19222/21888)
Epoch: 58 | Batch_idx: 180 |  Loss: (0.3546) |  Loss2: (0.0000) | Acc: (87.00%) (20356/23168)
Epoch: 58 | Batch_idx: 190 |  Loss: (0.3556) |  Loss2: (0.0000) | Acc: (87.00%) (21464/24448)
Epoch: 58 | Batch_idx: 200 |  Loss: (0.3557) |  Loss2: (0.0000) | Acc: (87.00%) (22585/25728)
Epoch: 58 | Batch_idx: 210 |  Loss: (0.3558) |  Loss2: (0.0000) | Acc: (87.00%) (23711/27008)
Epoch: 58 | Batch_idx: 220 |  Loss: (0.3575) |  Loss2: (0.0000) | Acc: (87.00%) (24811/28288)
Epoch: 58 | Batch_idx: 230 |  Loss: (0.3578) |  Loss2: (0.0000) | Acc: (87.00%) (25934/29568)
Epoch: 58 | Batch_idx: 240 |  Loss: (0.3573) |  Loss2: (0.0000) | Acc: (87.00%) (27067/30848)
Epoch: 58 | Batch_idx: 250 |  Loss: (0.3572) |  Loss2: (0.0000) | Acc: (87.00%) (28197/32128)
Epoch: 58 | Batch_idx: 260 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (29313/33408)
Epoch: 58 | Batch_idx: 270 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (30427/34688)
Epoch: 58 | Batch_idx: 280 |  Loss: (0.3564) |  Loss2: (0.0000) | Acc: (87.00%) (31547/35968)
Epoch: 58 | Batch_idx: 290 |  Loss: (0.3576) |  Loss2: (0.0000) | Acc: (87.00%) (32661/37248)
Epoch: 58 | Batch_idx: 300 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (33799/38528)
Epoch: 58 | Batch_idx: 310 |  Loss: (0.3572) |  Loss2: (0.0000) | Acc: (87.00%) (34912/39808)
Epoch: 58 | Batch_idx: 320 |  Loss: (0.3562) |  Loss2: (0.0000) | Acc: (87.00%) (36043/41088)
Epoch: 58 | Batch_idx: 330 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (37160/42368)
Epoch: 58 | Batch_idx: 340 |  Loss: (0.3563) |  Loss2: (0.0000) | Acc: (87.00%) (38291/43648)
Epoch: 58 | Batch_idx: 350 |  Loss: (0.3559) |  Loss2: (0.0000) | Acc: (87.00%) (39417/44928)
Epoch: 58 | Batch_idx: 360 |  Loss: (0.3559) |  Loss2: (0.0000) | Acc: (87.00%) (40544/46208)
Epoch: 58 | Batch_idx: 370 |  Loss: (0.3553) |  Loss2: (0.0000) | Acc: (87.00%) (41672/47488)
Epoch: 58 | Batch_idx: 380 |  Loss: (0.3551) |  Loss2: (0.0000) | Acc: (87.00%) (42817/48768)
Epoch: 58 | Batch_idx: 390 |  Loss: (0.3553) |  Loss2: (0.0000) | Acc: (87.00%) (43894/50000)
# TEST : Loss: (0.4435) | Acc: (85.00%) (8513/10000)
percent tensor([0.5279, 0.5472, 0.5378, 0.5319, 0.5399, 0.5192, 0.5501, 0.5425, 0.5395,
        0.5420, 0.5355, 0.5419, 0.5315, 0.5509, 0.5346, 0.5299],
       device='cuda:0') torch.Size([16])
percent tensor([0.5120, 0.5134, 0.5078, 0.5042, 0.5081, 0.5040, 0.5139, 0.5097, 0.5138,
        0.5114, 0.5131, 0.5125, 0.5147, 0.5121, 0.5075, 0.5090],
       device='cuda:0') torch.Size([16])
percent tensor([0.5456, 0.5527, 0.5467, 0.5804, 0.5924, 0.5927, 0.5823, 0.6139, 0.5393,
        0.5192, 0.5169, 0.5460, 0.5122, 0.5743, 0.5962, 0.5532],
       device='cuda:0') torch.Size([16])
percent tensor([0.6396, 0.5981, 0.6053, 0.6123, 0.6312, 0.6363, 0.6372, 0.6343, 0.5958,
        0.6023, 0.6009, 0.5952, 0.5911, 0.6152, 0.6447, 0.6307],
       device='cuda:0') torch.Size([16])
percent tensor([0.5179, 0.5333, 0.5163, 0.5177, 0.4992, 0.5057, 0.5244, 0.5082, 0.5347,
        0.5304, 0.5388, 0.5335, 0.5340, 0.5434, 0.5182, 0.5247],
       device='cuda:0') torch.Size([16])
percent tensor([0.6259, 0.6493, 0.6318, 0.6687, 0.6379, 0.6375, 0.6523, 0.6171, 0.6694,
        0.6369, 0.6697, 0.6669, 0.6428, 0.7243, 0.6165, 0.6547],
       device='cuda:0') torch.Size([16])
percent tensor([0.5321, 0.5031, 0.6537, 0.6787, 0.6408, 0.6894, 0.5350, 0.5957, 0.5774,
        0.5565, 0.5336, 0.5850, 0.5049, 0.5852, 0.4903, 0.5945],
       device='cuda:0') torch.Size([16])
percent tensor([0.9984, 0.9987, 0.9991, 0.9991, 0.9994, 0.9981, 0.9987, 0.9991, 0.9980,
        0.9990, 0.9987, 0.9993, 0.9976, 0.9983, 0.9993, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 59 | Batch_idx: 0 |  Loss: (0.3244) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 59 | Batch_idx: 10 |  Loss: (0.3386) |  Loss2: (0.0000) | Acc: (87.00%) (1230/1408)
Epoch: 59 | Batch_idx: 20 |  Loss: (0.3531) |  Loss2: (0.0000) | Acc: (87.00%) (2352/2688)
Epoch: 59 | Batch_idx: 30 |  Loss: (0.3424) |  Loss2: (0.0000) | Acc: (88.00%) (3493/3968)
Epoch: 59 | Batch_idx: 40 |  Loss: (0.3431) |  Loss2: (0.0000) | Acc: (88.00%) (4630/5248)
Epoch: 59 | Batch_idx: 50 |  Loss: (0.3487) |  Loss2: (0.0000) | Acc: (87.00%) (5737/6528)
Epoch: 59 | Batch_idx: 60 |  Loss: (0.3457) |  Loss2: (0.0000) | Acc: (87.00%) (6870/7808)
Epoch: 59 | Batch_idx: 70 |  Loss: (0.3445) |  Loss2: (0.0000) | Acc: (88.00%) (8002/9088)
Epoch: 59 | Batch_idx: 80 |  Loss: (0.3416) |  Loss2: (0.0000) | Acc: (88.00%) (9134/10368)
Epoch: 59 | Batch_idx: 90 |  Loss: (0.3425) |  Loss2: (0.0000) | Acc: (87.00%) (10248/11648)
Epoch: 59 | Batch_idx: 100 |  Loss: (0.3443) |  Loss2: (0.0000) | Acc: (88.00%) (11378/12928)
Epoch: 59 | Batch_idx: 110 |  Loss: (0.3464) |  Loss2: (0.0000) | Acc: (87.00%) (12482/14208)
Epoch: 59 | Batch_idx: 120 |  Loss: (0.3445) |  Loss2: (0.0000) | Acc: (87.00%) (13627/15488)
Epoch: 59 | Batch_idx: 130 |  Loss: (0.3465) |  Loss2: (0.0000) | Acc: (87.00%) (14746/16768)
Epoch: 59 | Batch_idx: 140 |  Loss: (0.3463) |  Loss2: (0.0000) | Acc: (87.00%) (15871/18048)
Epoch: 59 | Batch_idx: 150 |  Loss: (0.3484) |  Loss2: (0.0000) | Acc: (87.00%) (16989/19328)
Epoch: 59 | Batch_idx: 160 |  Loss: (0.3499) |  Loss2: (0.0000) | Acc: (87.00%) (18103/20608)
Epoch: 59 | Batch_idx: 170 |  Loss: (0.3528) |  Loss2: (0.0000) | Acc: (87.00%) (19212/21888)
Epoch: 59 | Batch_idx: 180 |  Loss: (0.3515) |  Loss2: (0.0000) | Acc: (87.00%) (20347/23168)
Epoch: 59 | Batch_idx: 190 |  Loss: (0.3513) |  Loss2: (0.0000) | Acc: (87.00%) (21485/24448)
Epoch: 59 | Batch_idx: 200 |  Loss: (0.3497) |  Loss2: (0.0000) | Acc: (87.00%) (22627/25728)
Epoch: 59 | Batch_idx: 210 |  Loss: (0.3499) |  Loss2: (0.0000) | Acc: (87.00%) (23756/27008)
Epoch: 59 | Batch_idx: 220 |  Loss: (0.3495) |  Loss2: (0.0000) | Acc: (87.00%) (24873/28288)
Epoch: 59 | Batch_idx: 230 |  Loss: (0.3487) |  Loss2: (0.0000) | Acc: (87.00%) (26010/29568)
Epoch: 59 | Batch_idx: 240 |  Loss: (0.3481) |  Loss2: (0.0000) | Acc: (87.00%) (27142/30848)
Epoch: 59 | Batch_idx: 250 |  Loss: (0.3494) |  Loss2: (0.0000) | Acc: (87.00%) (28255/32128)
Epoch: 59 | Batch_idx: 260 |  Loss: (0.3496) |  Loss2: (0.0000) | Acc: (87.00%) (29370/33408)
Epoch: 59 | Batch_idx: 270 |  Loss: (0.3486) |  Loss2: (0.0000) | Acc: (87.00%) (30506/34688)
Epoch: 59 | Batch_idx: 280 |  Loss: (0.3487) |  Loss2: (0.0000) | Acc: (87.00%) (31630/35968)
Epoch: 59 | Batch_idx: 290 |  Loss: (0.3486) |  Loss2: (0.0000) | Acc: (87.00%) (32756/37248)
Epoch: 59 | Batch_idx: 300 |  Loss: (0.3490) |  Loss2: (0.0000) | Acc: (87.00%) (33864/38528)
Epoch: 59 | Batch_idx: 310 |  Loss: (0.3492) |  Loss2: (0.0000) | Acc: (87.00%) (34990/39808)
Epoch: 59 | Batch_idx: 320 |  Loss: (0.3493) |  Loss2: (0.0000) | Acc: (87.00%) (36123/41088)
Epoch: 59 | Batch_idx: 330 |  Loss: (0.3501) |  Loss2: (0.0000) | Acc: (87.00%) (37242/42368)
Epoch: 59 | Batch_idx: 340 |  Loss: (0.3496) |  Loss2: (0.0000) | Acc: (87.00%) (38377/43648)
Epoch: 59 | Batch_idx: 350 |  Loss: (0.3491) |  Loss2: (0.0000) | Acc: (87.00%) (39522/44928)
Epoch: 59 | Batch_idx: 360 |  Loss: (0.3491) |  Loss2: (0.0000) | Acc: (87.00%) (40653/46208)
Epoch: 59 | Batch_idx: 370 |  Loss: (0.3491) |  Loss2: (0.0000) | Acc: (87.00%) (41787/47488)
Epoch: 59 | Batch_idx: 380 |  Loss: (0.3494) |  Loss2: (0.0000) | Acc: (88.00%) (42922/48768)
Epoch: 59 | Batch_idx: 390 |  Loss: (0.3490) |  Loss2: (0.0000) | Acc: (88.00%) (44009/50000)
# TEST : Loss: (0.4358) | Acc: (85.00%) (8532/10000)
percent tensor([0.5283, 0.5472, 0.5387, 0.5320, 0.5406, 0.5192, 0.5505, 0.5430, 0.5398,
        0.5423, 0.5356, 0.5427, 0.5318, 0.5507, 0.5347, 0.5300],
       device='cuda:0') torch.Size([16])
percent tensor([0.5129, 0.5144, 0.5097, 0.5054, 0.5097, 0.5043, 0.5151, 0.5111, 0.5152,
        0.5126, 0.5142, 0.5141, 0.5158, 0.5131, 0.5081, 0.5098],
       device='cuda:0') torch.Size([16])
percent tensor([0.5493, 0.5548, 0.5533, 0.5863, 0.5985, 0.5982, 0.5859, 0.6196, 0.5440,
        0.5225, 0.5208, 0.5510, 0.5147, 0.5766, 0.6000, 0.5575],
       device='cuda:0') torch.Size([16])
percent tensor([0.6406, 0.5975, 0.6066, 0.6138, 0.6319, 0.6362, 0.6378, 0.6352, 0.5956,
        0.6025, 0.6006, 0.5958, 0.5909, 0.6151, 0.6447, 0.6309],
       device='cuda:0') torch.Size([16])
percent tensor([0.5181, 0.5336, 0.5186, 0.5213, 0.5003, 0.5076, 0.5241, 0.5093, 0.5365,
        0.5303, 0.5392, 0.5360, 0.5344, 0.5452, 0.5184, 0.5258],
       device='cuda:0') torch.Size([16])
percent tensor([0.6327, 0.6542, 0.6362, 0.6741, 0.6437, 0.6439, 0.6584, 0.6226, 0.6748,
        0.6431, 0.6751, 0.6739, 0.6484, 0.7307, 0.6227, 0.6623],
       device='cuda:0') torch.Size([16])
percent tensor([0.5286, 0.5016, 0.6570, 0.6825, 0.6447, 0.6881, 0.5343, 0.5988, 0.5766,
        0.5558, 0.5310, 0.5880, 0.5038, 0.5834, 0.4885, 0.5931],
       device='cuda:0') torch.Size([16])
percent tensor([0.9986, 0.9987, 0.9992, 0.9992, 0.9995, 0.9982, 0.9989, 0.9992, 0.9982,
        0.9991, 0.9988, 0.9994, 0.9977, 0.9984, 0.9993, 0.9992],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 60 | Batch_idx: 0 |  Loss: (0.3734) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 60 | Batch_idx: 10 |  Loss: (0.3691) |  Loss2: (0.0000) | Acc: (87.00%) (1229/1408)
Epoch: 60 | Batch_idx: 20 |  Loss: (0.3442) |  Loss2: (0.0000) | Acc: (87.00%) (2361/2688)
Epoch: 60 | Batch_idx: 30 |  Loss: (0.3399) |  Loss2: (0.0000) | Acc: (88.00%) (3501/3968)
Epoch: 60 | Batch_idx: 40 |  Loss: (0.3403) |  Loss2: (0.0000) | Acc: (88.00%) (4621/5248)
Epoch: 60 | Batch_idx: 50 |  Loss: (0.3346) |  Loss2: (0.0000) | Acc: (88.00%) (5763/6528)
Epoch: 60 | Batch_idx: 60 |  Loss: (0.3359) |  Loss2: (0.0000) | Acc: (88.00%) (6881/7808)
Epoch: 60 | Batch_idx: 70 |  Loss: (0.3398) |  Loss2: (0.0000) | Acc: (87.00%) (7990/9088)
Epoch: 60 | Batch_idx: 80 |  Loss: (0.3408) |  Loss2: (0.0000) | Acc: (87.00%) (9121/10368)
Epoch: 60 | Batch_idx: 90 |  Loss: (0.3448) |  Loss2: (0.0000) | Acc: (87.00%) (10222/11648)
Epoch: 60 | Batch_idx: 100 |  Loss: (0.3459) |  Loss2: (0.0000) | Acc: (87.00%) (11352/12928)
Epoch: 60 | Batch_idx: 110 |  Loss: (0.3443) |  Loss2: (0.0000) | Acc: (87.00%) (12471/14208)
Epoch: 60 | Batch_idx: 120 |  Loss: (0.3431) |  Loss2: (0.0000) | Acc: (87.00%) (13607/15488)
Epoch: 60 | Batch_idx: 130 |  Loss: (0.3460) |  Loss2: (0.0000) | Acc: (87.00%) (14728/16768)
Epoch: 60 | Batch_idx: 140 |  Loss: (0.3462) |  Loss2: (0.0000) | Acc: (87.00%) (15846/18048)
Epoch: 60 | Batch_idx: 150 |  Loss: (0.3474) |  Loss2: (0.0000) | Acc: (87.00%) (16955/19328)
Epoch: 60 | Batch_idx: 160 |  Loss: (0.3491) |  Loss2: (0.0000) | Acc: (87.00%) (18051/20608)
Epoch: 60 | Batch_idx: 170 |  Loss: (0.3483) |  Loss2: (0.0000) | Acc: (87.00%) (19178/21888)
Epoch: 60 | Batch_idx: 180 |  Loss: (0.3496) |  Loss2: (0.0000) | Acc: (87.00%) (20303/23168)
Epoch: 60 | Batch_idx: 190 |  Loss: (0.3495) |  Loss2: (0.0000) | Acc: (87.00%) (21443/24448)
Epoch: 60 | Batch_idx: 200 |  Loss: (0.3495) |  Loss2: (0.0000) | Acc: (87.00%) (22577/25728)
Epoch: 60 | Batch_idx: 210 |  Loss: (0.3471) |  Loss2: (0.0000) | Acc: (87.00%) (23720/27008)
Epoch: 60 | Batch_idx: 220 |  Loss: (0.3489) |  Loss2: (0.0000) | Acc: (87.00%) (24829/28288)
Epoch: 60 | Batch_idx: 230 |  Loss: (0.3495) |  Loss2: (0.0000) | Acc: (87.00%) (25941/29568)
Epoch: 60 | Batch_idx: 240 |  Loss: (0.3495) |  Loss2: (0.0000) | Acc: (87.00%) (27065/30848)
Epoch: 60 | Batch_idx: 250 |  Loss: (0.3499) |  Loss2: (0.0000) | Acc: (87.00%) (28194/32128)
Epoch: 60 | Batch_idx: 260 |  Loss: (0.3515) |  Loss2: (0.0000) | Acc: (87.00%) (29299/33408)
Epoch: 60 | Batch_idx: 270 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (30403/34688)
Epoch: 60 | Batch_idx: 280 |  Loss: (0.3532) |  Loss2: (0.0000) | Acc: (87.00%) (31532/35968)
Epoch: 60 | Batch_idx: 290 |  Loss: (0.3535) |  Loss2: (0.0000) | Acc: (87.00%) (32646/37248)
Epoch: 60 | Batch_idx: 300 |  Loss: (0.3537) |  Loss2: (0.0000) | Acc: (87.00%) (33755/38528)
Epoch: 60 | Batch_idx: 310 |  Loss: (0.3545) |  Loss2: (0.0000) | Acc: (87.00%) (34865/39808)
Epoch: 60 | Batch_idx: 320 |  Loss: (0.3549) |  Loss2: (0.0000) | Acc: (87.00%) (35983/41088)
Epoch: 60 | Batch_idx: 330 |  Loss: (0.3554) |  Loss2: (0.0000) | Acc: (87.00%) (37109/42368)
Epoch: 60 | Batch_idx: 340 |  Loss: (0.3559) |  Loss2: (0.0000) | Acc: (87.00%) (38228/43648)
Epoch: 60 | Batch_idx: 350 |  Loss: (0.3564) |  Loss2: (0.0000) | Acc: (87.00%) (39345/44928)
Epoch: 60 | Batch_idx: 360 |  Loss: (0.3555) |  Loss2: (0.0000) | Acc: (87.00%) (40474/46208)
Epoch: 60 | Batch_idx: 370 |  Loss: (0.3562) |  Loss2: (0.0000) | Acc: (87.00%) (41586/47488)
Epoch: 60 | Batch_idx: 380 |  Loss: (0.3560) |  Loss2: (0.0000) | Acc: (87.00%) (42711/48768)
Epoch: 60 | Batch_idx: 390 |  Loss: (0.3561) |  Loss2: (0.0000) | Acc: (87.00%) (43790/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_060.pth.tar'
# TEST : Loss: (0.4534) | Acc: (84.00%) (8465/10000)
percent tensor([0.5278, 0.5482, 0.5362, 0.5312, 0.5386, 0.5187, 0.5499, 0.5428, 0.5392,
        0.5417, 0.5355, 0.5399, 0.5314, 0.5518, 0.5350, 0.5300],
       device='cuda:0') torch.Size([16])
percent tensor([0.5127, 0.5144, 0.5091, 0.5053, 0.5096, 0.5044, 0.5145, 0.5107, 0.5151,
        0.5125, 0.5144, 0.5133, 0.5155, 0.5116, 0.5079, 0.5097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5501, 0.5628, 0.5381, 0.5743, 0.5867, 0.6002, 0.5843, 0.6122, 0.5447,
        0.5178, 0.5254, 0.5363, 0.5110, 0.5891, 0.6060, 0.5594],
       device='cuda:0') torch.Size([16])
percent tensor([0.6417, 0.5973, 0.6135, 0.6138, 0.6335, 0.6339, 0.6386, 0.6301, 0.5935,
        0.5987, 0.6023, 0.6013, 0.5872, 0.6137, 0.6468, 0.6302],
       device='cuda:0') torch.Size([16])
percent tensor([0.5196, 0.5291, 0.5209, 0.5240, 0.4999, 0.5159, 0.5243, 0.5123, 0.5380,
        0.5301, 0.5384, 0.5354, 0.5366, 0.5414, 0.5193, 0.5260],
       device='cuda:0') torch.Size([16])
percent tensor([0.6289, 0.6312, 0.6518, 0.6819, 0.6434, 0.6531, 0.6624, 0.6272, 0.6701,
        0.6290, 0.6665, 0.6868, 0.6383, 0.7054, 0.6179, 0.6568],
       device='cuda:0') torch.Size([16])
percent tensor([0.5182, 0.4735, 0.6394, 0.6780, 0.6375, 0.6770, 0.5378, 0.5950, 0.5685,
        0.5330, 0.5319, 0.5990, 0.4768, 0.5500, 0.4735, 0.5805],
       device='cuda:0') torch.Size([16])
percent tensor([0.9986, 0.9988, 0.9988, 0.9988, 0.9994, 0.9967, 0.9987, 0.9993, 0.9987,
        0.9992, 0.9991, 0.9991, 0.9977, 0.9985, 0.9994, 0.9991],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(170.6484, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(801.0145, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(795.3135, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1531.0974, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(497.7559, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2199.9255, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4281.9492, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1421.7002, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6115.1943, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12013.3750, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4011.7812, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16904.8711, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 61 | Batch_idx: 0 |  Loss: (0.3583) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 61 | Batch_idx: 10 |  Loss: (0.3255) |  Loss2: (0.0000) | Acc: (88.00%) (1251/1408)
Epoch: 61 | Batch_idx: 20 |  Loss: (0.3334) |  Loss2: (0.0000) | Acc: (88.00%) (2386/2688)
Epoch: 61 | Batch_idx: 30 |  Loss: (0.3335) |  Loss2: (0.0000) | Acc: (88.00%) (3521/3968)
Epoch: 61 | Batch_idx: 40 |  Loss: (0.3355) |  Loss2: (0.0000) | Acc: (88.00%) (4650/5248)
Epoch: 61 | Batch_idx: 50 |  Loss: (0.3371) |  Loss2: (0.0000) | Acc: (88.00%) (5778/6528)
Epoch: 61 | Batch_idx: 60 |  Loss: (0.3376) |  Loss2: (0.0000) | Acc: (88.00%) (6900/7808)
Epoch: 61 | Batch_idx: 70 |  Loss: (0.3371) |  Loss2: (0.0000) | Acc: (88.00%) (8031/9088)
Epoch: 61 | Batch_idx: 80 |  Loss: (0.3348) |  Loss2: (0.0000) | Acc: (88.00%) (9173/10368)
Epoch: 61 | Batch_idx: 90 |  Loss: (0.3380) |  Loss2: (0.0000) | Acc: (88.00%) (10289/11648)
Epoch: 61 | Batch_idx: 100 |  Loss: (0.3373) |  Loss2: (0.0000) | Acc: (88.00%) (11418/12928)
Epoch: 61 | Batch_idx: 110 |  Loss: (0.3370) |  Loss2: (0.0000) | Acc: (88.00%) (12558/14208)
Epoch: 61 | Batch_idx: 120 |  Loss: (0.3374) |  Loss2: (0.0000) | Acc: (88.00%) (13682/15488)
Epoch: 61 | Batch_idx: 130 |  Loss: (0.3370) |  Loss2: (0.0000) | Acc: (88.00%) (14812/16768)
Epoch: 61 | Batch_idx: 140 |  Loss: (0.3370) |  Loss2: (0.0000) | Acc: (88.00%) (15946/18048)
Epoch: 61 | Batch_idx: 150 |  Loss: (0.3381) |  Loss2: (0.0000) | Acc: (88.00%) (17072/19328)
Epoch: 61 | Batch_idx: 160 |  Loss: (0.3384) |  Loss2: (0.0000) | Acc: (88.00%) (18204/20608)
Epoch: 61 | Batch_idx: 170 |  Loss: (0.3398) |  Loss2: (0.0000) | Acc: (88.00%) (19317/21888)
Epoch: 61 | Batch_idx: 180 |  Loss: (0.3399) |  Loss2: (0.0000) | Acc: (88.00%) (20435/23168)
Epoch: 61 | Batch_idx: 190 |  Loss: (0.3389) |  Loss2: (0.0000) | Acc: (88.00%) (21555/24448)
Epoch: 61 | Batch_idx: 200 |  Loss: (0.3385) |  Loss2: (0.0000) | Acc: (88.00%) (22687/25728)
Epoch: 61 | Batch_idx: 210 |  Loss: (0.3372) |  Loss2: (0.0000) | Acc: (88.00%) (23835/27008)
Epoch: 61 | Batch_idx: 220 |  Loss: (0.3387) |  Loss2: (0.0000) | Acc: (88.00%) (24949/28288)
Epoch: 61 | Batch_idx: 230 |  Loss: (0.3367) |  Loss2: (0.0000) | Acc: (88.00%) (26101/29568)
Epoch: 61 | Batch_idx: 240 |  Loss: (0.3380) |  Loss2: (0.0000) | Acc: (88.00%) (27220/30848)
Epoch: 61 | Batch_idx: 250 |  Loss: (0.3385) |  Loss2: (0.0000) | Acc: (88.00%) (28347/32128)
Epoch: 61 | Batch_idx: 260 |  Loss: (0.3384) |  Loss2: (0.0000) | Acc: (88.00%) (29476/33408)
Epoch: 61 | Batch_idx: 270 |  Loss: (0.3420) |  Loss2: (0.0000) | Acc: (88.00%) (30560/34688)
Epoch: 61 | Batch_idx: 280 |  Loss: (0.3426) |  Loss2: (0.0000) | Acc: (88.00%) (31678/35968)
Epoch: 61 | Batch_idx: 290 |  Loss: (0.3441) |  Loss2: (0.0000) | Acc: (87.00%) (32776/37248)
Epoch: 61 | Batch_idx: 300 |  Loss: (0.3436) |  Loss2: (0.0000) | Acc: (88.00%) (33913/38528)
Epoch: 61 | Batch_idx: 310 |  Loss: (0.3440) |  Loss2: (0.0000) | Acc: (88.00%) (35034/39808)
Epoch: 61 | Batch_idx: 320 |  Loss: (0.3443) |  Loss2: (0.0000) | Acc: (88.00%) (36161/41088)
Epoch: 61 | Batch_idx: 330 |  Loss: (0.3456) |  Loss2: (0.0000) | Acc: (87.00%) (37267/42368)
Epoch: 61 | Batch_idx: 340 |  Loss: (0.3458) |  Loss2: (0.0000) | Acc: (87.00%) (38384/43648)
Epoch: 61 | Batch_idx: 350 |  Loss: (0.3458) |  Loss2: (0.0000) | Acc: (87.00%) (39515/44928)
Epoch: 61 | Batch_idx: 360 |  Loss: (0.3468) |  Loss2: (0.0000) | Acc: (87.00%) (40622/46208)
Epoch: 61 | Batch_idx: 370 |  Loss: (0.3470) |  Loss2: (0.0000) | Acc: (87.00%) (41757/47488)
Epoch: 61 | Batch_idx: 380 |  Loss: (0.3474) |  Loss2: (0.0000) | Acc: (87.00%) (42879/48768)
Epoch: 61 | Batch_idx: 390 |  Loss: (0.3482) |  Loss2: (0.0000) | Acc: (87.00%) (43943/50000)
# TEST : Loss: (0.4407) | Acc: (85.00%) (8504/10000)
percent tensor([0.5283, 0.5479, 0.5369, 0.5314, 0.5396, 0.5192, 0.5504, 0.5427, 0.5395,
        0.5416, 0.5361, 0.5412, 0.5319, 0.5512, 0.5350, 0.5302],
       device='cuda:0') torch.Size([16])
percent tensor([0.5130, 0.5147, 0.5077, 0.5056, 0.5086, 0.5042, 0.5144, 0.5111, 0.5150,
        0.5127, 0.5143, 0.5125, 0.5160, 0.5127, 0.5079, 0.5101],
       device='cuda:0') torch.Size([16])
percent tensor([0.5500, 0.5581, 0.5509, 0.5856, 0.6052, 0.6038, 0.5891, 0.6187, 0.5549,
        0.5203, 0.5259, 0.5483, 0.5122, 0.5914, 0.6061, 0.5604],
       device='cuda:0') torch.Size([16])
percent tensor([0.6443, 0.5961, 0.6174, 0.6209, 0.6346, 0.6337, 0.6366, 0.6360, 0.5976,
        0.6019, 0.6040, 0.5981, 0.5928, 0.6123, 0.6438, 0.6344],
       device='cuda:0') torch.Size([16])
percent tensor([0.5156, 0.5285, 0.5158, 0.5201, 0.5001, 0.5133, 0.5250, 0.5093, 0.5371,
        0.5272, 0.5372, 0.5362, 0.5333, 0.5427, 0.5165, 0.5223],
       device='cuda:0') torch.Size([16])
percent tensor([0.6214, 0.6394, 0.6242, 0.6756, 0.6413, 0.6487, 0.6521, 0.6153, 0.6699,
        0.6231, 0.6698, 0.6736, 0.6414, 0.7080, 0.6157, 0.6577],
       device='cuda:0') torch.Size([16])
percent tensor([0.5248, 0.4997, 0.6337, 0.6766, 0.6464, 0.6815, 0.5398, 0.5843, 0.5683,
        0.5373, 0.5427, 0.5911, 0.4905, 0.5640, 0.4919, 0.5987],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9988, 0.9994, 0.9988, 0.9993, 0.9977, 0.9990, 0.9994, 0.9989,
        0.9992, 0.9993, 0.9995, 0.9980, 0.9988, 0.9991, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 62 | Batch_idx: 0 |  Loss: (0.4057) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 62 | Batch_idx: 10 |  Loss: (0.3401) |  Loss2: (0.0000) | Acc: (88.00%) (1240/1408)
Epoch: 62 | Batch_idx: 20 |  Loss: (0.3340) |  Loss2: (0.0000) | Acc: (88.00%) (2390/2688)
Epoch: 62 | Batch_idx: 30 |  Loss: (0.3428) |  Loss2: (0.0000) | Acc: (88.00%) (3500/3968)
Epoch: 62 | Batch_idx: 40 |  Loss: (0.3385) |  Loss2: (0.0000) | Acc: (88.00%) (4635/5248)
Epoch: 62 | Batch_idx: 50 |  Loss: (0.3375) |  Loss2: (0.0000) | Acc: (88.00%) (5768/6528)
Epoch: 62 | Batch_idx: 60 |  Loss: (0.3415) |  Loss2: (0.0000) | Acc: (88.00%) (6873/7808)
Epoch: 62 | Batch_idx: 70 |  Loss: (0.3398) |  Loss2: (0.0000) | Acc: (88.00%) (8007/9088)
Epoch: 62 | Batch_idx: 80 |  Loss: (0.3393) |  Loss2: (0.0000) | Acc: (88.00%) (9135/10368)
Epoch: 62 | Batch_idx: 90 |  Loss: (0.3385) |  Loss2: (0.0000) | Acc: (88.00%) (10277/11648)
Epoch: 62 | Batch_idx: 100 |  Loss: (0.3390) |  Loss2: (0.0000) | Acc: (88.00%) (11406/12928)
Epoch: 62 | Batch_idx: 110 |  Loss: (0.3421) |  Loss2: (0.0000) | Acc: (88.00%) (12513/14208)
Epoch: 62 | Batch_idx: 120 |  Loss: (0.3414) |  Loss2: (0.0000) | Acc: (88.00%) (13645/15488)
Epoch: 62 | Batch_idx: 130 |  Loss: (0.3405) |  Loss2: (0.0000) | Acc: (88.00%) (14793/16768)
Epoch: 62 | Batch_idx: 140 |  Loss: (0.3392) |  Loss2: (0.0000) | Acc: (88.00%) (15931/18048)
Epoch: 62 | Batch_idx: 150 |  Loss: (0.3388) |  Loss2: (0.0000) | Acc: (88.00%) (17065/19328)
Epoch: 62 | Batch_idx: 160 |  Loss: (0.3385) |  Loss2: (0.0000) | Acc: (88.00%) (18195/20608)
Epoch: 62 | Batch_idx: 170 |  Loss: (0.3388) |  Loss2: (0.0000) | Acc: (88.00%) (19319/21888)
Epoch: 62 | Batch_idx: 180 |  Loss: (0.3399) |  Loss2: (0.0000) | Acc: (88.00%) (20447/23168)
Epoch: 62 | Batch_idx: 190 |  Loss: (0.3386) |  Loss2: (0.0000) | Acc: (88.00%) (21586/24448)
Epoch: 62 | Batch_idx: 200 |  Loss: (0.3371) |  Loss2: (0.0000) | Acc: (88.00%) (22738/25728)
Epoch: 62 | Batch_idx: 210 |  Loss: (0.3364) |  Loss2: (0.0000) | Acc: (88.00%) (23874/27008)
Epoch: 62 | Batch_idx: 220 |  Loss: (0.3365) |  Loss2: (0.0000) | Acc: (88.00%) (25007/28288)
Epoch: 62 | Batch_idx: 230 |  Loss: (0.3379) |  Loss2: (0.0000) | Acc: (88.00%) (26123/29568)
Epoch: 62 | Batch_idx: 240 |  Loss: (0.3361) |  Loss2: (0.0000) | Acc: (88.00%) (27272/30848)
Epoch: 62 | Batch_idx: 250 |  Loss: (0.3357) |  Loss2: (0.0000) | Acc: (88.00%) (28414/32128)
Epoch: 62 | Batch_idx: 260 |  Loss: (0.3362) |  Loss2: (0.0000) | Acc: (88.00%) (29548/33408)
Epoch: 62 | Batch_idx: 270 |  Loss: (0.3364) |  Loss2: (0.0000) | Acc: (88.00%) (30673/34688)
Epoch: 62 | Batch_idx: 280 |  Loss: (0.3371) |  Loss2: (0.0000) | Acc: (88.00%) (31795/35968)
Epoch: 62 | Batch_idx: 290 |  Loss: (0.3366) |  Loss2: (0.0000) | Acc: (88.00%) (32933/37248)
Epoch: 62 | Batch_idx: 300 |  Loss: (0.3368) |  Loss2: (0.0000) | Acc: (88.00%) (34060/38528)
Epoch: 62 | Batch_idx: 310 |  Loss: (0.3361) |  Loss2: (0.0000) | Acc: (88.00%) (35191/39808)
Epoch: 62 | Batch_idx: 320 |  Loss: (0.3362) |  Loss2: (0.0000) | Acc: (88.00%) (36327/41088)
Epoch: 62 | Batch_idx: 330 |  Loss: (0.3355) |  Loss2: (0.0000) | Acc: (88.00%) (37462/42368)
Epoch: 62 | Batch_idx: 340 |  Loss: (0.3349) |  Loss2: (0.0000) | Acc: (88.00%) (38609/43648)
Epoch: 62 | Batch_idx: 350 |  Loss: (0.3342) |  Loss2: (0.0000) | Acc: (88.00%) (39759/44928)
Epoch: 62 | Batch_idx: 360 |  Loss: (0.3340) |  Loss2: (0.0000) | Acc: (88.00%) (40885/46208)
Epoch: 62 | Batch_idx: 370 |  Loss: (0.3338) |  Loss2: (0.0000) | Acc: (88.00%) (42015/47488)
Epoch: 62 | Batch_idx: 380 |  Loss: (0.3352) |  Loss2: (0.0000) | Acc: (88.00%) (43119/48768)
Epoch: 62 | Batch_idx: 390 |  Loss: (0.3355) |  Loss2: (0.0000) | Acc: (88.00%) (44196/50000)
# TEST : Loss: (0.4457) | Acc: (85.00%) (8514/10000)
percent tensor([0.5274, 0.5479, 0.5355, 0.5310, 0.5377, 0.5187, 0.5496, 0.5431, 0.5386,
        0.5411, 0.5352, 0.5392, 0.5311, 0.5518, 0.5349, 0.5300],
       device='cuda:0') torch.Size([16])
percent tensor([0.5136, 0.5163, 0.5087, 0.5058, 0.5092, 0.5046, 0.5159, 0.5121, 0.5154,
        0.5136, 0.5154, 0.5131, 0.5169, 0.5138, 0.5092, 0.5112],
       device='cuda:0') torch.Size([16])
percent tensor([0.5502, 0.5564, 0.5475, 0.5760, 0.5947, 0.6033, 0.5823, 0.6151, 0.5489,
        0.5195, 0.5232, 0.5496, 0.5126, 0.5813, 0.6058, 0.5540],
       device='cuda:0') torch.Size([16])
percent tensor([0.6371, 0.5920, 0.6127, 0.6180, 0.6321, 0.6309, 0.6339, 0.6333, 0.5908,
        0.5979, 0.5957, 0.5952, 0.5856, 0.6111, 0.6421, 0.6280],
       device='cuda:0') torch.Size([16])
percent tensor([0.5188, 0.5323, 0.5165, 0.5214, 0.4973, 0.5174, 0.5253, 0.5088, 0.5391,
        0.5292, 0.5396, 0.5333, 0.5326, 0.5465, 0.5201, 0.5280],
       device='cuda:0') torch.Size([16])
percent tensor([0.6179, 0.6475, 0.6264, 0.6726, 0.6365, 0.6508, 0.6479, 0.6158, 0.6646,
        0.6318, 0.6684, 0.6707, 0.6438, 0.7201, 0.6234, 0.6569],
       device='cuda:0') torch.Size([16])
percent tensor([0.5137, 0.4967, 0.6396, 0.6630, 0.6441, 0.6809, 0.5141, 0.5793, 0.5643,
        0.5464, 0.5395, 0.6036, 0.5140, 0.5712, 0.4854, 0.5770],
       device='cuda:0') torch.Size([16])
percent tensor([0.9984, 0.9989, 0.9991, 0.9988, 0.9992, 0.9971, 0.9985, 0.9990, 0.9985,
        0.9988, 0.9987, 0.9995, 0.9983, 0.9985, 0.9993, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 63 | Batch_idx: 0 |  Loss: (0.2630) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 63 | Batch_idx: 10 |  Loss: (0.3013) |  Loss2: (0.0000) | Acc: (89.00%) (1257/1408)
Epoch: 63 | Batch_idx: 20 |  Loss: (0.3166) |  Loss2: (0.0000) | Acc: (88.00%) (2391/2688)
Epoch: 63 | Batch_idx: 30 |  Loss: (0.3122) |  Loss2: (0.0000) | Acc: (89.00%) (3539/3968)
Epoch: 63 | Batch_idx: 40 |  Loss: (0.3063) |  Loss2: (0.0000) | Acc: (89.00%) (4687/5248)
Epoch: 63 | Batch_idx: 50 |  Loss: (0.3095) |  Loss2: (0.0000) | Acc: (89.00%) (5833/6528)
Epoch: 63 | Batch_idx: 60 |  Loss: (0.3122) |  Loss2: (0.0000) | Acc: (89.00%) (6965/7808)
Epoch: 63 | Batch_idx: 70 |  Loss: (0.3170) |  Loss2: (0.0000) | Acc: (89.00%) (8098/9088)
Epoch: 63 | Batch_idx: 80 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (89.00%) (9246/10368)
Epoch: 63 | Batch_idx: 90 |  Loss: (0.3135) |  Loss2: (0.0000) | Acc: (89.00%) (10389/11648)
Epoch: 63 | Batch_idx: 100 |  Loss: (0.3142) |  Loss2: (0.0000) | Acc: (89.00%) (11528/12928)
Epoch: 63 | Batch_idx: 110 |  Loss: (0.3165) |  Loss2: (0.0000) | Acc: (89.00%) (12658/14208)
Epoch: 63 | Batch_idx: 120 |  Loss: (0.3163) |  Loss2: (0.0000) | Acc: (89.00%) (13801/15488)
Epoch: 63 | Batch_idx: 130 |  Loss: (0.3187) |  Loss2: (0.0000) | Acc: (88.00%) (14921/16768)
Epoch: 63 | Batch_idx: 140 |  Loss: (0.3198) |  Loss2: (0.0000) | Acc: (88.00%) (16050/18048)
Epoch: 63 | Batch_idx: 150 |  Loss: (0.3186) |  Loss2: (0.0000) | Acc: (89.00%) (17202/19328)
Epoch: 63 | Batch_idx: 160 |  Loss: (0.3189) |  Loss2: (0.0000) | Acc: (89.00%) (18343/20608)
Epoch: 63 | Batch_idx: 170 |  Loss: (0.3230) |  Loss2: (0.0000) | Acc: (88.00%) (19448/21888)
Epoch: 63 | Batch_idx: 180 |  Loss: (0.3222) |  Loss2: (0.0000) | Acc: (88.00%) (20593/23168)
Epoch: 63 | Batch_idx: 190 |  Loss: (0.3230) |  Loss2: (0.0000) | Acc: (88.00%) (21724/24448)
Epoch: 63 | Batch_idx: 200 |  Loss: (0.3242) |  Loss2: (0.0000) | Acc: (88.00%) (22856/25728)
Epoch: 63 | Batch_idx: 210 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (88.00%) (23995/27008)
Epoch: 63 | Batch_idx: 220 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (88.00%) (25130/28288)
Epoch: 63 | Batch_idx: 230 |  Loss: (0.3255) |  Loss2: (0.0000) | Acc: (88.00%) (26238/29568)
Epoch: 63 | Batch_idx: 240 |  Loss: (0.3263) |  Loss2: (0.0000) | Acc: (88.00%) (27364/30848)
Epoch: 63 | Batch_idx: 250 |  Loss: (0.3258) |  Loss2: (0.0000) | Acc: (88.00%) (28496/32128)
Epoch: 63 | Batch_idx: 260 |  Loss: (0.3251) |  Loss2: (0.0000) | Acc: (88.00%) (29650/33408)
Epoch: 63 | Batch_idx: 270 |  Loss: (0.3241) |  Loss2: (0.0000) | Acc: (88.00%) (30796/34688)
Epoch: 63 | Batch_idx: 280 |  Loss: (0.3248) |  Loss2: (0.0000) | Acc: (88.00%) (31922/35968)
Epoch: 63 | Batch_idx: 290 |  Loss: (0.3251) |  Loss2: (0.0000) | Acc: (88.00%) (33066/37248)
Epoch: 63 | Batch_idx: 300 |  Loss: (0.3247) |  Loss2: (0.0000) | Acc: (88.00%) (34213/38528)
Epoch: 63 | Batch_idx: 310 |  Loss: (0.3240) |  Loss2: (0.0000) | Acc: (88.00%) (35356/39808)
Epoch: 63 | Batch_idx: 320 |  Loss: (0.3248) |  Loss2: (0.0000) | Acc: (88.00%) (36473/41088)
Epoch: 63 | Batch_idx: 330 |  Loss: (0.3253) |  Loss2: (0.0000) | Acc: (88.00%) (37599/42368)
Epoch: 63 | Batch_idx: 340 |  Loss: (0.3249) |  Loss2: (0.0000) | Acc: (88.00%) (38743/43648)
Epoch: 63 | Batch_idx: 350 |  Loss: (0.3259) |  Loss2: (0.0000) | Acc: (88.00%) (39863/44928)
Epoch: 63 | Batch_idx: 360 |  Loss: (0.3261) |  Loss2: (0.0000) | Acc: (88.00%) (40995/46208)
Epoch: 63 | Batch_idx: 370 |  Loss: (0.3265) |  Loss2: (0.0000) | Acc: (88.00%) (42120/47488)
Epoch: 63 | Batch_idx: 380 |  Loss: (0.3275) |  Loss2: (0.0000) | Acc: (88.00%) (43242/48768)
Epoch: 63 | Batch_idx: 390 |  Loss: (0.3269) |  Loss2: (0.0000) | Acc: (88.00%) (44342/50000)
# TEST : Loss: (0.4591) | Acc: (84.00%) (8490/10000)
percent tensor([0.5271, 0.5486, 0.5342, 0.5301, 0.5369, 0.5185, 0.5497, 0.5426, 0.5384,
        0.5409, 0.5353, 0.5381, 0.5307, 0.5527, 0.5350, 0.5296],
       device='cuda:0') torch.Size([16])
percent tensor([0.5123, 0.5151, 0.5071, 0.5047, 0.5082, 0.5036, 0.5145, 0.5105, 0.5140,
        0.5124, 0.5140, 0.5121, 0.5155, 0.5124, 0.5082, 0.5092],
       device='cuda:0') torch.Size([16])
percent tensor([0.5564, 0.5597, 0.5598, 0.5893, 0.6054, 0.6171, 0.5877, 0.6203, 0.5511,
        0.5201, 0.5235, 0.5521, 0.5126, 0.5917, 0.6161, 0.5648],
       device='cuda:0') torch.Size([16])
percent tensor([0.6410, 0.5955, 0.6210, 0.6163, 0.6379, 0.6360, 0.6392, 0.6367, 0.6006,
        0.6018, 0.6024, 0.6019, 0.5893, 0.6161, 0.6476, 0.6306],
       device='cuda:0') torch.Size([16])
percent tensor([0.5181, 0.5304, 0.5153, 0.5242, 0.4985, 0.5145, 0.5238, 0.5086, 0.5368,
        0.5314, 0.5404, 0.5355, 0.5342, 0.5448, 0.5177, 0.5268],
       device='cuda:0') torch.Size([16])
percent tensor([0.6224, 0.6439, 0.6340, 0.6745, 0.6418, 0.6472, 0.6534, 0.6174, 0.6752,
        0.6295, 0.6770, 0.6762, 0.6446, 0.7305, 0.6129, 0.6536],
       device='cuda:0') torch.Size([16])
percent tensor([0.5056, 0.5181, 0.6351, 0.6682, 0.6363, 0.6717, 0.5400, 0.5867, 0.5873,
        0.5391, 0.5559, 0.6065, 0.5160, 0.5994, 0.4661, 0.5735],
       device='cuda:0') torch.Size([16])
percent tensor([0.9986, 0.9986, 0.9990, 0.9987, 0.9991, 0.9967, 0.9985, 0.9994, 0.9985,
        0.9990, 0.9991, 0.9995, 0.9982, 0.9983, 0.9994, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 64 | Batch_idx: 0 |  Loss: (0.2452) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 64 | Batch_idx: 10 |  Loss: (0.3436) |  Loss2: (0.0000) | Acc: (89.00%) (1257/1408)
Epoch: 64 | Batch_idx: 20 |  Loss: (0.3236) |  Loss2: (0.0000) | Acc: (89.00%) (2398/2688)
Epoch: 64 | Batch_idx: 30 |  Loss: (0.3143) |  Loss2: (0.0000) | Acc: (89.00%) (3547/3968)
Epoch: 64 | Batch_idx: 40 |  Loss: (0.3158) |  Loss2: (0.0000) | Acc: (89.00%) (4681/5248)
Epoch: 64 | Batch_idx: 50 |  Loss: (0.3102) |  Loss2: (0.0000) | Acc: (89.00%) (5841/6528)
Epoch: 64 | Batch_idx: 60 |  Loss: (0.3062) |  Loss2: (0.0000) | Acc: (89.00%) (7001/7808)
Epoch: 64 | Batch_idx: 70 |  Loss: (0.3031) |  Loss2: (0.0000) | Acc: (89.00%) (8161/9088)
Epoch: 64 | Batch_idx: 80 |  Loss: (0.3055) |  Loss2: (0.0000) | Acc: (89.00%) (9299/10368)
Epoch: 64 | Batch_idx: 90 |  Loss: (0.3065) |  Loss2: (0.0000) | Acc: (89.00%) (10449/11648)
Epoch: 64 | Batch_idx: 100 |  Loss: (0.3058) |  Loss2: (0.0000) | Acc: (89.00%) (11597/12928)
Epoch: 64 | Batch_idx: 110 |  Loss: (0.3077) |  Loss2: (0.0000) | Acc: (89.00%) (12731/14208)
Epoch: 64 | Batch_idx: 120 |  Loss: (0.3110) |  Loss2: (0.0000) | Acc: (89.00%) (13850/15488)
Epoch: 64 | Batch_idx: 130 |  Loss: (0.3094) |  Loss2: (0.0000) | Acc: (89.00%) (15009/16768)
Epoch: 64 | Batch_idx: 140 |  Loss: (0.3095) |  Loss2: (0.0000) | Acc: (89.00%) (16145/18048)
Epoch: 64 | Batch_idx: 150 |  Loss: (0.3114) |  Loss2: (0.0000) | Acc: (89.00%) (17274/19328)
Epoch: 64 | Batch_idx: 160 |  Loss: (0.3124) |  Loss2: (0.0000) | Acc: (89.00%) (18406/20608)
Epoch: 64 | Batch_idx: 170 |  Loss: (0.3118) |  Loss2: (0.0000) | Acc: (89.00%) (19547/21888)
Epoch: 64 | Batch_idx: 180 |  Loss: (0.3109) |  Loss2: (0.0000) | Acc: (89.00%) (20701/23168)
Epoch: 64 | Batch_idx: 190 |  Loss: (0.3095) |  Loss2: (0.0000) | Acc: (89.00%) (21851/24448)
Epoch: 64 | Batch_idx: 200 |  Loss: (0.3105) |  Loss2: (0.0000) | Acc: (89.00%) (22988/25728)
Epoch: 64 | Batch_idx: 210 |  Loss: (0.3110) |  Loss2: (0.0000) | Acc: (89.00%) (24115/27008)
Epoch: 64 | Batch_idx: 220 |  Loss: (0.3122) |  Loss2: (0.0000) | Acc: (89.00%) (25240/28288)
Epoch: 64 | Batch_idx: 230 |  Loss: (0.3131) |  Loss2: (0.0000) | Acc: (89.00%) (26378/29568)
Epoch: 64 | Batch_idx: 240 |  Loss: (0.3142) |  Loss2: (0.0000) | Acc: (89.00%) (27508/30848)
Epoch: 64 | Batch_idx: 250 |  Loss: (0.3154) |  Loss2: (0.0000) | Acc: (89.00%) (28627/32128)
Epoch: 64 | Batch_idx: 260 |  Loss: (0.3168) |  Loss2: (0.0000) | Acc: (89.00%) (29745/33408)
Epoch: 64 | Batch_idx: 270 |  Loss: (0.3165) |  Loss2: (0.0000) | Acc: (89.00%) (30885/34688)
Epoch: 64 | Batch_idx: 280 |  Loss: (0.3175) |  Loss2: (0.0000) | Acc: (89.00%) (32020/35968)
Epoch: 64 | Batch_idx: 290 |  Loss: (0.3175) |  Loss2: (0.0000) | Acc: (89.00%) (33159/37248)
Epoch: 64 | Batch_idx: 300 |  Loss: (0.3163) |  Loss2: (0.0000) | Acc: (89.00%) (34309/38528)
Epoch: 64 | Batch_idx: 310 |  Loss: (0.3168) |  Loss2: (0.0000) | Acc: (89.00%) (35445/39808)
Epoch: 64 | Batch_idx: 320 |  Loss: (0.3175) |  Loss2: (0.0000) | Acc: (89.00%) (36586/41088)
Epoch: 64 | Batch_idx: 330 |  Loss: (0.3185) |  Loss2: (0.0000) | Acc: (88.00%) (37703/42368)
Epoch: 64 | Batch_idx: 340 |  Loss: (0.3182) |  Loss2: (0.0000) | Acc: (88.00%) (38835/43648)
Epoch: 64 | Batch_idx: 350 |  Loss: (0.3182) |  Loss2: (0.0000) | Acc: (88.00%) (39978/44928)
Epoch: 64 | Batch_idx: 360 |  Loss: (0.3175) |  Loss2: (0.0000) | Acc: (89.00%) (41136/46208)
Epoch: 64 | Batch_idx: 370 |  Loss: (0.3188) |  Loss2: (0.0000) | Acc: (88.00%) (42251/47488)
Epoch: 64 | Batch_idx: 380 |  Loss: (0.3187) |  Loss2: (0.0000) | Acc: (88.00%) (43394/48768)
Epoch: 64 | Batch_idx: 390 |  Loss: (0.3185) |  Loss2: (0.0000) | Acc: (88.00%) (44494/50000)
# TEST : Loss: (0.4390) | Acc: (85.00%) (8553/10000)
percent tensor([0.5276, 0.5484, 0.5348, 0.5309, 0.5372, 0.5194, 0.5501, 0.5426, 0.5391,
        0.5413, 0.5359, 0.5388, 0.5314, 0.5531, 0.5351, 0.5299],
       device='cuda:0') torch.Size([16])
percent tensor([0.5130, 0.5157, 0.5087, 0.5079, 0.5093, 0.5047, 0.5150, 0.5122, 0.5139,
        0.5131, 0.5141, 0.5131, 0.5160, 0.5129, 0.5086, 0.5110],
       device='cuda:0') torch.Size([16])
percent tensor([0.5497, 0.5588, 0.5408, 0.5795, 0.5932, 0.6084, 0.5825, 0.6106, 0.5503,
        0.5146, 0.5283, 0.5402, 0.5144, 0.5880, 0.6069, 0.5569],
       device='cuda:0') torch.Size([16])
percent tensor([0.6344, 0.5921, 0.6144, 0.6202, 0.6349, 0.6213, 0.6345, 0.6349, 0.5907,
        0.5972, 0.5935, 0.5948, 0.5860, 0.6109, 0.6384, 0.6258],
       device='cuda:0') torch.Size([16])
percent tensor([0.5223, 0.5344, 0.5196, 0.5239, 0.4997, 0.5230, 0.5277, 0.5099, 0.5405,
        0.5358, 0.5447, 0.5384, 0.5382, 0.5468, 0.5229, 0.5317],
       device='cuda:0') torch.Size([16])
percent tensor([0.6262, 0.6527, 0.6461, 0.6814, 0.6500, 0.6504, 0.6614, 0.6129, 0.6706,
        0.6534, 0.6764, 0.6832, 0.6484, 0.7302, 0.6222, 0.6664],
       device='cuda:0') torch.Size([16])
percent tensor([0.5281, 0.5186, 0.6453, 0.6828, 0.6498, 0.6673, 0.5486, 0.5855, 0.5839,
        0.5790, 0.5531, 0.6144, 0.5201, 0.5927, 0.4808, 0.5924],
       device='cuda:0') torch.Size([16])
percent tensor([0.9982, 0.9989, 0.9988, 0.9992, 0.9993, 0.9978, 0.9992, 0.9993, 0.9984,
        0.9991, 0.9992, 0.9996, 0.9976, 0.9988, 0.9996, 0.9988],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 65 | Batch_idx: 0 |  Loss: (0.1893) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 65 | Batch_idx: 10 |  Loss: (0.3241) |  Loss2: (0.0000) | Acc: (88.00%) (1251/1408)
Epoch: 65 | Batch_idx: 20 |  Loss: (0.3540) |  Loss2: (0.0000) | Acc: (87.00%) (2361/2688)
Epoch: 65 | Batch_idx: 30 |  Loss: (0.3693) |  Loss2: (0.0000) | Acc: (87.00%) (3469/3968)
Epoch: 65 | Batch_idx: 40 |  Loss: (0.3706) |  Loss2: (0.0000) | Acc: (87.00%) (4578/5248)
Epoch: 65 | Batch_idx: 50 |  Loss: (0.3689) |  Loss2: (0.0000) | Acc: (87.00%) (5711/6528)
Epoch: 65 | Batch_idx: 60 |  Loss: (0.3733) |  Loss2: (0.0000) | Acc: (87.00%) (6807/7808)
Epoch: 65 | Batch_idx: 70 |  Loss: (0.3745) |  Loss2: (0.0000) | Acc: (87.00%) (7913/9088)
Epoch: 65 | Batch_idx: 80 |  Loss: (0.3766) |  Loss2: (0.0000) | Acc: (86.00%) (9011/10368)
Epoch: 65 | Batch_idx: 90 |  Loss: (0.3816) |  Loss2: (0.0000) | Acc: (86.00%) (10099/11648)
Epoch: 65 | Batch_idx: 100 |  Loss: (0.3792) |  Loss2: (0.0000) | Acc: (86.00%) (11210/12928)
Epoch: 65 | Batch_idx: 110 |  Loss: (0.3818) |  Loss2: (0.0000) | Acc: (86.00%) (12303/14208)
Epoch: 65 | Batch_idx: 120 |  Loss: (0.3795) |  Loss2: (0.0000) | Acc: (86.00%) (13423/15488)
Epoch: 65 | Batch_idx: 130 |  Loss: (0.3774) |  Loss2: (0.0000) | Acc: (86.00%) (14549/16768)
Epoch: 65 | Batch_idx: 140 |  Loss: (0.3786) |  Loss2: (0.0000) | Acc: (86.00%) (15651/18048)
Epoch: 65 | Batch_idx: 150 |  Loss: (0.3780) |  Loss2: (0.0000) | Acc: (86.00%) (16769/19328)
Epoch: 65 | Batch_idx: 160 |  Loss: (0.3779) |  Loss2: (0.0000) | Acc: (86.00%) (17875/20608)
Epoch: 65 | Batch_idx: 170 |  Loss: (0.3769) |  Loss2: (0.0000) | Acc: (86.00%) (18991/21888)
Epoch: 65 | Batch_idx: 180 |  Loss: (0.3776) |  Loss2: (0.0000) | Acc: (86.00%) (20088/23168)
Epoch: 65 | Batch_idx: 190 |  Loss: (0.3752) |  Loss2: (0.0000) | Acc: (86.00%) (21216/24448)
Epoch: 65 | Batch_idx: 200 |  Loss: (0.3747) |  Loss2: (0.0000) | Acc: (86.00%) (22334/25728)
Epoch: 65 | Batch_idx: 210 |  Loss: (0.3734) |  Loss2: (0.0000) | Acc: (86.00%) (23447/27008)
Epoch: 65 | Batch_idx: 220 |  Loss: (0.3719) |  Loss2: (0.0000) | Acc: (86.00%) (24571/28288)
Epoch: 65 | Batch_idx: 230 |  Loss: (0.3721) |  Loss2: (0.0000) | Acc: (86.00%) (25693/29568)
Epoch: 65 | Batch_idx: 240 |  Loss: (0.3718) |  Loss2: (0.0000) | Acc: (86.00%) (26799/30848)
Epoch: 65 | Batch_idx: 250 |  Loss: (0.3705) |  Loss2: (0.0000) | Acc: (86.00%) (27936/32128)
Epoch: 65 | Batch_idx: 260 |  Loss: (0.3706) |  Loss2: (0.0000) | Acc: (86.00%) (29055/33408)
Epoch: 65 | Batch_idx: 270 |  Loss: (0.3697) |  Loss2: (0.0000) | Acc: (87.00%) (30183/34688)
Epoch: 65 | Batch_idx: 280 |  Loss: (0.3696) |  Loss2: (0.0000) | Acc: (87.00%) (31303/35968)
Epoch: 65 | Batch_idx: 290 |  Loss: (0.3679) |  Loss2: (0.0000) | Acc: (87.00%) (32447/37248)
Epoch: 65 | Batch_idx: 300 |  Loss: (0.3670) |  Loss2: (0.0000) | Acc: (87.00%) (33577/38528)
Epoch: 65 | Batch_idx: 310 |  Loss: (0.3671) |  Loss2: (0.0000) | Acc: (87.00%) (34692/39808)
Epoch: 65 | Batch_idx: 320 |  Loss: (0.3665) |  Loss2: (0.0000) | Acc: (87.00%) (35822/41088)
Epoch: 65 | Batch_idx: 330 |  Loss: (0.3655) |  Loss2: (0.0000) | Acc: (87.00%) (36964/42368)
Epoch: 65 | Batch_idx: 340 |  Loss: (0.3646) |  Loss2: (0.0000) | Acc: (87.00%) (38091/43648)
Epoch: 65 | Batch_idx: 350 |  Loss: (0.3641) |  Loss2: (0.0000) | Acc: (87.00%) (39212/44928)
Epoch: 65 | Batch_idx: 360 |  Loss: (0.3638) |  Loss2: (0.0000) | Acc: (87.00%) (40341/46208)
Epoch: 65 | Batch_idx: 370 |  Loss: (0.3634) |  Loss2: (0.0000) | Acc: (87.00%) (41458/47488)
Epoch: 65 | Batch_idx: 380 |  Loss: (0.3625) |  Loss2: (0.0000) | Acc: (87.00%) (42593/48768)
Epoch: 65 | Batch_idx: 390 |  Loss: (0.3621) |  Loss2: (0.0000) | Acc: (87.00%) (43685/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_065.pth.tar'
# TEST : Loss: (0.4544) | Acc: (84.00%) (8486/10000)
percent tensor([0.5333, 0.5553, 0.5413, 0.5367, 0.5441, 0.5252, 0.5572, 0.5494, 0.5455,
        0.5476, 0.5416, 0.5454, 0.5371, 0.5599, 0.5414, 0.5359],
       device='cuda:0') torch.Size([16])
percent tensor([0.5281, 0.5292, 0.5261, 0.5234, 0.5271, 0.5195, 0.5309, 0.5286, 0.5287,
        0.5274, 0.5277, 0.5298, 0.5299, 0.5257, 0.5235, 0.5254],
       device='cuda:0') torch.Size([16])
percent tensor([0.5461, 0.5644, 0.5432, 0.5720, 0.5922, 0.5880, 0.5863, 0.6098, 0.5511,
        0.5258, 0.5324, 0.5506, 0.5193, 0.5824, 0.5994, 0.5509],
       device='cuda:0') torch.Size([16])
percent tensor([0.6698, 0.6114, 0.6500, 0.6600, 0.6762, 0.6657, 0.6633, 0.6749, 0.6175,
        0.6202, 0.6140, 0.6187, 0.6078, 0.6326, 0.6708, 0.6638],
       device='cuda:0') torch.Size([16])
percent tensor([0.5349, 0.5402, 0.5376, 0.5437, 0.5243, 0.5439, 0.5380, 0.5328, 0.5491,
        0.5397, 0.5465, 0.5489, 0.5394, 0.5502, 0.5380, 0.5465],
       device='cuda:0') torch.Size([16])
percent tensor([0.6272, 0.6455, 0.6494, 0.6851, 0.6561, 0.6497, 0.6589, 0.6263, 0.6679,
        0.6471, 0.6720, 0.6809, 0.6374, 0.7151, 0.6270, 0.6648],
       device='cuda:0') torch.Size([16])
percent tensor([0.4991, 0.4833, 0.5939, 0.6208, 0.5895, 0.6361, 0.5017, 0.5163, 0.5479,
        0.5466, 0.5288, 0.5471, 0.5079, 0.5557, 0.4332, 0.5635],
       device='cuda:0') torch.Size([16])
percent tensor([0.9984, 0.9989, 0.9984, 0.9985, 0.9993, 0.9979, 0.9989, 0.9992, 0.9987,
        0.9992, 0.9991, 0.9993, 0.9982, 0.9986, 0.9994, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 66 | Batch_idx: 0 |  Loss: (0.2831) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 66 | Batch_idx: 10 |  Loss: (0.3381) |  Loss2: (0.0000) | Acc: (88.00%) (1246/1408)
Epoch: 66 | Batch_idx: 20 |  Loss: (0.3282) |  Loss2: (0.0000) | Acc: (88.00%) (2379/2688)
Epoch: 66 | Batch_idx: 30 |  Loss: (0.3375) |  Loss2: (0.0000) | Acc: (88.00%) (3497/3968)
Epoch: 66 | Batch_idx: 40 |  Loss: (0.3297) |  Loss2: (0.0000) | Acc: (88.00%) (4635/5248)
Epoch: 66 | Batch_idx: 50 |  Loss: (0.3371) |  Loss2: (0.0000) | Acc: (88.00%) (5759/6528)
Epoch: 66 | Batch_idx: 60 |  Loss: (0.3380) |  Loss2: (0.0000) | Acc: (88.00%) (6888/7808)
Epoch: 66 | Batch_idx: 70 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (88.00%) (8045/9088)
Epoch: 66 | Batch_idx: 80 |  Loss: (0.3341) |  Loss2: (0.0000) | Acc: (88.00%) (9175/10368)
Epoch: 66 | Batch_idx: 90 |  Loss: (0.3398) |  Loss2: (0.0000) | Acc: (88.00%) (10281/11648)
Epoch: 66 | Batch_idx: 100 |  Loss: (0.3395) |  Loss2: (0.0000) | Acc: (88.00%) (11409/12928)
Epoch: 66 | Batch_idx: 110 |  Loss: (0.3385) |  Loss2: (0.0000) | Acc: (88.00%) (12543/14208)
Epoch: 66 | Batch_idx: 120 |  Loss: (0.3378) |  Loss2: (0.0000) | Acc: (88.00%) (13673/15488)
Epoch: 66 | Batch_idx: 130 |  Loss: (0.3349) |  Loss2: (0.0000) | Acc: (88.00%) (14822/16768)
Epoch: 66 | Batch_idx: 140 |  Loss: (0.3356) |  Loss2: (0.0000) | Acc: (88.00%) (15952/18048)
Epoch: 66 | Batch_idx: 150 |  Loss: (0.3340) |  Loss2: (0.0000) | Acc: (88.00%) (17077/19328)
Epoch: 66 | Batch_idx: 160 |  Loss: (0.3308) |  Loss2: (0.0000) | Acc: (88.00%) (18235/20608)
Epoch: 66 | Batch_idx: 170 |  Loss: (0.3330) |  Loss2: (0.0000) | Acc: (88.00%) (19356/21888)
Epoch: 66 | Batch_idx: 180 |  Loss: (0.3325) |  Loss2: (0.0000) | Acc: (88.00%) (20494/23168)
Epoch: 66 | Batch_idx: 190 |  Loss: (0.3331) |  Loss2: (0.0000) | Acc: (88.00%) (21626/24448)
Epoch: 66 | Batch_idx: 200 |  Loss: (0.3340) |  Loss2: (0.0000) | Acc: (88.00%) (22760/25728)
Epoch: 66 | Batch_idx: 210 |  Loss: (0.3361) |  Loss2: (0.0000) | Acc: (88.00%) (23868/27008)
Epoch: 66 | Batch_idx: 220 |  Loss: (0.3358) |  Loss2: (0.0000) | Acc: (88.00%) (25003/28288)
Epoch: 66 | Batch_idx: 230 |  Loss: (0.3346) |  Loss2: (0.0000) | Acc: (88.00%) (26144/29568)
Epoch: 66 | Batch_idx: 240 |  Loss: (0.3336) |  Loss2: (0.0000) | Acc: (88.00%) (27289/30848)
Epoch: 66 | Batch_idx: 250 |  Loss: (0.3323) |  Loss2: (0.0000) | Acc: (88.00%) (28425/32128)
Epoch: 66 | Batch_idx: 260 |  Loss: (0.3327) |  Loss2: (0.0000) | Acc: (88.00%) (29555/33408)
Epoch: 66 | Batch_idx: 270 |  Loss: (0.3319) |  Loss2: (0.0000) | Acc: (88.00%) (30693/34688)
Epoch: 66 | Batch_idx: 280 |  Loss: (0.3323) |  Loss2: (0.0000) | Acc: (88.00%) (31831/35968)
Epoch: 66 | Batch_idx: 290 |  Loss: (0.3327) |  Loss2: (0.0000) | Acc: (88.00%) (32950/37248)
Epoch: 66 | Batch_idx: 300 |  Loss: (0.3320) |  Loss2: (0.0000) | Acc: (88.00%) (34093/38528)
Epoch: 66 | Batch_idx: 310 |  Loss: (0.3317) |  Loss2: (0.0000) | Acc: (88.00%) (35220/39808)
Epoch: 66 | Batch_idx: 320 |  Loss: (0.3318) |  Loss2: (0.0000) | Acc: (88.00%) (36359/41088)
Epoch: 66 | Batch_idx: 330 |  Loss: (0.3308) |  Loss2: (0.0000) | Acc: (88.00%) (37515/42368)
Epoch: 66 | Batch_idx: 340 |  Loss: (0.3302) |  Loss2: (0.0000) | Acc: (88.00%) (38667/43648)
Epoch: 66 | Batch_idx: 350 |  Loss: (0.3299) |  Loss2: (0.0000) | Acc: (88.00%) (39807/44928)
Epoch: 66 | Batch_idx: 360 |  Loss: (0.3297) |  Loss2: (0.0000) | Acc: (88.00%) (40936/46208)
Epoch: 66 | Batch_idx: 370 |  Loss: (0.3294) |  Loss2: (0.0000) | Acc: (88.00%) (42076/47488)
Epoch: 66 | Batch_idx: 380 |  Loss: (0.3296) |  Loss2: (0.0000) | Acc: (88.00%) (43211/48768)
Epoch: 66 | Batch_idx: 390 |  Loss: (0.3300) |  Loss2: (0.0000) | Acc: (88.00%) (44304/50000)
# TEST : Loss: (0.4259) | Acc: (85.00%) (8558/10000)
percent tensor([0.5369, 0.5591, 0.5452, 0.5405, 0.5481, 0.5289, 0.5613, 0.5535, 0.5493,
        0.5512, 0.5452, 0.5491, 0.5406, 0.5640, 0.5452, 0.5395],
       device='cuda:0') torch.Size([16])
percent tensor([0.5316, 0.5314, 0.5297, 0.5272, 0.5309, 0.5233, 0.5339, 0.5325, 0.5319,
        0.5299, 0.5302, 0.5330, 0.5324, 0.5286, 0.5266, 0.5287],
       device='cuda:0') torch.Size([16])
percent tensor([0.5499, 0.5734, 0.5483, 0.5761, 0.5988, 0.5843, 0.5941, 0.6159, 0.5585,
        0.5373, 0.5420, 0.5600, 0.5264, 0.5908, 0.6036, 0.5540],
       device='cuda:0') torch.Size([16])
percent tensor([0.6799, 0.6151, 0.6564, 0.6665, 0.6867, 0.6834, 0.6702, 0.6843, 0.6207,
        0.6219, 0.6154, 0.6191, 0.6111, 0.6348, 0.6804, 0.6752],
       device='cuda:0') torch.Size([16])
percent tensor([0.5389, 0.5387, 0.5475, 0.5560, 0.5370, 0.5559, 0.5391, 0.5444, 0.5526,
        0.5384, 0.5432, 0.5516, 0.5363, 0.5496, 0.5407, 0.5528],
       device='cuda:0') torch.Size([16])
percent tensor([0.6409, 0.6545, 0.6640, 0.6996, 0.6730, 0.6631, 0.6724, 0.6460, 0.6796,
        0.6572, 0.6810, 0.6925, 0.6441, 0.7217, 0.6426, 0.6777],
       device='cuda:0') torch.Size([16])
percent tensor([0.5187, 0.4986, 0.6020, 0.6285, 0.5925, 0.6614, 0.5129, 0.5121, 0.5670,
        0.5636, 0.5461, 0.5511, 0.5235, 0.5765, 0.4324, 0.5835],
       device='cuda:0') torch.Size([16])
percent tensor([0.9985, 0.9990, 0.9986, 0.9985, 0.9994, 0.9976, 0.9990, 0.9993, 0.9988,
        0.9993, 0.9991, 0.9994, 0.9983, 0.9987, 0.9995, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 67 | Batch_idx: 0 |  Loss: (0.2595) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 67 | Batch_idx: 10 |  Loss: (0.2984) |  Loss2: (0.0000) | Acc: (90.00%) (1271/1408)
Epoch: 67 | Batch_idx: 20 |  Loss: (0.3129) |  Loss2: (0.0000) | Acc: (89.00%) (2404/2688)
Epoch: 67 | Batch_idx: 30 |  Loss: (0.3179) |  Loss2: (0.0000) | Acc: (89.00%) (3541/3968)
Epoch: 67 | Batch_idx: 40 |  Loss: (0.3222) |  Loss2: (0.0000) | Acc: (89.00%) (4681/5248)
Epoch: 67 | Batch_idx: 50 |  Loss: (0.3194) |  Loss2: (0.0000) | Acc: (89.00%) (5836/6528)
Epoch: 67 | Batch_idx: 60 |  Loss: (0.3203) |  Loss2: (0.0000) | Acc: (89.00%) (6988/7808)
Epoch: 67 | Batch_idx: 70 |  Loss: (0.3187) |  Loss2: (0.0000) | Acc: (89.00%) (8128/9088)
Epoch: 67 | Batch_idx: 80 |  Loss: (0.3211) |  Loss2: (0.0000) | Acc: (89.00%) (9250/10368)
Epoch: 67 | Batch_idx: 90 |  Loss: (0.3233) |  Loss2: (0.0000) | Acc: (89.00%) (10384/11648)
Epoch: 67 | Batch_idx: 100 |  Loss: (0.3218) |  Loss2: (0.0000) | Acc: (89.00%) (11528/12928)
Epoch: 67 | Batch_idx: 110 |  Loss: (0.3206) |  Loss2: (0.0000) | Acc: (89.00%) (12669/14208)
Epoch: 67 | Batch_idx: 120 |  Loss: (0.3171) |  Loss2: (0.0000) | Acc: (89.00%) (13826/15488)
Epoch: 67 | Batch_idx: 130 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (89.00%) (14975/16768)
Epoch: 67 | Batch_idx: 140 |  Loss: (0.3185) |  Loss2: (0.0000) | Acc: (89.00%) (16095/18048)
Epoch: 67 | Batch_idx: 150 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (89.00%) (17253/19328)
Epoch: 67 | Batch_idx: 160 |  Loss: (0.3152) |  Loss2: (0.0000) | Acc: (89.00%) (18382/20608)
Epoch: 67 | Batch_idx: 170 |  Loss: (0.3134) |  Loss2: (0.0000) | Acc: (89.00%) (19541/21888)
Epoch: 67 | Batch_idx: 180 |  Loss: (0.3139) |  Loss2: (0.0000) | Acc: (89.00%) (20673/23168)
Epoch: 67 | Batch_idx: 190 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (89.00%) (21804/24448)
Epoch: 67 | Batch_idx: 200 |  Loss: (0.3135) |  Loss2: (0.0000) | Acc: (89.00%) (22956/25728)
Epoch: 67 | Batch_idx: 210 |  Loss: (0.3128) |  Loss2: (0.0000) | Acc: (89.00%) (24110/27008)
Epoch: 67 | Batch_idx: 220 |  Loss: (0.3117) |  Loss2: (0.0000) | Acc: (89.00%) (25263/28288)
Epoch: 67 | Batch_idx: 230 |  Loss: (0.3118) |  Loss2: (0.0000) | Acc: (89.00%) (26402/29568)
Epoch: 67 | Batch_idx: 240 |  Loss: (0.3121) |  Loss2: (0.0000) | Acc: (89.00%) (27540/30848)
Epoch: 67 | Batch_idx: 250 |  Loss: (0.3132) |  Loss2: (0.0000) | Acc: (89.00%) (28674/32128)
Epoch: 67 | Batch_idx: 260 |  Loss: (0.3118) |  Loss2: (0.0000) | Acc: (89.00%) (29827/33408)
Epoch: 67 | Batch_idx: 270 |  Loss: (0.3115) |  Loss2: (0.0000) | Acc: (89.00%) (30980/34688)
Epoch: 67 | Batch_idx: 280 |  Loss: (0.3113) |  Loss2: (0.0000) | Acc: (89.00%) (32118/35968)
Epoch: 67 | Batch_idx: 290 |  Loss: (0.3110) |  Loss2: (0.0000) | Acc: (89.00%) (33264/37248)
Epoch: 67 | Batch_idx: 300 |  Loss: (0.3114) |  Loss2: (0.0000) | Acc: (89.00%) (34398/38528)
Epoch: 67 | Batch_idx: 310 |  Loss: (0.3116) |  Loss2: (0.0000) | Acc: (89.00%) (35533/39808)
Epoch: 67 | Batch_idx: 320 |  Loss: (0.3114) |  Loss2: (0.0000) | Acc: (89.00%) (36673/41088)
Epoch: 67 | Batch_idx: 330 |  Loss: (0.3113) |  Loss2: (0.0000) | Acc: (89.00%) (37815/42368)
Epoch: 67 | Batch_idx: 340 |  Loss: (0.3120) |  Loss2: (0.0000) | Acc: (89.00%) (38950/43648)
Epoch: 67 | Batch_idx: 350 |  Loss: (0.3117) |  Loss2: (0.0000) | Acc: (89.00%) (40094/44928)
Epoch: 67 | Batch_idx: 360 |  Loss: (0.3122) |  Loss2: (0.0000) | Acc: (89.00%) (41215/46208)
Epoch: 67 | Batch_idx: 370 |  Loss: (0.3117) |  Loss2: (0.0000) | Acc: (89.00%) (42367/47488)
Epoch: 67 | Batch_idx: 380 |  Loss: (0.3116) |  Loss2: (0.0000) | Acc: (89.00%) (43508/48768)
Epoch: 67 | Batch_idx: 390 |  Loss: (0.3122) |  Loss2: (0.0000) | Acc: (89.00%) (44601/50000)
# TEST : Loss: (0.4141) | Acc: (86.00%) (8606/10000)
percent tensor([0.5343, 0.5559, 0.5419, 0.5376, 0.5448, 0.5268, 0.5578, 0.5501, 0.5465,
        0.5480, 0.5425, 0.5458, 0.5379, 0.5609, 0.5424, 0.5368],
       device='cuda:0') torch.Size([16])
percent tensor([0.5317, 0.5306, 0.5299, 0.5273, 0.5310, 0.5238, 0.5336, 0.5327, 0.5317,
        0.5294, 0.5296, 0.5329, 0.5317, 0.5284, 0.5265, 0.5286],
       device='cuda:0') torch.Size([16])
percent tensor([0.5469, 0.5757, 0.5471, 0.5759, 0.5977, 0.5768, 0.5943, 0.6142, 0.5586,
        0.5411, 0.5444, 0.5614, 0.5269, 0.5934, 0.6020, 0.5518],
       device='cuda:0') torch.Size([16])
percent tensor([0.6881, 0.6192, 0.6640, 0.6738, 0.6972, 0.6967, 0.6759, 0.6925, 0.6244,
        0.6255, 0.6168, 0.6222, 0.6144, 0.6368, 0.6882, 0.6848],
       device='cuda:0') torch.Size([16])
percent tensor([0.5365, 0.5319, 0.5504, 0.5608, 0.5419, 0.5611, 0.5343, 0.5481, 0.5514,
        0.5316, 0.5358, 0.5492, 0.5288, 0.5452, 0.5377, 0.5518],
       device='cuda:0') torch.Size([16])
percent tensor([0.6449, 0.6576, 0.6683, 0.7041, 0.6796, 0.6679, 0.6772, 0.6523, 0.6832,
        0.6604, 0.6838, 0.6968, 0.6446, 0.7237, 0.6482, 0.6810],
       device='cuda:0') torch.Size([16])
percent tensor([0.5227, 0.4975, 0.6011, 0.6314, 0.5904, 0.6766, 0.5113, 0.4986, 0.5732,
        0.5663, 0.5498, 0.5434, 0.5249, 0.5842, 0.4214, 0.5905],
       device='cuda:0') torch.Size([16])
percent tensor([0.9986, 0.9990, 0.9988, 0.9987, 0.9995, 0.9975, 0.9991, 0.9994, 0.9989,
        0.9994, 0.9992, 0.9995, 0.9983, 0.9988, 0.9995, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 68 | Batch_idx: 0 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 68 | Batch_idx: 10 |  Loss: (0.2842) |  Loss2: (0.0000) | Acc: (90.00%) (1276/1408)
Epoch: 68 | Batch_idx: 20 |  Loss: (0.2960) |  Loss2: (0.0000) | Acc: (90.00%) (2426/2688)
Epoch: 68 | Batch_idx: 30 |  Loss: (0.3011) |  Loss2: (0.0000) | Acc: (90.00%) (3578/3968)
Epoch: 68 | Batch_idx: 40 |  Loss: (0.3038) |  Loss2: (0.0000) | Acc: (90.00%) (4725/5248)
Epoch: 68 | Batch_idx: 50 |  Loss: (0.2983) |  Loss2: (0.0000) | Acc: (90.00%) (5877/6528)
Epoch: 68 | Batch_idx: 60 |  Loss: (0.2970) |  Loss2: (0.0000) | Acc: (90.00%) (7033/7808)
Epoch: 68 | Batch_idx: 70 |  Loss: (0.3006) |  Loss2: (0.0000) | Acc: (89.00%) (8176/9088)
Epoch: 68 | Batch_idx: 80 |  Loss: (0.2981) |  Loss2: (0.0000) | Acc: (90.00%) (9332/10368)
Epoch: 68 | Batch_idx: 90 |  Loss: (0.3023) |  Loss2: (0.0000) | Acc: (89.00%) (10467/11648)
Epoch: 68 | Batch_idx: 100 |  Loss: (0.3045) |  Loss2: (0.0000) | Acc: (89.00%) (11596/12928)
Epoch: 68 | Batch_idx: 110 |  Loss: (0.3065) |  Loss2: (0.0000) | Acc: (89.00%) (12719/14208)
Epoch: 68 | Batch_idx: 120 |  Loss: (0.3039) |  Loss2: (0.0000) | Acc: (89.00%) (13876/15488)
Epoch: 68 | Batch_idx: 130 |  Loss: (0.3033) |  Loss2: (0.0000) | Acc: (89.00%) (15039/16768)
Epoch: 68 | Batch_idx: 140 |  Loss: (0.3049) |  Loss2: (0.0000) | Acc: (89.00%) (16178/18048)
Epoch: 68 | Batch_idx: 150 |  Loss: (0.3030) |  Loss2: (0.0000) | Acc: (89.00%) (17343/19328)
Epoch: 68 | Batch_idx: 160 |  Loss: (0.3029) |  Loss2: (0.0000) | Acc: (89.00%) (18505/20608)
Epoch: 68 | Batch_idx: 170 |  Loss: (0.3022) |  Loss2: (0.0000) | Acc: (89.00%) (19666/21888)
Epoch: 68 | Batch_idx: 180 |  Loss: (0.3009) |  Loss2: (0.0000) | Acc: (89.00%) (20821/23168)
Epoch: 68 | Batch_idx: 190 |  Loss: (0.3007) |  Loss2: (0.0000) | Acc: (89.00%) (21973/24448)
Epoch: 68 | Batch_idx: 200 |  Loss: (0.2993) |  Loss2: (0.0000) | Acc: (89.00%) (23141/25728)
Epoch: 68 | Batch_idx: 210 |  Loss: (0.2997) |  Loss2: (0.0000) | Acc: (89.00%) (24287/27008)
Epoch: 68 | Batch_idx: 220 |  Loss: (0.3002) |  Loss2: (0.0000) | Acc: (89.00%) (25430/28288)
Epoch: 68 | Batch_idx: 230 |  Loss: (0.3004) |  Loss2: (0.0000) | Acc: (89.00%) (26585/29568)
Epoch: 68 | Batch_idx: 240 |  Loss: (0.3010) |  Loss2: (0.0000) | Acc: (89.00%) (27732/30848)
Epoch: 68 | Batch_idx: 250 |  Loss: (0.3020) |  Loss2: (0.0000) | Acc: (89.00%) (28867/32128)
Epoch: 68 | Batch_idx: 260 |  Loss: (0.3015) |  Loss2: (0.0000) | Acc: (89.00%) (30037/33408)
Epoch: 68 | Batch_idx: 270 |  Loss: (0.3031) |  Loss2: (0.0000) | Acc: (89.00%) (31159/34688)
Epoch: 68 | Batch_idx: 280 |  Loss: (0.3046) |  Loss2: (0.0000) | Acc: (89.00%) (32283/35968)
Epoch: 68 | Batch_idx: 290 |  Loss: (0.3052) |  Loss2: (0.0000) | Acc: (89.00%) (33419/37248)
Epoch: 68 | Batch_idx: 300 |  Loss: (0.3044) |  Loss2: (0.0000) | Acc: (89.00%) (34577/38528)
Epoch: 68 | Batch_idx: 310 |  Loss: (0.3050) |  Loss2: (0.0000) | Acc: (89.00%) (35713/39808)
Epoch: 68 | Batch_idx: 320 |  Loss: (0.3042) |  Loss2: (0.0000) | Acc: (89.00%) (36855/41088)
Epoch: 68 | Batch_idx: 330 |  Loss: (0.3044) |  Loss2: (0.0000) | Acc: (89.00%) (38006/42368)
Epoch: 68 | Batch_idx: 340 |  Loss: (0.3039) |  Loss2: (0.0000) | Acc: (89.00%) (39153/43648)
Epoch: 68 | Batch_idx: 350 |  Loss: (0.3041) |  Loss2: (0.0000) | Acc: (89.00%) (40291/44928)
Epoch: 68 | Batch_idx: 360 |  Loss: (0.3052) |  Loss2: (0.0000) | Acc: (89.00%) (41429/46208)
Epoch: 68 | Batch_idx: 370 |  Loss: (0.3055) |  Loss2: (0.0000) | Acc: (89.00%) (42569/47488)
Epoch: 68 | Batch_idx: 380 |  Loss: (0.3052) |  Loss2: (0.0000) | Acc: (89.00%) (43719/48768)
Epoch: 68 | Batch_idx: 390 |  Loss: (0.3055) |  Loss2: (0.0000) | Acc: (89.00%) (44819/50000)
# TEST : Loss: (0.4075) | Acc: (86.00%) (8620/10000)
percent tensor([0.5347, 0.5560, 0.5427, 0.5379, 0.5454, 0.5272, 0.5581, 0.5506, 0.5468,
        0.5483, 0.5427, 0.5465, 0.5382, 0.5608, 0.5426, 0.5370],
       device='cuda:0') torch.Size([16])
percent tensor([0.5320, 0.5300, 0.5301, 0.5276, 0.5311, 0.5243, 0.5334, 0.5331, 0.5318,
        0.5289, 0.5292, 0.5327, 0.5314, 0.5284, 0.5265, 0.5287],
       device='cuda:0') torch.Size([16])
percent tensor([0.5433, 0.5734, 0.5441, 0.5725, 0.5947, 0.5691, 0.5920, 0.6108, 0.5564,
        0.5406, 0.5433, 0.5600, 0.5251, 0.5914, 0.5979, 0.5469],
       device='cuda:0') torch.Size([16])
percent tensor([0.6846, 0.6123, 0.6602, 0.6703, 0.6949, 0.6966, 0.6711, 0.6901, 0.6181,
        0.6186, 0.6083, 0.6146, 0.6073, 0.6298, 0.6835, 0.6815],
       device='cuda:0') torch.Size([16])
percent tensor([0.5351, 0.5282, 0.5523, 0.5638, 0.5457, 0.5642, 0.5320, 0.5502, 0.5508,
        0.5286, 0.5317, 0.5481, 0.5239, 0.5429, 0.5360, 0.5516],
       device='cuda:0') torch.Size([16])
percent tensor([0.6627, 0.6742, 0.6864, 0.7209, 0.6985, 0.6841, 0.6959, 0.6738, 0.6997,
        0.6786, 0.7005, 0.7150, 0.6604, 0.7382, 0.6691, 0.6977],
       device='cuda:0') torch.Size([16])
percent tensor([0.5319, 0.5045, 0.6123, 0.6409, 0.5969, 0.6901, 0.5198, 0.5028, 0.5858,
        0.5745, 0.5635, 0.5541, 0.5339, 0.5982, 0.4216, 0.5987],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9991, 0.9988, 0.9986, 0.9995, 0.9975, 0.9992, 0.9994, 0.9991,
        0.9995, 0.9992, 0.9996, 0.9985, 0.9990, 0.9995, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 69 | Batch_idx: 0 |  Loss: (0.3084) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 69 | Batch_idx: 10 |  Loss: (0.3007) |  Loss2: (0.0000) | Acc: (89.00%) (1264/1408)
Epoch: 69 | Batch_idx: 20 |  Loss: (0.2937) |  Loss2: (0.0000) | Acc: (90.00%) (2422/2688)
Epoch: 69 | Batch_idx: 30 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (3557/3968)
Epoch: 69 | Batch_idx: 40 |  Loss: (0.3040) |  Loss2: (0.0000) | Acc: (89.00%) (4702/5248)
Epoch: 69 | Batch_idx: 50 |  Loss: (0.3048) |  Loss2: (0.0000) | Acc: (89.00%) (5858/6528)
Epoch: 69 | Batch_idx: 60 |  Loss: (0.3060) |  Loss2: (0.0000) | Acc: (89.00%) (7006/7808)
Epoch: 69 | Batch_idx: 70 |  Loss: (0.3071) |  Loss2: (0.0000) | Acc: (89.00%) (8142/9088)
Epoch: 69 | Batch_idx: 80 |  Loss: (0.3094) |  Loss2: (0.0000) | Acc: (89.00%) (9286/10368)
Epoch: 69 | Batch_idx: 90 |  Loss: (0.3071) |  Loss2: (0.0000) | Acc: (89.00%) (10446/11648)
Epoch: 69 | Batch_idx: 100 |  Loss: (0.3121) |  Loss2: (0.0000) | Acc: (89.00%) (11560/12928)
Epoch: 69 | Batch_idx: 110 |  Loss: (0.3089) |  Loss2: (0.0000) | Acc: (89.00%) (12719/14208)
Epoch: 69 | Batch_idx: 120 |  Loss: (0.3069) |  Loss2: (0.0000) | Acc: (89.00%) (13873/15488)
Epoch: 69 | Batch_idx: 130 |  Loss: (0.3049) |  Loss2: (0.0000) | Acc: (89.00%) (15041/16768)
Epoch: 69 | Batch_idx: 140 |  Loss: (0.3046) |  Loss2: (0.0000) | Acc: (89.00%) (16194/18048)
Epoch: 69 | Batch_idx: 150 |  Loss: (0.3038) |  Loss2: (0.0000) | Acc: (89.00%) (17351/19328)
Epoch: 69 | Batch_idx: 160 |  Loss: (0.3033) |  Loss2: (0.0000) | Acc: (89.00%) (18515/20608)
Epoch: 69 | Batch_idx: 170 |  Loss: (0.3022) |  Loss2: (0.0000) | Acc: (89.00%) (19681/21888)
Epoch: 69 | Batch_idx: 180 |  Loss: (0.3020) |  Loss2: (0.0000) | Acc: (89.00%) (20831/23168)
Epoch: 69 | Batch_idx: 190 |  Loss: (0.3057) |  Loss2: (0.0000) | Acc: (89.00%) (21950/24448)
Epoch: 69 | Batch_idx: 200 |  Loss: (0.3073) |  Loss2: (0.0000) | Acc: (89.00%) (23078/25728)
Epoch: 69 | Batch_idx: 210 |  Loss: (0.3068) |  Loss2: (0.0000) | Acc: (89.00%) (24225/27008)
Epoch: 69 | Batch_idx: 220 |  Loss: (0.3048) |  Loss2: (0.0000) | Acc: (89.00%) (25396/28288)
Epoch: 69 | Batch_idx: 230 |  Loss: (0.3049) |  Loss2: (0.0000) | Acc: (89.00%) (26537/29568)
Epoch: 69 | Batch_idx: 240 |  Loss: (0.3031) |  Loss2: (0.0000) | Acc: (89.00%) (27701/30848)
Epoch: 69 | Batch_idx: 250 |  Loss: (0.3025) |  Loss2: (0.0000) | Acc: (89.00%) (28859/32128)
Epoch: 69 | Batch_idx: 260 |  Loss: (0.3019) |  Loss2: (0.0000) | Acc: (89.00%) (30004/33408)
Epoch: 69 | Batch_idx: 270 |  Loss: (0.3028) |  Loss2: (0.0000) | Acc: (89.00%) (31145/34688)
Epoch: 69 | Batch_idx: 280 |  Loss: (0.3024) |  Loss2: (0.0000) | Acc: (89.00%) (32292/35968)
Epoch: 69 | Batch_idx: 290 |  Loss: (0.3020) |  Loss2: (0.0000) | Acc: (89.00%) (33445/37248)
Epoch: 69 | Batch_idx: 300 |  Loss: (0.3015) |  Loss2: (0.0000) | Acc: (89.00%) (34595/38528)
Epoch: 69 | Batch_idx: 310 |  Loss: (0.3009) |  Loss2: (0.0000) | Acc: (89.00%) (35746/39808)
Epoch: 69 | Batch_idx: 320 |  Loss: (0.3012) |  Loss2: (0.0000) | Acc: (89.00%) (36908/41088)
Epoch: 69 | Batch_idx: 330 |  Loss: (0.3012) |  Loss2: (0.0000) | Acc: (89.00%) (38061/42368)
Epoch: 69 | Batch_idx: 340 |  Loss: (0.3012) |  Loss2: (0.0000) | Acc: (89.00%) (39204/43648)
Epoch: 69 | Batch_idx: 350 |  Loss: (0.3017) |  Loss2: (0.0000) | Acc: (89.00%) (40344/44928)
Epoch: 69 | Batch_idx: 360 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (41481/46208)
Epoch: 69 | Batch_idx: 370 |  Loss: (0.3015) |  Loss2: (0.0000) | Acc: (89.00%) (42643/47488)
Epoch: 69 | Batch_idx: 380 |  Loss: (0.3016) |  Loss2: (0.0000) | Acc: (89.00%) (43786/48768)
Epoch: 69 | Batch_idx: 390 |  Loss: (0.3016) |  Loss2: (0.0000) | Acc: (89.00%) (44901/50000)
# TEST : Loss: (0.4079) | Acc: (86.00%) (8622/10000)
percent tensor([0.5347, 0.5558, 0.5429, 0.5382, 0.5455, 0.5274, 0.5579, 0.5507, 0.5468,
        0.5482, 0.5425, 0.5465, 0.5381, 0.5607, 0.5426, 0.5371],
       device='cuda:0') torch.Size([16])
percent tensor([0.5308, 0.5280, 0.5288, 0.5262, 0.5297, 0.5234, 0.5317, 0.5318, 0.5304,
        0.5272, 0.5275, 0.5312, 0.5297, 0.5269, 0.5249, 0.5274],
       device='cuda:0') torch.Size([16])
percent tensor([0.5459, 0.5761, 0.5469, 0.5770, 0.5970, 0.5710, 0.5946, 0.6131, 0.5600,
        0.5446, 0.5474, 0.5631, 0.5267, 0.5978, 0.6002, 0.5499],
       device='cuda:0') torch.Size([16])
percent tensor([0.6923, 0.6178, 0.6660, 0.6768, 0.7024, 0.7049, 0.6784, 0.6972, 0.6234,
        0.6242, 0.6130, 0.6192, 0.6120, 0.6360, 0.6907, 0.6900],
       device='cuda:0') torch.Size([16])
percent tensor([0.5347, 0.5257, 0.5547, 0.5669, 0.5498, 0.5675, 0.5310, 0.5540, 0.5508,
        0.5256, 0.5283, 0.5479, 0.5203, 0.5417, 0.5360, 0.5519],
       device='cuda:0') torch.Size([16])
percent tensor([0.6561, 0.6674, 0.6815, 0.7157, 0.6933, 0.6794, 0.6895, 0.6672, 0.6949,
        0.6710, 0.6949, 0.7094, 0.6529, 0.7326, 0.6629, 0.6908],
       device='cuda:0') torch.Size([16])
percent tensor([0.5409, 0.5168, 0.6217, 0.6489, 0.6029, 0.7002, 0.5312, 0.5090, 0.5975,
        0.5841, 0.5754, 0.5660, 0.5466, 0.6083, 0.4266, 0.6074],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9992, 0.9991, 0.9987, 0.9996, 0.9976, 0.9992, 0.9994, 0.9991,
        0.9995, 0.9993, 0.9996, 0.9985, 0.9990, 0.9995, 0.9992],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 70 | Batch_idx: 0 |  Loss: (0.2499) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 70 | Batch_idx: 10 |  Loss: (0.2794) |  Loss2: (0.0000) | Acc: (90.00%) (1272/1408)
Epoch: 70 | Batch_idx: 20 |  Loss: (0.2907) |  Loss2: (0.0000) | Acc: (89.00%) (2416/2688)
Epoch: 70 | Batch_idx: 30 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (3552/3968)
Epoch: 70 | Batch_idx: 40 |  Loss: (0.3033) |  Loss2: (0.0000) | Acc: (89.00%) (4697/5248)
Epoch: 70 | Batch_idx: 50 |  Loss: (0.3010) |  Loss2: (0.0000) | Acc: (89.00%) (5852/6528)
Epoch: 70 | Batch_idx: 60 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (7007/7808)
Epoch: 70 | Batch_idx: 70 |  Loss: (0.3029) |  Loss2: (0.0000) | Acc: (89.00%) (8154/9088)
Epoch: 70 | Batch_idx: 80 |  Loss: (0.3058) |  Loss2: (0.0000) | Acc: (89.00%) (9285/10368)
Epoch: 70 | Batch_idx: 90 |  Loss: (0.3079) |  Loss2: (0.0000) | Acc: (89.00%) (10419/11648)
Epoch: 70 | Batch_idx: 100 |  Loss: (0.3098) |  Loss2: (0.0000) | Acc: (89.00%) (11567/12928)
Epoch: 70 | Batch_idx: 110 |  Loss: (0.3065) |  Loss2: (0.0000) | Acc: (89.00%) (12733/14208)
Epoch: 70 | Batch_idx: 120 |  Loss: (0.3070) |  Loss2: (0.0000) | Acc: (89.00%) (13878/15488)
Epoch: 70 | Batch_idx: 130 |  Loss: (0.3076) |  Loss2: (0.0000) | Acc: (89.00%) (15001/16768)
Epoch: 70 | Batch_idx: 140 |  Loss: (0.3097) |  Loss2: (0.0000) | Acc: (89.00%) (16134/18048)
Epoch: 70 | Batch_idx: 150 |  Loss: (0.3122) |  Loss2: (0.0000) | Acc: (89.00%) (17257/19328)
Epoch: 70 | Batch_idx: 160 |  Loss: (0.3129) |  Loss2: (0.0000) | Acc: (89.00%) (18395/20608)
Epoch: 70 | Batch_idx: 170 |  Loss: (0.3121) |  Loss2: (0.0000) | Acc: (89.00%) (19542/21888)
Epoch: 70 | Batch_idx: 180 |  Loss: (0.3114) |  Loss2: (0.0000) | Acc: (89.00%) (20686/23168)
Epoch: 70 | Batch_idx: 190 |  Loss: (0.3119) |  Loss2: (0.0000) | Acc: (89.00%) (21822/24448)
Epoch: 70 | Batch_idx: 200 |  Loss: (0.3112) |  Loss2: (0.0000) | Acc: (89.00%) (22976/25728)
Epoch: 70 | Batch_idx: 210 |  Loss: (0.3115) |  Loss2: (0.0000) | Acc: (89.00%) (24110/27008)
Epoch: 70 | Batch_idx: 220 |  Loss: (0.3123) |  Loss2: (0.0000) | Acc: (89.00%) (25256/28288)
Epoch: 70 | Batch_idx: 230 |  Loss: (0.3118) |  Loss2: (0.0000) | Acc: (89.00%) (26405/29568)
Epoch: 70 | Batch_idx: 240 |  Loss: (0.3125) |  Loss2: (0.0000) | Acc: (89.00%) (27538/30848)
Epoch: 70 | Batch_idx: 250 |  Loss: (0.3126) |  Loss2: (0.0000) | Acc: (89.00%) (28680/32128)
Epoch: 70 | Batch_idx: 260 |  Loss: (0.3119) |  Loss2: (0.0000) | Acc: (89.00%) (29828/33408)
Epoch: 70 | Batch_idx: 270 |  Loss: (0.3120) |  Loss2: (0.0000) | Acc: (89.00%) (30973/34688)
Epoch: 70 | Batch_idx: 280 |  Loss: (0.3117) |  Loss2: (0.0000) | Acc: (89.00%) (32124/35968)
Epoch: 70 | Batch_idx: 290 |  Loss: (0.3115) |  Loss2: (0.0000) | Acc: (89.00%) (33269/37248)
Epoch: 70 | Batch_idx: 300 |  Loss: (0.3115) |  Loss2: (0.0000) | Acc: (89.00%) (34405/38528)
Epoch: 70 | Batch_idx: 310 |  Loss: (0.3120) |  Loss2: (0.0000) | Acc: (89.00%) (35546/39808)
Epoch: 70 | Batch_idx: 320 |  Loss: (0.3120) |  Loss2: (0.0000) | Acc: (89.00%) (36686/41088)
Epoch: 70 | Batch_idx: 330 |  Loss: (0.3125) |  Loss2: (0.0000) | Acc: (89.00%) (37809/42368)
Epoch: 70 | Batch_idx: 340 |  Loss: (0.3128) |  Loss2: (0.0000) | Acc: (89.00%) (38938/43648)
Epoch: 70 | Batch_idx: 350 |  Loss: (0.3126) |  Loss2: (0.0000) | Acc: (89.00%) (40079/44928)
Epoch: 70 | Batch_idx: 360 |  Loss: (0.3125) |  Loss2: (0.0000) | Acc: (89.00%) (41222/46208)
Epoch: 70 | Batch_idx: 370 |  Loss: (0.3125) |  Loss2: (0.0000) | Acc: (89.00%) (42354/47488)
Epoch: 70 | Batch_idx: 380 |  Loss: (0.3142) |  Loss2: (0.0000) | Acc: (89.00%) (43475/48768)
Epoch: 70 | Batch_idx: 390 |  Loss: (0.3144) |  Loss2: (0.0000) | Acc: (89.00%) (44566/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_070.pth.tar'
# TEST : Loss: (0.4973) | Acc: (83.00%) (8328/10000)
percent tensor([0.5342, 0.5556, 0.5423, 0.5378, 0.5452, 0.5267, 0.5579, 0.5496, 0.5462,
        0.5479, 0.5426, 0.5464, 0.5376, 0.5607, 0.5426, 0.5365],
       device='cuda:0') torch.Size([16])
percent tensor([0.5303, 0.5276, 0.5263, 0.5241, 0.5279, 0.5212, 0.5311, 0.5303, 0.5313,
        0.5266, 0.5281, 0.5296, 0.5300, 0.5271, 0.5239, 0.5267],
       device='cuda:0') torch.Size([16])
percent tensor([0.5501, 0.5797, 0.5483, 0.5846, 0.6020, 0.5754, 0.5959, 0.6135, 0.5627,
        0.5454, 0.5486, 0.5607, 0.5267, 0.6079, 0.6091, 0.5563],
       device='cuda:0') torch.Size([16])
percent tensor([0.6941, 0.6217, 0.6677, 0.6789, 0.7034, 0.7015, 0.6800, 0.6926, 0.6309,
        0.6288, 0.6251, 0.6210, 0.6152, 0.6401, 0.6954, 0.6892],
       device='cuda:0') torch.Size([16])
percent tensor([0.5371, 0.5294, 0.5546, 0.5684, 0.5549, 0.5643, 0.5368, 0.5555, 0.5526,
        0.5297, 0.5306, 0.5514, 0.5239, 0.5450, 0.5411, 0.5549],
       device='cuda:0') torch.Size([16])
percent tensor([0.6640, 0.6783, 0.6751, 0.7081, 0.6946, 0.6796, 0.7002, 0.6705, 0.6946,
        0.6830, 0.6994, 0.7137, 0.6628, 0.7403, 0.6681, 0.7007],
       device='cuda:0') torch.Size([16])
percent tensor([0.5569, 0.5244, 0.6232, 0.6601, 0.6111, 0.7323, 0.5519, 0.5125, 0.5990,
        0.5959, 0.6056, 0.5903, 0.5619, 0.6435, 0.4342, 0.6263],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9988, 0.9993, 0.9990, 0.9995, 0.9984, 0.9993, 0.9997, 0.9989,
        0.9994, 0.9994, 0.9997, 0.9984, 0.9987, 0.9995, 0.9993],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(171.7932, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(803.3885, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(799.6820, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1530.4590, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(496.1018, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2208.0430, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4277.2549, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1416.5688, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6126.6021, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11975.1123, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3996.3669, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16836.1230, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 71 | Batch_idx: 0 |  Loss: (0.2294) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 71 | Batch_idx: 10 |  Loss: (0.2934) |  Loss2: (0.0000) | Acc: (89.00%) (1265/1408)
Epoch: 71 | Batch_idx: 20 |  Loss: (0.2793) |  Loss2: (0.0000) | Acc: (90.00%) (2426/2688)
Epoch: 71 | Batch_idx: 30 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (90.00%) (3573/3968)
Epoch: 71 | Batch_idx: 40 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (89.00%) (4722/5248)
Epoch: 71 | Batch_idx: 50 |  Loss: (0.2891) |  Loss2: (0.0000) | Acc: (89.00%) (5872/6528)
Epoch: 71 | Batch_idx: 60 |  Loss: (0.2892) |  Loss2: (0.0000) | Acc: (90.00%) (7028/7808)
Epoch: 71 | Batch_idx: 70 |  Loss: (0.2862) |  Loss2: (0.0000) | Acc: (90.00%) (8187/9088)
Epoch: 71 | Batch_idx: 80 |  Loss: (0.2902) |  Loss2: (0.0000) | Acc: (89.00%) (9324/10368)
Epoch: 71 | Batch_idx: 90 |  Loss: (0.2897) |  Loss2: (0.0000) | Acc: (89.00%) (10477/11648)
Epoch: 71 | Batch_idx: 100 |  Loss: (0.2903) |  Loss2: (0.0000) | Acc: (89.00%) (11629/12928)
Epoch: 71 | Batch_idx: 110 |  Loss: (0.2903) |  Loss2: (0.0000) | Acc: (89.00%) (12776/14208)
Epoch: 71 | Batch_idx: 120 |  Loss: (0.2922) |  Loss2: (0.0000) | Acc: (89.00%) (13929/15488)
Epoch: 71 | Batch_idx: 130 |  Loss: (0.2950) |  Loss2: (0.0000) | Acc: (89.00%) (15076/16768)
Epoch: 71 | Batch_idx: 140 |  Loss: (0.2938) |  Loss2: (0.0000) | Acc: (89.00%) (16231/18048)
Epoch: 71 | Batch_idx: 150 |  Loss: (0.2934) |  Loss2: (0.0000) | Acc: (89.00%) (17393/19328)
Epoch: 71 | Batch_idx: 160 |  Loss: (0.2925) |  Loss2: (0.0000) | Acc: (90.00%) (18553/20608)
Epoch: 71 | Batch_idx: 170 |  Loss: (0.2938) |  Loss2: (0.0000) | Acc: (90.00%) (19703/21888)
Epoch: 71 | Batch_idx: 180 |  Loss: (0.2948) |  Loss2: (0.0000) | Acc: (89.00%) (20850/23168)
Epoch: 71 | Batch_idx: 190 |  Loss: (0.2954) |  Loss2: (0.0000) | Acc: (89.00%) (21985/24448)
Epoch: 71 | Batch_idx: 200 |  Loss: (0.2950) |  Loss2: (0.0000) | Acc: (89.00%) (23138/25728)
Epoch: 71 | Batch_idx: 210 |  Loss: (0.2947) |  Loss2: (0.0000) | Acc: (89.00%) (24302/27008)
Epoch: 71 | Batch_idx: 220 |  Loss: (0.2964) |  Loss2: (0.0000) | Acc: (89.00%) (25436/28288)
Epoch: 71 | Batch_idx: 230 |  Loss: (0.2967) |  Loss2: (0.0000) | Acc: (89.00%) (26584/29568)
Epoch: 71 | Batch_idx: 240 |  Loss: (0.2979) |  Loss2: (0.0000) | Acc: (89.00%) (27723/30848)
Epoch: 71 | Batch_idx: 250 |  Loss: (0.2992) |  Loss2: (0.0000) | Acc: (89.00%) (28849/32128)
Epoch: 71 | Batch_idx: 260 |  Loss: (0.2986) |  Loss2: (0.0000) | Acc: (89.00%) (30011/33408)
Epoch: 71 | Batch_idx: 270 |  Loss: (0.2987) |  Loss2: (0.0000) | Acc: (89.00%) (31151/34688)
Epoch: 71 | Batch_idx: 280 |  Loss: (0.2980) |  Loss2: (0.0000) | Acc: (89.00%) (32304/35968)
Epoch: 71 | Batch_idx: 290 |  Loss: (0.2984) |  Loss2: (0.0000) | Acc: (89.00%) (33453/37248)
Epoch: 71 | Batch_idx: 300 |  Loss: (0.2991) |  Loss2: (0.0000) | Acc: (89.00%) (34593/38528)
Epoch: 71 | Batch_idx: 310 |  Loss: (0.2995) |  Loss2: (0.0000) | Acc: (89.00%) (35732/39808)
Epoch: 71 | Batch_idx: 320 |  Loss: (0.3002) |  Loss2: (0.0000) | Acc: (89.00%) (36870/41088)
Epoch: 71 | Batch_idx: 330 |  Loss: (0.3016) |  Loss2: (0.0000) | Acc: (89.00%) (37993/42368)
Epoch: 71 | Batch_idx: 340 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (39145/43648)
Epoch: 71 | Batch_idx: 350 |  Loss: (0.3016) |  Loss2: (0.0000) | Acc: (89.00%) (40302/44928)
Epoch: 71 | Batch_idx: 360 |  Loss: (0.3027) |  Loss2: (0.0000) | Acc: (89.00%) (41426/46208)
Epoch: 71 | Batch_idx: 370 |  Loss: (0.3028) |  Loss2: (0.0000) | Acc: (89.00%) (42557/47488)
Epoch: 71 | Batch_idx: 380 |  Loss: (0.3028) |  Loss2: (0.0000) | Acc: (89.00%) (43697/48768)
Epoch: 71 | Batch_idx: 390 |  Loss: (0.3032) |  Loss2: (0.0000) | Acc: (89.00%) (44792/50000)
# TEST : Loss: (0.4558) | Acc: (84.00%) (8469/10000)
percent tensor([0.5347, 0.5559, 0.5439, 0.5382, 0.5466, 0.5266, 0.5583, 0.5504, 0.5469,
        0.5482, 0.5432, 0.5474, 0.5381, 0.5597, 0.5427, 0.5367],
       device='cuda:0') torch.Size([16])
percent tensor([0.5305, 0.5277, 0.5295, 0.5256, 0.5299, 0.5209, 0.5314, 0.5315, 0.5307,
        0.5276, 0.5276, 0.5316, 0.5301, 0.5265, 0.5243, 0.5265],
       device='cuda:0') torch.Size([16])
percent tensor([0.5473, 0.5848, 0.5489, 0.5780, 0.5950, 0.5731, 0.5997, 0.6130, 0.5615,
        0.5449, 0.5483, 0.5620, 0.5273, 0.6126, 0.6055, 0.5519],
       device='cuda:0') torch.Size([16])
percent tensor([0.6925, 0.6336, 0.6672, 0.6742, 0.7028, 0.7005, 0.6876, 0.6899, 0.6276,
        0.6316, 0.6249, 0.6207, 0.6161, 0.6456, 0.6927, 0.6888],
       device='cuda:0') torch.Size([16])
percent tensor([0.5310, 0.5304, 0.5474, 0.5634, 0.5445, 0.5633, 0.5333, 0.5514, 0.5470,
        0.5251, 0.5287, 0.5442, 0.5198, 0.5458, 0.5374, 0.5497],
       device='cuda:0') torch.Size([16])
percent tensor([0.6447, 0.6752, 0.6817, 0.6981, 0.6903, 0.6667, 0.6899, 0.6717, 0.6878,
        0.6676, 0.6903, 0.7024, 0.6502, 0.7298, 0.6550, 0.6866],
       device='cuda:0') torch.Size([16])
percent tensor([0.5260, 0.5396, 0.6448, 0.6501, 0.5983, 0.6927, 0.5570, 0.5132, 0.5798,
        0.5791, 0.5810, 0.5862, 0.5293, 0.6270, 0.4308, 0.5957],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9989, 0.9992, 0.9992, 0.9994, 0.9981, 0.9990, 0.9995, 0.9989,
        0.9994, 0.9995, 0.9996, 0.9992, 0.9990, 0.9995, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 72 | Batch_idx: 0 |  Loss: (0.3412) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 72 | Batch_idx: 10 |  Loss: (0.2922) |  Loss2: (0.0000) | Acc: (89.00%) (1259/1408)
Epoch: 72 | Batch_idx: 20 |  Loss: (0.3043) |  Loss2: (0.0000) | Acc: (89.00%) (2395/2688)
Epoch: 72 | Batch_idx: 30 |  Loss: (0.2942) |  Loss2: (0.0000) | Acc: (89.00%) (3567/3968)
Epoch: 72 | Batch_idx: 40 |  Loss: (0.2969) |  Loss2: (0.0000) | Acc: (89.00%) (4706/5248)
Epoch: 72 | Batch_idx: 50 |  Loss: (0.2938) |  Loss2: (0.0000) | Acc: (89.00%) (5852/6528)
Epoch: 72 | Batch_idx: 60 |  Loss: (0.2944) |  Loss2: (0.0000) | Acc: (89.00%) (6998/7808)
Epoch: 72 | Batch_idx: 70 |  Loss: (0.2960) |  Loss2: (0.0000) | Acc: (89.00%) (8157/9088)
Epoch: 72 | Batch_idx: 80 |  Loss: (0.2965) |  Loss2: (0.0000) | Acc: (89.00%) (9307/10368)
Epoch: 72 | Batch_idx: 90 |  Loss: (0.2923) |  Loss2: (0.0000) | Acc: (89.00%) (10463/11648)
Epoch: 72 | Batch_idx: 100 |  Loss: (0.2925) |  Loss2: (0.0000) | Acc: (89.00%) (11606/12928)
Epoch: 72 | Batch_idx: 110 |  Loss: (0.2934) |  Loss2: (0.0000) | Acc: (89.00%) (12751/14208)
Epoch: 72 | Batch_idx: 120 |  Loss: (0.2924) |  Loss2: (0.0000) | Acc: (89.00%) (13916/15488)
Epoch: 72 | Batch_idx: 130 |  Loss: (0.2916) |  Loss2: (0.0000) | Acc: (89.00%) (15073/16768)
Epoch: 72 | Batch_idx: 140 |  Loss: (0.2921) |  Loss2: (0.0000) | Acc: (89.00%) (16210/18048)
Epoch: 72 | Batch_idx: 150 |  Loss: (0.2928) |  Loss2: (0.0000) | Acc: (89.00%) (17361/19328)
Epoch: 72 | Batch_idx: 160 |  Loss: (0.2962) |  Loss2: (0.0000) | Acc: (89.00%) (18489/20608)
Epoch: 72 | Batch_idx: 170 |  Loss: (0.2951) |  Loss2: (0.0000) | Acc: (89.00%) (19655/21888)
Epoch: 72 | Batch_idx: 180 |  Loss: (0.2968) |  Loss2: (0.0000) | Acc: (89.00%) (20802/23168)
Epoch: 72 | Batch_idx: 190 |  Loss: (0.2963) |  Loss2: (0.0000) | Acc: (89.00%) (21958/24448)
Epoch: 72 | Batch_idx: 200 |  Loss: (0.2960) |  Loss2: (0.0000) | Acc: (89.00%) (23098/25728)
Epoch: 72 | Batch_idx: 210 |  Loss: (0.2958) |  Loss2: (0.0000) | Acc: (89.00%) (24237/27008)
Epoch: 72 | Batch_idx: 220 |  Loss: (0.2965) |  Loss2: (0.0000) | Acc: (89.00%) (25371/28288)
Epoch: 72 | Batch_idx: 230 |  Loss: (0.2958) |  Loss2: (0.0000) | Acc: (89.00%) (26532/29568)
Epoch: 72 | Batch_idx: 240 |  Loss: (0.2966) |  Loss2: (0.0000) | Acc: (89.00%) (27661/30848)
Epoch: 72 | Batch_idx: 250 |  Loss: (0.2955) |  Loss2: (0.0000) | Acc: (89.00%) (28829/32128)
Epoch: 72 | Batch_idx: 260 |  Loss: (0.2954) |  Loss2: (0.0000) | Acc: (89.00%) (29990/33408)
Epoch: 72 | Batch_idx: 270 |  Loss: (0.2946) |  Loss2: (0.0000) | Acc: (89.00%) (31146/34688)
Epoch: 72 | Batch_idx: 280 |  Loss: (0.2936) |  Loss2: (0.0000) | Acc: (89.00%) (32305/35968)
Epoch: 72 | Batch_idx: 290 |  Loss: (0.2946) |  Loss2: (0.0000) | Acc: (89.00%) (33442/37248)
Epoch: 72 | Batch_idx: 300 |  Loss: (0.2943) |  Loss2: (0.0000) | Acc: (89.00%) (34605/38528)
Epoch: 72 | Batch_idx: 310 |  Loss: (0.2941) |  Loss2: (0.0000) | Acc: (89.00%) (35764/39808)
Epoch: 72 | Batch_idx: 320 |  Loss: (0.2940) |  Loss2: (0.0000) | Acc: (89.00%) (36919/41088)
Epoch: 72 | Batch_idx: 330 |  Loss: (0.2935) |  Loss2: (0.0000) | Acc: (89.00%) (38082/42368)
Epoch: 72 | Batch_idx: 340 |  Loss: (0.2936) |  Loss2: (0.0000) | Acc: (89.00%) (39226/43648)
Epoch: 72 | Batch_idx: 350 |  Loss: (0.2936) |  Loss2: (0.0000) | Acc: (89.00%) (40393/44928)
Epoch: 72 | Batch_idx: 360 |  Loss: (0.2936) |  Loss2: (0.0000) | Acc: (89.00%) (41534/46208)
Epoch: 72 | Batch_idx: 370 |  Loss: (0.2936) |  Loss2: (0.0000) | Acc: (89.00%) (42687/47488)
Epoch: 72 | Batch_idx: 380 |  Loss: (0.2943) |  Loss2: (0.0000) | Acc: (89.00%) (43811/48768)
Epoch: 72 | Batch_idx: 390 |  Loss: (0.2957) |  Loss2: (0.0000) | Acc: (89.00%) (44897/50000)
# TEST : Loss: (0.4229) | Acc: (85.00%) (8579/10000)
percent tensor([0.5346, 0.5557, 0.5423, 0.5378, 0.5454, 0.5262, 0.5577, 0.5500, 0.5472,
        0.5478, 0.5436, 0.5461, 0.5383, 0.5598, 0.5423, 0.5369],
       device='cuda:0') torch.Size([16])
percent tensor([0.5293, 0.5272, 0.5252, 0.5240, 0.5268, 0.5206, 0.5304, 0.5301, 0.5292,
        0.5260, 0.5273, 0.5287, 0.5293, 0.5268, 0.5237, 0.5261],
       device='cuda:0') torch.Size([16])
percent tensor([0.5472, 0.5760, 0.5457, 0.5859, 0.5977, 0.5699, 0.5940, 0.6097, 0.5544,
        0.5411, 0.5457, 0.5604, 0.5274, 0.6038, 0.6036, 0.5558],
       device='cuda:0') torch.Size([16])
percent tensor([0.6879, 0.6183, 0.6669, 0.6666, 0.6935, 0.6993, 0.6739, 0.6856, 0.6253,
        0.6228, 0.6219, 0.6173, 0.6090, 0.6278, 0.6892, 0.6827],
       device='cuda:0') torch.Size([16])
percent tensor([0.5317, 0.5272, 0.5510, 0.5660, 0.5487, 0.5585, 0.5331, 0.5497, 0.5461,
        0.5278, 0.5268, 0.5490, 0.5192, 0.5491, 0.5360, 0.5506],
       device='cuda:0') torch.Size([16])
percent tensor([0.6557, 0.6778, 0.6706, 0.7093, 0.6920, 0.6750, 0.6913, 0.6691, 0.6897,
        0.6699, 0.6952, 0.7042, 0.6544, 0.7310, 0.6635, 0.6836],
       device='cuda:0') torch.Size([16])
percent tensor([0.5367, 0.5273, 0.6350, 0.6770, 0.6277, 0.7015, 0.5476, 0.5144, 0.5785,
        0.5737, 0.5613, 0.5852, 0.5299, 0.6097, 0.4334, 0.5782],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9989, 0.9992, 0.9990, 0.9996, 0.9968, 0.9992, 0.9995, 0.9990,
        0.9995, 0.9991, 0.9996, 0.9986, 0.9988, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 73 | Batch_idx: 0 |  Loss: (0.2431) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 73 | Batch_idx: 10 |  Loss: (0.2849) |  Loss2: (0.0000) | Acc: (90.00%) (1271/1408)
Epoch: 73 | Batch_idx: 20 |  Loss: (0.2933) |  Loss2: (0.0000) | Acc: (90.00%) (2425/2688)
Epoch: 73 | Batch_idx: 30 |  Loss: (0.2892) |  Loss2: (0.0000) | Acc: (90.00%) (3579/3968)
Epoch: 73 | Batch_idx: 40 |  Loss: (0.2834) |  Loss2: (0.0000) | Acc: (90.00%) (4736/5248)
Epoch: 73 | Batch_idx: 50 |  Loss: (0.2823) |  Loss2: (0.0000) | Acc: (90.00%) (5898/6528)
Epoch: 73 | Batch_idx: 60 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (7056/7808)
Epoch: 73 | Batch_idx: 70 |  Loss: (0.2801) |  Loss2: (0.0000) | Acc: (90.00%) (8217/9088)
Epoch: 73 | Batch_idx: 80 |  Loss: (0.2785) |  Loss2: (0.0000) | Acc: (90.00%) (9388/10368)
Epoch: 73 | Batch_idx: 90 |  Loss: (0.2769) |  Loss2: (0.0000) | Acc: (90.00%) (10556/11648)
Epoch: 73 | Batch_idx: 100 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (90.00%) (11735/12928)
Epoch: 73 | Batch_idx: 110 |  Loss: (0.2780) |  Loss2: (0.0000) | Acc: (90.00%) (12885/14208)
Epoch: 73 | Batch_idx: 120 |  Loss: (0.2792) |  Loss2: (0.0000) | Acc: (90.00%) (14042/15488)
Epoch: 73 | Batch_idx: 130 |  Loss: (0.2803) |  Loss2: (0.0000) | Acc: (90.00%) (15189/16768)
Epoch: 73 | Batch_idx: 140 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (90.00%) (16334/18048)
Epoch: 73 | Batch_idx: 150 |  Loss: (0.2825) |  Loss2: (0.0000) | Acc: (90.00%) (17485/19328)
Epoch: 73 | Batch_idx: 160 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (90.00%) (18638/20608)
Epoch: 73 | Batch_idx: 170 |  Loss: (0.2817) |  Loss2: (0.0000) | Acc: (90.00%) (19800/21888)
Epoch: 73 | Batch_idx: 180 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (90.00%) (20946/23168)
Epoch: 73 | Batch_idx: 190 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (22111/24448)
Epoch: 73 | Batch_idx: 200 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (23271/25728)
Epoch: 73 | Batch_idx: 210 |  Loss: (0.2830) |  Loss2: (0.0000) | Acc: (90.00%) (24415/27008)
Epoch: 73 | Batch_idx: 220 |  Loss: (0.2840) |  Loss2: (0.0000) | Acc: (90.00%) (25575/28288)
Epoch: 73 | Batch_idx: 230 |  Loss: (0.2852) |  Loss2: (0.0000) | Acc: (90.00%) (26723/29568)
Epoch: 73 | Batch_idx: 240 |  Loss: (0.2849) |  Loss2: (0.0000) | Acc: (90.00%) (27878/30848)
Epoch: 73 | Batch_idx: 250 |  Loss: (0.2834) |  Loss2: (0.0000) | Acc: (90.00%) (29047/32128)
Epoch: 73 | Batch_idx: 260 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (90.00%) (30195/33408)
Epoch: 73 | Batch_idx: 270 |  Loss: (0.2850) |  Loss2: (0.0000) | Acc: (90.00%) (31349/34688)
Epoch: 73 | Batch_idx: 280 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (90.00%) (32523/35968)
Epoch: 73 | Batch_idx: 290 |  Loss: (0.2845) |  Loss2: (0.0000) | Acc: (90.00%) (33676/37248)
Epoch: 73 | Batch_idx: 300 |  Loss: (0.2856) |  Loss2: (0.0000) | Acc: (90.00%) (34816/38528)
Epoch: 73 | Batch_idx: 310 |  Loss: (0.2860) |  Loss2: (0.0000) | Acc: (90.00%) (35971/39808)
Epoch: 73 | Batch_idx: 320 |  Loss: (0.2863) |  Loss2: (0.0000) | Acc: (90.00%) (37135/41088)
Epoch: 73 | Batch_idx: 330 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (90.00%) (38302/42368)
Epoch: 73 | Batch_idx: 340 |  Loss: (0.2858) |  Loss2: (0.0000) | Acc: (90.00%) (39468/43648)
Epoch: 73 | Batch_idx: 350 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (90.00%) (40615/44928)
Epoch: 73 | Batch_idx: 360 |  Loss: (0.2863) |  Loss2: (0.0000) | Acc: (90.00%) (41770/46208)
Epoch: 73 | Batch_idx: 370 |  Loss: (0.2867) |  Loss2: (0.0000) | Acc: (90.00%) (42922/47488)
Epoch: 73 | Batch_idx: 380 |  Loss: (0.2872) |  Loss2: (0.0000) | Acc: (90.00%) (44070/48768)
Epoch: 73 | Batch_idx: 390 |  Loss: (0.2880) |  Loss2: (0.0000) | Acc: (90.00%) (45149/50000)
# TEST : Loss: (0.4575) | Acc: (84.00%) (8468/10000)
percent tensor([0.5341, 0.5561, 0.5425, 0.5372, 0.5458, 0.5252, 0.5582, 0.5500, 0.5474,
        0.5479, 0.5430, 0.5467, 0.5377, 0.5607, 0.5420, 0.5360],
       device='cuda:0') torch.Size([16])
percent tensor([0.5306, 0.5283, 0.5260, 0.5252, 0.5279, 0.5216, 0.5309, 0.5312, 0.5309,
        0.5271, 0.5281, 0.5288, 0.5299, 0.5280, 0.5248, 0.5276],
       device='cuda:0') torch.Size([16])
percent tensor([0.5503, 0.5809, 0.5512, 0.5793, 0.6067, 0.5782, 0.6017, 0.6135, 0.5663,
        0.5464, 0.5497, 0.5660, 0.5250, 0.6140, 0.6093, 0.5536],
       device='cuda:0') torch.Size([16])
percent tensor([0.6934, 0.6383, 0.6653, 0.6714, 0.6966, 0.7058, 0.6884, 0.6972, 0.6324,
        0.6348, 0.6305, 0.6244, 0.6161, 0.6576, 0.7008, 0.6913],
       device='cuda:0') torch.Size([16])
percent tensor([0.5330, 0.5262, 0.5517, 0.5683, 0.5571, 0.5606, 0.5362, 0.5547, 0.5511,
        0.5241, 0.5294, 0.5488, 0.5191, 0.5438, 0.5350, 0.5494],
       device='cuda:0') torch.Size([16])
percent tensor([0.6522, 0.6712, 0.6696, 0.7063, 0.6903, 0.6754, 0.6925, 0.6713, 0.6977,
        0.6698, 0.6984, 0.7041, 0.6535, 0.7408, 0.6586, 0.6864],
       device='cuda:0') torch.Size([16])
percent tensor([0.5295, 0.5257, 0.6273, 0.6534, 0.6107, 0.6971, 0.5464, 0.5318, 0.6027,
        0.5627, 0.5776, 0.5738, 0.5363, 0.5988, 0.4286, 0.5938],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9991, 0.9994, 0.9990, 0.9997, 0.9981, 0.9989, 0.9995, 0.9988,
        0.9997, 0.9993, 0.9997, 0.9987, 0.9992, 0.9994, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 74 | Batch_idx: 0 |  Loss: (0.3785) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 74 | Batch_idx: 10 |  Loss: (0.3056) |  Loss2: (0.0000) | Acc: (90.00%) (1273/1408)
Epoch: 74 | Batch_idx: 20 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (90.00%) (2445/2688)
Epoch: 74 | Batch_idx: 30 |  Loss: (0.2706) |  Loss2: (0.0000) | Acc: (91.00%) (3620/3968)
Epoch: 74 | Batch_idx: 40 |  Loss: (0.2690) |  Loss2: (0.0000) | Acc: (91.00%) (4788/5248)
Epoch: 74 | Batch_idx: 50 |  Loss: (0.2658) |  Loss2: (0.0000) | Acc: (91.00%) (5950/6528)
Epoch: 74 | Batch_idx: 60 |  Loss: (0.2744) |  Loss2: (0.0000) | Acc: (90.00%) (7089/7808)
Epoch: 74 | Batch_idx: 70 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (8252/9088)
Epoch: 74 | Batch_idx: 80 |  Loss: (0.2735) |  Loss2: (0.0000) | Acc: (90.00%) (9409/10368)
Epoch: 74 | Batch_idx: 90 |  Loss: (0.2736) |  Loss2: (0.0000) | Acc: (90.00%) (10569/11648)
Epoch: 74 | Batch_idx: 100 |  Loss: (0.2753) |  Loss2: (0.0000) | Acc: (90.00%) (11713/12928)
Epoch: 74 | Batch_idx: 110 |  Loss: (0.2748) |  Loss2: (0.0000) | Acc: (90.00%) (12875/14208)
Epoch: 74 | Batch_idx: 120 |  Loss: (0.2768) |  Loss2: (0.0000) | Acc: (90.00%) (14003/15488)
Epoch: 74 | Batch_idx: 130 |  Loss: (0.2761) |  Loss2: (0.0000) | Acc: (90.00%) (15162/16768)
Epoch: 74 | Batch_idx: 140 |  Loss: (0.2748) |  Loss2: (0.0000) | Acc: (90.00%) (16331/18048)
Epoch: 74 | Batch_idx: 150 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (90.00%) (17495/19328)
Epoch: 74 | Batch_idx: 160 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (90.00%) (18656/20608)
Epoch: 74 | Batch_idx: 170 |  Loss: (0.2769) |  Loss2: (0.0000) | Acc: (90.00%) (19799/21888)
Epoch: 74 | Batch_idx: 180 |  Loss: (0.2769) |  Loss2: (0.0000) | Acc: (90.00%) (20957/23168)
Epoch: 74 | Batch_idx: 190 |  Loss: (0.2754) |  Loss2: (0.0000) | Acc: (90.00%) (22131/24448)
Epoch: 74 | Batch_idx: 200 |  Loss: (0.2755) |  Loss2: (0.0000) | Acc: (90.00%) (23282/25728)
Epoch: 74 | Batch_idx: 210 |  Loss: (0.2756) |  Loss2: (0.0000) | Acc: (90.00%) (24433/27008)
Epoch: 74 | Batch_idx: 220 |  Loss: (0.2762) |  Loss2: (0.0000) | Acc: (90.00%) (25579/28288)
Epoch: 74 | Batch_idx: 230 |  Loss: (0.2774) |  Loss2: (0.0000) | Acc: (90.00%) (26717/29568)
Epoch: 74 | Batch_idx: 240 |  Loss: (0.2767) |  Loss2: (0.0000) | Acc: (90.00%) (27881/30848)
Epoch: 74 | Batch_idx: 250 |  Loss: (0.2761) |  Loss2: (0.0000) | Acc: (90.00%) (29054/32128)
Epoch: 74 | Batch_idx: 260 |  Loss: (0.2756) |  Loss2: (0.0000) | Acc: (90.00%) (30215/33408)
Epoch: 74 | Batch_idx: 270 |  Loss: (0.2764) |  Loss2: (0.0000) | Acc: (90.00%) (31355/34688)
Epoch: 74 | Batch_idx: 280 |  Loss: (0.2766) |  Loss2: (0.0000) | Acc: (90.00%) (32508/35968)
Epoch: 74 | Batch_idx: 290 |  Loss: (0.2762) |  Loss2: (0.0000) | Acc: (90.00%) (33670/37248)
Epoch: 74 | Batch_idx: 300 |  Loss: (0.2764) |  Loss2: (0.0000) | Acc: (90.00%) (34825/38528)
Epoch: 74 | Batch_idx: 310 |  Loss: (0.2774) |  Loss2: (0.0000) | Acc: (90.00%) (35965/39808)
Epoch: 74 | Batch_idx: 320 |  Loss: (0.2774) |  Loss2: (0.0000) | Acc: (90.00%) (37121/41088)
Epoch: 74 | Batch_idx: 330 |  Loss: (0.2774) |  Loss2: (0.0000) | Acc: (90.00%) (38282/42368)
Epoch: 74 | Batch_idx: 340 |  Loss: (0.2767) |  Loss2: (0.0000) | Acc: (90.00%) (39441/43648)
Epoch: 74 | Batch_idx: 350 |  Loss: (0.2764) |  Loss2: (0.0000) | Acc: (90.00%) (40602/44928)
Epoch: 74 | Batch_idx: 360 |  Loss: (0.2765) |  Loss2: (0.0000) | Acc: (90.00%) (41761/46208)
Epoch: 74 | Batch_idx: 370 |  Loss: (0.2760) |  Loss2: (0.0000) | Acc: (90.00%) (42932/47488)
Epoch: 74 | Batch_idx: 380 |  Loss: (0.2766) |  Loss2: (0.0000) | Acc: (90.00%) (44094/48768)
Epoch: 74 | Batch_idx: 390 |  Loss: (0.2762) |  Loss2: (0.0000) | Acc: (90.00%) (45204/50000)
# TEST : Loss: (0.4510) | Acc: (85.00%) (8507/10000)
percent tensor([0.5339, 0.5550, 0.5413, 0.5369, 0.5440, 0.5254, 0.5568, 0.5493, 0.5466,
        0.5473, 0.5429, 0.5451, 0.5378, 0.5599, 0.5417, 0.5362],
       device='cuda:0') torch.Size([16])
percent tensor([0.5304, 0.5286, 0.5262, 0.5244, 0.5277, 0.5208, 0.5311, 0.5304, 0.5307,
        0.5271, 0.5278, 0.5292, 0.5302, 0.5267, 0.5246, 0.5269],
       device='cuda:0') torch.Size([16])
percent tensor([0.5567, 0.5782, 0.5568, 0.5929, 0.6069, 0.5915, 0.5977, 0.6175, 0.5640,
        0.5457, 0.5518, 0.5624, 0.5309, 0.6068, 0.6147, 0.5634],
       device='cuda:0') torch.Size([16])
percent tensor([0.6932, 0.6256, 0.6815, 0.6834, 0.7118, 0.7082, 0.6858, 0.6993, 0.6299,
        0.6305, 0.6227, 0.6257, 0.6114, 0.6478, 0.7006, 0.6938],
       device='cuda:0') torch.Size([16])
percent tensor([0.5329, 0.5268, 0.5447, 0.5650, 0.5455, 0.5599, 0.5317, 0.5490, 0.5512,
        0.5248, 0.5317, 0.5464, 0.5212, 0.5430, 0.5369, 0.5500],
       device='cuda:0') torch.Size([16])
percent tensor([0.6554, 0.6794, 0.6760, 0.7077, 0.6989, 0.6849, 0.6909, 0.6744, 0.6954,
        0.6684, 0.6975, 0.7097, 0.6552, 0.7366, 0.6635, 0.6920],
       device='cuda:0') torch.Size([16])
percent tensor([0.5177, 0.5117, 0.6251, 0.6459, 0.6155, 0.7070, 0.5181, 0.5087, 0.5796,
        0.5480, 0.5668, 0.5688, 0.5285, 0.6011, 0.4224, 0.5668],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9992, 0.9994, 0.9988, 0.9998, 0.9977, 0.9987, 0.9997, 0.9991,
        0.9997, 0.9993, 0.9998, 0.9988, 0.9986, 0.9997, 0.9991],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 75 | Batch_idx: 0 |  Loss: (0.3482) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 75 | Batch_idx: 10 |  Loss: (0.2799) |  Loss2: (0.0000) | Acc: (90.00%) (1276/1408)
Epoch: 75 | Batch_idx: 20 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (2411/2688)
Epoch: 75 | Batch_idx: 30 |  Loss: (0.2977) |  Loss2: (0.0000) | Acc: (90.00%) (3573/3968)
Epoch: 75 | Batch_idx: 40 |  Loss: (0.3027) |  Loss2: (0.0000) | Acc: (89.00%) (4715/5248)
Epoch: 75 | Batch_idx: 50 |  Loss: (0.3133) |  Loss2: (0.0000) | Acc: (89.00%) (5829/6528)
Epoch: 75 | Batch_idx: 60 |  Loss: (0.3181) |  Loss2: (0.0000) | Acc: (89.00%) (6956/7808)
Epoch: 75 | Batch_idx: 70 |  Loss: (0.3155) |  Loss2: (0.0000) | Acc: (89.00%) (8100/9088)
Epoch: 75 | Batch_idx: 80 |  Loss: (0.3180) |  Loss2: (0.0000) | Acc: (89.00%) (9230/10368)
Epoch: 75 | Batch_idx: 90 |  Loss: (0.3164) |  Loss2: (0.0000) | Acc: (89.00%) (10367/11648)
Epoch: 75 | Batch_idx: 100 |  Loss: (0.3148) |  Loss2: (0.0000) | Acc: (89.00%) (11507/12928)
Epoch: 75 | Batch_idx: 110 |  Loss: (0.3155) |  Loss2: (0.0000) | Acc: (88.00%) (12634/14208)
Epoch: 75 | Batch_idx: 120 |  Loss: (0.3168) |  Loss2: (0.0000) | Acc: (88.00%) (13766/15488)
Epoch: 75 | Batch_idx: 130 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (88.00%) (14912/16768)
Epoch: 75 | Batch_idx: 140 |  Loss: (0.3152) |  Loss2: (0.0000) | Acc: (88.00%) (16061/18048)
Epoch: 75 | Batch_idx: 150 |  Loss: (0.3136) |  Loss2: (0.0000) | Acc: (89.00%) (17214/19328)
Epoch: 75 | Batch_idx: 160 |  Loss: (0.3120) |  Loss2: (0.0000) | Acc: (89.00%) (18367/20608)
Epoch: 75 | Batch_idx: 170 |  Loss: (0.3111) |  Loss2: (0.0000) | Acc: (89.00%) (19506/21888)
Epoch: 75 | Batch_idx: 180 |  Loss: (0.3097) |  Loss2: (0.0000) | Acc: (89.00%) (20662/23168)
Epoch: 75 | Batch_idx: 190 |  Loss: (0.3085) |  Loss2: (0.0000) | Acc: (89.00%) (21816/24448)
Epoch: 75 | Batch_idx: 200 |  Loss: (0.3085) |  Loss2: (0.0000) | Acc: (89.00%) (22956/25728)
Epoch: 75 | Batch_idx: 210 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (24094/27008)
Epoch: 75 | Batch_idx: 220 |  Loss: (0.3074) |  Loss2: (0.0000) | Acc: (89.00%) (25258/28288)
Epoch: 75 | Batch_idx: 230 |  Loss: (0.3080) |  Loss2: (0.0000) | Acc: (89.00%) (26402/29568)
Epoch: 75 | Batch_idx: 240 |  Loss: (0.3064) |  Loss2: (0.0000) | Acc: (89.00%) (27570/30848)
Epoch: 75 | Batch_idx: 250 |  Loss: (0.3059) |  Loss2: (0.0000) | Acc: (89.00%) (28724/32128)
Epoch: 75 | Batch_idx: 260 |  Loss: (0.3049) |  Loss2: (0.0000) | Acc: (89.00%) (29870/33408)
Epoch: 75 | Batch_idx: 270 |  Loss: (0.3047) |  Loss2: (0.0000) | Acc: (89.00%) (31015/34688)
Epoch: 75 | Batch_idx: 280 |  Loss: (0.3045) |  Loss2: (0.0000) | Acc: (89.00%) (32162/35968)
Epoch: 75 | Batch_idx: 290 |  Loss: (0.3034) |  Loss2: (0.0000) | Acc: (89.00%) (33323/37248)
Epoch: 75 | Batch_idx: 300 |  Loss: (0.3040) |  Loss2: (0.0000) | Acc: (89.00%) (34461/38528)
Epoch: 75 | Batch_idx: 310 |  Loss: (0.3030) |  Loss2: (0.0000) | Acc: (89.00%) (35616/39808)
Epoch: 75 | Batch_idx: 320 |  Loss: (0.3028) |  Loss2: (0.0000) | Acc: (89.00%) (36752/41088)
Epoch: 75 | Batch_idx: 330 |  Loss: (0.3026) |  Loss2: (0.0000) | Acc: (89.00%) (37902/42368)
Epoch: 75 | Batch_idx: 340 |  Loss: (0.3021) |  Loss2: (0.0000) | Acc: (89.00%) (39055/43648)
Epoch: 75 | Batch_idx: 350 |  Loss: (0.3020) |  Loss2: (0.0000) | Acc: (89.00%) (40199/44928)
Epoch: 75 | Batch_idx: 360 |  Loss: (0.3021) |  Loss2: (0.0000) | Acc: (89.00%) (41337/46208)
Epoch: 75 | Batch_idx: 370 |  Loss: (0.3021) |  Loss2: (0.0000) | Acc: (89.00%) (42478/47488)
Epoch: 75 | Batch_idx: 380 |  Loss: (0.3022) |  Loss2: (0.0000) | Acc: (89.00%) (43624/48768)
Epoch: 75 | Batch_idx: 390 |  Loss: (0.3015) |  Loss2: (0.0000) | Acc: (89.00%) (44744/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_075.pth.tar'
# TEST : Loss: (0.4163) | Acc: (86.00%) (8630/10000)
percent tensor([0.5475, 0.5704, 0.5560, 0.5503, 0.5595, 0.5376, 0.5727, 0.5648, 0.5610,
        0.5622, 0.5569, 0.5604, 0.5517, 0.5744, 0.5558, 0.5495],
       device='cuda:0') torch.Size([16])
percent tensor([0.5237, 0.5214, 0.5189, 0.5181, 0.5204, 0.5143, 0.5236, 0.5235, 0.5232,
        0.5198, 0.5201, 0.5216, 0.5230, 0.5196, 0.5176, 0.5198],
       device='cuda:0') torch.Size([16])
percent tensor([0.5587, 0.5881, 0.5557, 0.5947, 0.6070, 0.5896, 0.6041, 0.6238, 0.5643,
        0.5520, 0.5549, 0.5645, 0.5341, 0.6150, 0.6201, 0.5673],
       device='cuda:0') torch.Size([16])
percent tensor([0.6891, 0.6234, 0.6750, 0.6806, 0.7052, 0.6979, 0.6824, 0.6964, 0.6306,
        0.6292, 0.6237, 0.6261, 0.6083, 0.6495, 0.6963, 0.6874],
       device='cuda:0') torch.Size([16])
percent tensor([0.5177, 0.5180, 0.5287, 0.5442, 0.5252, 0.5378, 0.5199, 0.5314, 0.5404,
        0.5174, 0.5255, 0.5344, 0.5131, 0.5368, 0.5204, 0.5334],
       device='cuda:0') torch.Size([16])
percent tensor([0.6167, 0.6400, 0.6350, 0.6694, 0.6524, 0.6491, 0.6552, 0.6269, 0.6580,
        0.6312, 0.6597, 0.6655, 0.6143, 0.7008, 0.6196, 0.6540],
       device='cuda:0') torch.Size([16])
percent tensor([0.5346, 0.5309, 0.6430, 0.6635, 0.6175, 0.7400, 0.5453, 0.5003, 0.6103,
        0.5606, 0.5821, 0.5761, 0.5479, 0.6358, 0.4205, 0.5938],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9990, 0.9991, 0.9984, 0.9997, 0.9984, 0.9982, 0.9996, 0.9991,
        0.9995, 0.9993, 0.9997, 0.9989, 0.9988, 0.9994, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 76 | Batch_idx: 0 |  Loss: (0.3486) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 76 | Batch_idx: 10 |  Loss: (0.2836) |  Loss2: (0.0000) | Acc: (90.00%) (1277/1408)
Epoch: 76 | Batch_idx: 20 |  Loss: (0.2915) |  Loss2: (0.0000) | Acc: (89.00%) (2413/2688)
Epoch: 76 | Batch_idx: 30 |  Loss: (0.2937) |  Loss2: (0.0000) | Acc: (89.00%) (3548/3968)
Epoch: 76 | Batch_idx: 40 |  Loss: (0.2866) |  Loss2: (0.0000) | Acc: (89.00%) (4717/5248)
Epoch: 76 | Batch_idx: 50 |  Loss: (0.2815) |  Loss2: (0.0000) | Acc: (90.00%) (5889/6528)
Epoch: 76 | Batch_idx: 60 |  Loss: (0.2842) |  Loss2: (0.0000) | Acc: (90.00%) (7042/7808)
Epoch: 76 | Batch_idx: 70 |  Loss: (0.2844) |  Loss2: (0.0000) | Acc: (90.00%) (8202/9088)
Epoch: 76 | Batch_idx: 80 |  Loss: (0.2875) |  Loss2: (0.0000) | Acc: (90.00%) (9357/10368)
Epoch: 76 | Batch_idx: 90 |  Loss: (0.2894) |  Loss2: (0.0000) | Acc: (90.00%) (10506/11648)
Epoch: 76 | Batch_idx: 100 |  Loss: (0.2859) |  Loss2: (0.0000) | Acc: (90.00%) (11677/12928)
Epoch: 76 | Batch_idx: 110 |  Loss: (0.2862) |  Loss2: (0.0000) | Acc: (90.00%) (12833/14208)
Epoch: 76 | Batch_idx: 120 |  Loss: (0.2849) |  Loss2: (0.0000) | Acc: (90.00%) (13989/15488)
Epoch: 76 | Batch_idx: 130 |  Loss: (0.2859) |  Loss2: (0.0000) | Acc: (90.00%) (15145/16768)
Epoch: 76 | Batch_idx: 140 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (90.00%) (16310/18048)
Epoch: 76 | Batch_idx: 150 |  Loss: (0.2863) |  Loss2: (0.0000) | Acc: (90.00%) (17455/19328)
Epoch: 76 | Batch_idx: 160 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (90.00%) (18616/20608)
Epoch: 76 | Batch_idx: 170 |  Loss: (0.2869) |  Loss2: (0.0000) | Acc: (90.00%) (19758/21888)
Epoch: 76 | Batch_idx: 180 |  Loss: (0.2869) |  Loss2: (0.0000) | Acc: (90.00%) (20910/23168)
Epoch: 76 | Batch_idx: 190 |  Loss: (0.2870) |  Loss2: (0.0000) | Acc: (90.00%) (22070/24448)
Epoch: 76 | Batch_idx: 200 |  Loss: (0.2863) |  Loss2: (0.0000) | Acc: (90.00%) (23233/25728)
Epoch: 76 | Batch_idx: 210 |  Loss: (0.2871) |  Loss2: (0.0000) | Acc: (90.00%) (24380/27008)
Epoch: 76 | Batch_idx: 220 |  Loss: (0.2873) |  Loss2: (0.0000) | Acc: (90.00%) (25532/28288)
Epoch: 76 | Batch_idx: 230 |  Loss: (0.2869) |  Loss2: (0.0000) | Acc: (90.00%) (26693/29568)
Epoch: 76 | Batch_idx: 240 |  Loss: (0.2865) |  Loss2: (0.0000) | Acc: (90.00%) (27852/30848)
Epoch: 76 | Batch_idx: 250 |  Loss: (0.2860) |  Loss2: (0.0000) | Acc: (90.00%) (29005/32128)
Epoch: 76 | Batch_idx: 260 |  Loss: (0.2863) |  Loss2: (0.0000) | Acc: (90.00%) (30159/33408)
Epoch: 76 | Batch_idx: 270 |  Loss: (0.2862) |  Loss2: (0.0000) | Acc: (90.00%) (31308/34688)
Epoch: 76 | Batch_idx: 280 |  Loss: (0.2852) |  Loss2: (0.0000) | Acc: (90.00%) (32474/35968)
Epoch: 76 | Batch_idx: 290 |  Loss: (0.2848) |  Loss2: (0.0000) | Acc: (90.00%) (33633/37248)
Epoch: 76 | Batch_idx: 300 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (90.00%) (34788/38528)
Epoch: 76 | Batch_idx: 310 |  Loss: (0.2836) |  Loss2: (0.0000) | Acc: (90.00%) (35950/39808)
Epoch: 76 | Batch_idx: 320 |  Loss: (0.2830) |  Loss2: (0.0000) | Acc: (90.00%) (37113/41088)
Epoch: 76 | Batch_idx: 330 |  Loss: (0.2826) |  Loss2: (0.0000) | Acc: (90.00%) (38270/42368)
Epoch: 76 | Batch_idx: 340 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (39438/43648)
Epoch: 76 | Batch_idx: 350 |  Loss: (0.2817) |  Loss2: (0.0000) | Acc: (90.00%) (40606/44928)
Epoch: 76 | Batch_idx: 360 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (41760/46208)
Epoch: 76 | Batch_idx: 370 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (42913/47488)
Epoch: 76 | Batch_idx: 380 |  Loss: (0.2818) |  Loss2: (0.0000) | Acc: (90.00%) (44079/48768)
Epoch: 76 | Batch_idx: 390 |  Loss: (0.2811) |  Loss2: (0.0000) | Acc: (90.00%) (45205/50000)
# TEST : Loss: (0.4052) | Acc: (86.00%) (8678/10000)
percent tensor([0.5476, 0.5697, 0.5559, 0.5500, 0.5593, 0.5382, 0.5722, 0.5643, 0.5611,
        0.5616, 0.5570, 0.5601, 0.5516, 0.5739, 0.5555, 0.5493],
       device='cuda:0') torch.Size([16])
percent tensor([0.5206, 0.5182, 0.5155, 0.5147, 0.5170, 0.5111, 0.5203, 0.5201, 0.5196,
        0.5164, 0.5166, 0.5179, 0.5196, 0.5165, 0.5144, 0.5165],
       device='cuda:0') torch.Size([16])
percent tensor([0.5552, 0.5885, 0.5506, 0.5900, 0.6031, 0.5878, 0.6029, 0.6198, 0.5603,
        0.5496, 0.5529, 0.5621, 0.5326, 0.6138, 0.6192, 0.5647],
       device='cuda:0') torch.Size([16])
percent tensor([0.6846, 0.6188, 0.6702, 0.6757, 0.6997, 0.6921, 0.6772, 0.6915, 0.6293,
        0.6253, 0.6220, 0.6231, 0.6046, 0.6451, 0.6914, 0.6805],
       device='cuda:0') torch.Size([16])
percent tensor([0.5160, 0.5193, 0.5251, 0.5399, 0.5205, 0.5309, 0.5196, 0.5295, 0.5414,
        0.5189, 0.5275, 0.5353, 0.5141, 0.5388, 0.5195, 0.5294],
       device='cuda:0') torch.Size([16])
percent tensor([0.6189, 0.6402, 0.6340, 0.6681, 0.6516, 0.6484, 0.6552, 0.6260, 0.6570,
        0.6331, 0.6587, 0.6638, 0.6138, 0.7009, 0.6204, 0.6564],
       device='cuda:0') torch.Size([16])
percent tensor([0.5362, 0.5280, 0.6457, 0.6679, 0.6226, 0.7528, 0.5471, 0.4976, 0.6150,
        0.5561, 0.5832, 0.5685, 0.5425, 0.6493, 0.4160, 0.6000],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9991, 0.9992, 0.9986, 0.9997, 0.9985, 0.9984, 0.9996, 0.9992,
        0.9995, 0.9993, 0.9997, 0.9990, 0.9989, 0.9994, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 77 | Batch_idx: 0 |  Loss: (0.2227) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 77 | Batch_idx: 10 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (1268/1408)
Epoch: 77 | Batch_idx: 20 |  Loss: (0.2795) |  Loss2: (0.0000) | Acc: (89.00%) (2419/2688)
Epoch: 77 | Batch_idx: 30 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (3588/3968)
Epoch: 77 | Batch_idx: 40 |  Loss: (0.2757) |  Loss2: (0.0000) | Acc: (90.00%) (4739/5248)
Epoch: 77 | Batch_idx: 50 |  Loss: (0.2755) |  Loss2: (0.0000) | Acc: (90.00%) (5900/6528)
Epoch: 77 | Batch_idx: 60 |  Loss: (0.2790) |  Loss2: (0.0000) | Acc: (90.00%) (7051/7808)
Epoch: 77 | Batch_idx: 70 |  Loss: (0.2733) |  Loss2: (0.0000) | Acc: (90.00%) (8219/9088)
Epoch: 77 | Batch_idx: 80 |  Loss: (0.2731) |  Loss2: (0.0000) | Acc: (90.00%) (9381/10368)
Epoch: 77 | Batch_idx: 90 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (90.00%) (10543/11648)
Epoch: 77 | Batch_idx: 100 |  Loss: (0.2735) |  Loss2: (0.0000) | Acc: (90.00%) (11713/12928)
Epoch: 77 | Batch_idx: 110 |  Loss: (0.2742) |  Loss2: (0.0000) | Acc: (90.00%) (12871/14208)
Epoch: 77 | Batch_idx: 120 |  Loss: (0.2759) |  Loss2: (0.0000) | Acc: (90.00%) (14028/15488)
Epoch: 77 | Batch_idx: 130 |  Loss: (0.2754) |  Loss2: (0.0000) | Acc: (90.00%) (15188/16768)
Epoch: 77 | Batch_idx: 140 |  Loss: (0.2748) |  Loss2: (0.0000) | Acc: (90.00%) (16355/18048)
Epoch: 77 | Batch_idx: 150 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (90.00%) (17505/19328)
Epoch: 77 | Batch_idx: 160 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (18668/20608)
Epoch: 77 | Batch_idx: 170 |  Loss: (0.2760) |  Loss2: (0.0000) | Acc: (90.00%) (19818/21888)
Epoch: 77 | Batch_idx: 180 |  Loss: (0.2748) |  Loss2: (0.0000) | Acc: (90.00%) (20985/23168)
Epoch: 77 | Batch_idx: 190 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (22153/24448)
Epoch: 77 | Batch_idx: 200 |  Loss: (0.2756) |  Loss2: (0.0000) | Acc: (90.00%) (23294/25728)
Epoch: 77 | Batch_idx: 210 |  Loss: (0.2741) |  Loss2: (0.0000) | Acc: (90.00%) (24477/27008)
Epoch: 77 | Batch_idx: 220 |  Loss: (0.2743) |  Loss2: (0.0000) | Acc: (90.00%) (25634/28288)
Epoch: 77 | Batch_idx: 230 |  Loss: (0.2744) |  Loss2: (0.0000) | Acc: (90.00%) (26792/29568)
Epoch: 77 | Batch_idx: 240 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (27945/30848)
Epoch: 77 | Batch_idx: 250 |  Loss: (0.2742) |  Loss2: (0.0000) | Acc: (90.00%) (29112/32128)
Epoch: 77 | Batch_idx: 260 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (30279/33408)
Epoch: 77 | Batch_idx: 270 |  Loss: (0.2728) |  Loss2: (0.0000) | Acc: (90.00%) (31443/34688)
Epoch: 77 | Batch_idx: 280 |  Loss: (0.2729) |  Loss2: (0.0000) | Acc: (90.00%) (32608/35968)
Epoch: 77 | Batch_idx: 290 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (33768/37248)
Epoch: 77 | Batch_idx: 300 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (34922/38528)
Epoch: 77 | Batch_idx: 310 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (36091/39808)
Epoch: 77 | Batch_idx: 320 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (37250/41088)
Epoch: 77 | Batch_idx: 330 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (38420/42368)
Epoch: 77 | Batch_idx: 340 |  Loss: (0.2721) |  Loss2: (0.0000) | Acc: (90.00%) (39588/43648)
Epoch: 77 | Batch_idx: 350 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (40735/44928)
Epoch: 77 | Batch_idx: 360 |  Loss: (0.2729) |  Loss2: (0.0000) | Acc: (90.00%) (41879/46208)
Epoch: 77 | Batch_idx: 370 |  Loss: (0.2730) |  Loss2: (0.0000) | Acc: (90.00%) (43040/47488)
Epoch: 77 | Batch_idx: 380 |  Loss: (0.2740) |  Loss2: (0.0000) | Acc: (90.00%) (44188/48768)
Epoch: 77 | Batch_idx: 390 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (45300/50000)
# TEST : Loss: (0.3980) | Acc: (86.00%) (8699/10000)
percent tensor([0.5473, 0.5686, 0.5556, 0.5494, 0.5587, 0.5381, 0.5713, 0.5635, 0.5605,
        0.5606, 0.5563, 0.5595, 0.5510, 0.5728, 0.5548, 0.5486],
       device='cuda:0') torch.Size([16])
percent tensor([0.5212, 0.5189, 0.5158, 0.5153, 0.5176, 0.5114, 0.5211, 0.5207, 0.5200,
        0.5169, 0.5169, 0.5184, 0.5202, 0.5171, 0.5150, 0.5170],
       device='cuda:0') torch.Size([16])
percent tensor([0.5547, 0.5888, 0.5519, 0.5922, 0.6044, 0.5893, 0.6032, 0.6214, 0.5606,
        0.5485, 0.5520, 0.5636, 0.5316, 0.6151, 0.6201, 0.5642],
       device='cuda:0') torch.Size([16])
percent tensor([0.6910, 0.6249, 0.6749, 0.6812, 0.7043, 0.6962, 0.6835, 0.6983, 0.6368,
        0.6321, 0.6296, 0.6303, 0.6104, 0.6522, 0.6979, 0.6856],
       device='cuda:0') torch.Size([16])
percent tensor([0.5196, 0.5250, 0.5268, 0.5405, 0.5219, 0.5307, 0.5238, 0.5326, 0.5468,
        0.5241, 0.5330, 0.5404, 0.5203, 0.5441, 0.5237, 0.5308],
       device='cuda:0') torch.Size([16])
percent tensor([0.6243, 0.6465, 0.6384, 0.6743, 0.6569, 0.6534, 0.6619, 0.6322, 0.6623,
        0.6398, 0.6643, 0.6697, 0.6188, 0.7085, 0.6267, 0.6637],
       device='cuda:0') torch.Size([16])
percent tensor([0.5346, 0.5297, 0.6521, 0.6736, 0.6288, 0.7613, 0.5478, 0.5000, 0.6211,
        0.5568, 0.5892, 0.5667, 0.5387, 0.6629, 0.4115, 0.5998],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9991, 0.9993, 0.9987, 0.9997, 0.9986, 0.9986, 0.9996, 0.9992,
        0.9996, 0.9994, 0.9997, 0.9990, 0.9990, 0.9995, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 78 | Batch_idx: 0 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 78 | Batch_idx: 10 |  Loss: (0.2733) |  Loss2: (0.0000) | Acc: (90.00%) (1277/1408)
Epoch: 78 | Batch_idx: 20 |  Loss: (0.2748) |  Loss2: (0.0000) | Acc: (90.00%) (2437/2688)
Epoch: 78 | Batch_idx: 30 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (90.00%) (3607/3968)
Epoch: 78 | Batch_idx: 40 |  Loss: (0.2616) |  Loss2: (0.0000) | Acc: (91.00%) (4787/5248)
Epoch: 78 | Batch_idx: 50 |  Loss: (0.2590) |  Loss2: (0.0000) | Acc: (91.00%) (5971/6528)
Epoch: 78 | Batch_idx: 60 |  Loss: (0.2643) |  Loss2: (0.0000) | Acc: (91.00%) (7131/7808)
Epoch: 78 | Batch_idx: 70 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (91.00%) (8287/9088)
Epoch: 78 | Batch_idx: 80 |  Loss: (0.2701) |  Loss2: (0.0000) | Acc: (90.00%) (9430/10368)
Epoch: 78 | Batch_idx: 90 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (90.00%) (10595/11648)
Epoch: 78 | Batch_idx: 100 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (11754/12928)
Epoch: 78 | Batch_idx: 110 |  Loss: (0.2677) |  Loss2: (0.0000) | Acc: (91.00%) (12937/14208)
Epoch: 78 | Batch_idx: 120 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (91.00%) (14106/15488)
Epoch: 78 | Batch_idx: 130 |  Loss: (0.2646) |  Loss2: (0.0000) | Acc: (91.00%) (15285/16768)
Epoch: 78 | Batch_idx: 140 |  Loss: (0.2655) |  Loss2: (0.0000) | Acc: (91.00%) (16438/18048)
Epoch: 78 | Batch_idx: 150 |  Loss: (0.2656) |  Loss2: (0.0000) | Acc: (91.00%) (17604/19328)
Epoch: 78 | Batch_idx: 160 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (91.00%) (18771/20608)
Epoch: 78 | Batch_idx: 170 |  Loss: (0.2669) |  Loss2: (0.0000) | Acc: (91.00%) (19939/21888)
Epoch: 78 | Batch_idx: 180 |  Loss: (0.2666) |  Loss2: (0.0000) | Acc: (91.00%) (21090/23168)
Epoch: 78 | Batch_idx: 190 |  Loss: (0.2660) |  Loss2: (0.0000) | Acc: (91.00%) (22261/24448)
Epoch: 78 | Batch_idx: 200 |  Loss: (0.2658) |  Loss2: (0.0000) | Acc: (91.00%) (23430/25728)
Epoch: 78 | Batch_idx: 210 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (91.00%) (24607/27008)
Epoch: 78 | Batch_idx: 220 |  Loss: (0.2647) |  Loss2: (0.0000) | Acc: (91.00%) (25767/28288)
Epoch: 78 | Batch_idx: 230 |  Loss: (0.2644) |  Loss2: (0.0000) | Acc: (91.00%) (26924/29568)
Epoch: 78 | Batch_idx: 240 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (91.00%) (28073/30848)
Epoch: 78 | Batch_idx: 250 |  Loss: (0.2656) |  Loss2: (0.0000) | Acc: (91.00%) (29246/32128)
Epoch: 78 | Batch_idx: 260 |  Loss: (0.2669) |  Loss2: (0.0000) | Acc: (91.00%) (30404/33408)
Epoch: 78 | Batch_idx: 270 |  Loss: (0.2668) |  Loss2: (0.0000) | Acc: (90.00%) (31562/34688)
Epoch: 78 | Batch_idx: 280 |  Loss: (0.2679) |  Loss2: (0.0000) | Acc: (90.00%) (32707/35968)
Epoch: 78 | Batch_idx: 290 |  Loss: (0.2692) |  Loss2: (0.0000) | Acc: (90.00%) (33853/37248)
Epoch: 78 | Batch_idx: 300 |  Loss: (0.2692) |  Loss2: (0.0000) | Acc: (90.00%) (35017/38528)
Epoch: 78 | Batch_idx: 310 |  Loss: (0.2688) |  Loss2: (0.0000) | Acc: (90.00%) (36170/39808)
Epoch: 78 | Batch_idx: 320 |  Loss: (0.2680) |  Loss2: (0.0000) | Acc: (90.00%) (37344/41088)
Epoch: 78 | Batch_idx: 330 |  Loss: (0.2684) |  Loss2: (0.0000) | Acc: (90.00%) (38503/42368)
Epoch: 78 | Batch_idx: 340 |  Loss: (0.2686) |  Loss2: (0.0000) | Acc: (90.00%) (39659/43648)
Epoch: 78 | Batch_idx: 350 |  Loss: (0.2683) |  Loss2: (0.0000) | Acc: (90.00%) (40826/44928)
Epoch: 78 | Batch_idx: 360 |  Loss: (0.2684) |  Loss2: (0.0000) | Acc: (90.00%) (41977/46208)
Epoch: 78 | Batch_idx: 370 |  Loss: (0.2691) |  Loss2: (0.0000) | Acc: (90.00%) (43118/47488)
Epoch: 78 | Batch_idx: 380 |  Loss: (0.2685) |  Loss2: (0.0000) | Acc: (90.00%) (44299/48768)
Epoch: 78 | Batch_idx: 390 |  Loss: (0.2688) |  Loss2: (0.0000) | Acc: (90.00%) (45408/50000)
# TEST : Loss: (0.3924) | Acc: (86.00%) (8692/10000)
percent tensor([0.5506, 0.5718, 0.5586, 0.5523, 0.5619, 0.5413, 0.5747, 0.5664, 0.5642,
        0.5636, 0.5598, 0.5626, 0.5542, 0.5764, 0.5578, 0.5516],
       device='cuda:0') torch.Size([16])
percent tensor([0.5212, 0.5189, 0.5151, 0.5148, 0.5173, 0.5110, 0.5212, 0.5203, 0.5195,
        0.5166, 0.5166, 0.5178, 0.5200, 0.5169, 0.5149, 0.5169],
       device='cuda:0') torch.Size([16])
percent tensor([0.5571, 0.5900, 0.5512, 0.5918, 0.6032, 0.5947, 0.6032, 0.6202, 0.5619,
        0.5486, 0.5544, 0.5633, 0.5335, 0.6170, 0.6222, 0.5670],
       device='cuda:0') torch.Size([16])
percent tensor([0.6960, 0.6293, 0.6788, 0.6854, 0.7075, 0.7012, 0.6878, 0.7021, 0.6431,
        0.6360, 0.6363, 0.6350, 0.6155, 0.6571, 0.7029, 0.6897],
       device='cuda:0') torch.Size([16])
percent tensor([0.5207, 0.5283, 0.5269, 0.5397, 0.5224, 0.5288, 0.5257, 0.5340, 0.5495,
        0.5271, 0.5353, 0.5420, 0.5233, 0.5466, 0.5248, 0.5313],
       device='cuda:0') torch.Size([16])
percent tensor([0.6305, 0.6514, 0.6424, 0.6783, 0.6602, 0.6576, 0.6664, 0.6362, 0.6669,
        0.6455, 0.6694, 0.6737, 0.6246, 0.7136, 0.6324, 0.6697],
       device='cuda:0') torch.Size([16])
percent tensor([0.5393, 0.5311, 0.6605, 0.6851, 0.6382, 0.7689, 0.5569, 0.5145, 0.6244,
        0.5579, 0.5926, 0.5691, 0.5348, 0.6719, 0.4149, 0.6091],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9992, 0.9993, 0.9988, 0.9997, 0.9987, 0.9986, 0.9996, 0.9993,
        0.9996, 0.9994, 0.9997, 0.9991, 0.9990, 0.9995, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 79 | Batch_idx: 0 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 79 | Batch_idx: 10 |  Loss: (0.2491) |  Loss2: (0.0000) | Acc: (90.00%) (1281/1408)
Epoch: 79 | Batch_idx: 20 |  Loss: (0.2574) |  Loss2: (0.0000) | Acc: (91.00%) (2455/2688)
Epoch: 79 | Batch_idx: 30 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (91.00%) (3628/3968)
Epoch: 79 | Batch_idx: 40 |  Loss: (0.2542) |  Loss2: (0.0000) | Acc: (91.00%) (4783/5248)
Epoch: 79 | Batch_idx: 50 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (5950/6528)
Epoch: 79 | Batch_idx: 60 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (7124/7808)
Epoch: 79 | Batch_idx: 70 |  Loss: (0.2571) |  Loss2: (0.0000) | Acc: (91.00%) (8275/9088)
Epoch: 79 | Batch_idx: 80 |  Loss: (0.2543) |  Loss2: (0.0000) | Acc: (91.00%) (9450/10368)
Epoch: 79 | Batch_idx: 90 |  Loss: (0.2584) |  Loss2: (0.0000) | Acc: (90.00%) (10595/11648)
Epoch: 79 | Batch_idx: 100 |  Loss: (0.2596) |  Loss2: (0.0000) | Acc: (90.00%) (11755/12928)
Epoch: 79 | Batch_idx: 110 |  Loss: (0.2615) |  Loss2: (0.0000) | Acc: (90.00%) (12913/14208)
Epoch: 79 | Batch_idx: 120 |  Loss: (0.2630) |  Loss2: (0.0000) | Acc: (90.00%) (14074/15488)
Epoch: 79 | Batch_idx: 130 |  Loss: (0.2642) |  Loss2: (0.0000) | Acc: (90.00%) (15232/16768)
Epoch: 79 | Batch_idx: 140 |  Loss: (0.2639) |  Loss2: (0.0000) | Acc: (90.00%) (16398/18048)
Epoch: 79 | Batch_idx: 150 |  Loss: (0.2644) |  Loss2: (0.0000) | Acc: (90.00%) (17559/19328)
Epoch: 79 | Batch_idx: 160 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (90.00%) (18731/20608)
Epoch: 79 | Batch_idx: 170 |  Loss: (0.2643) |  Loss2: (0.0000) | Acc: (90.00%) (19884/21888)
Epoch: 79 | Batch_idx: 180 |  Loss: (0.2641) |  Loss2: (0.0000) | Acc: (90.00%) (21058/23168)
Epoch: 79 | Batch_idx: 190 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (90.00%) (22222/24448)
Epoch: 79 | Batch_idx: 200 |  Loss: (0.2637) |  Loss2: (0.0000) | Acc: (90.00%) (23387/25728)
Epoch: 79 | Batch_idx: 210 |  Loss: (0.2631) |  Loss2: (0.0000) | Acc: (90.00%) (24556/27008)
Epoch: 79 | Batch_idx: 220 |  Loss: (0.2634) |  Loss2: (0.0000) | Acc: (90.00%) (25722/28288)
Epoch: 79 | Batch_idx: 230 |  Loss: (0.2625) |  Loss2: (0.0000) | Acc: (91.00%) (26908/29568)
Epoch: 79 | Batch_idx: 240 |  Loss: (0.2635) |  Loss2: (0.0000) | Acc: (91.00%) (28077/30848)
Epoch: 79 | Batch_idx: 250 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (91.00%) (29237/32128)
Epoch: 79 | Batch_idx: 260 |  Loss: (0.2644) |  Loss2: (0.0000) | Acc: (90.00%) (30394/33408)
Epoch: 79 | Batch_idx: 270 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (90.00%) (31560/34688)
Epoch: 79 | Batch_idx: 280 |  Loss: (0.2643) |  Loss2: (0.0000) | Acc: (90.00%) (32726/35968)
Epoch: 79 | Batch_idx: 290 |  Loss: (0.2647) |  Loss2: (0.0000) | Acc: (90.00%) (33885/37248)
Epoch: 79 | Batch_idx: 300 |  Loss: (0.2643) |  Loss2: (0.0000) | Acc: (90.00%) (35049/38528)
Epoch: 79 | Batch_idx: 310 |  Loss: (0.2642) |  Loss2: (0.0000) | Acc: (90.00%) (36212/39808)
Epoch: 79 | Batch_idx: 320 |  Loss: (0.2645) |  Loss2: (0.0000) | Acc: (90.00%) (37372/41088)
Epoch: 79 | Batch_idx: 330 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (90.00%) (38537/42368)
Epoch: 79 | Batch_idx: 340 |  Loss: (0.2646) |  Loss2: (0.0000) | Acc: (90.00%) (39695/43648)
Epoch: 79 | Batch_idx: 350 |  Loss: (0.2639) |  Loss2: (0.0000) | Acc: (90.00%) (40875/44928)
Epoch: 79 | Batch_idx: 360 |  Loss: (0.2629) |  Loss2: (0.0000) | Acc: (91.00%) (42055/46208)
Epoch: 79 | Batch_idx: 370 |  Loss: (0.2629) |  Loss2: (0.0000) | Acc: (91.00%) (43223/47488)
Epoch: 79 | Batch_idx: 380 |  Loss: (0.2636) |  Loss2: (0.0000) | Acc: (90.00%) (44372/48768)
Epoch: 79 | Batch_idx: 390 |  Loss: (0.2640) |  Loss2: (0.0000) | Acc: (90.00%) (45487/50000)
# TEST : Loss: (0.3886) | Acc: (87.00%) (8706/10000)
percent tensor([0.5495, 0.5703, 0.5576, 0.5509, 0.5607, 0.5405, 0.5733, 0.5650, 0.5632,
        0.5623, 0.5587, 0.5614, 0.5531, 0.5749, 0.5566, 0.5502],
       device='cuda:0') torch.Size([16])
percent tensor([0.5230, 0.5209, 0.5169, 0.5167, 0.5193, 0.5127, 0.5234, 0.5225, 0.5212,
        0.5184, 0.5183, 0.5197, 0.5218, 0.5186, 0.5170, 0.5187],
       device='cuda:0') torch.Size([16])
percent tensor([0.5500, 0.5832, 0.5460, 0.5873, 0.5981, 0.5892, 0.5964, 0.6145, 0.5548,
        0.5409, 0.5465, 0.5580, 0.5269, 0.6093, 0.6163, 0.5603],
       device='cuda:0') torch.Size([16])
percent tensor([0.6945, 0.6281, 0.6780, 0.6853, 0.7061, 0.6994, 0.6861, 0.7007, 0.6436,
        0.6353, 0.6363, 0.6355, 0.6149, 0.6563, 0.7015, 0.6879],
       device='cuda:0') torch.Size([16])
percent tensor([0.5236, 0.5316, 0.5289, 0.5412, 0.5232, 0.5303, 0.5280, 0.5367, 0.5535,
        0.5297, 0.5381, 0.5451, 0.5269, 0.5496, 0.5273, 0.5315],
       device='cuda:0') torch.Size([16])
percent tensor([0.6277, 0.6486, 0.6389, 0.6758, 0.6562, 0.6553, 0.6632, 0.6324, 0.6638,
        0.6426, 0.6669, 0.6711, 0.6225, 0.7108, 0.6285, 0.6670],
       device='cuda:0') torch.Size([16])
percent tensor([0.5464, 0.5344, 0.6658, 0.6884, 0.6401, 0.7773, 0.5590, 0.5162, 0.6299,
        0.5616, 0.5980, 0.5708, 0.5410, 0.6764, 0.4146, 0.6153],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9992, 0.9993, 0.9989, 0.9997, 0.9987, 0.9987, 0.9996, 0.9993,
        0.9996, 0.9995, 0.9997, 0.9991, 0.9991, 0.9995, 0.9993],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 80 | Batch_idx: 0 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 80 | Batch_idx: 10 |  Loss: (0.2574) |  Loss2: (0.0000) | Acc: (91.00%) (1286/1408)
Epoch: 80 | Batch_idx: 20 |  Loss: (0.2598) |  Loss2: (0.0000) | Acc: (91.00%) (2452/2688)
Epoch: 80 | Batch_idx: 30 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (91.00%) (3615/3968)
Epoch: 80 | Batch_idx: 40 |  Loss: (0.2564) |  Loss2: (0.0000) | Acc: (91.00%) (4780/5248)
Epoch: 80 | Batch_idx: 50 |  Loss: (0.2593) |  Loss2: (0.0000) | Acc: (90.00%) (5935/6528)
Epoch: 80 | Batch_idx: 60 |  Loss: (0.2632) |  Loss2: (0.0000) | Acc: (90.00%) (7094/7808)
Epoch: 80 | Batch_idx: 70 |  Loss: (0.2641) |  Loss2: (0.0000) | Acc: (90.00%) (8256/9088)
Epoch: 80 | Batch_idx: 80 |  Loss: (0.2622) |  Loss2: (0.0000) | Acc: (90.00%) (9423/10368)
Epoch: 80 | Batch_idx: 90 |  Loss: (0.2628) |  Loss2: (0.0000) | Acc: (90.00%) (10584/11648)
Epoch: 80 | Batch_idx: 100 |  Loss: (0.2649) |  Loss2: (0.0000) | Acc: (90.00%) (11750/12928)
Epoch: 80 | Batch_idx: 110 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (12907/14208)
Epoch: 80 | Batch_idx: 120 |  Loss: (0.2645) |  Loss2: (0.0000) | Acc: (90.00%) (14083/15488)
Epoch: 80 | Batch_idx: 130 |  Loss: (0.2658) |  Loss2: (0.0000) | Acc: (90.00%) (15252/16768)
Epoch: 80 | Batch_idx: 140 |  Loss: (0.2678) |  Loss2: (0.0000) | Acc: (90.00%) (16397/18048)
Epoch: 80 | Batch_idx: 150 |  Loss: (0.2698) |  Loss2: (0.0000) | Acc: (90.00%) (17541/19328)
Epoch: 80 | Batch_idx: 160 |  Loss: (0.2694) |  Loss2: (0.0000) | Acc: (90.00%) (18703/20608)
Epoch: 80 | Batch_idx: 170 |  Loss: (0.2698) |  Loss2: (0.0000) | Acc: (90.00%) (19852/21888)
Epoch: 80 | Batch_idx: 180 |  Loss: (0.2705) |  Loss2: (0.0000) | Acc: (90.00%) (21007/23168)
Epoch: 80 | Batch_idx: 190 |  Loss: (0.2708) |  Loss2: (0.0000) | Acc: (90.00%) (22156/24448)
Epoch: 80 | Batch_idx: 200 |  Loss: (0.2707) |  Loss2: (0.0000) | Acc: (90.00%) (23313/25728)
Epoch: 80 | Batch_idx: 210 |  Loss: (0.2697) |  Loss2: (0.0000) | Acc: (90.00%) (24491/27008)
Epoch: 80 | Batch_idx: 220 |  Loss: (0.2702) |  Loss2: (0.0000) | Acc: (90.00%) (25644/28288)
Epoch: 80 | Batch_idx: 230 |  Loss: (0.2702) |  Loss2: (0.0000) | Acc: (90.00%) (26810/29568)
Epoch: 80 | Batch_idx: 240 |  Loss: (0.2713) |  Loss2: (0.0000) | Acc: (90.00%) (27952/30848)
Epoch: 80 | Batch_idx: 250 |  Loss: (0.2717) |  Loss2: (0.0000) | Acc: (90.00%) (29105/32128)
Epoch: 80 | Batch_idx: 260 |  Loss: (0.2730) |  Loss2: (0.0000) | Acc: (90.00%) (30255/33408)
Epoch: 80 | Batch_idx: 270 |  Loss: (0.2737) |  Loss2: (0.0000) | Acc: (90.00%) (31411/34688)
Epoch: 80 | Batch_idx: 280 |  Loss: (0.2743) |  Loss2: (0.0000) | Acc: (90.00%) (32564/35968)
Epoch: 80 | Batch_idx: 290 |  Loss: (0.2740) |  Loss2: (0.0000) | Acc: (90.00%) (33725/37248)
Epoch: 80 | Batch_idx: 300 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (34871/38528)
Epoch: 80 | Batch_idx: 310 |  Loss: (0.2741) |  Loss2: (0.0000) | Acc: (90.00%) (36045/39808)
Epoch: 80 | Batch_idx: 320 |  Loss: (0.2733) |  Loss2: (0.0000) | Acc: (90.00%) (37229/41088)
Epoch: 80 | Batch_idx: 330 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (38382/42368)
Epoch: 80 | Batch_idx: 340 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (39544/43648)
Epoch: 80 | Batch_idx: 350 |  Loss: (0.2730) |  Loss2: (0.0000) | Acc: (90.00%) (40717/44928)
Epoch: 80 | Batch_idx: 360 |  Loss: (0.2735) |  Loss2: (0.0000) | Acc: (90.00%) (41861/46208)
Epoch: 80 | Batch_idx: 370 |  Loss: (0.2736) |  Loss2: (0.0000) | Acc: (90.00%) (43021/47488)
Epoch: 80 | Batch_idx: 380 |  Loss: (0.2733) |  Loss2: (0.0000) | Acc: (90.00%) (44187/48768)
Epoch: 80 | Batch_idx: 390 |  Loss: (0.2740) |  Loss2: (0.0000) | Acc: (90.00%) (45292/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_080.pth.tar'
# TEST : Loss: (0.4140) | Acc: (86.00%) (8631/10000)
percent tensor([0.5490, 0.5694, 0.5559, 0.5502, 0.5598, 0.5400, 0.5726, 0.5634, 0.5622,
        0.5615, 0.5580, 0.5608, 0.5522, 0.5738, 0.5560, 0.5496],
       device='cuda:0') torch.Size([16])
percent tensor([0.5232, 0.5214, 0.5172, 0.5173, 0.5200, 0.5130, 0.5239, 0.5235, 0.5211,
        0.5191, 0.5192, 0.5209, 0.5227, 0.5206, 0.5174, 0.5197],
       device='cuda:0') torch.Size([16])
percent tensor([0.5442, 0.5791, 0.5491, 0.5866, 0.6034, 0.5787, 0.5947, 0.6087, 0.5516,
        0.5410, 0.5432, 0.5640, 0.5251, 0.5975, 0.6126, 0.5539],
       device='cuda:0') torch.Size([16])
percent tensor([0.6990, 0.6332, 0.6811, 0.6851, 0.7045, 0.7009, 0.6867, 0.6979, 0.6500,
        0.6401, 0.6370, 0.6409, 0.6268, 0.6549, 0.7016, 0.6885],
       device='cuda:0') torch.Size([16])
percent tensor([0.5172, 0.5279, 0.5281, 0.5347, 0.5279, 0.5287, 0.5286, 0.5348, 0.5475,
        0.5244, 0.5325, 0.5444, 0.5173, 0.5484, 0.5232, 0.5260],
       device='cuda:0') torch.Size([16])
percent tensor([0.6331, 0.6433, 0.6243, 0.6746, 0.6527, 0.6553, 0.6622, 0.6227, 0.6616,
        0.6484, 0.6713, 0.6696, 0.6294, 0.7106, 0.6248, 0.6632],
       device='cuda:0') torch.Size([16])
percent tensor([0.5489, 0.5185, 0.6193, 0.6890, 0.6460, 0.7794, 0.5515, 0.5097, 0.6029,
        0.5559, 0.5998, 0.5431, 0.5267, 0.6618, 0.4150, 0.6078],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9991, 0.9994, 0.9989, 0.9998, 0.9989, 0.9990, 0.9994, 0.9991,
        0.9996, 0.9996, 0.9997, 0.9989, 0.9990, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(172.7675, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(805.5921, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(803.7543, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1530.1416, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(494.3874, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2215.8367, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4273.2617, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1411.6077, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6138.6675, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11937.7725, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3981.0176, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16767.7188, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 81 | Batch_idx: 0 |  Loss: (0.2845) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 81 | Batch_idx: 10 |  Loss: (0.2542) |  Loss2: (0.0000) | Acc: (91.00%) (1286/1408)
Epoch: 81 | Batch_idx: 20 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (91.00%) (2455/2688)
Epoch: 81 | Batch_idx: 30 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (3628/3968)
Epoch: 81 | Batch_idx: 40 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (91.00%) (4795/5248)
Epoch: 81 | Batch_idx: 50 |  Loss: (0.2560) |  Loss2: (0.0000) | Acc: (91.00%) (5975/6528)
Epoch: 81 | Batch_idx: 60 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (91.00%) (7138/7808)
Epoch: 81 | Batch_idx: 70 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (91.00%) (8305/9088)
Epoch: 81 | Batch_idx: 80 |  Loss: (0.2555) |  Loss2: (0.0000) | Acc: (91.00%) (9478/10368)
Epoch: 81 | Batch_idx: 90 |  Loss: (0.2584) |  Loss2: (0.0000) | Acc: (91.00%) (10634/11648)
Epoch: 81 | Batch_idx: 100 |  Loss: (0.2593) |  Loss2: (0.0000) | Acc: (91.00%) (11788/12928)
Epoch: 81 | Batch_idx: 110 |  Loss: (0.2610) |  Loss2: (0.0000) | Acc: (91.00%) (12951/14208)
Epoch: 81 | Batch_idx: 120 |  Loss: (0.2642) |  Loss2: (0.0000) | Acc: (91.00%) (14101/15488)
Epoch: 81 | Batch_idx: 130 |  Loss: (0.2623) |  Loss2: (0.0000) | Acc: (91.00%) (15280/16768)
Epoch: 81 | Batch_idx: 140 |  Loss: (0.2628) |  Loss2: (0.0000) | Acc: (91.00%) (16443/18048)
Epoch: 81 | Batch_idx: 150 |  Loss: (0.2634) |  Loss2: (0.0000) | Acc: (91.00%) (17599/19328)
Epoch: 81 | Batch_idx: 160 |  Loss: (0.2636) |  Loss2: (0.0000) | Acc: (91.00%) (18766/20608)
Epoch: 81 | Batch_idx: 170 |  Loss: (0.2651) |  Loss2: (0.0000) | Acc: (90.00%) (19915/21888)
Epoch: 81 | Batch_idx: 180 |  Loss: (0.2633) |  Loss2: (0.0000) | Acc: (91.00%) (21088/23168)
Epoch: 81 | Batch_idx: 190 |  Loss: (0.2632) |  Loss2: (0.0000) | Acc: (90.00%) (22247/24448)
Epoch: 81 | Batch_idx: 200 |  Loss: (0.2639) |  Loss2: (0.0000) | Acc: (90.00%) (23397/25728)
Epoch: 81 | Batch_idx: 210 |  Loss: (0.2636) |  Loss2: (0.0000) | Acc: (90.00%) (24556/27008)
Epoch: 81 | Batch_idx: 220 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (90.00%) (25712/28288)
Epoch: 81 | Batch_idx: 230 |  Loss: (0.2650) |  Loss2: (0.0000) | Acc: (90.00%) (26877/29568)
Epoch: 81 | Batch_idx: 240 |  Loss: (0.2657) |  Loss2: (0.0000) | Acc: (90.00%) (28035/30848)
Epoch: 81 | Batch_idx: 250 |  Loss: (0.2667) |  Loss2: (0.0000) | Acc: (90.00%) (29191/32128)
Epoch: 81 | Batch_idx: 260 |  Loss: (0.2657) |  Loss2: (0.0000) | Acc: (90.00%) (30360/33408)
Epoch: 81 | Batch_idx: 270 |  Loss: (0.2647) |  Loss2: (0.0000) | Acc: (90.00%) (31532/34688)
Epoch: 81 | Batch_idx: 280 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (90.00%) (32688/35968)
Epoch: 81 | Batch_idx: 290 |  Loss: (0.2657) |  Loss2: (0.0000) | Acc: (90.00%) (33851/37248)
Epoch: 81 | Batch_idx: 300 |  Loss: (0.2667) |  Loss2: (0.0000) | Acc: (90.00%) (35000/38528)
Epoch: 81 | Batch_idx: 310 |  Loss: (0.2665) |  Loss2: (0.0000) | Acc: (90.00%) (36158/39808)
Epoch: 81 | Batch_idx: 320 |  Loss: (0.2664) |  Loss2: (0.0000) | Acc: (90.00%) (37322/41088)
Epoch: 81 | Batch_idx: 330 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (90.00%) (38489/42368)
Epoch: 81 | Batch_idx: 340 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (39640/43648)
Epoch: 81 | Batch_idx: 350 |  Loss: (0.2670) |  Loss2: (0.0000) | Acc: (90.00%) (40802/44928)
Epoch: 81 | Batch_idx: 360 |  Loss: (0.2671) |  Loss2: (0.0000) | Acc: (90.00%) (41957/46208)
Epoch: 81 | Batch_idx: 370 |  Loss: (0.2671) |  Loss2: (0.0000) | Acc: (90.00%) (43119/47488)
Epoch: 81 | Batch_idx: 380 |  Loss: (0.2669) |  Loss2: (0.0000) | Acc: (90.00%) (44281/48768)
Epoch: 81 | Batch_idx: 390 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (45390/50000)
# TEST : Loss: (0.4434) | Acc: (85.00%) (8551/10000)
percent tensor([0.5492, 0.5697, 0.5562, 0.5509, 0.5599, 0.5399, 0.5729, 0.5632, 0.5615,
        0.5617, 0.5575, 0.5608, 0.5524, 0.5740, 0.5560, 0.5498],
       device='cuda:0') torch.Size([16])
percent tensor([0.5228, 0.5196, 0.5169, 0.5164, 0.5189, 0.5131, 0.5227, 0.5232, 0.5210,
        0.5175, 0.5184, 0.5184, 0.5218, 0.5183, 0.5169, 0.5191],
       device='cuda:0') torch.Size([16])
percent tensor([0.5488, 0.5889, 0.5473, 0.5904, 0.5986, 0.5781, 0.5998, 0.6129, 0.5593,
        0.5454, 0.5468, 0.5642, 0.5311, 0.6158, 0.6146, 0.5590],
       device='cuda:0') torch.Size([16])
percent tensor([0.7001, 0.6292, 0.6781, 0.6850, 0.7042, 0.7089, 0.6897, 0.6988, 0.6472,
        0.6397, 0.6399, 0.6383, 0.6231, 0.6549, 0.7040, 0.6911],
       device='cuda:0') torch.Size([16])
percent tensor([0.5196, 0.5360, 0.5273, 0.5424, 0.5253, 0.5313, 0.5279, 0.5369, 0.5503,
        0.5281, 0.5320, 0.5400, 0.5214, 0.5525, 0.5291, 0.5308],
       device='cuda:0') torch.Size([16])
percent tensor([0.6247, 0.6455, 0.6397, 0.6742, 0.6578, 0.6486, 0.6647, 0.6310, 0.6594,
        0.6454, 0.6647, 0.6778, 0.6277, 0.7063, 0.6340, 0.6687],
       device='cuda:0') torch.Size([16])
percent tensor([0.5499, 0.5395, 0.6637, 0.6912, 0.6528, 0.7643, 0.5658, 0.5301, 0.6132,
        0.5764, 0.6054, 0.5790, 0.5413, 0.6545, 0.4300, 0.6386],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9992, 0.9997, 0.9993, 0.9997, 0.9982, 0.9992, 0.9997, 0.9991,
        0.9992, 0.9996, 0.9996, 0.9989, 0.9989, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 82 | Batch_idx: 0 |  Loss: (0.2052) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 82 | Batch_idx: 10 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (90.00%) (1275/1408)
Epoch: 82 | Batch_idx: 20 |  Loss: (0.2487) |  Loss2: (0.0000) | Acc: (91.00%) (2450/2688)
Epoch: 82 | Batch_idx: 30 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (3617/3968)
Epoch: 82 | Batch_idx: 40 |  Loss: (0.2486) |  Loss2: (0.0000) | Acc: (91.00%) (4797/5248)
Epoch: 82 | Batch_idx: 50 |  Loss: (0.2504) |  Loss2: (0.0000) | Acc: (91.00%) (5960/6528)
Epoch: 82 | Batch_idx: 60 |  Loss: (0.2491) |  Loss2: (0.0000) | Acc: (91.00%) (7134/7808)
Epoch: 82 | Batch_idx: 70 |  Loss: (0.2456) |  Loss2: (0.0000) | Acc: (91.00%) (8322/9088)
Epoch: 82 | Batch_idx: 80 |  Loss: (0.2441) |  Loss2: (0.0000) | Acc: (91.00%) (9484/10368)
Epoch: 82 | Batch_idx: 90 |  Loss: (0.2454) |  Loss2: (0.0000) | Acc: (91.00%) (10636/11648)
Epoch: 82 | Batch_idx: 100 |  Loss: (0.2484) |  Loss2: (0.0000) | Acc: (91.00%) (11796/12928)
Epoch: 82 | Batch_idx: 110 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (91.00%) (12962/14208)
Epoch: 82 | Batch_idx: 120 |  Loss: (0.2501) |  Loss2: (0.0000) | Acc: (91.00%) (14129/15488)
Epoch: 82 | Batch_idx: 130 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (15307/16768)
Epoch: 82 | Batch_idx: 140 |  Loss: (0.2518) |  Loss2: (0.0000) | Acc: (91.00%) (16472/18048)
Epoch: 82 | Batch_idx: 150 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (17656/19328)
Epoch: 82 | Batch_idx: 160 |  Loss: (0.2504) |  Loss2: (0.0000) | Acc: (91.00%) (18834/20608)
Epoch: 82 | Batch_idx: 170 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (91.00%) (19978/21888)
Epoch: 82 | Batch_idx: 180 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (21127/23168)
Epoch: 82 | Batch_idx: 190 |  Loss: (0.2552) |  Loss2: (0.0000) | Acc: (91.00%) (22286/24448)
Epoch: 82 | Batch_idx: 200 |  Loss: (0.2558) |  Loss2: (0.0000) | Acc: (91.00%) (23444/25728)
Epoch: 82 | Batch_idx: 210 |  Loss: (0.2562) |  Loss2: (0.0000) | Acc: (91.00%) (24606/27008)
Epoch: 82 | Batch_idx: 220 |  Loss: (0.2566) |  Loss2: (0.0000) | Acc: (91.00%) (25775/28288)
Epoch: 82 | Batch_idx: 230 |  Loss: (0.2574) |  Loss2: (0.0000) | Acc: (91.00%) (26921/29568)
Epoch: 82 | Batch_idx: 240 |  Loss: (0.2579) |  Loss2: (0.0000) | Acc: (91.00%) (28082/30848)
Epoch: 82 | Batch_idx: 250 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (91.00%) (29240/32128)
Epoch: 82 | Batch_idx: 260 |  Loss: (0.2576) |  Loss2: (0.0000) | Acc: (91.00%) (30415/33408)
Epoch: 82 | Batch_idx: 270 |  Loss: (0.2577) |  Loss2: (0.0000) | Acc: (91.00%) (31572/34688)
Epoch: 82 | Batch_idx: 280 |  Loss: (0.2579) |  Loss2: (0.0000) | Acc: (91.00%) (32738/35968)
Epoch: 82 | Batch_idx: 290 |  Loss: (0.2589) |  Loss2: (0.0000) | Acc: (90.00%) (33883/37248)
Epoch: 82 | Batch_idx: 300 |  Loss: (0.2587) |  Loss2: (0.0000) | Acc: (90.00%) (35051/38528)
Epoch: 82 | Batch_idx: 310 |  Loss: (0.2598) |  Loss2: (0.0000) | Acc: (90.00%) (36209/39808)
Epoch: 82 | Batch_idx: 320 |  Loss: (0.2605) |  Loss2: (0.0000) | Acc: (90.00%) (37362/41088)
Epoch: 82 | Batch_idx: 330 |  Loss: (0.2623) |  Loss2: (0.0000) | Acc: (90.00%) (38505/42368)
Epoch: 82 | Batch_idx: 340 |  Loss: (0.2628) |  Loss2: (0.0000) | Acc: (90.00%) (39668/43648)
Epoch: 82 | Batch_idx: 350 |  Loss: (0.2628) |  Loss2: (0.0000) | Acc: (90.00%) (40838/44928)
Epoch: 82 | Batch_idx: 360 |  Loss: (0.2621) |  Loss2: (0.0000) | Acc: (90.00%) (42016/46208)
Epoch: 82 | Batch_idx: 370 |  Loss: (0.2616) |  Loss2: (0.0000) | Acc: (90.00%) (43178/47488)
Epoch: 82 | Batch_idx: 380 |  Loss: (0.2623) |  Loss2: (0.0000) | Acc: (90.00%) (44336/48768)
Epoch: 82 | Batch_idx: 390 |  Loss: (0.2633) |  Loss2: (0.0000) | Acc: (90.00%) (45434/50000)
# TEST : Loss: (0.4177) | Acc: (86.00%) (8636/10000)
percent tensor([0.5493, 0.5694, 0.5567, 0.5499, 0.5602, 0.5402, 0.5728, 0.5631, 0.5624,
        0.5616, 0.5580, 0.5615, 0.5524, 0.5734, 0.5558, 0.5495],
       device='cuda:0') torch.Size([16])
percent tensor([0.5237, 0.5206, 0.5184, 0.5169, 0.5205, 0.5136, 0.5240, 0.5227, 0.5218,
        0.5187, 0.5191, 0.5212, 0.5226, 0.5195, 0.5170, 0.5194],
       device='cuda:0') torch.Size([16])
percent tensor([0.5499, 0.5879, 0.5432, 0.5899, 0.5943, 0.5826, 0.5951, 0.6117, 0.5586,
        0.5461, 0.5508, 0.5561, 0.5301, 0.6141, 0.6185, 0.5606],
       device='cuda:0') torch.Size([16])
percent tensor([0.6995, 0.6314, 0.6805, 0.6846, 0.7077, 0.7037, 0.6904, 0.6984, 0.6516,
        0.6451, 0.6428, 0.6390, 0.6243, 0.6580, 0.7015, 0.6917],
       device='cuda:0') torch.Size([16])
percent tensor([0.5190, 0.5320, 0.5302, 0.5461, 0.5269, 0.5327, 0.5241, 0.5359, 0.5451,
        0.5253, 0.5282, 0.5439, 0.5198, 0.5469, 0.5293, 0.5291],
       device='cuda:0') torch.Size([16])
percent tensor([0.6269, 0.6421, 0.6309, 0.6756, 0.6566, 0.6472, 0.6618, 0.6293, 0.6554,
        0.6467, 0.6634, 0.6727, 0.6247, 0.7013, 0.6269, 0.6614],
       device='cuda:0') torch.Size([16])
percent tensor([0.5465, 0.5067, 0.6325, 0.6931, 0.6352, 0.7572, 0.5459, 0.5349, 0.6090,
        0.5556, 0.5728, 0.5610, 0.5408, 0.6066, 0.4103, 0.5964],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9991, 0.9997, 0.9994, 0.9997, 0.9982, 0.9992, 0.9997, 0.9993,
        0.9995, 0.9996, 0.9996, 0.9991, 0.9990, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 83 | Batch_idx: 0 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 83 | Batch_idx: 10 |  Loss: (0.2322) |  Loss2: (0.0000) | Acc: (91.00%) (1291/1408)
Epoch: 83 | Batch_idx: 20 |  Loss: (0.2326) |  Loss2: (0.0000) | Acc: (92.00%) (2478/2688)
Epoch: 83 | Batch_idx: 30 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (92.00%) (3653/3968)
Epoch: 83 | Batch_idx: 40 |  Loss: (0.2414) |  Loss2: (0.0000) | Acc: (91.00%) (4827/5248)
Epoch: 83 | Batch_idx: 50 |  Loss: (0.2454) |  Loss2: (0.0000) | Acc: (91.00%) (5997/6528)
Epoch: 83 | Batch_idx: 60 |  Loss: (0.2462) |  Loss2: (0.0000) | Acc: (91.00%) (7168/7808)
Epoch: 83 | Batch_idx: 70 |  Loss: (0.2450) |  Loss2: (0.0000) | Acc: (91.00%) (8332/9088)
Epoch: 83 | Batch_idx: 80 |  Loss: (0.2464) |  Loss2: (0.0000) | Acc: (91.00%) (9501/10368)
Epoch: 83 | Batch_idx: 90 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (10656/11648)
Epoch: 83 | Batch_idx: 100 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (91.00%) (11805/12928)
Epoch: 83 | Batch_idx: 110 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (12989/14208)
Epoch: 83 | Batch_idx: 120 |  Loss: (0.2461) |  Loss2: (0.0000) | Acc: (91.00%) (14164/15488)
Epoch: 83 | Batch_idx: 130 |  Loss: (0.2446) |  Loss2: (0.0000) | Acc: (91.00%) (15348/16768)
Epoch: 83 | Batch_idx: 140 |  Loss: (0.2463) |  Loss2: (0.0000) | Acc: (91.00%) (16514/18048)
Epoch: 83 | Batch_idx: 150 |  Loss: (0.2453) |  Loss2: (0.0000) | Acc: (91.00%) (17681/19328)
Epoch: 83 | Batch_idx: 160 |  Loss: (0.2465) |  Loss2: (0.0000) | Acc: (91.00%) (18839/20608)
Epoch: 83 | Batch_idx: 170 |  Loss: (0.2494) |  Loss2: (0.0000) | Acc: (91.00%) (19996/21888)
Epoch: 83 | Batch_idx: 180 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (91.00%) (21165/23168)
Epoch: 83 | Batch_idx: 190 |  Loss: (0.2502) |  Loss2: (0.0000) | Acc: (91.00%) (22328/24448)
Epoch: 83 | Batch_idx: 200 |  Loss: (0.2502) |  Loss2: (0.0000) | Acc: (91.00%) (23491/25728)
Epoch: 83 | Batch_idx: 210 |  Loss: (0.2519) |  Loss2: (0.0000) | Acc: (91.00%) (24642/27008)
Epoch: 83 | Batch_idx: 220 |  Loss: (0.2537) |  Loss2: (0.0000) | Acc: (91.00%) (25786/28288)
Epoch: 83 | Batch_idx: 230 |  Loss: (0.2538) |  Loss2: (0.0000) | Acc: (91.00%) (26957/29568)
Epoch: 83 | Batch_idx: 240 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (28117/30848)
Epoch: 83 | Batch_idx: 250 |  Loss: (0.2551) |  Loss2: (0.0000) | Acc: (91.00%) (29285/32128)
Epoch: 83 | Batch_idx: 260 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (91.00%) (30458/33408)
Epoch: 83 | Batch_idx: 270 |  Loss: (0.2542) |  Loss2: (0.0000) | Acc: (91.00%) (31646/34688)
Epoch: 83 | Batch_idx: 280 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (91.00%) (32818/35968)
Epoch: 83 | Batch_idx: 290 |  Loss: (0.2538) |  Loss2: (0.0000) | Acc: (91.00%) (33977/37248)
Epoch: 83 | Batch_idx: 300 |  Loss: (0.2538) |  Loss2: (0.0000) | Acc: (91.00%) (35140/38528)
Epoch: 83 | Batch_idx: 310 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (36306/39808)
Epoch: 83 | Batch_idx: 320 |  Loss: (0.2540) |  Loss2: (0.0000) | Acc: (91.00%) (37467/41088)
Epoch: 83 | Batch_idx: 330 |  Loss: (0.2544) |  Loss2: (0.0000) | Acc: (91.00%) (38629/42368)
Epoch: 83 | Batch_idx: 340 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (91.00%) (39790/43648)
Epoch: 83 | Batch_idx: 350 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (91.00%) (40951/44928)
Epoch: 83 | Batch_idx: 360 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (42116/46208)
Epoch: 83 | Batch_idx: 370 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (43294/47488)
Epoch: 83 | Batch_idx: 380 |  Loss: (0.2553) |  Loss2: (0.0000) | Acc: (91.00%) (44450/48768)
Epoch: 83 | Batch_idx: 390 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (91.00%) (45578/50000)
# TEST : Loss: (0.4168) | Acc: (86.00%) (8611/10000)
percent tensor([0.5488, 0.5699, 0.5550, 0.5501, 0.5592, 0.5402, 0.5725, 0.5622, 0.5624,
        0.5613, 0.5582, 0.5599, 0.5522, 0.5745, 0.5559, 0.5498],
       device='cuda:0') torch.Size([16])
percent tensor([0.5230, 0.5198, 0.5196, 0.5175, 0.5205, 0.5139, 0.5230, 0.5232, 0.5210,
        0.5185, 0.5184, 0.5208, 0.5221, 0.5189, 0.5171, 0.5196],
       device='cuda:0') torch.Size([16])
percent tensor([0.5466, 0.5810, 0.5359, 0.5873, 0.5923, 0.5883, 0.5929, 0.6058, 0.5467,
        0.5388, 0.5438, 0.5564, 0.5241, 0.6082, 0.6149, 0.5573],
       device='cuda:0') torch.Size([16])
percent tensor([0.6909, 0.6257, 0.6804, 0.6867, 0.7014, 0.7076, 0.6836, 0.6940, 0.6421,
        0.6389, 0.6355, 0.6354, 0.6175, 0.6519, 0.6967, 0.6842],
       device='cuda:0') torch.Size([16])
percent tensor([0.5222, 0.5320, 0.5254, 0.5425, 0.5315, 0.5383, 0.5285, 0.5356, 0.5443,
        0.5233, 0.5294, 0.5432, 0.5174, 0.5445, 0.5310, 0.5332],
       device='cuda:0') torch.Size([16])
percent tensor([0.6283, 0.6469, 0.6361, 0.6760, 0.6595, 0.6537, 0.6616, 0.6320, 0.6650,
        0.6453, 0.6661, 0.6718, 0.6282, 0.7071, 0.6317, 0.6714],
       device='cuda:0') torch.Size([16])
percent tensor([0.5621, 0.5464, 0.6775, 0.7017, 0.6731, 0.7649, 0.5625, 0.5493, 0.6304,
        0.5832, 0.5994, 0.5778, 0.5510, 0.6383, 0.4180, 0.6132],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9994, 0.9993, 0.9992, 0.9997, 0.9977, 0.9989, 0.9995, 0.9993,
        0.9995, 0.9996, 0.9997, 0.9991, 0.9992, 0.9996, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 84 | Batch_idx: 0 |  Loss: (0.2362) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 84 | Batch_idx: 10 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (91.00%) (1284/1408)
Epoch: 84 | Batch_idx: 20 |  Loss: (0.2521) |  Loss2: (0.0000) | Acc: (91.00%) (2452/2688)
Epoch: 84 | Batch_idx: 30 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (3624/3968)
Epoch: 84 | Batch_idx: 40 |  Loss: (0.2462) |  Loss2: (0.0000) | Acc: (91.00%) (4802/5248)
Epoch: 84 | Batch_idx: 50 |  Loss: (0.2459) |  Loss2: (0.0000) | Acc: (91.00%) (5969/6528)
Epoch: 84 | Batch_idx: 60 |  Loss: (0.2414) |  Loss2: (0.0000) | Acc: (91.00%) (7153/7808)
Epoch: 84 | Batch_idx: 70 |  Loss: (0.2422) |  Loss2: (0.0000) | Acc: (91.00%) (8317/9088)
Epoch: 84 | Batch_idx: 80 |  Loss: (0.2408) |  Loss2: (0.0000) | Acc: (91.00%) (9493/10368)
Epoch: 84 | Batch_idx: 90 |  Loss: (0.2423) |  Loss2: (0.0000) | Acc: (91.00%) (10668/11648)
Epoch: 84 | Batch_idx: 100 |  Loss: (0.2408) |  Loss2: (0.0000) | Acc: (91.00%) (11842/12928)
Epoch: 84 | Batch_idx: 110 |  Loss: (0.2411) |  Loss2: (0.0000) | Acc: (91.00%) (13007/14208)
Epoch: 84 | Batch_idx: 120 |  Loss: (0.2429) |  Loss2: (0.0000) | Acc: (91.00%) (14162/15488)
Epoch: 84 | Batch_idx: 130 |  Loss: (0.2450) |  Loss2: (0.0000) | Acc: (91.00%) (15316/16768)
Epoch: 84 | Batch_idx: 140 |  Loss: (0.2465) |  Loss2: (0.0000) | Acc: (91.00%) (16473/18048)
Epoch: 84 | Batch_idx: 150 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (91.00%) (17640/19328)
Epoch: 84 | Batch_idx: 160 |  Loss: (0.2484) |  Loss2: (0.0000) | Acc: (91.00%) (18792/20608)
Epoch: 84 | Batch_idx: 170 |  Loss: (0.2486) |  Loss2: (0.0000) | Acc: (91.00%) (19963/21888)
Epoch: 84 | Batch_idx: 180 |  Loss: (0.2487) |  Loss2: (0.0000) | Acc: (91.00%) (21144/23168)
Epoch: 84 | Batch_idx: 190 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (22326/24448)
Epoch: 84 | Batch_idx: 200 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (23516/25728)
Epoch: 84 | Batch_idx: 210 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (24687/27008)
Epoch: 84 | Batch_idx: 220 |  Loss: (0.2446) |  Loss2: (0.0000) | Acc: (91.00%) (25872/28288)
Epoch: 84 | Batch_idx: 230 |  Loss: (0.2449) |  Loss2: (0.0000) | Acc: (91.00%) (27031/29568)
Epoch: 84 | Batch_idx: 240 |  Loss: (0.2451) |  Loss2: (0.0000) | Acc: (91.00%) (28204/30848)
Epoch: 84 | Batch_idx: 250 |  Loss: (0.2444) |  Loss2: (0.0000) | Acc: (91.00%) (29375/32128)
Epoch: 84 | Batch_idx: 260 |  Loss: (0.2457) |  Loss2: (0.0000) | Acc: (91.00%) (30525/33408)
Epoch: 84 | Batch_idx: 270 |  Loss: (0.2468) |  Loss2: (0.0000) | Acc: (91.00%) (31698/34688)
Epoch: 84 | Batch_idx: 280 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (91.00%) (32859/35968)
Epoch: 84 | Batch_idx: 290 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (91.00%) (34036/37248)
Epoch: 84 | Batch_idx: 300 |  Loss: (0.2473) |  Loss2: (0.0000) | Acc: (91.00%) (35214/38528)
Epoch: 84 | Batch_idx: 310 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (36394/39808)
Epoch: 84 | Batch_idx: 320 |  Loss: (0.2481) |  Loss2: (0.0000) | Acc: (91.00%) (37541/41088)
Epoch: 84 | Batch_idx: 330 |  Loss: (0.2479) |  Loss2: (0.0000) | Acc: (91.00%) (38712/42368)
Epoch: 84 | Batch_idx: 340 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (91.00%) (39875/43648)
Epoch: 84 | Batch_idx: 350 |  Loss: (0.2485) |  Loss2: (0.0000) | Acc: (91.00%) (41042/44928)
Epoch: 84 | Batch_idx: 360 |  Loss: (0.2484) |  Loss2: (0.0000) | Acc: (91.00%) (42207/46208)
Epoch: 84 | Batch_idx: 370 |  Loss: (0.2496) |  Loss2: (0.0000) | Acc: (91.00%) (43370/47488)
Epoch: 84 | Batch_idx: 380 |  Loss: (0.2495) |  Loss2: (0.0000) | Acc: (91.00%) (44539/48768)
Epoch: 84 | Batch_idx: 390 |  Loss: (0.2491) |  Loss2: (0.0000) | Acc: (91.00%) (45671/50000)
# TEST : Loss: (0.4132) | Acc: (86.00%) (8647/10000)
percent tensor([0.5490, 0.5689, 0.5555, 0.5506, 0.5593, 0.5405, 0.5721, 0.5630, 0.5620,
        0.5610, 0.5582, 0.5599, 0.5522, 0.5735, 0.5557, 0.5498],
       device='cuda:0') torch.Size([16])
percent tensor([0.5233, 0.5206, 0.5190, 0.5177, 0.5206, 0.5130, 0.5240, 0.5242, 0.5224,
        0.5189, 0.5187, 0.5213, 0.5228, 0.5195, 0.5174, 0.5194],
       device='cuda:0') torch.Size([16])
percent tensor([0.5454, 0.5816, 0.5416, 0.5840, 0.5988, 0.5808, 0.5922, 0.6098, 0.5586,
        0.5376, 0.5434, 0.5572, 0.5247, 0.6179, 0.6128, 0.5555],
       device='cuda:0') torch.Size([16])
percent tensor([0.6975, 0.6341, 0.6791, 0.6834, 0.6989, 0.6979, 0.6879, 0.6970, 0.6474,
        0.6446, 0.6425, 0.6391, 0.6233, 0.6585, 0.7015, 0.6881],
       device='cuda:0') torch.Size([16])
percent tensor([0.5192, 0.5294, 0.5305, 0.5437, 0.5318, 0.5332, 0.5262, 0.5360, 0.5476,
        0.5251, 0.5280, 0.5448, 0.5177, 0.5472, 0.5286, 0.5302],
       device='cuda:0') torch.Size([16])
percent tensor([0.6280, 0.6411, 0.6361, 0.6724, 0.6566, 0.6477, 0.6627, 0.6276, 0.6602,
        0.6393, 0.6568, 0.6753, 0.6188, 0.7119, 0.6236, 0.6589],
       device='cuda:0') torch.Size([16])
percent tensor([0.5640, 0.5318, 0.6623, 0.7049, 0.6415, 0.7591, 0.5781, 0.5349, 0.6011,
        0.5713, 0.5929, 0.5700, 0.5409, 0.6495, 0.4138, 0.6099],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9992, 0.9996, 0.9994, 0.9997, 0.9985, 0.9991, 0.9997, 0.9993,
        0.9995, 0.9995, 0.9997, 0.9992, 0.9988, 0.9996, 0.9990],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 85 | Batch_idx: 0 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 85 | Batch_idx: 10 |  Loss: (0.2451) |  Loss2: (0.0000) | Acc: (91.00%) (1293/1408)
Epoch: 85 | Batch_idx: 20 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (2463/2688)
Epoch: 85 | Batch_idx: 30 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (3603/3968)
Epoch: 85 | Batch_idx: 40 |  Loss: (0.2722) |  Loss2: (0.0000) | Acc: (90.00%) (4757/5248)
Epoch: 85 | Batch_idx: 50 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (90.00%) (5887/6528)
Epoch: 85 | Batch_idx: 60 |  Loss: (0.2901) |  Loss2: (0.0000) | Acc: (89.00%) (7024/7808)
Epoch: 85 | Batch_idx: 70 |  Loss: (0.2941) |  Loss2: (0.0000) | Acc: (89.00%) (8155/9088)
Epoch: 85 | Batch_idx: 80 |  Loss: (0.2930) |  Loss2: (0.0000) | Acc: (89.00%) (9298/10368)
Epoch: 85 | Batch_idx: 90 |  Loss: (0.2938) |  Loss2: (0.0000) | Acc: (89.00%) (10429/11648)
Epoch: 85 | Batch_idx: 100 |  Loss: (0.2930) |  Loss2: (0.0000) | Acc: (89.00%) (11578/12928)
Epoch: 85 | Batch_idx: 110 |  Loss: (0.2920) |  Loss2: (0.0000) | Acc: (89.00%) (12724/14208)
Epoch: 85 | Batch_idx: 120 |  Loss: (0.2923) |  Loss2: (0.0000) | Acc: (89.00%) (13874/15488)
Epoch: 85 | Batch_idx: 130 |  Loss: (0.2926) |  Loss2: (0.0000) | Acc: (89.00%) (15012/16768)
Epoch: 85 | Batch_idx: 140 |  Loss: (0.2949) |  Loss2: (0.0000) | Acc: (89.00%) (16149/18048)
Epoch: 85 | Batch_idx: 150 |  Loss: (0.2935) |  Loss2: (0.0000) | Acc: (89.00%) (17312/19328)
Epoch: 85 | Batch_idx: 160 |  Loss: (0.2928) |  Loss2: (0.0000) | Acc: (89.00%) (18466/20608)
Epoch: 85 | Batch_idx: 170 |  Loss: (0.2926) |  Loss2: (0.0000) | Acc: (89.00%) (19603/21888)
Epoch: 85 | Batch_idx: 180 |  Loss: (0.2933) |  Loss2: (0.0000) | Acc: (89.00%) (20747/23168)
Epoch: 85 | Batch_idx: 190 |  Loss: (0.2930) |  Loss2: (0.0000) | Acc: (89.00%) (21898/24448)
Epoch: 85 | Batch_idx: 200 |  Loss: (0.2928) |  Loss2: (0.0000) | Acc: (89.00%) (23040/25728)
Epoch: 85 | Batch_idx: 210 |  Loss: (0.2936) |  Loss2: (0.0000) | Acc: (89.00%) (24182/27008)
Epoch: 85 | Batch_idx: 220 |  Loss: (0.2944) |  Loss2: (0.0000) | Acc: (89.00%) (25330/28288)
Epoch: 85 | Batch_idx: 230 |  Loss: (0.2937) |  Loss2: (0.0000) | Acc: (89.00%) (26488/29568)
Epoch: 85 | Batch_idx: 240 |  Loss: (0.2931) |  Loss2: (0.0000) | Acc: (89.00%) (27645/30848)
Epoch: 85 | Batch_idx: 250 |  Loss: (0.2924) |  Loss2: (0.0000) | Acc: (89.00%) (28811/32128)
Epoch: 85 | Batch_idx: 260 |  Loss: (0.2923) |  Loss2: (0.0000) | Acc: (89.00%) (29965/33408)
Epoch: 85 | Batch_idx: 270 |  Loss: (0.2920) |  Loss2: (0.0000) | Acc: (89.00%) (31116/34688)
Epoch: 85 | Batch_idx: 280 |  Loss: (0.2930) |  Loss2: (0.0000) | Acc: (89.00%) (32239/35968)
Epoch: 85 | Batch_idx: 290 |  Loss: (0.2919) |  Loss2: (0.0000) | Acc: (89.00%) (33408/37248)
Epoch: 85 | Batch_idx: 300 |  Loss: (0.2906) |  Loss2: (0.0000) | Acc: (89.00%) (34574/38528)
Epoch: 85 | Batch_idx: 310 |  Loss: (0.2894) |  Loss2: (0.0000) | Acc: (89.00%) (35749/39808)
Epoch: 85 | Batch_idx: 320 |  Loss: (0.2884) |  Loss2: (0.0000) | Acc: (89.00%) (36919/41088)
Epoch: 85 | Batch_idx: 330 |  Loss: (0.2871) |  Loss2: (0.0000) | Acc: (89.00%) (38091/42368)
Epoch: 85 | Batch_idx: 340 |  Loss: (0.2866) |  Loss2: (0.0000) | Acc: (89.00%) (39254/43648)
Epoch: 85 | Batch_idx: 350 |  Loss: (0.2868) |  Loss2: (0.0000) | Acc: (89.00%) (40396/44928)
Epoch: 85 | Batch_idx: 360 |  Loss: (0.2869) |  Loss2: (0.0000) | Acc: (89.00%) (41542/46208)
Epoch: 85 | Batch_idx: 370 |  Loss: (0.2869) |  Loss2: (0.0000) | Acc: (89.00%) (42689/47488)
Epoch: 85 | Batch_idx: 380 |  Loss: (0.2865) |  Loss2: (0.0000) | Acc: (89.00%) (43839/48768)
Epoch: 85 | Batch_idx: 390 |  Loss: (0.2857) |  Loss2: (0.0000) | Acc: (89.00%) (44955/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_085.pth.tar'
# TEST : Loss: (0.4322) | Acc: (85.00%) (8589/10000)
percent tensor([0.5577, 0.5791, 0.5649, 0.5593, 0.5696, 0.5484, 0.5830, 0.5736, 0.5716,
        0.5709, 0.5677, 0.5702, 0.5612, 0.5835, 0.5651, 0.5587],
       device='cuda:0') torch.Size([16])
percent tensor([0.5218, 0.5206, 0.5138, 0.5137, 0.5160, 0.5115, 0.5229, 0.5209, 0.5201,
        0.5171, 0.5180, 0.5174, 0.5216, 0.5197, 0.5164, 0.5184],
       device='cuda:0') torch.Size([16])
percent tensor([0.5392, 0.5727, 0.5263, 0.5721, 0.5926, 0.5829, 0.5887, 0.6116, 0.5431,
        0.5165, 0.5240, 0.5343, 0.5149, 0.6068, 0.6162, 0.5518],
       device='cuda:0') torch.Size([16])
percent tensor([0.6868, 0.6308, 0.6639, 0.6711, 0.6812, 0.6906, 0.6790, 0.6859, 0.6457,
        0.6406, 0.6446, 0.6331, 0.6186, 0.6596, 0.6964, 0.6805],
       device='cuda:0') torch.Size([16])
percent tensor([0.5240, 0.5278, 0.5392, 0.5611, 0.5479, 0.5427, 0.5320, 0.5408, 0.5520,
        0.5308, 0.5298, 0.5522, 0.5168, 0.5571, 0.5274, 0.5418],
       device='cuda:0') torch.Size([16])
percent tensor([0.6015, 0.6066, 0.6178, 0.6665, 0.6404, 0.6325, 0.6388, 0.6100, 0.6380,
        0.6101, 0.6307, 0.6501, 0.5883, 0.6886, 0.5916, 0.6399],
       device='cuda:0') torch.Size([16])
percent tensor([0.5911, 0.5199, 0.6813, 0.7297, 0.6602, 0.8012, 0.5912, 0.5459, 0.6326,
        0.5547, 0.6100, 0.5844, 0.5231, 0.6673, 0.4199, 0.6209],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9990, 0.9998, 0.9995, 0.9997, 0.9990, 0.9992, 0.9997, 0.9994,
        0.9995, 0.9995, 0.9997, 0.9993, 0.9991, 0.9996, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 86 | Batch_idx: 0 |  Loss: (0.3215) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 86 | Batch_idx: 10 |  Loss: (0.2871) |  Loss2: (0.0000) | Acc: (89.00%) (1262/1408)
Epoch: 86 | Batch_idx: 20 |  Loss: (0.2846) |  Loss2: (0.0000) | Acc: (89.00%) (2414/2688)
Epoch: 86 | Batch_idx: 30 |  Loss: (0.2740) |  Loss2: (0.0000) | Acc: (90.00%) (3582/3968)
Epoch: 86 | Batch_idx: 40 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (4734/5248)
Epoch: 86 | Batch_idx: 50 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (90.00%) (5909/6528)
Epoch: 86 | Batch_idx: 60 |  Loss: (0.2703) |  Loss2: (0.0000) | Acc: (90.00%) (7056/7808)
Epoch: 86 | Batch_idx: 70 |  Loss: (0.2673) |  Loss2: (0.0000) | Acc: (90.00%) (8237/9088)
Epoch: 86 | Batch_idx: 80 |  Loss: (0.2642) |  Loss2: (0.0000) | Acc: (90.00%) (9409/10368)
Epoch: 86 | Batch_idx: 90 |  Loss: (0.2633) |  Loss2: (0.0000) | Acc: (90.00%) (10585/11648)
Epoch: 86 | Batch_idx: 100 |  Loss: (0.2613) |  Loss2: (0.0000) | Acc: (90.00%) (11756/12928)
Epoch: 86 | Batch_idx: 110 |  Loss: (0.2613) |  Loss2: (0.0000) | Acc: (91.00%) (12932/14208)
Epoch: 86 | Batch_idx: 120 |  Loss: (0.2598) |  Loss2: (0.0000) | Acc: (91.00%) (14104/15488)
Epoch: 86 | Batch_idx: 130 |  Loss: (0.2599) |  Loss2: (0.0000) | Acc: (91.00%) (15271/16768)
Epoch: 86 | Batch_idx: 140 |  Loss: (0.2600) |  Loss2: (0.0000) | Acc: (91.00%) (16438/18048)
Epoch: 86 | Batch_idx: 150 |  Loss: (0.2625) |  Loss2: (0.0000) | Acc: (91.00%) (17591/19328)
Epoch: 86 | Batch_idx: 160 |  Loss: (0.2607) |  Loss2: (0.0000) | Acc: (91.00%) (18775/20608)
Epoch: 86 | Batch_idx: 170 |  Loss: (0.2610) |  Loss2: (0.0000) | Acc: (91.00%) (19937/21888)
Epoch: 86 | Batch_idx: 180 |  Loss: (0.2596) |  Loss2: (0.0000) | Acc: (91.00%) (21105/23168)
Epoch: 86 | Batch_idx: 190 |  Loss: (0.2599) |  Loss2: (0.0000) | Acc: (91.00%) (22264/24448)
Epoch: 86 | Batch_idx: 200 |  Loss: (0.2591) |  Loss2: (0.0000) | Acc: (91.00%) (23442/25728)
Epoch: 86 | Batch_idx: 210 |  Loss: (0.2590) |  Loss2: (0.0000) | Acc: (91.00%) (24597/27008)
Epoch: 86 | Batch_idx: 220 |  Loss: (0.2589) |  Loss2: (0.0000) | Acc: (91.00%) (25755/28288)
Epoch: 86 | Batch_idx: 230 |  Loss: (0.2591) |  Loss2: (0.0000) | Acc: (91.00%) (26913/29568)
Epoch: 86 | Batch_idx: 240 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (91.00%) (28077/30848)
Epoch: 86 | Batch_idx: 250 |  Loss: (0.2577) |  Loss2: (0.0000) | Acc: (91.00%) (29260/32128)
Epoch: 86 | Batch_idx: 260 |  Loss: (0.2574) |  Loss2: (0.0000) | Acc: (91.00%) (30425/33408)
Epoch: 86 | Batch_idx: 270 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (31596/34688)
Epoch: 86 | Batch_idx: 280 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (91.00%) (32770/35968)
Epoch: 86 | Batch_idx: 290 |  Loss: (0.2557) |  Loss2: (0.0000) | Acc: (91.00%) (33937/37248)
Epoch: 86 | Batch_idx: 300 |  Loss: (0.2559) |  Loss2: (0.0000) | Acc: (91.00%) (35099/38528)
Epoch: 86 | Batch_idx: 310 |  Loss: (0.2552) |  Loss2: (0.0000) | Acc: (91.00%) (36265/39808)
Epoch: 86 | Batch_idx: 320 |  Loss: (0.2552) |  Loss2: (0.0000) | Acc: (91.00%) (37442/41088)
Epoch: 86 | Batch_idx: 330 |  Loss: (0.2550) |  Loss2: (0.0000) | Acc: (91.00%) (38613/42368)
Epoch: 86 | Batch_idx: 340 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (91.00%) (39776/43648)
Epoch: 86 | Batch_idx: 350 |  Loss: (0.2548) |  Loss2: (0.0000) | Acc: (91.00%) (40943/44928)
Epoch: 86 | Batch_idx: 360 |  Loss: (0.2557) |  Loss2: (0.0000) | Acc: (91.00%) (42091/46208)
Epoch: 86 | Batch_idx: 370 |  Loss: (0.2558) |  Loss2: (0.0000) | Acc: (91.00%) (43261/47488)
Epoch: 86 | Batch_idx: 380 |  Loss: (0.2552) |  Loss2: (0.0000) | Acc: (91.00%) (44438/48768)
Epoch: 86 | Batch_idx: 390 |  Loss: (0.2554) |  Loss2: (0.0000) | Acc: (91.00%) (45544/50000)
# TEST : Loss: (0.4051) | Acc: (86.00%) (8678/10000)
percent tensor([0.5590, 0.5795, 0.5671, 0.5605, 0.5716, 0.5496, 0.5841, 0.5750, 0.5725,
        0.5719, 0.5684, 0.5721, 0.5623, 0.5830, 0.5661, 0.5596],
       device='cuda:0') torch.Size([16])
percent tensor([0.5214, 0.5200, 0.5114, 0.5107, 0.5135, 0.5098, 0.5213, 0.5188, 0.5179,
        0.5155, 0.5165, 0.5151, 0.5211, 0.5177, 0.5146, 0.5169],
       device='cuda:0') torch.Size([16])
percent tensor([0.5421, 0.5662, 0.5327, 0.5766, 0.6009, 0.5923, 0.5883, 0.6229, 0.5422,
        0.5075, 0.5150, 0.5318, 0.5097, 0.6017, 0.6203, 0.5534],
       device='cuda:0') torch.Size([16])
percent tensor([0.6875, 0.6339, 0.6632, 0.6704, 0.6804, 0.6885, 0.6798, 0.6841, 0.6478,
        0.6448, 0.6495, 0.6361, 0.6234, 0.6618, 0.6960, 0.6814],
       device='cuda:0') torch.Size([16])
percent tensor([0.5283, 0.5297, 0.5443, 0.5731, 0.5559, 0.5519, 0.5346, 0.5465, 0.5573,
        0.5348, 0.5329, 0.5569, 0.5161, 0.5640, 0.5287, 0.5518],
       device='cuda:0') torch.Size([16])
percent tensor([0.6025, 0.6113, 0.6207, 0.6741, 0.6434, 0.6323, 0.6425, 0.6120, 0.6429,
        0.6150, 0.6358, 0.6562, 0.5933, 0.6958, 0.5901, 0.6438],
       device='cuda:0') torch.Size([16])
percent tensor([0.6025, 0.5314, 0.6842, 0.7352, 0.6520, 0.8028, 0.5991, 0.5413, 0.6454,
        0.5680, 0.6285, 0.6000, 0.5414, 0.6857, 0.4228, 0.6238],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9990, 0.9998, 0.9996, 0.9997, 0.9989, 0.9992, 0.9997, 0.9994,
        0.9995, 0.9996, 0.9998, 0.9993, 0.9991, 0.9996, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 87 | Batch_idx: 0 |  Loss: (0.2907) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 87 | Batch_idx: 10 |  Loss: (0.2715) |  Loss2: (0.0000) | Acc: (90.00%) (1269/1408)
Epoch: 87 | Batch_idx: 20 |  Loss: (0.2665) |  Loss2: (0.0000) | Acc: (90.00%) (2433/2688)
Epoch: 87 | Batch_idx: 30 |  Loss: (0.2621) |  Loss2: (0.0000) | Acc: (90.00%) (3604/3968)
Epoch: 87 | Batch_idx: 40 |  Loss: (0.2613) |  Loss2: (0.0000) | Acc: (90.00%) (4767/5248)
Epoch: 87 | Batch_idx: 50 |  Loss: (0.2551) |  Loss2: (0.0000) | Acc: (91.00%) (5950/6528)
Epoch: 87 | Batch_idx: 60 |  Loss: (0.2516) |  Loss2: (0.0000) | Acc: (91.00%) (7124/7808)
Epoch: 87 | Batch_idx: 70 |  Loss: (0.2499) |  Loss2: (0.0000) | Acc: (91.00%) (8304/9088)
Epoch: 87 | Batch_idx: 80 |  Loss: (0.2476) |  Loss2: (0.0000) | Acc: (91.00%) (9487/10368)
Epoch: 87 | Batch_idx: 90 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (10661/11648)
Epoch: 87 | Batch_idx: 100 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (11821/12928)
Epoch: 87 | Batch_idx: 110 |  Loss: (0.2494) |  Loss2: (0.0000) | Acc: (91.00%) (12976/14208)
Epoch: 87 | Batch_idx: 120 |  Loss: (0.2494) |  Loss2: (0.0000) | Acc: (91.00%) (14150/15488)
Epoch: 87 | Batch_idx: 130 |  Loss: (0.2514) |  Loss2: (0.0000) | Acc: (91.00%) (15303/16768)
Epoch: 87 | Batch_idx: 140 |  Loss: (0.2490) |  Loss2: (0.0000) | Acc: (91.00%) (16485/18048)
Epoch: 87 | Batch_idx: 150 |  Loss: (0.2501) |  Loss2: (0.0000) | Acc: (91.00%) (17642/19328)
Epoch: 87 | Batch_idx: 160 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (18811/20608)
Epoch: 87 | Batch_idx: 170 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (19978/21888)
Epoch: 87 | Batch_idx: 180 |  Loss: (0.2505) |  Loss2: (0.0000) | Acc: (91.00%) (21153/23168)
Epoch: 87 | Batch_idx: 190 |  Loss: (0.2504) |  Loss2: (0.0000) | Acc: (91.00%) (22320/24448)
Epoch: 87 | Batch_idx: 200 |  Loss: (0.2503) |  Loss2: (0.0000) | Acc: (91.00%) (23484/25728)
Epoch: 87 | Batch_idx: 210 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (91.00%) (24665/27008)
Epoch: 87 | Batch_idx: 220 |  Loss: (0.2501) |  Loss2: (0.0000) | Acc: (91.00%) (25828/28288)
Epoch: 87 | Batch_idx: 230 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (27005/29568)
Epoch: 87 | Batch_idx: 240 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (91.00%) (28180/30848)
Epoch: 87 | Batch_idx: 250 |  Loss: (0.2497) |  Loss2: (0.0000) | Acc: (91.00%) (29332/32128)
Epoch: 87 | Batch_idx: 260 |  Loss: (0.2486) |  Loss2: (0.0000) | Acc: (91.00%) (30518/33408)
Epoch: 87 | Batch_idx: 270 |  Loss: (0.2484) |  Loss2: (0.0000) | Acc: (91.00%) (31686/34688)
Epoch: 87 | Batch_idx: 280 |  Loss: (0.2484) |  Loss2: (0.0000) | Acc: (91.00%) (32866/35968)
Epoch: 87 | Batch_idx: 290 |  Loss: (0.2477) |  Loss2: (0.0000) | Acc: (91.00%) (34043/37248)
Epoch: 87 | Batch_idx: 300 |  Loss: (0.2483) |  Loss2: (0.0000) | Acc: (91.00%) (35203/38528)
Epoch: 87 | Batch_idx: 310 |  Loss: (0.2481) |  Loss2: (0.0000) | Acc: (91.00%) (36362/39808)
Epoch: 87 | Batch_idx: 320 |  Loss: (0.2482) |  Loss2: (0.0000) | Acc: (91.00%) (37534/41088)
Epoch: 87 | Batch_idx: 330 |  Loss: (0.2482) |  Loss2: (0.0000) | Acc: (91.00%) (38708/42368)
Epoch: 87 | Batch_idx: 340 |  Loss: (0.2481) |  Loss2: (0.0000) | Acc: (91.00%) (39877/43648)
Epoch: 87 | Batch_idx: 350 |  Loss: (0.2483) |  Loss2: (0.0000) | Acc: (91.00%) (41047/44928)
Epoch: 87 | Batch_idx: 360 |  Loss: (0.2479) |  Loss2: (0.0000) | Acc: (91.00%) (42220/46208)
Epoch: 87 | Batch_idx: 370 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (91.00%) (43400/47488)
Epoch: 87 | Batch_idx: 380 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (44569/48768)
Epoch: 87 | Batch_idx: 390 |  Loss: (0.2481) |  Loss2: (0.0000) | Acc: (91.00%) (45691/50000)
# TEST : Loss: (0.3962) | Acc: (87.00%) (8703/10000)
percent tensor([0.5573, 0.5770, 0.5654, 0.5587, 0.5698, 0.5482, 0.5818, 0.5731, 0.5705,
        0.5698, 0.5665, 0.5702, 0.5605, 0.5802, 0.5642, 0.5578],
       device='cuda:0') torch.Size([16])
percent tensor([0.5226, 0.5212, 0.5120, 0.5106, 0.5140, 0.5102, 0.5225, 0.5195, 0.5186,
        0.5167, 0.5175, 0.5160, 0.5222, 0.5184, 0.5153, 0.5177],
       device='cuda:0') torch.Size([16])
percent tensor([0.5478, 0.5654, 0.5433, 0.5840, 0.6101, 0.5995, 0.5916, 0.6332, 0.5464,
        0.5065, 0.5138, 0.5362, 0.5123, 0.5995, 0.6253, 0.5580],
       device='cuda:0') torch.Size([16])
percent tensor([0.6787, 0.6258, 0.6557, 0.6621, 0.6725, 0.6792, 0.6709, 0.6746, 0.6409,
        0.6381, 0.6424, 0.6287, 0.6160, 0.6543, 0.6856, 0.6723],
       device='cuda:0') torch.Size([16])
percent tensor([0.5241, 0.5257, 0.5399, 0.5746, 0.5535, 0.5521, 0.5290, 0.5424, 0.5553,
        0.5328, 0.5314, 0.5540, 0.5102, 0.5641, 0.5220, 0.5526],
       device='cuda:0') torch.Size([16])
percent tensor([0.6003, 0.6128, 0.6182, 0.6738, 0.6416, 0.6279, 0.6411, 0.6116, 0.6420,
        0.6168, 0.6378, 0.6571, 0.5933, 0.6971, 0.5867, 0.6430],
       device='cuda:0') torch.Size([16])
percent tensor([0.6068, 0.5306, 0.6866, 0.7402, 0.6474, 0.8012, 0.5988, 0.5490, 0.6446,
        0.5709, 0.6320, 0.6049, 0.5419, 0.6852, 0.4299, 0.6236],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9991, 0.9998, 0.9996, 0.9997, 0.9990, 0.9992, 0.9997, 0.9995,
        0.9995, 0.9996, 0.9997, 0.9993, 0.9992, 0.9997, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 88 | Batch_idx: 0 |  Loss: (0.2431) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 88 | Batch_idx: 10 |  Loss: (0.2499) |  Loss2: (0.0000) | Acc: (91.00%) (1289/1408)
Epoch: 88 | Batch_idx: 20 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (92.00%) (2476/2688)
Epoch: 88 | Batch_idx: 30 |  Loss: (0.2341) |  Loss2: (0.0000) | Acc: (92.00%) (3653/3968)
Epoch: 88 | Batch_idx: 40 |  Loss: (0.2403) |  Loss2: (0.0000) | Acc: (91.00%) (4814/5248)
Epoch: 88 | Batch_idx: 50 |  Loss: (0.2411) |  Loss2: (0.0000) | Acc: (91.00%) (5988/6528)
Epoch: 88 | Batch_idx: 60 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (7174/7808)
Epoch: 88 | Batch_idx: 70 |  Loss: (0.2360) |  Loss2: (0.0000) | Acc: (91.00%) (8359/9088)
Epoch: 88 | Batch_idx: 80 |  Loss: (0.2353) |  Loss2: (0.0000) | Acc: (91.00%) (9526/10368)
Epoch: 88 | Batch_idx: 90 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (91.00%) (10687/11648)
Epoch: 88 | Batch_idx: 100 |  Loss: (0.2382) |  Loss2: (0.0000) | Acc: (91.00%) (11857/12928)
Epoch: 88 | Batch_idx: 110 |  Loss: (0.2408) |  Loss2: (0.0000) | Acc: (91.00%) (13010/14208)
Epoch: 88 | Batch_idx: 120 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (14152/15488)
Epoch: 88 | Batch_idx: 130 |  Loss: (0.2445) |  Loss2: (0.0000) | Acc: (91.00%) (15316/16768)
Epoch: 88 | Batch_idx: 140 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (16476/18048)
Epoch: 88 | Batch_idx: 150 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (17665/19328)
Epoch: 88 | Batch_idx: 160 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (18845/20608)
Epoch: 88 | Batch_idx: 170 |  Loss: (0.2436) |  Loss2: (0.0000) | Acc: (91.00%) (20030/21888)
Epoch: 88 | Batch_idx: 180 |  Loss: (0.2438) |  Loss2: (0.0000) | Acc: (91.00%) (21193/23168)
Epoch: 88 | Batch_idx: 190 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (22367/24448)
Epoch: 88 | Batch_idx: 200 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (23540/25728)
Epoch: 88 | Batch_idx: 210 |  Loss: (0.2435) |  Loss2: (0.0000) | Acc: (91.00%) (24718/27008)
Epoch: 88 | Batch_idx: 220 |  Loss: (0.2428) |  Loss2: (0.0000) | Acc: (91.00%) (25907/28288)
Epoch: 88 | Batch_idx: 230 |  Loss: (0.2419) |  Loss2: (0.0000) | Acc: (91.00%) (27093/29568)
Epoch: 88 | Batch_idx: 240 |  Loss: (0.2426) |  Loss2: (0.0000) | Acc: (91.00%) (28258/30848)
Epoch: 88 | Batch_idx: 250 |  Loss: (0.2424) |  Loss2: (0.0000) | Acc: (91.00%) (29428/32128)
Epoch: 88 | Batch_idx: 260 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (30618/33408)
Epoch: 88 | Batch_idx: 270 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (31801/34688)
Epoch: 88 | Batch_idx: 280 |  Loss: (0.2403) |  Loss2: (0.0000) | Acc: (91.00%) (32980/35968)
Epoch: 88 | Batch_idx: 290 |  Loss: (0.2394) |  Loss2: (0.0000) | Acc: (91.00%) (34171/37248)
Epoch: 88 | Batch_idx: 300 |  Loss: (0.2393) |  Loss2: (0.0000) | Acc: (91.00%) (35347/38528)
Epoch: 88 | Batch_idx: 310 |  Loss: (0.2400) |  Loss2: (0.0000) | Acc: (91.00%) (36517/39808)
Epoch: 88 | Batch_idx: 320 |  Loss: (0.2393) |  Loss2: (0.0000) | Acc: (91.00%) (37702/41088)
Epoch: 88 | Batch_idx: 330 |  Loss: (0.2396) |  Loss2: (0.0000) | Acc: (91.00%) (38871/42368)
Epoch: 88 | Batch_idx: 340 |  Loss: (0.2387) |  Loss2: (0.0000) | Acc: (91.00%) (40066/43648)
Epoch: 88 | Batch_idx: 350 |  Loss: (0.2389) |  Loss2: (0.0000) | Acc: (91.00%) (41241/44928)
Epoch: 88 | Batch_idx: 360 |  Loss: (0.2393) |  Loss2: (0.0000) | Acc: (91.00%) (42407/46208)
Epoch: 88 | Batch_idx: 370 |  Loss: (0.2390) |  Loss2: (0.0000) | Acc: (91.00%) (43582/47488)
Epoch: 88 | Batch_idx: 380 |  Loss: (0.2395) |  Loss2: (0.0000) | Acc: (91.00%) (44752/48768)
Epoch: 88 | Batch_idx: 390 |  Loss: (0.2400) |  Loss2: (0.0000) | Acc: (91.00%) (45868/50000)
# TEST : Loss: (0.3863) | Acc: (87.00%) (8731/10000)
percent tensor([0.5587, 0.5783, 0.5673, 0.5602, 0.5718, 0.5495, 0.5834, 0.5747, 0.5717,
        0.5713, 0.5677, 0.5721, 0.5619, 0.5810, 0.5656, 0.5592],
       device='cuda:0') torch.Size([16])
percent tensor([0.5232, 0.5214, 0.5114, 0.5100, 0.5136, 0.5096, 0.5226, 0.5193, 0.5185,
        0.5169, 0.5177, 0.5157, 0.5226, 0.5184, 0.5148, 0.5175],
       device='cuda:0') torch.Size([16])
percent tensor([0.5489, 0.5615, 0.5493, 0.5878, 0.6131, 0.6013, 0.5901, 0.6364, 0.5467,
        0.5047, 0.5102, 0.5382, 0.5108, 0.5961, 0.6241, 0.5589],
       device='cuda:0') torch.Size([16])
percent tensor([0.6836, 0.6311, 0.6584, 0.6650, 0.6760, 0.6827, 0.6754, 0.6781, 0.6460,
        0.6443, 0.6491, 0.6338, 0.6224, 0.6592, 0.6895, 0.6778],
       device='cuda:0') torch.Size([16])
percent tensor([0.5240, 0.5277, 0.5390, 0.5738, 0.5522, 0.5522, 0.5285, 0.5409, 0.5559,
        0.5348, 0.5331, 0.5538, 0.5116, 0.5655, 0.5198, 0.5543],
       device='cuda:0') torch.Size([16])
percent tensor([0.6052, 0.6227, 0.6238, 0.6813, 0.6468, 0.6296, 0.6483, 0.6161, 0.6496,
        0.6266, 0.6458, 0.6658, 0.6021, 0.7064, 0.5910, 0.6499],
       device='cuda:0') torch.Size([16])
percent tensor([0.6094, 0.5399, 0.6834, 0.7404, 0.6420, 0.7990, 0.6018, 0.5449, 0.6465,
        0.5765, 0.6380, 0.6067, 0.5468, 0.6922, 0.4337, 0.6255],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9991, 0.9998, 0.9997, 0.9997, 0.9990, 0.9992, 0.9997, 0.9995,
        0.9995, 0.9996, 0.9998, 0.9993, 0.9992, 0.9997, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 89 | Batch_idx: 0 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 89 | Batch_idx: 10 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (93.00%) (1320/1408)
Epoch: 89 | Batch_idx: 20 |  Loss: (0.2389) |  Loss2: (0.0000) | Acc: (92.00%) (2479/2688)
Epoch: 89 | Batch_idx: 30 |  Loss: (0.2391) |  Loss2: (0.0000) | Acc: (92.00%) (3656/3968)
Epoch: 89 | Batch_idx: 40 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (92.00%) (4834/5248)
Epoch: 89 | Batch_idx: 50 |  Loss: (0.2348) |  Loss2: (0.0000) | Acc: (92.00%) (6021/6528)
Epoch: 89 | Batch_idx: 60 |  Loss: (0.2345) |  Loss2: (0.0000) | Acc: (92.00%) (7200/7808)
Epoch: 89 | Batch_idx: 70 |  Loss: (0.2391) |  Loss2: (0.0000) | Acc: (91.00%) (8355/9088)
Epoch: 89 | Batch_idx: 80 |  Loss: (0.2387) |  Loss2: (0.0000) | Acc: (91.00%) (9538/10368)
Epoch: 89 | Batch_idx: 90 |  Loss: (0.2402) |  Loss2: (0.0000) | Acc: (91.00%) (10704/11648)
Epoch: 89 | Batch_idx: 100 |  Loss: (0.2391) |  Loss2: (0.0000) | Acc: (91.00%) (11886/12928)
Epoch: 89 | Batch_idx: 110 |  Loss: (0.2389) |  Loss2: (0.0000) | Acc: (91.00%) (13063/14208)
Epoch: 89 | Batch_idx: 120 |  Loss: (0.2393) |  Loss2: (0.0000) | Acc: (91.00%) (14232/15488)
Epoch: 89 | Batch_idx: 130 |  Loss: (0.2396) |  Loss2: (0.0000) | Acc: (91.00%) (15413/16768)
Epoch: 89 | Batch_idx: 140 |  Loss: (0.2392) |  Loss2: (0.0000) | Acc: (91.00%) (16581/18048)
Epoch: 89 | Batch_idx: 150 |  Loss: (0.2393) |  Loss2: (0.0000) | Acc: (91.00%) (17755/19328)
Epoch: 89 | Batch_idx: 160 |  Loss: (0.2405) |  Loss2: (0.0000) | Acc: (91.00%) (18917/20608)
Epoch: 89 | Batch_idx: 170 |  Loss: (0.2412) |  Loss2: (0.0000) | Acc: (91.00%) (20088/21888)
Epoch: 89 | Batch_idx: 180 |  Loss: (0.2406) |  Loss2: (0.0000) | Acc: (91.00%) (21261/23168)
Epoch: 89 | Batch_idx: 190 |  Loss: (0.2407) |  Loss2: (0.0000) | Acc: (91.00%) (22435/24448)
Epoch: 89 | Batch_idx: 200 |  Loss: (0.2393) |  Loss2: (0.0000) | Acc: (91.00%) (23628/25728)
Epoch: 89 | Batch_idx: 210 |  Loss: (0.2396) |  Loss2: (0.0000) | Acc: (91.00%) (24806/27008)
Epoch: 89 | Batch_idx: 220 |  Loss: (0.2383) |  Loss2: (0.0000) | Acc: (91.00%) (25994/28288)
Epoch: 89 | Batch_idx: 230 |  Loss: (0.2379) |  Loss2: (0.0000) | Acc: (91.00%) (27169/29568)
Epoch: 89 | Batch_idx: 240 |  Loss: (0.2374) |  Loss2: (0.0000) | Acc: (91.00%) (28355/30848)
Epoch: 89 | Batch_idx: 250 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (29512/32128)
Epoch: 89 | Batch_idx: 260 |  Loss: (0.2387) |  Loss2: (0.0000) | Acc: (91.00%) (30676/33408)
Epoch: 89 | Batch_idx: 270 |  Loss: (0.2384) |  Loss2: (0.0000) | Acc: (91.00%) (31859/34688)
Epoch: 89 | Batch_idx: 280 |  Loss: (0.2395) |  Loss2: (0.0000) | Acc: (91.00%) (33016/35968)
Epoch: 89 | Batch_idx: 290 |  Loss: (0.2392) |  Loss2: (0.0000) | Acc: (91.00%) (34185/37248)
Epoch: 89 | Batch_idx: 300 |  Loss: (0.2386) |  Loss2: (0.0000) | Acc: (91.00%) (35371/38528)
Epoch: 89 | Batch_idx: 310 |  Loss: (0.2388) |  Loss2: (0.0000) | Acc: (91.00%) (36548/39808)
Epoch: 89 | Batch_idx: 320 |  Loss: (0.2395) |  Loss2: (0.0000) | Acc: (91.00%) (37715/41088)
Epoch: 89 | Batch_idx: 330 |  Loss: (0.2397) |  Loss2: (0.0000) | Acc: (91.00%) (38883/42368)
Epoch: 89 | Batch_idx: 340 |  Loss: (0.2400) |  Loss2: (0.0000) | Acc: (91.00%) (40066/43648)
Epoch: 89 | Batch_idx: 350 |  Loss: (0.2391) |  Loss2: (0.0000) | Acc: (91.00%) (41250/44928)
Epoch: 89 | Batch_idx: 360 |  Loss: (0.2379) |  Loss2: (0.0000) | Acc: (91.00%) (42442/46208)
Epoch: 89 | Batch_idx: 370 |  Loss: (0.2384) |  Loss2: (0.0000) | Acc: (91.00%) (43610/47488)
Epoch: 89 | Batch_idx: 380 |  Loss: (0.2378) |  Loss2: (0.0000) | Acc: (91.00%) (44798/48768)
Epoch: 89 | Batch_idx: 390 |  Loss: (0.2379) |  Loss2: (0.0000) | Acc: (91.00%) (45930/50000)
# TEST : Loss: (0.3833) | Acc: (87.00%) (8732/10000)
percent tensor([0.5573, 0.5765, 0.5661, 0.5590, 0.5704, 0.5485, 0.5816, 0.5730, 0.5700,
        0.5696, 0.5660, 0.5706, 0.5604, 0.5791, 0.5641, 0.5576],
       device='cuda:0') torch.Size([16])
percent tensor([0.5258, 0.5247, 0.5138, 0.5120, 0.5162, 0.5113, 0.5259, 0.5220, 0.5212,
        0.5199, 0.5206, 0.5185, 0.5256, 0.5212, 0.5172, 0.5202],
       device='cuda:0') torch.Size([16])
percent tensor([0.5550, 0.5637, 0.5563, 0.5933, 0.6194, 0.6070, 0.5941, 0.6409, 0.5522,
        0.5090, 0.5151, 0.5440, 0.5139, 0.5990, 0.6276, 0.5638],
       device='cuda:0') torch.Size([16])
percent tensor([0.6834, 0.6303, 0.6585, 0.6655, 0.6771, 0.6827, 0.6745, 0.6785, 0.6454,
        0.6439, 0.6481, 0.6333, 0.6216, 0.6577, 0.6887, 0.6777],
       device='cuda:0') torch.Size([16])
percent tensor([0.5262, 0.5299, 0.5402, 0.5759, 0.5527, 0.5555, 0.5298, 0.5408, 0.5590,
        0.5383, 0.5362, 0.5555, 0.5146, 0.5684, 0.5195, 0.5586],
       device='cuda:0') torch.Size([16])
percent tensor([0.6061, 0.6281, 0.6267, 0.6858, 0.6510, 0.6292, 0.6520, 0.6184, 0.6546,
        0.6316, 0.6512, 0.6725, 0.6073, 0.7132, 0.5921, 0.6519],
       device='cuda:0') torch.Size([16])
percent tensor([0.6132, 0.5490, 0.6877, 0.7429, 0.6455, 0.7991, 0.6086, 0.5525, 0.6511,
        0.5805, 0.6424, 0.6149, 0.5570, 0.6974, 0.4397, 0.6274],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9991, 0.9998, 0.9997, 0.9997, 0.9990, 0.9992, 0.9997, 0.9995,
        0.9995, 0.9996, 0.9998, 0.9993, 0.9992, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 90 | Batch_idx: 0 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 90 | Batch_idx: 10 |  Loss: (0.2116) |  Loss2: (0.0000) | Acc: (92.00%) (1304/1408)
Epoch: 90 | Batch_idx: 20 |  Loss: (0.2076) |  Loss2: (0.0000) | Acc: (92.00%) (2494/2688)
Epoch: 90 | Batch_idx: 30 |  Loss: (0.2189) |  Loss2: (0.0000) | Acc: (92.00%) (3667/3968)
Epoch: 90 | Batch_idx: 40 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (4839/5248)
Epoch: 90 | Batch_idx: 50 |  Loss: (0.2279) |  Loss2: (0.0000) | Acc: (92.00%) (6010/6528)
Epoch: 90 | Batch_idx: 60 |  Loss: (0.2323) |  Loss2: (0.0000) | Acc: (91.00%) (7174/7808)
Epoch: 90 | Batch_idx: 70 |  Loss: (0.2318) |  Loss2: (0.0000) | Acc: (91.00%) (8355/9088)
Epoch: 90 | Batch_idx: 80 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (91.00%) (9518/10368)
Epoch: 90 | Batch_idx: 90 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (10684/11648)
Epoch: 90 | Batch_idx: 100 |  Loss: (0.2391) |  Loss2: (0.0000) | Acc: (91.00%) (11848/12928)
Epoch: 90 | Batch_idx: 110 |  Loss: (0.2389) |  Loss2: (0.0000) | Acc: (91.00%) (13023/14208)
Epoch: 90 | Batch_idx: 120 |  Loss: (0.2397) |  Loss2: (0.0000) | Acc: (91.00%) (14185/15488)
Epoch: 90 | Batch_idx: 130 |  Loss: (0.2403) |  Loss2: (0.0000) | Acc: (91.00%) (15364/16768)
Epoch: 90 | Batch_idx: 140 |  Loss: (0.2405) |  Loss2: (0.0000) | Acc: (91.00%) (16537/18048)
Epoch: 90 | Batch_idx: 150 |  Loss: (0.2411) |  Loss2: (0.0000) | Acc: (91.00%) (17697/19328)
Epoch: 90 | Batch_idx: 160 |  Loss: (0.2391) |  Loss2: (0.0000) | Acc: (91.00%) (18881/20608)
Epoch: 90 | Batch_idx: 170 |  Loss: (0.2390) |  Loss2: (0.0000) | Acc: (91.00%) (20066/21888)
Epoch: 90 | Batch_idx: 180 |  Loss: (0.2380) |  Loss2: (0.0000) | Acc: (91.00%) (21244/23168)
Epoch: 90 | Batch_idx: 190 |  Loss: (0.2387) |  Loss2: (0.0000) | Acc: (91.00%) (22413/24448)
Epoch: 90 | Batch_idx: 200 |  Loss: (0.2410) |  Loss2: (0.0000) | Acc: (91.00%) (23570/25728)
Epoch: 90 | Batch_idx: 210 |  Loss: (0.2416) |  Loss2: (0.0000) | Acc: (91.00%) (24744/27008)
Epoch: 90 | Batch_idx: 220 |  Loss: (0.2400) |  Loss2: (0.0000) | Acc: (91.00%) (25940/28288)
Epoch: 90 | Batch_idx: 230 |  Loss: (0.2408) |  Loss2: (0.0000) | Acc: (91.00%) (27102/29568)
Epoch: 90 | Batch_idx: 240 |  Loss: (0.2406) |  Loss2: (0.0000) | Acc: (91.00%) (28279/30848)
Epoch: 90 | Batch_idx: 250 |  Loss: (0.2399) |  Loss2: (0.0000) | Acc: (91.00%) (29471/32128)
Epoch: 90 | Batch_idx: 260 |  Loss: (0.2411) |  Loss2: (0.0000) | Acc: (91.00%) (30628/33408)
Epoch: 90 | Batch_idx: 270 |  Loss: (0.2421) |  Loss2: (0.0000) | Acc: (91.00%) (31792/34688)
Epoch: 90 | Batch_idx: 280 |  Loss: (0.2422) |  Loss2: (0.0000) | Acc: (91.00%) (32960/35968)
Epoch: 90 | Batch_idx: 290 |  Loss: (0.2436) |  Loss2: (0.0000) | Acc: (91.00%) (34105/37248)
Epoch: 90 | Batch_idx: 300 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (35271/38528)
Epoch: 90 | Batch_idx: 310 |  Loss: (0.2441) |  Loss2: (0.0000) | Acc: (91.00%) (36442/39808)
Epoch: 90 | Batch_idx: 320 |  Loss: (0.2437) |  Loss2: (0.0000) | Acc: (91.00%) (37614/41088)
Epoch: 90 | Batch_idx: 330 |  Loss: (0.2439) |  Loss2: (0.0000) | Acc: (91.00%) (38788/42368)
Epoch: 90 | Batch_idx: 340 |  Loss: (0.2450) |  Loss2: (0.0000) | Acc: (91.00%) (39947/43648)
Epoch: 90 | Batch_idx: 350 |  Loss: (0.2455) |  Loss2: (0.0000) | Acc: (91.00%) (41102/44928)
Epoch: 90 | Batch_idx: 360 |  Loss: (0.2452) |  Loss2: (0.0000) | Acc: (91.00%) (42277/46208)
Epoch: 90 | Batch_idx: 370 |  Loss: (0.2446) |  Loss2: (0.0000) | Acc: (91.00%) (43456/47488)
Epoch: 90 | Batch_idx: 380 |  Loss: (0.2444) |  Loss2: (0.0000) | Acc: (91.00%) (44634/48768)
Epoch: 90 | Batch_idx: 390 |  Loss: (0.2452) |  Loss2: (0.0000) | Acc: (91.00%) (45747/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_090.pth.tar'
# TEST : Loss: (0.3886) | Acc: (87.00%) (8736/10000)
percent tensor([0.5561, 0.5770, 0.5656, 0.5583, 0.5700, 0.5466, 0.5819, 0.5723, 0.5693,
        0.5700, 0.5654, 0.5706, 0.5597, 0.5802, 0.5637, 0.5572],
       device='cuda:0') torch.Size([16])
percent tensor([0.5268, 0.5228, 0.5142, 0.5128, 0.5172, 0.5126, 0.5240, 0.5211, 0.5194,
        0.5195, 0.5201, 0.5183, 0.5254, 0.5167, 0.5170, 0.5213],
       device='cuda:0') torch.Size([16])
percent tensor([0.5593, 0.5668, 0.5618, 0.5958, 0.6213, 0.6115, 0.6020, 0.6398, 0.5554,
        0.5187, 0.5237, 0.5585, 0.5236, 0.5929, 0.6249, 0.5666],
       device='cuda:0') torch.Size([16])
percent tensor([0.6819, 0.6305, 0.6576, 0.6739, 0.6817, 0.6806, 0.6774, 0.6777, 0.6415,
        0.6459, 0.6482, 0.6365, 0.6209, 0.6560, 0.6878, 0.6820],
       device='cuda:0') torch.Size([16])
percent tensor([0.5306, 0.5305, 0.5445, 0.5721, 0.5479, 0.5664, 0.5267, 0.5457, 0.5614,
        0.5381, 0.5353, 0.5524, 0.5237, 0.5693, 0.5217, 0.5617],
       device='cuda:0') torch.Size([16])
percent tensor([0.6103, 0.6386, 0.6224, 0.6782, 0.6417, 0.6352, 0.6500, 0.6210, 0.6613,
        0.6367, 0.6584, 0.6711, 0.6183, 0.7152, 0.6009, 0.6525],
       device='cuda:0') torch.Size([16])
percent tensor([0.6029, 0.5564, 0.6543, 0.7101, 0.6310, 0.7697, 0.5824, 0.5468, 0.6660,
        0.5995, 0.6482, 0.5906, 0.5876, 0.7115, 0.4422, 0.6039],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9993, 0.9996, 0.9993, 0.9998, 0.9984, 0.9990, 0.9995, 0.9996,
        0.9996, 0.9998, 0.9997, 0.9994, 0.9992, 0.9995, 0.9993],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(173.5972, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(807.8300, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(807.1199, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1529.7217, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(492.7816, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2223.8896, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4269.5820, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1406.6316, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6150.7915, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11901.5459, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3965.6177, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16700.0645, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 91 | Batch_idx: 0 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 91 | Batch_idx: 10 |  Loss: (0.2521) |  Loss2: (0.0000) | Acc: (90.00%) (1280/1408)
Epoch: 91 | Batch_idx: 20 |  Loss: (0.2505) |  Loss2: (0.0000) | Acc: (91.00%) (2454/2688)
Epoch: 91 | Batch_idx: 30 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (3647/3968)
Epoch: 91 | Batch_idx: 40 |  Loss: (0.2401) |  Loss2: (0.0000) | Acc: (92.00%) (4831/5248)
Epoch: 91 | Batch_idx: 50 |  Loss: (0.2427) |  Loss2: (0.0000) | Acc: (91.00%) (6001/6528)
Epoch: 91 | Batch_idx: 60 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (92.00%) (7188/7808)
Epoch: 91 | Batch_idx: 70 |  Loss: (0.2406) |  Loss2: (0.0000) | Acc: (92.00%) (8365/9088)
Epoch: 91 | Batch_idx: 80 |  Loss: (0.2379) |  Loss2: (0.0000) | Acc: (92.00%) (9551/10368)
Epoch: 91 | Batch_idx: 90 |  Loss: (0.2403) |  Loss2: (0.0000) | Acc: (92.00%) (10718/11648)
Epoch: 91 | Batch_idx: 100 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (91.00%) (11888/12928)
Epoch: 91 | Batch_idx: 110 |  Loss: (0.2417) |  Loss2: (0.0000) | Acc: (91.00%) (13052/14208)
Epoch: 91 | Batch_idx: 120 |  Loss: (0.2397) |  Loss2: (0.0000) | Acc: (91.00%) (14231/15488)
Epoch: 91 | Batch_idx: 130 |  Loss: (0.2392) |  Loss2: (0.0000) | Acc: (91.00%) (15412/16768)
Epoch: 91 | Batch_idx: 140 |  Loss: (0.2378) |  Loss2: (0.0000) | Acc: (91.00%) (16593/18048)
Epoch: 91 | Batch_idx: 150 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (17775/19328)
Epoch: 91 | Batch_idx: 160 |  Loss: (0.2355) |  Loss2: (0.0000) | Acc: (91.00%) (18959/20608)
Epoch: 91 | Batch_idx: 170 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (20132/21888)
Epoch: 91 | Batch_idx: 180 |  Loss: (0.2378) |  Loss2: (0.0000) | Acc: (91.00%) (21285/23168)
Epoch: 91 | Batch_idx: 190 |  Loss: (0.2379) |  Loss2: (0.0000) | Acc: (91.00%) (22459/24448)
Epoch: 91 | Batch_idx: 200 |  Loss: (0.2377) |  Loss2: (0.0000) | Acc: (91.00%) (23622/25728)
Epoch: 91 | Batch_idx: 210 |  Loss: (0.2378) |  Loss2: (0.0000) | Acc: (91.00%) (24798/27008)
Epoch: 91 | Batch_idx: 220 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (25991/28288)
Epoch: 91 | Batch_idx: 230 |  Loss: (0.2362) |  Loss2: (0.0000) | Acc: (91.00%) (27166/29568)
Epoch: 91 | Batch_idx: 240 |  Loss: (0.2368) |  Loss2: (0.0000) | Acc: (91.00%) (28338/30848)
Epoch: 91 | Batch_idx: 250 |  Loss: (0.2360) |  Loss2: (0.0000) | Acc: (91.00%) (29512/32128)
Epoch: 91 | Batch_idx: 260 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (91.00%) (30685/33408)
Epoch: 91 | Batch_idx: 270 |  Loss: (0.2374) |  Loss2: (0.0000) | Acc: (91.00%) (31848/34688)
Epoch: 91 | Batch_idx: 280 |  Loss: (0.2369) |  Loss2: (0.0000) | Acc: (91.00%) (33031/35968)
Epoch: 91 | Batch_idx: 290 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (34212/37248)
Epoch: 91 | Batch_idx: 300 |  Loss: (0.2376) |  Loss2: (0.0000) | Acc: (91.00%) (35392/38528)
Epoch: 91 | Batch_idx: 310 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (36553/39808)
Epoch: 91 | Batch_idx: 320 |  Loss: (0.2386) |  Loss2: (0.0000) | Acc: (91.00%) (37718/41088)
Epoch: 91 | Batch_idx: 330 |  Loss: (0.2386) |  Loss2: (0.0000) | Acc: (91.00%) (38887/42368)
Epoch: 91 | Batch_idx: 340 |  Loss: (0.2387) |  Loss2: (0.0000) | Acc: (91.00%) (40060/43648)
Epoch: 91 | Batch_idx: 350 |  Loss: (0.2390) |  Loss2: (0.0000) | Acc: (91.00%) (41232/44928)
Epoch: 91 | Batch_idx: 360 |  Loss: (0.2388) |  Loss2: (0.0000) | Acc: (91.00%) (42406/46208)
Epoch: 91 | Batch_idx: 370 |  Loss: (0.2392) |  Loss2: (0.0000) | Acc: (91.00%) (43576/47488)
Epoch: 91 | Batch_idx: 380 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (91.00%) (44735/48768)
Epoch: 91 | Batch_idx: 390 |  Loss: (0.2399) |  Loss2: (0.0000) | Acc: (91.00%) (45852/50000)
# TEST : Loss: (0.4326) | Acc: (85.00%) (8597/10000)
percent tensor([0.5571, 0.5773, 0.5685, 0.5588, 0.5727, 0.5479, 0.5833, 0.5726, 0.5700,
        0.5705, 0.5654, 0.5733, 0.5600, 0.5804, 0.5642, 0.5574],
       device='cuda:0') torch.Size([16])
percent tensor([0.5269, 0.5240, 0.5145, 0.5121, 0.5171, 0.5131, 0.5252, 0.5210, 0.5201,
        0.5194, 0.5203, 0.5182, 0.5254, 0.5192, 0.5168, 0.5213],
       device='cuda:0') torch.Size([16])
percent tensor([0.5629, 0.5806, 0.5676, 0.6016, 0.6269, 0.6005, 0.6076, 0.6427, 0.5555,
        0.5290, 0.5256, 0.5640, 0.5250, 0.5992, 0.6288, 0.5702],
       device='cuda:0') torch.Size([16])
percent tensor([0.6866, 0.6317, 0.6560, 0.6701, 0.6787, 0.6850, 0.6761, 0.6771, 0.6411,
        0.6420, 0.6470, 0.6352, 0.6209, 0.6566, 0.6890, 0.6817],
       device='cuda:0') torch.Size([16])
percent tensor([0.5254, 0.5362, 0.5369, 0.5667, 0.5439, 0.5600, 0.5291, 0.5394, 0.5600,
        0.5377, 0.5391, 0.5480, 0.5224, 0.5716, 0.5195, 0.5593],
       device='cuda:0') torch.Size([16])
percent tensor([0.5993, 0.6352, 0.6235, 0.6695, 0.6350, 0.6336, 0.6513, 0.6158, 0.6571,
        0.6285, 0.6556, 0.6644, 0.6084, 0.7118, 0.6012, 0.6601],
       device='cuda:0') torch.Size([16])
percent tensor([0.5749, 0.5524, 0.6840, 0.7055, 0.6333, 0.7828, 0.6150, 0.5335, 0.6627,
        0.5796, 0.6384, 0.6015, 0.5391, 0.6955, 0.4372, 0.6382],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9994, 0.9997, 0.9991, 0.9996, 0.9982, 0.9991, 0.9995, 0.9990,
        0.9994, 0.9996, 0.9999, 0.9992, 0.9992, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 92 | Batch_idx: 0 |  Loss: (0.2404) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 92 | Batch_idx: 10 |  Loss: (0.2380) |  Loss2: (0.0000) | Acc: (92.00%) (1297/1408)
Epoch: 92 | Batch_idx: 20 |  Loss: (0.2313) |  Loss2: (0.0000) | Acc: (92.00%) (2482/2688)
Epoch: 92 | Batch_idx: 30 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (3672/3968)
Epoch: 92 | Batch_idx: 40 |  Loss: (0.2314) |  Loss2: (0.0000) | Acc: (92.00%) (4843/5248)
Epoch: 92 | Batch_idx: 50 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (92.00%) (6031/6528)
Epoch: 92 | Batch_idx: 60 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (92.00%) (7208/7808)
Epoch: 92 | Batch_idx: 70 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (8391/9088)
Epoch: 92 | Batch_idx: 80 |  Loss: (0.2346) |  Loss2: (0.0000) | Acc: (92.00%) (9547/10368)
Epoch: 92 | Batch_idx: 90 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (92.00%) (10723/11648)
Epoch: 92 | Batch_idx: 100 |  Loss: (0.2344) |  Loss2: (0.0000) | Acc: (92.00%) (11908/12928)
Epoch: 92 | Batch_idx: 110 |  Loss: (0.2324) |  Loss2: (0.0000) | Acc: (92.00%) (13088/14208)
Epoch: 92 | Batch_idx: 120 |  Loss: (0.2330) |  Loss2: (0.0000) | Acc: (92.00%) (14264/15488)
Epoch: 92 | Batch_idx: 130 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (92.00%) (15455/16768)
Epoch: 92 | Batch_idx: 140 |  Loss: (0.2314) |  Loss2: (0.0000) | Acc: (92.00%) (16626/18048)
Epoch: 92 | Batch_idx: 150 |  Loss: (0.2317) |  Loss2: (0.0000) | Acc: (92.00%) (17792/19328)
Epoch: 92 | Batch_idx: 160 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (92.00%) (18970/20608)
Epoch: 92 | Batch_idx: 170 |  Loss: (0.2331) |  Loss2: (0.0000) | Acc: (91.00%) (20135/21888)
Epoch: 92 | Batch_idx: 180 |  Loss: (0.2318) |  Loss2: (0.0000) | Acc: (92.00%) (21322/23168)
Epoch: 92 | Batch_idx: 190 |  Loss: (0.2321) |  Loss2: (0.0000) | Acc: (92.00%) (22499/24448)
Epoch: 92 | Batch_idx: 200 |  Loss: (0.2321) |  Loss2: (0.0000) | Acc: (92.00%) (23673/25728)
Epoch: 92 | Batch_idx: 210 |  Loss: (0.2325) |  Loss2: (0.0000) | Acc: (91.00%) (24839/27008)
Epoch: 92 | Batch_idx: 220 |  Loss: (0.2327) |  Loss2: (0.0000) | Acc: (91.00%) (26004/28288)
Epoch: 92 | Batch_idx: 230 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (91.00%) (27188/29568)
Epoch: 92 | Batch_idx: 240 |  Loss: (0.2322) |  Loss2: (0.0000) | Acc: (91.00%) (28368/30848)
Epoch: 92 | Batch_idx: 250 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (91.00%) (29551/32128)
Epoch: 92 | Batch_idx: 260 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (91.00%) (30726/33408)
Epoch: 92 | Batch_idx: 270 |  Loss: (0.2324) |  Loss2: (0.0000) | Acc: (91.00%) (31894/34688)
Epoch: 92 | Batch_idx: 280 |  Loss: (0.2337) |  Loss2: (0.0000) | Acc: (91.00%) (33056/35968)
Epoch: 92 | Batch_idx: 290 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (91.00%) (34222/37248)
Epoch: 92 | Batch_idx: 300 |  Loss: (0.2338) |  Loss2: (0.0000) | Acc: (91.00%) (35415/38528)
Epoch: 92 | Batch_idx: 310 |  Loss: (0.2343) |  Loss2: (0.0000) | Acc: (91.00%) (36577/39808)
Epoch: 92 | Batch_idx: 320 |  Loss: (0.2346) |  Loss2: (0.0000) | Acc: (91.00%) (37743/41088)
Epoch: 92 | Batch_idx: 330 |  Loss: (0.2343) |  Loss2: (0.0000) | Acc: (91.00%) (38927/42368)
Epoch: 92 | Batch_idx: 340 |  Loss: (0.2340) |  Loss2: (0.0000) | Acc: (91.00%) (40104/43648)
Epoch: 92 | Batch_idx: 350 |  Loss: (0.2342) |  Loss2: (0.0000) | Acc: (91.00%) (41278/44928)
Epoch: 92 | Batch_idx: 360 |  Loss: (0.2339) |  Loss2: (0.0000) | Acc: (91.00%) (42457/46208)
Epoch: 92 | Batch_idx: 370 |  Loss: (0.2338) |  Loss2: (0.0000) | Acc: (91.00%) (43632/47488)
Epoch: 92 | Batch_idx: 380 |  Loss: (0.2345) |  Loss2: (0.0000) | Acc: (91.00%) (44798/48768)
Epoch: 92 | Batch_idx: 390 |  Loss: (0.2342) |  Loss2: (0.0000) | Acc: (91.00%) (45934/50000)
# TEST : Loss: (0.4308) | Acc: (85.00%) (8574/10000)
percent tensor([0.5579, 0.5769, 0.5672, 0.5590, 0.5715, 0.5485, 0.5824, 0.5727, 0.5696,
        0.5704, 0.5657, 0.5718, 0.5609, 0.5794, 0.5643, 0.5577],
       device='cuda:0') torch.Size([16])
percent tensor([0.5280, 0.5263, 0.5167, 0.5148, 0.5189, 0.5116, 0.5274, 0.5239, 0.5212,
        0.5223, 0.5214, 0.5214, 0.5274, 0.5217, 0.5180, 0.5228],
       device='cuda:0') torch.Size([16])
percent tensor([0.5637, 0.5691, 0.5745, 0.6064, 0.6304, 0.6070, 0.6024, 0.6432, 0.5544,
        0.5250, 0.5176, 0.5653, 0.5192, 0.5962, 0.6260, 0.5669],
       device='cuda:0') torch.Size([16])
percent tensor([0.6914, 0.6351, 0.6650, 0.6738, 0.6875, 0.6931, 0.6827, 0.6821, 0.6461,
        0.6504, 0.6538, 0.6394, 0.6282, 0.6614, 0.6930, 0.6858],
       device='cuda:0') torch.Size([16])
percent tensor([0.5237, 0.5308, 0.5335, 0.5609, 0.5401, 0.5605, 0.5237, 0.5311, 0.5610,
        0.5330, 0.5380, 0.5456, 0.5198, 0.5668, 0.5161, 0.5522],
       device='cuda:0') torch.Size([16])
percent tensor([0.6043, 0.6262, 0.6205, 0.6685, 0.6421, 0.6444, 0.6391, 0.6126, 0.6567,
        0.6220, 0.6500, 0.6563, 0.6135, 0.7028, 0.6004, 0.6519],
       device='cuda:0') torch.Size([16])
percent tensor([0.5817, 0.5400, 0.6736, 0.7176, 0.6435, 0.7917, 0.5741, 0.5450, 0.6444,
        0.5572, 0.6149, 0.5653, 0.5597, 0.6711, 0.4373, 0.6149],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9995, 0.9996, 0.9989, 0.9998, 0.9982, 0.9991, 0.9993, 0.9993,
        0.9995, 0.9995, 0.9998, 0.9993, 0.9993, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 93 | Batch_idx: 0 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 93 | Batch_idx: 10 |  Loss: (0.2228) |  Loss2: (0.0000) | Acc: (91.00%) (1295/1408)
Epoch: 93 | Batch_idx: 20 |  Loss: (0.2254) |  Loss2: (0.0000) | Acc: (91.00%) (2469/2688)
Epoch: 93 | Batch_idx: 30 |  Loss: (0.2239) |  Loss2: (0.0000) | Acc: (91.00%) (3648/3968)
Epoch: 93 | Batch_idx: 40 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (91.00%) (4820/5248)
Epoch: 93 | Batch_idx: 50 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (6013/6528)
Epoch: 93 | Batch_idx: 60 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (7201/7808)
Epoch: 93 | Batch_idx: 70 |  Loss: (0.2235) |  Loss2: (0.0000) | Acc: (92.00%) (8386/9088)
Epoch: 93 | Batch_idx: 80 |  Loss: (0.2214) |  Loss2: (0.0000) | Acc: (92.00%) (9571/10368)
Epoch: 93 | Batch_idx: 90 |  Loss: (0.2239) |  Loss2: (0.0000) | Acc: (92.00%) (10743/11648)
Epoch: 93 | Batch_idx: 100 |  Loss: (0.2251) |  Loss2: (0.0000) | Acc: (92.00%) (11913/12928)
Epoch: 93 | Batch_idx: 110 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (13091/14208)
Epoch: 93 | Batch_idx: 120 |  Loss: (0.2270) |  Loss2: (0.0000) | Acc: (92.00%) (14260/15488)
Epoch: 93 | Batch_idx: 130 |  Loss: (0.2262) |  Loss2: (0.0000) | Acc: (92.00%) (15427/16768)
Epoch: 93 | Batch_idx: 140 |  Loss: (0.2279) |  Loss2: (0.0000) | Acc: (91.00%) (16586/18048)
Epoch: 93 | Batch_idx: 150 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (91.00%) (17781/19328)
Epoch: 93 | Batch_idx: 160 |  Loss: (0.2280) |  Loss2: (0.0000) | Acc: (92.00%) (18963/20608)
Epoch: 93 | Batch_idx: 170 |  Loss: (0.2282) |  Loss2: (0.0000) | Acc: (91.00%) (20131/21888)
Epoch: 93 | Batch_idx: 180 |  Loss: (0.2282) |  Loss2: (0.0000) | Acc: (91.00%) (21308/23168)
Epoch: 93 | Batch_idx: 190 |  Loss: (0.2290) |  Loss2: (0.0000) | Acc: (91.00%) (22472/24448)
Epoch: 93 | Batch_idx: 200 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (91.00%) (23660/25728)
Epoch: 93 | Batch_idx: 210 |  Loss: (0.2280) |  Loss2: (0.0000) | Acc: (91.00%) (24843/27008)
Epoch: 93 | Batch_idx: 220 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (91.00%) (26023/28288)
Epoch: 93 | Batch_idx: 230 |  Loss: (0.2277) |  Loss2: (0.0000) | Acc: (91.00%) (27198/29568)
Epoch: 93 | Batch_idx: 240 |  Loss: (0.2277) |  Loss2: (0.0000) | Acc: (91.00%) (28365/30848)
Epoch: 93 | Batch_idx: 250 |  Loss: (0.2288) |  Loss2: (0.0000) | Acc: (91.00%) (29534/32128)
Epoch: 93 | Batch_idx: 260 |  Loss: (0.2280) |  Loss2: (0.0000) | Acc: (91.00%) (30721/33408)
Epoch: 93 | Batch_idx: 270 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (91.00%) (31906/34688)
Epoch: 93 | Batch_idx: 280 |  Loss: (0.2271) |  Loss2: (0.0000) | Acc: (91.00%) (33087/35968)
Epoch: 93 | Batch_idx: 290 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (91.00%) (34260/37248)
Epoch: 93 | Batch_idx: 300 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (91.00%) (35430/38528)
Epoch: 93 | Batch_idx: 310 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (36624/39808)
Epoch: 93 | Batch_idx: 320 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (91.00%) (37797/41088)
Epoch: 93 | Batch_idx: 330 |  Loss: (0.2272) |  Loss2: (0.0000) | Acc: (91.00%) (38978/42368)
Epoch: 93 | Batch_idx: 340 |  Loss: (0.2274) |  Loss2: (0.0000) | Acc: (92.00%) (40159/43648)
Epoch: 93 | Batch_idx: 350 |  Loss: (0.2267) |  Loss2: (0.0000) | Acc: (92.00%) (41354/44928)
Epoch: 93 | Batch_idx: 360 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (42527/46208)
Epoch: 93 | Batch_idx: 370 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (92.00%) (43700/47488)
Epoch: 93 | Batch_idx: 380 |  Loss: (0.2279) |  Loss2: (0.0000) | Acc: (92.00%) (44883/48768)
Epoch: 93 | Batch_idx: 390 |  Loss: (0.2272) |  Loss2: (0.0000) | Acc: (92.00%) (46025/50000)
# TEST : Loss: (0.4125) | Acc: (86.00%) (8669/10000)
percent tensor([0.5572, 0.5775, 0.5645, 0.5582, 0.5696, 0.5475, 0.5821, 0.5717, 0.5702,
        0.5697, 0.5662, 0.5699, 0.5608, 0.5818, 0.5641, 0.5578],
       device='cuda:0') torch.Size([16])
percent tensor([0.5264, 0.5250, 0.5116, 0.5112, 0.5153, 0.5117, 0.5260, 0.5204, 0.5208,
        0.5193, 0.5209, 0.5165, 0.5255, 0.5219, 0.5173, 0.5213],
       device='cuda:0') torch.Size([16])
percent tensor([0.5517, 0.5551, 0.5672, 0.5907, 0.6202, 0.5923, 0.5943, 0.6376, 0.5534,
        0.5169, 0.5150, 0.5584, 0.5158, 0.5858, 0.6136, 0.5552],
       device='cuda:0') torch.Size([16])
percent tensor([0.6835, 0.6230, 0.6598, 0.6648, 0.6798, 0.6821, 0.6749, 0.6756, 0.6409,
        0.6410, 0.6434, 0.6301, 0.6219, 0.6535, 0.6841, 0.6760],
       device='cuda:0') torch.Size([16])
percent tensor([0.5275, 0.5385, 0.5426, 0.5734, 0.5479, 0.5574, 0.5274, 0.5454, 0.5632,
        0.5449, 0.5442, 0.5576, 0.5262, 0.5631, 0.5201, 0.5597],
       device='cuda:0') torch.Size([16])
percent tensor([0.6034, 0.6326, 0.6235, 0.6754, 0.6407, 0.6357, 0.6430, 0.6076, 0.6674,
        0.6376, 0.6590, 0.6727, 0.6119, 0.7170, 0.6010, 0.6554],
       device='cuda:0') torch.Size([16])
percent tensor([0.5901, 0.5540, 0.6738, 0.7004, 0.6245, 0.7728, 0.5624, 0.5094, 0.6608,
        0.6020, 0.6251, 0.6162, 0.5727, 0.6804, 0.4404, 0.6035],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9994, 0.9997, 0.9992, 0.9998, 0.9981, 0.9990, 0.9994, 0.9994,
        0.9995, 0.9996, 0.9999, 0.9993, 0.9993, 0.9996, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 94 | Batch_idx: 0 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 94 | Batch_idx: 10 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (93.00%) (1310/1408)
Epoch: 94 | Batch_idx: 20 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (2493/2688)
Epoch: 94 | Batch_idx: 30 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (92.00%) (3669/3968)
Epoch: 94 | Batch_idx: 40 |  Loss: (0.2240) |  Loss2: (0.0000) | Acc: (92.00%) (4855/5248)
Epoch: 94 | Batch_idx: 50 |  Loss: (0.2217) |  Loss2: (0.0000) | Acc: (92.00%) (6039/6528)
Epoch: 94 | Batch_idx: 60 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (7220/7808)
Epoch: 94 | Batch_idx: 70 |  Loss: (0.2214) |  Loss2: (0.0000) | Acc: (92.00%) (8415/9088)
Epoch: 94 | Batch_idx: 80 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (9601/10368)
Epoch: 94 | Batch_idx: 90 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (10803/11648)
Epoch: 94 | Batch_idx: 100 |  Loss: (0.2158) |  Loss2: (0.0000) | Acc: (92.00%) (11982/12928)
Epoch: 94 | Batch_idx: 110 |  Loss: (0.2137) |  Loss2: (0.0000) | Acc: (92.00%) (13186/14208)
Epoch: 94 | Batch_idx: 120 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (92.00%) (14354/15488)
Epoch: 94 | Batch_idx: 130 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (15532/16768)
Epoch: 94 | Batch_idx: 140 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (16707/18048)
Epoch: 94 | Batch_idx: 150 |  Loss: (0.2186) |  Loss2: (0.0000) | Acc: (92.00%) (17886/19328)
Epoch: 94 | Batch_idx: 160 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (19082/20608)
Epoch: 94 | Batch_idx: 170 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (92.00%) (20258/21888)
Epoch: 94 | Batch_idx: 180 |  Loss: (0.2178) |  Loss2: (0.0000) | Acc: (92.00%) (21445/23168)
Epoch: 94 | Batch_idx: 190 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (92.00%) (22638/24448)
Epoch: 94 | Batch_idx: 200 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (23818/25728)
Epoch: 94 | Batch_idx: 210 |  Loss: (0.2186) |  Loss2: (0.0000) | Acc: (92.00%) (24990/27008)
Epoch: 94 | Batch_idx: 220 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (26163/28288)
Epoch: 94 | Batch_idx: 230 |  Loss: (0.2180) |  Loss2: (0.0000) | Acc: (92.00%) (27361/29568)
Epoch: 94 | Batch_idx: 240 |  Loss: (0.2186) |  Loss2: (0.0000) | Acc: (92.00%) (28535/30848)
Epoch: 94 | Batch_idx: 250 |  Loss: (0.2194) |  Loss2: (0.0000) | Acc: (92.00%) (29714/32128)
Epoch: 94 | Batch_idx: 260 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (30903/33408)
Epoch: 94 | Batch_idx: 270 |  Loss: (0.2199) |  Loss2: (0.0000) | Acc: (92.00%) (32061/34688)
Epoch: 94 | Batch_idx: 280 |  Loss: (0.2206) |  Loss2: (0.0000) | Acc: (92.00%) (33237/35968)
Epoch: 94 | Batch_idx: 290 |  Loss: (0.2219) |  Loss2: (0.0000) | Acc: (92.00%) (34409/37248)
Epoch: 94 | Batch_idx: 300 |  Loss: (0.2226) |  Loss2: (0.0000) | Acc: (92.00%) (35576/38528)
Epoch: 94 | Batch_idx: 310 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (36764/39808)
Epoch: 94 | Batch_idx: 320 |  Loss: (0.2214) |  Loss2: (0.0000) | Acc: (92.00%) (37969/41088)
Epoch: 94 | Batch_idx: 330 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (39159/42368)
Epoch: 94 | Batch_idx: 340 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (40348/43648)
Epoch: 94 | Batch_idx: 350 |  Loss: (0.2206) |  Loss2: (0.0000) | Acc: (92.00%) (41533/44928)
Epoch: 94 | Batch_idx: 360 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (42724/46208)
Epoch: 94 | Batch_idx: 370 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (43908/47488)
Epoch: 94 | Batch_idx: 380 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (45095/48768)
Epoch: 94 | Batch_idx: 390 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (46243/50000)
# TEST : Loss: (0.4066) | Acc: (87.00%) (8715/10000)
percent tensor([0.5576, 0.5771, 0.5677, 0.5590, 0.5721, 0.5478, 0.5824, 0.5729, 0.5689,
        0.5705, 0.5650, 0.5720, 0.5603, 0.5787, 0.5643, 0.5575],
       device='cuda:0') torch.Size([16])
percent tensor([0.5261, 0.5246, 0.5138, 0.5114, 0.5157, 0.5098, 0.5255, 0.5199, 0.5202,
        0.5197, 0.5203, 0.5179, 0.5249, 0.5222, 0.5159, 0.5203],
       device='cuda:0') torch.Size([16])
percent tensor([0.5588, 0.5654, 0.5757, 0.5963, 0.6292, 0.6060, 0.6026, 0.6394, 0.5500,
        0.5206, 0.5167, 0.5692, 0.5159, 0.5899, 0.6227, 0.5622],
       device='cuda:0') torch.Size([16])
percent tensor([0.6826, 0.6286, 0.6544, 0.6705, 0.6750, 0.6823, 0.6720, 0.6743, 0.6393,
        0.6412, 0.6443, 0.6287, 0.6184, 0.6574, 0.6845, 0.6781],
       device='cuda:0') torch.Size([16])
percent tensor([0.5301, 0.5372, 0.5464, 0.5690, 0.5579, 0.5641, 0.5347, 0.5452, 0.5626,
        0.5409, 0.5405, 0.5609, 0.5249, 0.5715, 0.5246, 0.5611],
       device='cuda:0') torch.Size([16])
percent tensor([0.6004, 0.6335, 0.6187, 0.6785, 0.6470, 0.6350, 0.6469, 0.6166, 0.6614,
        0.6365, 0.6579, 0.6701, 0.6168, 0.7141, 0.6099, 0.6578],
       device='cuda:0') torch.Size([16])
percent tensor([0.5897, 0.5790, 0.6798, 0.7174, 0.6290, 0.7862, 0.6216, 0.5517, 0.6768,
        0.5834, 0.6418, 0.6046, 0.5855, 0.7002, 0.4672, 0.6298],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9994, 0.9997, 0.9996, 0.9998, 0.9983, 0.9992, 0.9994, 0.9993,
        0.9996, 0.9997, 0.9999, 0.9993, 0.9992, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 95 | Batch_idx: 0 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 95 | Batch_idx: 10 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (92.00%) (1303/1408)
Epoch: 95 | Batch_idx: 20 |  Loss: (0.2498) |  Loss2: (0.0000) | Acc: (91.00%) (2457/2688)
Epoch: 95 | Batch_idx: 30 |  Loss: (0.2513) |  Loss2: (0.0000) | Acc: (91.00%) (3620/3968)
Epoch: 95 | Batch_idx: 40 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (4802/5248)
Epoch: 95 | Batch_idx: 50 |  Loss: (0.2452) |  Loss2: (0.0000) | Acc: (91.00%) (5969/6528)
Epoch: 95 | Batch_idx: 60 |  Loss: (0.2505) |  Loss2: (0.0000) | Acc: (91.00%) (7121/7808)
Epoch: 95 | Batch_idx: 70 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (91.00%) (8277/9088)
Epoch: 95 | Batch_idx: 80 |  Loss: (0.2590) |  Loss2: (0.0000) | Acc: (90.00%) (9430/10368)
Epoch: 95 | Batch_idx: 90 |  Loss: (0.2579) |  Loss2: (0.0000) | Acc: (90.00%) (10593/11648)
Epoch: 95 | Batch_idx: 100 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (91.00%) (11776/12928)
Epoch: 95 | Batch_idx: 110 |  Loss: (0.2540) |  Loss2: (0.0000) | Acc: (91.00%) (12944/14208)
Epoch: 95 | Batch_idx: 120 |  Loss: (0.2522) |  Loss2: (0.0000) | Acc: (91.00%) (14119/15488)
Epoch: 95 | Batch_idx: 130 |  Loss: (0.2521) |  Loss2: (0.0000) | Acc: (91.00%) (15294/16768)
Epoch: 95 | Batch_idx: 140 |  Loss: (0.2516) |  Loss2: (0.0000) | Acc: (91.00%) (16459/18048)
Epoch: 95 | Batch_idx: 150 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (17633/19328)
Epoch: 95 | Batch_idx: 160 |  Loss: (0.2494) |  Loss2: (0.0000) | Acc: (91.00%) (18810/20608)
Epoch: 95 | Batch_idx: 170 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (19974/21888)
Epoch: 95 | Batch_idx: 180 |  Loss: (0.2502) |  Loss2: (0.0000) | Acc: (91.00%) (21134/23168)
Epoch: 95 | Batch_idx: 190 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (22319/24448)
Epoch: 95 | Batch_idx: 200 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (91.00%) (23489/25728)
Epoch: 95 | Batch_idx: 210 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (24655/27008)
Epoch: 95 | Batch_idx: 220 |  Loss: (0.2476) |  Loss2: (0.0000) | Acc: (91.00%) (25818/28288)
Epoch: 95 | Batch_idx: 230 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (27001/29568)
Epoch: 95 | Batch_idx: 240 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (28189/30848)
Epoch: 95 | Batch_idx: 250 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (29365/32128)
Epoch: 95 | Batch_idx: 260 |  Loss: (0.2455) |  Loss2: (0.0000) | Acc: (91.00%) (30538/33408)
Epoch: 95 | Batch_idx: 270 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (31699/34688)
Epoch: 95 | Batch_idx: 280 |  Loss: (0.2449) |  Loss2: (0.0000) | Acc: (91.00%) (32877/35968)
Epoch: 95 | Batch_idx: 290 |  Loss: (0.2464) |  Loss2: (0.0000) | Acc: (91.00%) (34041/37248)
Epoch: 95 | Batch_idx: 300 |  Loss: (0.2450) |  Loss2: (0.0000) | Acc: (91.00%) (35236/38528)
Epoch: 95 | Batch_idx: 310 |  Loss: (0.2441) |  Loss2: (0.0000) | Acc: (91.00%) (36408/39808)
Epoch: 95 | Batch_idx: 320 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (37580/41088)
Epoch: 95 | Batch_idx: 330 |  Loss: (0.2436) |  Loss2: (0.0000) | Acc: (91.00%) (38762/42368)
Epoch: 95 | Batch_idx: 340 |  Loss: (0.2427) |  Loss2: (0.0000) | Acc: (91.00%) (39943/43648)
Epoch: 95 | Batch_idx: 350 |  Loss: (0.2426) |  Loss2: (0.0000) | Acc: (91.00%) (41121/44928)
Epoch: 95 | Batch_idx: 360 |  Loss: (0.2421) |  Loss2: (0.0000) | Acc: (91.00%) (42300/46208)
Epoch: 95 | Batch_idx: 370 |  Loss: (0.2419) |  Loss2: (0.0000) | Acc: (91.00%) (43479/47488)
Epoch: 95 | Batch_idx: 380 |  Loss: (0.2418) |  Loss2: (0.0000) | Acc: (91.00%) (44661/48768)
Epoch: 95 | Batch_idx: 390 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (91.00%) (45784/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_095.pth.tar'
# TEST : Loss: (0.3985) | Acc: (87.00%) (8726/10000)
percent tensor([0.5605, 0.5814, 0.5699, 0.5609, 0.5752, 0.5510, 0.5866, 0.5753, 0.5731,
        0.5738, 0.5692, 0.5751, 0.5637, 0.5834, 0.5676, 0.5604],
       device='cuda:0') torch.Size([16])
percent tensor([0.5382, 0.5366, 0.5289, 0.5244, 0.5304, 0.5208, 0.5386, 0.5344, 0.5330,
        0.5324, 0.5327, 0.5327, 0.5379, 0.5320, 0.5279, 0.5324],
       device='cuda:0') torch.Size([16])
percent tensor([0.5557, 0.5557, 0.5648, 0.5943, 0.6212, 0.6200, 0.5919, 0.6275, 0.5442,
        0.5078, 0.5074, 0.5548, 0.5052, 0.5879, 0.6213, 0.5630],
       device='cuda:0') torch.Size([16])
percent tensor([0.6630, 0.6125, 0.6381, 0.6510, 0.6558, 0.6647, 0.6526, 0.6568, 0.6223,
        0.6241, 0.6268, 0.6130, 0.6030, 0.6385, 0.6636, 0.6581],
       device='cuda:0') torch.Size([16])
percent tensor([0.5537, 0.5616, 0.5677, 0.5901, 0.5813, 0.5901, 0.5600, 0.5643, 0.5846,
        0.5625, 0.5601, 0.5798, 0.5460, 0.5931, 0.5497, 0.5866],
       device='cuda:0') torch.Size([16])
percent tensor([0.5729, 0.5977, 0.6043, 0.6649, 0.6312, 0.6130, 0.6238, 0.6099, 0.6349,
        0.6032, 0.6293, 0.6475, 0.5773, 0.6866, 0.5861, 0.6333],
       device='cuda:0') torch.Size([16])
percent tensor([0.6333, 0.6154, 0.7113, 0.7140, 0.6362, 0.8103, 0.6539, 0.5657, 0.7063,
        0.6282, 0.6787, 0.6211, 0.6367, 0.7203, 0.4931, 0.6578],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9993, 0.9998, 0.9996, 0.9999, 0.9985, 0.9992, 0.9995, 0.9995,
        0.9996, 0.9997, 0.9999, 0.9993, 0.9992, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 96 | Batch_idx: 0 |  Loss: (0.3064) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 96 | Batch_idx: 10 |  Loss: (0.2286) |  Loss2: (0.0000) | Acc: (92.00%) (1296/1408)
Epoch: 96 | Batch_idx: 20 |  Loss: (0.2331) |  Loss2: (0.0000) | Acc: (92.00%) (2481/2688)
Epoch: 96 | Batch_idx: 30 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (3640/3968)
Epoch: 96 | Batch_idx: 40 |  Loss: (0.2495) |  Loss2: (0.0000) | Acc: (91.00%) (4799/5248)
Epoch: 96 | Batch_idx: 50 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (91.00%) (5989/6528)
Epoch: 96 | Batch_idx: 60 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (7172/7808)
Epoch: 96 | Batch_idx: 70 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (8343/9088)
Epoch: 96 | Batch_idx: 80 |  Loss: (0.2340) |  Loss2: (0.0000) | Acc: (91.00%) (9533/10368)
Epoch: 96 | Batch_idx: 90 |  Loss: (0.2345) |  Loss2: (0.0000) | Acc: (91.00%) (10711/11648)
Epoch: 96 | Batch_idx: 100 |  Loss: (0.2318) |  Loss2: (0.0000) | Acc: (92.00%) (11907/12928)
Epoch: 96 | Batch_idx: 110 |  Loss: (0.2324) |  Loss2: (0.0000) | Acc: (92.00%) (13091/14208)
Epoch: 96 | Batch_idx: 120 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (92.00%) (14277/15488)
Epoch: 96 | Batch_idx: 130 |  Loss: (0.2303) |  Loss2: (0.0000) | Acc: (92.00%) (15457/16768)
Epoch: 96 | Batch_idx: 140 |  Loss: (0.2297) |  Loss2: (0.0000) | Acc: (92.00%) (16632/18048)
Epoch: 96 | Batch_idx: 150 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (17814/19328)
Epoch: 96 | Batch_idx: 160 |  Loss: (0.2287) |  Loss2: (0.0000) | Acc: (92.00%) (18999/20608)
Epoch: 96 | Batch_idx: 170 |  Loss: (0.2287) |  Loss2: (0.0000) | Acc: (92.00%) (20173/21888)
Epoch: 96 | Batch_idx: 180 |  Loss: (0.2277) |  Loss2: (0.0000) | Acc: (92.00%) (21358/23168)
Epoch: 96 | Batch_idx: 190 |  Loss: (0.2283) |  Loss2: (0.0000) | Acc: (92.00%) (22533/24448)
Epoch: 96 | Batch_idx: 200 |  Loss: (0.2280) |  Loss2: (0.0000) | Acc: (92.00%) (23710/25728)
Epoch: 96 | Batch_idx: 210 |  Loss: (0.2274) |  Loss2: (0.0000) | Acc: (92.00%) (24887/27008)
Epoch: 96 | Batch_idx: 220 |  Loss: (0.2269) |  Loss2: (0.0000) | Acc: (92.00%) (26061/28288)
Epoch: 96 | Batch_idx: 230 |  Loss: (0.2266) |  Loss2: (0.0000) | Acc: (92.00%) (27235/29568)
Epoch: 96 | Batch_idx: 240 |  Loss: (0.2256) |  Loss2: (0.0000) | Acc: (92.00%) (28423/30848)
Epoch: 96 | Batch_idx: 250 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (29606/32128)
Epoch: 96 | Batch_idx: 260 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (30802/33408)
Epoch: 96 | Batch_idx: 270 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (31990/34688)
Epoch: 96 | Batch_idx: 280 |  Loss: (0.2229) |  Loss2: (0.0000) | Acc: (92.00%) (33188/35968)
Epoch: 96 | Batch_idx: 290 |  Loss: (0.2227) |  Loss2: (0.0000) | Acc: (92.00%) (34377/37248)
Epoch: 96 | Batch_idx: 300 |  Loss: (0.2216) |  Loss2: (0.0000) | Acc: (92.00%) (35571/38528)
Epoch: 96 | Batch_idx: 310 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (36754/39808)
Epoch: 96 | Batch_idx: 320 |  Loss: (0.2209) |  Loss2: (0.0000) | Acc: (92.00%) (37944/41088)
Epoch: 96 | Batch_idx: 330 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (39133/42368)
Epoch: 96 | Batch_idx: 340 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (40322/43648)
Epoch: 96 | Batch_idx: 350 |  Loss: (0.2197) |  Loss2: (0.0000) | Acc: (92.00%) (41518/44928)
Epoch: 96 | Batch_idx: 360 |  Loss: (0.2190) |  Loss2: (0.0000) | Acc: (92.00%) (42719/46208)
Epoch: 96 | Batch_idx: 370 |  Loss: (0.2199) |  Loss2: (0.0000) | Acc: (92.00%) (43896/47488)
Epoch: 96 | Batch_idx: 380 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (45091/48768)
Epoch: 96 | Batch_idx: 390 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (46226/50000)
# TEST : Loss: (0.3843) | Acc: (87.00%) (8759/10000)
percent tensor([0.5593, 0.5805, 0.5679, 0.5596, 0.5734, 0.5503, 0.5853, 0.5737, 0.5719,
        0.5724, 0.5684, 0.5733, 0.5627, 0.5825, 0.5666, 0.5595],
       device='cuda:0') torch.Size([16])
percent tensor([0.5437, 0.5428, 0.5338, 0.5291, 0.5357, 0.5250, 0.5448, 0.5399, 0.5384,
        0.5381, 0.5383, 0.5385, 0.5437, 0.5374, 0.5332, 0.5375],
       device='cuda:0') torch.Size([16])
percent tensor([0.5600, 0.5595, 0.5648, 0.5983, 0.6249, 0.6264, 0.5960, 0.6325, 0.5463,
        0.5099, 0.5096, 0.5552, 0.5077, 0.5907, 0.6287, 0.5676],
       device='cuda:0') torch.Size([16])
percent tensor([0.6717, 0.6223, 0.6460, 0.6587, 0.6649, 0.6714, 0.6625, 0.6659, 0.6315,
        0.6340, 0.6371, 0.6227, 0.6131, 0.6467, 0.6731, 0.6670],
       device='cuda:0') torch.Size([16])
percent tensor([0.5528, 0.5615, 0.5659, 0.5886, 0.5809, 0.5882, 0.5586, 0.5635, 0.5826,
        0.5625, 0.5585, 0.5785, 0.5471, 0.5908, 0.5474, 0.5879],
       device='cuda:0') torch.Size([16])
percent tensor([0.5762, 0.5965, 0.6153, 0.6761, 0.6452, 0.6168, 0.6288, 0.6246, 0.6421,
        0.6025, 0.6333, 0.6566, 0.5752, 0.6875, 0.5931, 0.6362],
       device='cuda:0') torch.Size([16])
percent tensor([0.6321, 0.6221, 0.6998, 0.7062, 0.6209, 0.8121, 0.6529, 0.5572, 0.7083,
        0.6356, 0.6824, 0.6136, 0.6452, 0.7184, 0.4906, 0.6546],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9993, 0.9998, 0.9996, 0.9999, 0.9986, 0.9993, 0.9995, 0.9995,
        0.9996, 0.9998, 0.9999, 0.9993, 0.9992, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 97 | Batch_idx: 0 |  Loss: (0.2321) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 97 | Batch_idx: 10 |  Loss: (0.2305) |  Loss2: (0.0000) | Acc: (92.00%) (1301/1408)
Epoch: 97 | Batch_idx: 20 |  Loss: (0.2226) |  Loss2: (0.0000) | Acc: (92.00%) (2499/2688)
Epoch: 97 | Batch_idx: 30 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (3686/3968)
Epoch: 97 | Batch_idx: 40 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (93.00%) (4885/5248)
Epoch: 97 | Batch_idx: 50 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (93.00%) (6078/6528)
Epoch: 97 | Batch_idx: 60 |  Loss: (0.2137) |  Loss2: (0.0000) | Acc: (93.00%) (7271/7808)
Epoch: 97 | Batch_idx: 70 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (93.00%) (8472/9088)
Epoch: 97 | Batch_idx: 80 |  Loss: (0.2111) |  Loss2: (0.0000) | Acc: (93.00%) (9661/10368)
Epoch: 97 | Batch_idx: 90 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (93.00%) (10845/11648)
Epoch: 97 | Batch_idx: 100 |  Loss: (0.2135) |  Loss2: (0.0000) | Acc: (92.00%) (12021/12928)
Epoch: 97 | Batch_idx: 110 |  Loss: (0.2143) |  Loss2: (0.0000) | Acc: (92.00%) (13199/14208)
Epoch: 97 | Batch_idx: 120 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (14373/15488)
Epoch: 97 | Batch_idx: 130 |  Loss: (0.2169) |  Loss2: (0.0000) | Acc: (92.00%) (15550/16768)
Epoch: 97 | Batch_idx: 140 |  Loss: (0.2163) |  Loss2: (0.0000) | Acc: (92.00%) (16743/18048)
Epoch: 97 | Batch_idx: 150 |  Loss: (0.2158) |  Loss2: (0.0000) | Acc: (92.00%) (17935/19328)
Epoch: 97 | Batch_idx: 160 |  Loss: (0.2173) |  Loss2: (0.0000) | Acc: (92.00%) (19109/20608)
Epoch: 97 | Batch_idx: 170 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (20293/21888)
Epoch: 97 | Batch_idx: 180 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (21481/23168)
Epoch: 97 | Batch_idx: 190 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (22679/24448)
Epoch: 97 | Batch_idx: 200 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (23871/25728)
Epoch: 97 | Batch_idx: 210 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (25058/27008)
Epoch: 97 | Batch_idx: 220 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (26254/28288)
Epoch: 97 | Batch_idx: 230 |  Loss: (0.2139) |  Loss2: (0.0000) | Acc: (92.00%) (27443/29568)
Epoch: 97 | Batch_idx: 240 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (28611/30848)
Epoch: 97 | Batch_idx: 250 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (29775/32128)
Epoch: 97 | Batch_idx: 260 |  Loss: (0.2160) |  Loss2: (0.0000) | Acc: (92.00%) (30962/33408)
Epoch: 97 | Batch_idx: 270 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (32131/34688)
Epoch: 97 | Batch_idx: 280 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (33330/35968)
Epoch: 97 | Batch_idx: 290 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (34521/37248)
Epoch: 97 | Batch_idx: 300 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (35712/38528)
Epoch: 97 | Batch_idx: 310 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (36893/39808)
Epoch: 97 | Batch_idx: 320 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (38064/41088)
Epoch: 97 | Batch_idx: 330 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (39247/42368)
Epoch: 97 | Batch_idx: 340 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (40426/43648)
Epoch: 97 | Batch_idx: 350 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (41620/44928)
Epoch: 97 | Batch_idx: 360 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (42813/46208)
Epoch: 97 | Batch_idx: 370 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (44007/47488)
Epoch: 97 | Batch_idx: 380 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (45193/48768)
Epoch: 97 | Batch_idx: 390 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (46337/50000)
# TEST : Loss: (0.3835) | Acc: (87.00%) (8794/10000)
percent tensor([0.5602, 0.5818, 0.5686, 0.5604, 0.5744, 0.5514, 0.5865, 0.5747, 0.5729,
        0.5735, 0.5695, 0.5742, 0.5637, 0.5836, 0.5678, 0.5606],
       device='cuda:0') torch.Size([16])
percent tensor([0.5408, 0.5388, 0.5287, 0.5239, 0.5305, 0.5205, 0.5407, 0.5349, 0.5342,
        0.5338, 0.5343, 0.5340, 0.5398, 0.5333, 0.5287, 0.5332],
       device='cuda:0') torch.Size([16])
percent tensor([0.5578, 0.5573, 0.5632, 0.5954, 0.6233, 0.6223, 0.5939, 0.6319, 0.5447,
        0.5092, 0.5075, 0.5534, 0.5070, 0.5873, 0.6258, 0.5650],
       device='cuda:0') torch.Size([16])
percent tensor([0.6724, 0.6224, 0.6462, 0.6579, 0.6650, 0.6728, 0.6623, 0.6667, 0.6322,
        0.6338, 0.6368, 0.6229, 0.6141, 0.6456, 0.6732, 0.6670],
       device='cuda:0') torch.Size([16])
percent tensor([0.5548, 0.5650, 0.5684, 0.5897, 0.5842, 0.5886, 0.5607, 0.5658, 0.5835,
        0.5651, 0.5588, 0.5809, 0.5516, 0.5902, 0.5488, 0.5906],
       device='cuda:0') torch.Size([16])
percent tensor([0.5778, 0.5967, 0.6231, 0.6826, 0.6537, 0.6214, 0.6325, 0.6335, 0.6464,
        0.6006, 0.6355, 0.6617, 0.5749, 0.6876, 0.5971, 0.6386],
       device='cuda:0') torch.Size([16])
percent tensor([0.6220, 0.6220, 0.6854, 0.6937, 0.6013, 0.8093, 0.6467, 0.5436, 0.7038,
        0.6344, 0.6843, 0.6003, 0.6453, 0.7154, 0.4861, 0.6463],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9993, 0.9998, 0.9996, 0.9999, 0.9985, 0.9993, 0.9996, 0.9995,
        0.9996, 0.9998, 0.9999, 0.9993, 0.9991, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 98 | Batch_idx: 0 |  Loss: (0.1907) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 98 | Batch_idx: 10 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (91.00%) (1293/1408)
Epoch: 98 | Batch_idx: 20 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (2487/2688)
Epoch: 98 | Batch_idx: 30 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (3673/3968)
Epoch: 98 | Batch_idx: 40 |  Loss: (0.2181) |  Loss2: (0.0000) | Acc: (92.00%) (4859/5248)
Epoch: 98 | Batch_idx: 50 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (6057/6528)
Epoch: 98 | Batch_idx: 60 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (7240/7808)
Epoch: 98 | Batch_idx: 70 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (8430/9088)
Epoch: 98 | Batch_idx: 80 |  Loss: (0.2111) |  Loss2: (0.0000) | Acc: (92.00%) (9633/10368)
Epoch: 98 | Batch_idx: 90 |  Loss: (0.2129) |  Loss2: (0.0000) | Acc: (92.00%) (10814/11648)
Epoch: 98 | Batch_idx: 100 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (11997/12928)
Epoch: 98 | Batch_idx: 110 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (13178/14208)
Epoch: 98 | Batch_idx: 120 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (14352/15488)
Epoch: 98 | Batch_idx: 130 |  Loss: (0.2165) |  Loss2: (0.0000) | Acc: (92.00%) (15524/16768)
Epoch: 98 | Batch_idx: 140 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (16723/18048)
Epoch: 98 | Batch_idx: 150 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (17921/19328)
Epoch: 98 | Batch_idx: 160 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (19137/20608)
Epoch: 98 | Batch_idx: 170 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (20326/21888)
Epoch: 98 | Batch_idx: 180 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (21521/23168)
Epoch: 98 | Batch_idx: 190 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (22710/24448)
Epoch: 98 | Batch_idx: 200 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (23897/25728)
Epoch: 98 | Batch_idx: 210 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (25097/27008)
Epoch: 98 | Batch_idx: 220 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (26292/28288)
Epoch: 98 | Batch_idx: 230 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (27482/29568)
Epoch: 98 | Batch_idx: 240 |  Loss: (0.2084) |  Loss2: (0.0000) | Acc: (92.00%) (28677/30848)
Epoch: 98 | Batch_idx: 250 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (29853/32128)
Epoch: 98 | Batch_idx: 260 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (31042/33408)
Epoch: 98 | Batch_idx: 270 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (32230/34688)
Epoch: 98 | Batch_idx: 280 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (33412/35968)
Epoch: 98 | Batch_idx: 290 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (34598/37248)
Epoch: 98 | Batch_idx: 300 |  Loss: (0.2091) |  Loss2: (0.0000) | Acc: (92.00%) (35799/38528)
Epoch: 98 | Batch_idx: 310 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (36995/39808)
Epoch: 98 | Batch_idx: 320 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (38185/41088)
Epoch: 98 | Batch_idx: 330 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (92.00%) (39366/42368)
Epoch: 98 | Batch_idx: 340 |  Loss: (0.2077) |  Loss2: (0.0000) | Acc: (92.00%) (40560/43648)
Epoch: 98 | Batch_idx: 350 |  Loss: (0.2080) |  Loss2: (0.0000) | Acc: (92.00%) (41751/44928)
Epoch: 98 | Batch_idx: 360 |  Loss: (0.2072) |  Loss2: (0.0000) | Acc: (92.00%) (42955/46208)
Epoch: 98 | Batch_idx: 370 |  Loss: (0.2076) |  Loss2: (0.0000) | Acc: (92.00%) (44132/47488)
Epoch: 98 | Batch_idx: 380 |  Loss: (0.2079) |  Loss2: (0.0000) | Acc: (92.00%) (45317/48768)
Epoch: 98 | Batch_idx: 390 |  Loss: (0.2077) |  Loss2: (0.0000) | Acc: (92.00%) (46466/50000)
# TEST : Loss: (0.3728) | Acc: (88.00%) (8813/10000)
percent tensor([0.5589, 0.5808, 0.5662, 0.5588, 0.5722, 0.5506, 0.5849, 0.5727, 0.5716,
        0.5720, 0.5686, 0.5720, 0.5626, 0.5829, 0.5667, 0.5596],
       device='cuda:0') torch.Size([16])
percent tensor([0.5413, 0.5397, 0.5300, 0.5250, 0.5317, 0.5207, 0.5416, 0.5359, 0.5349,
        0.5349, 0.5350, 0.5355, 0.5406, 0.5340, 0.5293, 0.5336],
       device='cuda:0') torch.Size([16])
percent tensor([0.5608, 0.5617, 0.5649, 0.5966, 0.6252, 0.6229, 0.5975, 0.6356, 0.5475,
        0.5126, 0.5119, 0.5547, 0.5112, 0.5900, 0.6281, 0.5684],
       device='cuda:0') torch.Size([16])
percent tensor([0.6724, 0.6230, 0.6476, 0.6584, 0.6661, 0.6721, 0.6633, 0.6678, 0.6324,
        0.6347, 0.6373, 0.6243, 0.6151, 0.6446, 0.6728, 0.6670],
       device='cuda:0') torch.Size([16])
percent tensor([0.5518, 0.5636, 0.5646, 0.5857, 0.5806, 0.5841, 0.5579, 0.5617, 0.5807,
        0.5633, 0.5568, 0.5780, 0.5507, 0.5877, 0.5457, 0.5884],
       device='cuda:0') torch.Size([16])
percent tensor([0.5814, 0.5994, 0.6276, 0.6856, 0.6603, 0.6253, 0.6365, 0.6418, 0.6484,
        0.6018, 0.6387, 0.6663, 0.5759, 0.6877, 0.6032, 0.6411],
       device='cuda:0') torch.Size([16])
percent tensor([0.6135, 0.6162, 0.6722, 0.6883, 0.5834, 0.8100, 0.6380, 0.5330, 0.6943,
        0.6273, 0.6795, 0.5849, 0.6364, 0.7091, 0.4812, 0.6392],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9994, 0.9998, 0.9996, 0.9999, 0.9986, 0.9993, 0.9996, 0.9995,
        0.9996, 0.9998, 0.9999, 0.9994, 0.9992, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 99 | Batch_idx: 0 |  Loss: (0.2383) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 99 | Batch_idx: 10 |  Loss: (0.2080) |  Loss2: (0.0000) | Acc: (92.00%) (1308/1408)
Epoch: 99 | Batch_idx: 20 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (2476/2688)
Epoch: 99 | Batch_idx: 30 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (3666/3968)
Epoch: 99 | Batch_idx: 40 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (4862/5248)
Epoch: 99 | Batch_idx: 50 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (92.00%) (6057/6528)
Epoch: 99 | Batch_idx: 60 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (7240/7808)
Epoch: 99 | Batch_idx: 70 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (8435/9088)
Epoch: 99 | Batch_idx: 80 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (9613/10368)
Epoch: 99 | Batch_idx: 90 |  Loss: (0.2077) |  Loss2: (0.0000) | Acc: (92.00%) (10821/11648)
Epoch: 99 | Batch_idx: 100 |  Loss: (0.2069) |  Loss2: (0.0000) | Acc: (92.00%) (12011/12928)
Epoch: 99 | Batch_idx: 110 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (92.00%) (13202/14208)
Epoch: 99 | Batch_idx: 120 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (14395/15488)
Epoch: 99 | Batch_idx: 130 |  Loss: (0.2054) |  Loss2: (0.0000) | Acc: (93.00%) (15599/16768)
Epoch: 99 | Batch_idx: 140 |  Loss: (0.2047) |  Loss2: (0.0000) | Acc: (93.00%) (16795/18048)
Epoch: 99 | Batch_idx: 150 |  Loss: (0.2051) |  Loss2: (0.0000) | Acc: (93.00%) (17982/19328)
Epoch: 99 | Batch_idx: 160 |  Loss: (0.2071) |  Loss2: (0.0000) | Acc: (92.00%) (19163/20608)
Epoch: 99 | Batch_idx: 170 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (92.00%) (20342/21888)
Epoch: 99 | Batch_idx: 180 |  Loss: (0.2090) |  Loss2: (0.0000) | Acc: (92.00%) (21525/23168)
Epoch: 99 | Batch_idx: 190 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (22713/24448)
Epoch: 99 | Batch_idx: 200 |  Loss: (0.2090) |  Loss2: (0.0000) | Acc: (92.00%) (23888/25728)
Epoch: 99 | Batch_idx: 210 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (25071/27008)
Epoch: 99 | Batch_idx: 220 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (26247/28288)
Epoch: 99 | Batch_idx: 230 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (27435/29568)
Epoch: 99 | Batch_idx: 240 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (28629/30848)
Epoch: 99 | Batch_idx: 250 |  Loss: (0.2083) |  Loss2: (0.0000) | Acc: (92.00%) (29828/32128)
Epoch: 99 | Batch_idx: 260 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (31017/33408)
Epoch: 99 | Batch_idx: 270 |  Loss: (0.2077) |  Loss2: (0.0000) | Acc: (92.00%) (32219/34688)
Epoch: 99 | Batch_idx: 280 |  Loss: (0.2078) |  Loss2: (0.0000) | Acc: (92.00%) (33402/35968)
Epoch: 99 | Batch_idx: 290 |  Loss: (0.2073) |  Loss2: (0.0000) | Acc: (92.00%) (34602/37248)
Epoch: 99 | Batch_idx: 300 |  Loss: (0.2070) |  Loss2: (0.0000) | Acc: (92.00%) (35797/38528)
Epoch: 99 | Batch_idx: 310 |  Loss: (0.2073) |  Loss2: (0.0000) | Acc: (92.00%) (36984/39808)
Epoch: 99 | Batch_idx: 320 |  Loss: (0.2070) |  Loss2: (0.0000) | Acc: (92.00%) (38171/41088)
Epoch: 99 | Batch_idx: 330 |  Loss: (0.2073) |  Loss2: (0.0000) | Acc: (92.00%) (39354/42368)
Epoch: 99 | Batch_idx: 340 |  Loss: (0.2071) |  Loss2: (0.0000) | Acc: (92.00%) (40544/43648)
Epoch: 99 | Batch_idx: 350 |  Loss: (0.2072) |  Loss2: (0.0000) | Acc: (92.00%) (41728/44928)
Epoch: 99 | Batch_idx: 360 |  Loss: (0.2076) |  Loss2: (0.0000) | Acc: (92.00%) (42911/46208)
Epoch: 99 | Batch_idx: 370 |  Loss: (0.2074) |  Loss2: (0.0000) | Acc: (92.00%) (44108/47488)
Epoch: 99 | Batch_idx: 380 |  Loss: (0.2069) |  Loss2: (0.0000) | Acc: (92.00%) (45303/48768)
Epoch: 99 | Batch_idx: 390 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (92.00%) (46450/50000)
# TEST : Loss: (0.3684) | Acc: (88.00%) (8819/10000)
percent tensor([0.5581, 0.5803, 0.5650, 0.5578, 0.5712, 0.5500, 0.5842, 0.5716, 0.5710,
        0.5712, 0.5680, 0.5711, 0.5619, 0.5825, 0.5660, 0.5588],
       device='cuda:0') torch.Size([16])
percent tensor([0.5438, 0.5428, 0.5319, 0.5269, 0.5340, 0.5223, 0.5448, 0.5385, 0.5376,
        0.5377, 0.5379, 0.5380, 0.5435, 0.5368, 0.5317, 0.5361],
       device='cuda:0') torch.Size([16])
percent tensor([0.5629, 0.5646, 0.5674, 0.5991, 0.6287, 0.6253, 0.6010, 0.6395, 0.5522,
        0.5154, 0.5152, 0.5584, 0.5127, 0.5942, 0.6317, 0.5701],
       device='cuda:0') torch.Size([16])
percent tensor([0.6711, 0.6217, 0.6463, 0.6569, 0.6647, 0.6707, 0.6615, 0.6668, 0.6310,
        0.6331, 0.6360, 0.6228, 0.6139, 0.6427, 0.6718, 0.6655],
       device='cuda:0') torch.Size([16])
percent tensor([0.5521, 0.5653, 0.5666, 0.5884, 0.5824, 0.5859, 0.5591, 0.5634, 0.5827,
        0.5650, 0.5577, 0.5808, 0.5527, 0.5899, 0.5453, 0.5913],
       device='cuda:0') torch.Size([16])
percent tensor([0.5814, 0.5998, 0.6318, 0.6894, 0.6652, 0.6256, 0.6379, 0.6465, 0.6517,
        0.6015, 0.6409, 0.6692, 0.5757, 0.6892, 0.6031, 0.6421],
       device='cuda:0') torch.Size([16])
percent tensor([0.6156, 0.6226, 0.6682, 0.6880, 0.5837, 0.8090, 0.6438, 0.5376, 0.6968,
        0.6314, 0.6828, 0.5877, 0.6382, 0.7106, 0.4891, 0.6416],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9994, 0.9998, 0.9996, 0.9999, 0.9986, 0.9993, 0.9995, 0.9995,
        0.9996, 0.9998, 0.9999, 0.9994, 0.9992, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 100 | Batch_idx: 0 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 100 | Batch_idx: 10 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (1299/1408)
Epoch: 100 | Batch_idx: 20 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (2487/2688)
Epoch: 100 | Batch_idx: 30 |  Loss: (0.2115) |  Loss2: (0.0000) | Acc: (92.00%) (3683/3968)
Epoch: 100 | Batch_idx: 40 |  Loss: (0.2162) |  Loss2: (0.0000) | Acc: (92.00%) (4861/5248)
Epoch: 100 | Batch_idx: 50 |  Loss: (0.2201) |  Loss2: (0.0000) | Acc: (92.00%) (6037/6528)
Epoch: 100 | Batch_idx: 60 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (7210/7808)
Epoch: 100 | Batch_idx: 70 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (8391/9088)
Epoch: 100 | Batch_idx: 80 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (9570/10368)
Epoch: 100 | Batch_idx: 90 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (10754/11648)
Epoch: 100 | Batch_idx: 100 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (11929/12928)
Epoch: 100 | Batch_idx: 110 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (13110/14208)
Epoch: 100 | Batch_idx: 120 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (14301/15488)
Epoch: 100 | Batch_idx: 130 |  Loss: (0.2193) |  Loss2: (0.0000) | Acc: (92.00%) (15490/16768)
Epoch: 100 | Batch_idx: 140 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (16668/18048)
Epoch: 100 | Batch_idx: 150 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (17860/19328)
Epoch: 100 | Batch_idx: 160 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (19045/20608)
Epoch: 100 | Batch_idx: 170 |  Loss: (0.2195) |  Loss2: (0.0000) | Acc: (92.00%) (20219/21888)
Epoch: 100 | Batch_idx: 180 |  Loss: (0.2199) |  Loss2: (0.0000) | Acc: (92.00%) (21396/23168)
Epoch: 100 | Batch_idx: 190 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (22580/24448)
Epoch: 100 | Batch_idx: 200 |  Loss: (0.2207) |  Loss2: (0.0000) | Acc: (92.00%) (23756/25728)
Epoch: 100 | Batch_idx: 210 |  Loss: (0.2212) |  Loss2: (0.0000) | Acc: (92.00%) (24937/27008)
Epoch: 100 | Batch_idx: 220 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (26110/28288)
Epoch: 100 | Batch_idx: 230 |  Loss: (0.2217) |  Loss2: (0.0000) | Acc: (92.00%) (27291/29568)
Epoch: 100 | Batch_idx: 240 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (28479/30848)
Epoch: 100 | Batch_idx: 250 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (29671/32128)
Epoch: 100 | Batch_idx: 260 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (30835/33408)
Epoch: 100 | Batch_idx: 270 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (32011/34688)
Epoch: 100 | Batch_idx: 280 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (33208/35968)
Epoch: 100 | Batch_idx: 290 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (34394/37248)
Epoch: 100 | Batch_idx: 300 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (35571/38528)
Epoch: 100 | Batch_idx: 310 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (36745/39808)
Epoch: 100 | Batch_idx: 320 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (37932/41088)
Epoch: 100 | Batch_idx: 330 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (39104/42368)
Epoch: 100 | Batch_idx: 340 |  Loss: (0.2201) |  Loss2: (0.0000) | Acc: (92.00%) (40284/43648)
Epoch: 100 | Batch_idx: 350 |  Loss: (0.2209) |  Loss2: (0.0000) | Acc: (92.00%) (41451/44928)
Epoch: 100 | Batch_idx: 360 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (42639/46208)
Epoch: 100 | Batch_idx: 370 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (43819/47488)
Epoch: 100 | Batch_idx: 380 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (44999/48768)
Epoch: 100 | Batch_idx: 390 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (46127/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_100.pth.tar'
# TEST : Loss: (0.4078) | Acc: (86.00%) (8683/10000)
percent tensor([0.5571, 0.5786, 0.5656, 0.5580, 0.5709, 0.5491, 0.5832, 0.5714, 0.5694,
        0.5707, 0.5663, 0.5717, 0.5608, 0.5814, 0.5651, 0.5582],
       device='cuda:0') torch.Size([16])
percent tensor([0.5431, 0.5432, 0.5293, 0.5256, 0.5321, 0.5226, 0.5452, 0.5383, 0.5390,
        0.5375, 0.5384, 0.5367, 0.5434, 0.5397, 0.5319, 0.5364],
       device='cuda:0') torch.Size([16])
percent tensor([0.5673, 0.5712, 0.5617, 0.6081, 0.6237, 0.6183, 0.6001, 0.6486, 0.5573,
        0.5216, 0.5177, 0.5493, 0.5239, 0.6074, 0.6322, 0.5720],
       device='cuda:0') torch.Size([16])
percent tensor([0.6722, 0.6173, 0.6537, 0.6530, 0.6703, 0.6668, 0.6645, 0.6649, 0.6330,
        0.6332, 0.6335, 0.6254, 0.6170, 0.6382, 0.6709, 0.6656],
       device='cuda:0') torch.Size([16])
percent tensor([0.5548, 0.5716, 0.5578, 0.5973, 0.5721, 0.5872, 0.5586, 0.5667, 0.5808,
        0.5667, 0.5616, 0.5782, 0.5506, 0.5921, 0.5503, 0.5928],
       device='cuda:0') torch.Size([16])
percent tensor([0.5813, 0.5918, 0.6351, 0.7027, 0.6692, 0.6251, 0.6330, 0.6466, 0.6454,
        0.5930, 0.6355, 0.6664, 0.5692, 0.6738, 0.6074, 0.6388],
       device='cuda:0') torch.Size([16])
percent tensor([0.5914, 0.6007, 0.6653, 0.6641, 0.5628, 0.7987, 0.5946, 0.5097, 0.6746,
        0.6247, 0.6729, 0.5984, 0.6204, 0.6737, 0.4737, 0.6191],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9995, 0.9998, 0.9998, 0.9999, 0.9985, 0.9993, 0.9997, 0.9995,
        0.9996, 0.9997, 0.9999, 0.9992, 0.9989, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(174.4596, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(810.0559, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(810.1537, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1529.2195, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(491.1333, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2232.0037, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4266.1089, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1401.6238, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6162.9639, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11866.4033, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3950.2292, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16632.6738, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 101 | Batch_idx: 0 |  Loss: (0.1548) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 101 | Batch_idx: 10 |  Loss: (0.2052) |  Loss2: (0.0000) | Acc: (92.00%) (1299/1408)
Epoch: 101 | Batch_idx: 20 |  Loss: (0.2020) |  Loss2: (0.0000) | Acc: (92.00%) (2491/2688)
Epoch: 101 | Batch_idx: 30 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (92.00%) (3677/3968)
Epoch: 101 | Batch_idx: 40 |  Loss: (0.2062) |  Loss2: (0.0000) | Acc: (92.00%) (4866/5248)
Epoch: 101 | Batch_idx: 50 |  Loss: (0.2080) |  Loss2: (0.0000) | Acc: (92.00%) (6050/6528)
Epoch: 101 | Batch_idx: 60 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (7221/7808)
Epoch: 101 | Batch_idx: 70 |  Loss: (0.2083) |  Loss2: (0.0000) | Acc: (92.00%) (8414/9088)
Epoch: 101 | Batch_idx: 80 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (9604/10368)
Epoch: 101 | Batch_idx: 90 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (92.00%) (10805/11648)
Epoch: 101 | Batch_idx: 100 |  Loss: (0.2090) |  Loss2: (0.0000) | Acc: (92.00%) (11984/12928)
Epoch: 101 | Batch_idx: 110 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (13153/14208)
Epoch: 101 | Batch_idx: 120 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (14340/15488)
Epoch: 101 | Batch_idx: 130 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (15535/16768)
Epoch: 101 | Batch_idx: 140 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (16716/18048)
Epoch: 101 | Batch_idx: 150 |  Loss: (0.2109) |  Loss2: (0.0000) | Acc: (92.00%) (17892/19328)
Epoch: 101 | Batch_idx: 160 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (92.00%) (19091/20608)
Epoch: 101 | Batch_idx: 170 |  Loss: (0.2119) |  Loss2: (0.0000) | Acc: (92.00%) (20274/21888)
Epoch: 101 | Batch_idx: 180 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (21468/23168)
Epoch: 101 | Batch_idx: 190 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (22652/24448)
Epoch: 101 | Batch_idx: 200 |  Loss: (0.2125) |  Loss2: (0.0000) | Acc: (92.00%) (23839/25728)
Epoch: 101 | Batch_idx: 210 |  Loss: (0.2138) |  Loss2: (0.0000) | Acc: (92.00%) (25008/27008)
Epoch: 101 | Batch_idx: 220 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (26172/28288)
Epoch: 101 | Batch_idx: 230 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (27364/29568)
Epoch: 101 | Batch_idx: 240 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (28540/30848)
Epoch: 101 | Batch_idx: 250 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (29729/32128)
Epoch: 101 | Batch_idx: 260 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (30888/33408)
Epoch: 101 | Batch_idx: 270 |  Loss: (0.2186) |  Loss2: (0.0000) | Acc: (92.00%) (32065/34688)
Epoch: 101 | Batch_idx: 280 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (33242/35968)
Epoch: 101 | Batch_idx: 290 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (34435/37248)
Epoch: 101 | Batch_idx: 300 |  Loss: (0.2173) |  Loss2: (0.0000) | Acc: (92.00%) (35630/38528)
Epoch: 101 | Batch_idx: 310 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (36812/39808)
Epoch: 101 | Batch_idx: 320 |  Loss: (0.2168) |  Loss2: (0.0000) | Acc: (92.00%) (37995/41088)
Epoch: 101 | Batch_idx: 330 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (92.00%) (39190/42368)
Epoch: 101 | Batch_idx: 340 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (40377/43648)
Epoch: 101 | Batch_idx: 350 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (41579/44928)
Epoch: 101 | Batch_idx: 360 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (42767/46208)
Epoch: 101 | Batch_idx: 370 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (43949/47488)
Epoch: 101 | Batch_idx: 380 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (45134/48768)
Epoch: 101 | Batch_idx: 390 |  Loss: (0.2159) |  Loss2: (0.0000) | Acc: (92.00%) (46263/50000)
# TEST : Loss: (0.3941) | Acc: (86.00%) (8686/10000)
percent tensor([0.5578, 0.5806, 0.5651, 0.5590, 0.5713, 0.5493, 0.5840, 0.5728, 0.5707,
        0.5713, 0.5671, 0.5710, 0.5614, 0.5836, 0.5662, 0.5590],
       device='cuda:0') torch.Size([16])
percent tensor([0.5453, 0.5433, 0.5317, 0.5270, 0.5345, 0.5244, 0.5453, 0.5395, 0.5415,
        0.5390, 0.5405, 0.5391, 0.5464, 0.5383, 0.5331, 0.5378],
       device='cuda:0') torch.Size([16])
percent tensor([0.5722, 0.5689, 0.5726, 0.6084, 0.6321, 0.6269, 0.6014, 0.6485, 0.5607,
        0.5239, 0.5196, 0.5688, 0.5193, 0.6010, 0.6352, 0.5701],
       device='cuda:0') torch.Size([16])
percent tensor([0.6752, 0.6238, 0.6463, 0.6550, 0.6670, 0.6759, 0.6653, 0.6650, 0.6346,
        0.6377, 0.6405, 0.6224, 0.6195, 0.6484, 0.6781, 0.6697],
       device='cuda:0') torch.Size([16])
percent tensor([0.5478, 0.5635, 0.5719, 0.5923, 0.5830, 0.5759, 0.5552, 0.5708, 0.5778,
        0.5606, 0.5501, 0.5911, 0.5442, 0.5797, 0.5405, 0.5845],
       device='cuda:0') torch.Size([16])
percent tensor([0.5811, 0.5965, 0.6392, 0.6936, 0.6761, 0.6252, 0.6409, 0.6516, 0.6432,
        0.5977, 0.6257, 0.6700, 0.5638, 0.6891, 0.5986, 0.6348],
       device='cuda:0') torch.Size([16])
percent tensor([0.6050, 0.6212, 0.7012, 0.6948, 0.6198, 0.8144, 0.6168, 0.5509, 0.6712,
        0.6161, 0.6485, 0.5733, 0.6089, 0.6578, 0.4744, 0.6352],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9994, 0.9996, 0.9996, 0.9998, 0.9985, 0.9994, 0.9996, 0.9997,
        0.9996, 0.9997, 0.9999, 0.9993, 0.9992, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 102 | Batch_idx: 0 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 102 | Batch_idx: 10 |  Loss: (0.2040) |  Loss2: (0.0000) | Acc: (93.00%) (1313/1408)
Epoch: 102 | Batch_idx: 20 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (2506/2688)
Epoch: 102 | Batch_idx: 30 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (3719/3968)
Epoch: 102 | Batch_idx: 40 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (4917/5248)
Epoch: 102 | Batch_idx: 50 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (6126/6528)
Epoch: 102 | Batch_idx: 60 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (93.00%) (7309/7808)
Epoch: 102 | Batch_idx: 70 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (8483/9088)
Epoch: 102 | Batch_idx: 80 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (93.00%) (9678/10368)
Epoch: 102 | Batch_idx: 90 |  Loss: (0.2026) |  Loss2: (0.0000) | Acc: (93.00%) (10867/11648)
Epoch: 102 | Batch_idx: 100 |  Loss: (0.2044) |  Loss2: (0.0000) | Acc: (93.00%) (12053/12928)
Epoch: 102 | Batch_idx: 110 |  Loss: (0.2027) |  Loss2: (0.0000) | Acc: (93.00%) (13252/14208)
Epoch: 102 | Batch_idx: 120 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (14432/15488)
Epoch: 102 | Batch_idx: 130 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (93.00%) (15635/16768)
Epoch: 102 | Batch_idx: 140 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (93.00%) (16829/18048)
Epoch: 102 | Batch_idx: 150 |  Loss: (0.2018) |  Loss2: (0.0000) | Acc: (93.00%) (18010/19328)
Epoch: 102 | Batch_idx: 160 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (93.00%) (19200/20608)
Epoch: 102 | Batch_idx: 170 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (93.00%) (20391/21888)
Epoch: 102 | Batch_idx: 180 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (93.00%) (21577/23168)
Epoch: 102 | Batch_idx: 190 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (22759/24448)
Epoch: 102 | Batch_idx: 200 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (93.00%) (23953/25728)
Epoch: 102 | Batch_idx: 210 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (93.00%) (25143/27008)
Epoch: 102 | Batch_idx: 220 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (93.00%) (26345/28288)
Epoch: 102 | Batch_idx: 230 |  Loss: (0.2022) |  Loss2: (0.0000) | Acc: (93.00%) (27524/29568)
Epoch: 102 | Batch_idx: 240 |  Loss: (0.2022) |  Loss2: (0.0000) | Acc: (93.00%) (28726/30848)
Epoch: 102 | Batch_idx: 250 |  Loss: (0.2026) |  Loss2: (0.0000) | Acc: (93.00%) (29908/32128)
Epoch: 102 | Batch_idx: 260 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (93.00%) (31088/33408)
Epoch: 102 | Batch_idx: 270 |  Loss: (0.2038) |  Loss2: (0.0000) | Acc: (93.00%) (32281/34688)
Epoch: 102 | Batch_idx: 280 |  Loss: (0.2043) |  Loss2: (0.0000) | Acc: (93.00%) (33471/35968)
Epoch: 102 | Batch_idx: 290 |  Loss: (0.2047) |  Loss2: (0.0000) | Acc: (93.00%) (34656/37248)
Epoch: 102 | Batch_idx: 300 |  Loss: (0.2048) |  Loss2: (0.0000) | Acc: (93.00%) (35839/38528)
Epoch: 102 | Batch_idx: 310 |  Loss: (0.2051) |  Loss2: (0.0000) | Acc: (92.00%) (37021/39808)
Epoch: 102 | Batch_idx: 320 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (92.00%) (38201/41088)
Epoch: 102 | Batch_idx: 330 |  Loss: (0.2065) |  Loss2: (0.0000) | Acc: (92.00%) (39370/42368)
Epoch: 102 | Batch_idx: 340 |  Loss: (0.2081) |  Loss2: (0.0000) | Acc: (92.00%) (40526/43648)
Epoch: 102 | Batch_idx: 350 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (92.00%) (41712/44928)
Epoch: 102 | Batch_idx: 360 |  Loss: (0.2081) |  Loss2: (0.0000) | Acc: (92.00%) (42902/46208)
Epoch: 102 | Batch_idx: 370 |  Loss: (0.2074) |  Loss2: (0.0000) | Acc: (92.00%) (44106/47488)
Epoch: 102 | Batch_idx: 380 |  Loss: (0.2070) |  Loss2: (0.0000) | Acc: (92.00%) (45305/48768)
Epoch: 102 | Batch_idx: 390 |  Loss: (0.2072) |  Loss2: (0.0000) | Acc: (92.00%) (46451/50000)
# TEST : Loss: (0.4076) | Acc: (87.00%) (8705/10000)
percent tensor([0.5568, 0.5796, 0.5643, 0.5577, 0.5699, 0.5492, 0.5837, 0.5711, 0.5694,
        0.5707, 0.5665, 0.5710, 0.5605, 0.5830, 0.5654, 0.5582],
       device='cuda:0') torch.Size([16])
percent tensor([0.5450, 0.5440, 0.5330, 0.5290, 0.5358, 0.5256, 0.5460, 0.5398, 0.5399,
        0.5397, 0.5400, 0.5401, 0.5460, 0.5357, 0.5338, 0.5388],
       device='cuda:0') torch.Size([16])
percent tensor([0.5631, 0.5673, 0.5536, 0.5999, 0.6207, 0.6146, 0.5929, 0.6396, 0.5538,
        0.5128, 0.5165, 0.5473, 0.5140, 0.6010, 0.6298, 0.5679],
       device='cuda:0') torch.Size([16])
percent tensor([0.6709, 0.6186, 0.6493, 0.6537, 0.6684, 0.6697, 0.6614, 0.6639, 0.6337,
        0.6332, 0.6356, 0.6233, 0.6151, 0.6413, 0.6723, 0.6644],
       device='cuda:0') torch.Size([16])
percent tensor([0.5547, 0.5716, 0.5677, 0.5980, 0.5802, 0.5853, 0.5636, 0.5726, 0.5810,
        0.5674, 0.5589, 0.5819, 0.5503, 0.5911, 0.5503, 0.5942],
       device='cuda:0') torch.Size([16])
percent tensor([0.5866, 0.5979, 0.6369, 0.6980, 0.6768, 0.6319, 0.6447, 0.6569, 0.6535,
        0.5957, 0.6309, 0.6632, 0.5798, 0.6835, 0.6092, 0.6448],
       device='cuda:0') torch.Size([16])
percent tensor([0.5948, 0.6082, 0.6794, 0.6820, 0.6185, 0.7837, 0.6364, 0.5593, 0.6727,
        0.6200, 0.6721, 0.5888, 0.6322, 0.6633, 0.4834, 0.6412],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9993, 0.9998, 0.9997, 0.9999, 0.9990, 0.9995, 0.9996, 0.9995,
        0.9996, 0.9998, 0.9999, 0.9993, 0.9990, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 103 | Batch_idx: 0 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 103 | Batch_idx: 10 |  Loss: (0.2245) |  Loss2: (0.0000) | Acc: (91.00%) (1291/1408)
Epoch: 103 | Batch_idx: 20 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (2473/2688)
Epoch: 103 | Batch_idx: 30 |  Loss: (0.2128) |  Loss2: (0.0000) | Acc: (92.00%) (3667/3968)
Epoch: 103 | Batch_idx: 40 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (92.00%) (4867/5248)
Epoch: 103 | Batch_idx: 50 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (92.00%) (6061/6528)
Epoch: 103 | Batch_idx: 60 |  Loss: (0.2030) |  Loss2: (0.0000) | Acc: (92.00%) (7260/7808)
Epoch: 103 | Batch_idx: 70 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (93.00%) (8456/9088)
Epoch: 103 | Batch_idx: 80 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (9648/10368)
Epoch: 103 | Batch_idx: 90 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (93.00%) (10833/11648)
Epoch: 103 | Batch_idx: 100 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (12032/12928)
Epoch: 103 | Batch_idx: 110 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (93.00%) (13233/14208)
Epoch: 103 | Batch_idx: 120 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (93.00%) (14426/15488)
Epoch: 103 | Batch_idx: 130 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (15618/16768)
Epoch: 103 | Batch_idx: 140 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (93.00%) (16814/18048)
Epoch: 103 | Batch_idx: 150 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (17981/19328)
Epoch: 103 | Batch_idx: 160 |  Loss: (0.1994) |  Loss2: (0.0000) | Acc: (93.00%) (19166/20608)
Epoch: 103 | Batch_idx: 170 |  Loss: (0.1994) |  Loss2: (0.0000) | Acc: (92.00%) (20347/21888)
Epoch: 103 | Batch_idx: 180 |  Loss: (0.1998) |  Loss2: (0.0000) | Acc: (92.00%) (21534/23168)
Epoch: 103 | Batch_idx: 190 |  Loss: (0.1999) |  Loss2: (0.0000) | Acc: (92.00%) (22726/24448)
Epoch: 103 | Batch_idx: 200 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (92.00%) (23894/25728)
Epoch: 103 | Batch_idx: 210 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (92.00%) (25085/27008)
Epoch: 103 | Batch_idx: 220 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (92.00%) (26279/28288)
Epoch: 103 | Batch_idx: 230 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (92.00%) (27478/29568)
Epoch: 103 | Batch_idx: 240 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (92.00%) (28671/30848)
Epoch: 103 | Batch_idx: 250 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (92.00%) (29858/32128)
Epoch: 103 | Batch_idx: 260 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (92.00%) (31059/33408)
Epoch: 103 | Batch_idx: 270 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (92.00%) (32248/34688)
Epoch: 103 | Batch_idx: 280 |  Loss: (0.2032) |  Loss2: (0.0000) | Acc: (92.00%) (33412/35968)
Epoch: 103 | Batch_idx: 290 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (92.00%) (34586/37248)
Epoch: 103 | Batch_idx: 300 |  Loss: (0.2039) |  Loss2: (0.0000) | Acc: (92.00%) (35773/38528)
Epoch: 103 | Batch_idx: 310 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (92.00%) (36958/39808)
Epoch: 103 | Batch_idx: 320 |  Loss: (0.2045) |  Loss2: (0.0000) | Acc: (92.00%) (38144/41088)
Epoch: 103 | Batch_idx: 330 |  Loss: (0.2040) |  Loss2: (0.0000) | Acc: (92.00%) (39338/42368)
Epoch: 103 | Batch_idx: 340 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (92.00%) (40509/43648)
Epoch: 103 | Batch_idx: 350 |  Loss: (0.2035) |  Loss2: (0.0000) | Acc: (92.00%) (41701/44928)
Epoch: 103 | Batch_idx: 360 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (92.00%) (42891/46208)
Epoch: 103 | Batch_idx: 370 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (92.00%) (44082/47488)
Epoch: 103 | Batch_idx: 380 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (92.00%) (45270/48768)
Epoch: 103 | Batch_idx: 390 |  Loss: (0.2031) |  Loss2: (0.0000) | Acc: (92.00%) (46412/50000)
# TEST : Loss: (0.3967) | Acc: (87.00%) (8752/10000)
percent tensor([0.5574, 0.5783, 0.5660, 0.5581, 0.5711, 0.5493, 0.5825, 0.5719, 0.5693,
        0.5702, 0.5660, 0.5713, 0.5611, 0.5795, 0.5651, 0.5579],
       device='cuda:0') torch.Size([16])
percent tensor([0.5440, 0.5417, 0.5306, 0.5285, 0.5344, 0.5265, 0.5437, 0.5384, 0.5372,
        0.5375, 0.5374, 0.5376, 0.5441, 0.5349, 0.5330, 0.5379],
       device='cuda:0') torch.Size([16])
percent tensor([0.5638, 0.5743, 0.5600, 0.6006, 0.6255, 0.6090, 0.6010, 0.6425, 0.5600,
        0.5191, 0.5254, 0.5539, 0.5202, 0.6112, 0.6266, 0.5671],
       device='cuda:0') torch.Size([16])
percent tensor([0.6698, 0.6211, 0.6508, 0.6554, 0.6662, 0.6760, 0.6650, 0.6642, 0.6349,
        0.6343, 0.6390, 0.6242, 0.6145, 0.6467, 0.6747, 0.6650],
       device='cuda:0') torch.Size([16])
percent tensor([0.5547, 0.5643, 0.5635, 0.5904, 0.5820, 0.5856, 0.5574, 0.5661, 0.5834,
        0.5653, 0.5568, 0.5870, 0.5503, 0.5904, 0.5467, 0.5905],
       device='cuda:0') torch.Size([16])
percent tensor([0.5836, 0.5987, 0.6231, 0.6762, 0.6662, 0.6436, 0.6420, 0.6451, 0.6539,
        0.6017, 0.6359, 0.6649, 0.5797, 0.6883, 0.6017, 0.6430],
       device='cuda:0') torch.Size([16])
percent tensor([0.6006, 0.6002, 0.6425, 0.6755, 0.6150, 0.8185, 0.6094, 0.5446, 0.6861,
        0.6179, 0.6735, 0.5789, 0.6183, 0.7136, 0.4687, 0.6470],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9992, 0.9997, 0.9996, 0.9998, 0.9987, 0.9993, 0.9996, 0.9992,
        0.9995, 0.9998, 0.9998, 0.9994, 0.9983, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 104 | Batch_idx: 0 |  Loss: (0.2007) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 104 | Batch_idx: 10 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (92.00%) (1306/1408)
Epoch: 104 | Batch_idx: 20 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (93.00%) (2500/2688)
Epoch: 104 | Batch_idx: 30 |  Loss: (0.2079) |  Loss2: (0.0000) | Acc: (92.00%) (3679/3968)
Epoch: 104 | Batch_idx: 40 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (93.00%) (4881/5248)
Epoch: 104 | Batch_idx: 50 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (93.00%) (6084/6528)
Epoch: 104 | Batch_idx: 60 |  Loss: (0.2022) |  Loss2: (0.0000) | Acc: (92.00%) (7261/7808)
Epoch: 104 | Batch_idx: 70 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (92.00%) (8446/9088)
Epoch: 104 | Batch_idx: 80 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (93.00%) (9646/10368)
Epoch: 104 | Batch_idx: 90 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (10849/11648)
Epoch: 104 | Batch_idx: 100 |  Loss: (0.1996) |  Loss2: (0.0000) | Acc: (93.00%) (12041/12928)
Epoch: 104 | Batch_idx: 110 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (93.00%) (13247/14208)
Epoch: 104 | Batch_idx: 120 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (14455/15488)
Epoch: 104 | Batch_idx: 130 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (93.00%) (15643/16768)
Epoch: 104 | Batch_idx: 140 |  Loss: (0.1949) |  Loss2: (0.0000) | Acc: (93.00%) (16840/18048)
Epoch: 104 | Batch_idx: 150 |  Loss: (0.1956) |  Loss2: (0.0000) | Acc: (93.00%) (18021/19328)
Epoch: 104 | Batch_idx: 160 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (19207/20608)
Epoch: 104 | Batch_idx: 170 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (93.00%) (20392/21888)
Epoch: 104 | Batch_idx: 180 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (93.00%) (21582/23168)
Epoch: 104 | Batch_idx: 190 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (22775/24448)
Epoch: 104 | Batch_idx: 200 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (23954/25728)
Epoch: 104 | Batch_idx: 210 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (25146/27008)
Epoch: 104 | Batch_idx: 220 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (93.00%) (26337/28288)
Epoch: 104 | Batch_idx: 230 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (27525/29568)
Epoch: 104 | Batch_idx: 240 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (28707/30848)
Epoch: 104 | Batch_idx: 250 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (93.00%) (29894/32128)
Epoch: 104 | Batch_idx: 260 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (93.00%) (31076/33408)
Epoch: 104 | Batch_idx: 270 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (93.00%) (32261/34688)
Epoch: 104 | Batch_idx: 280 |  Loss: (0.2022) |  Loss2: (0.0000) | Acc: (92.00%) (33438/35968)
Epoch: 104 | Batch_idx: 290 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (92.00%) (34633/37248)
Epoch: 104 | Batch_idx: 300 |  Loss: (0.2021) |  Loss2: (0.0000) | Acc: (92.00%) (35817/38528)
Epoch: 104 | Batch_idx: 310 |  Loss: (0.2023) |  Loss2: (0.0000) | Acc: (92.00%) (36999/39808)
Epoch: 104 | Batch_idx: 320 |  Loss: (0.2029) |  Loss2: (0.0000) | Acc: (92.00%) (38185/41088)
Epoch: 104 | Batch_idx: 330 |  Loss: (0.2027) |  Loss2: (0.0000) | Acc: (92.00%) (39374/42368)
Epoch: 104 | Batch_idx: 340 |  Loss: (0.2027) |  Loss2: (0.0000) | Acc: (92.00%) (40565/43648)
Epoch: 104 | Batch_idx: 350 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (92.00%) (41739/44928)
Epoch: 104 | Batch_idx: 360 |  Loss: (0.2029) |  Loss2: (0.0000) | Acc: (92.00%) (42930/46208)
Epoch: 104 | Batch_idx: 370 |  Loss: (0.2021) |  Loss2: (0.0000) | Acc: (92.00%) (44140/47488)
Epoch: 104 | Batch_idx: 380 |  Loss: (0.2019) |  Loss2: (0.0000) | Acc: (92.00%) (45336/48768)
Epoch: 104 | Batch_idx: 390 |  Loss: (0.2027) |  Loss2: (0.0000) | Acc: (92.00%) (46468/50000)
# TEST : Loss: (0.3946) | Acc: (87.00%) (8762/10000)
percent tensor([0.5572, 0.5792, 0.5639, 0.5585, 0.5697, 0.5489, 0.5826, 0.5714, 0.5698,
        0.5703, 0.5667, 0.5700, 0.5610, 0.5820, 0.5653, 0.5586],
       device='cuda:0') torch.Size([16])
percent tensor([0.5441, 0.5433, 0.5284, 0.5253, 0.5323, 0.5258, 0.5448, 0.5366, 0.5381,
        0.5378, 0.5383, 0.5367, 0.5440, 0.5386, 0.5325, 0.5362],
       device='cuda:0') torch.Size([16])
percent tensor([0.5708, 0.5715, 0.5725, 0.6131, 0.6322, 0.6033, 0.6033, 0.6461, 0.5582,
        0.5223, 0.5185, 0.5595, 0.5212, 0.6065, 0.6302, 0.5767],
       device='cuda:0') torch.Size([16])
percent tensor([0.6721, 0.6185, 0.6514, 0.6575, 0.6703, 0.6729, 0.6638, 0.6639, 0.6313,
        0.6356, 0.6363, 0.6253, 0.6148, 0.6430, 0.6749, 0.6674],
       device='cuda:0') torch.Size([16])
percent tensor([0.5484, 0.5654, 0.5637, 0.5936, 0.5757, 0.5743, 0.5577, 0.5720, 0.5791,
        0.5664, 0.5576, 0.5850, 0.5483, 0.5893, 0.5438, 0.5865],
       device='cuda:0') torch.Size([16])
percent tensor([0.5797, 0.5930, 0.6274, 0.6882, 0.6603, 0.6267, 0.6354, 0.6442, 0.6516,
        0.5931, 0.6328, 0.6635, 0.5769, 0.6852, 0.5936, 0.6356],
       device='cuda:0') torch.Size([16])
percent tensor([0.5861, 0.5759, 0.6451, 0.6790, 0.5968, 0.8089, 0.6118, 0.5205, 0.6760,
        0.5719, 0.6313, 0.5625, 0.6216, 0.6484, 0.4634, 0.6232],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9994, 0.9997, 0.9994, 0.9999, 0.9990, 0.9993, 0.9996, 0.9996,
        0.9995, 0.9998, 0.9998, 0.9996, 0.9990, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 105 | Batch_idx: 0 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 105 | Batch_idx: 10 |  Loss: (0.2122) |  Loss2: (0.0000) | Acc: (91.00%) (1295/1408)
Epoch: 105 | Batch_idx: 20 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (91.00%) (2462/2688)
Epoch: 105 | Batch_idx: 30 |  Loss: (0.2510) |  Loss2: (0.0000) | Acc: (90.00%) (3610/3968)
Epoch: 105 | Batch_idx: 40 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (90.00%) (4764/5248)
Epoch: 105 | Batch_idx: 50 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (90.00%) (5923/6528)
Epoch: 105 | Batch_idx: 60 |  Loss: (0.2604) |  Loss2: (0.0000) | Acc: (90.00%) (7067/7808)
Epoch: 105 | Batch_idx: 70 |  Loss: (0.2679) |  Loss2: (0.0000) | Acc: (90.00%) (8221/9088)
Epoch: 105 | Batch_idx: 80 |  Loss: (0.2651) |  Loss2: (0.0000) | Acc: (90.00%) (9392/10368)
Epoch: 105 | Batch_idx: 90 |  Loss: (0.2646) |  Loss2: (0.0000) | Acc: (90.00%) (10571/11648)
Epoch: 105 | Batch_idx: 100 |  Loss: (0.2643) |  Loss2: (0.0000) | Acc: (90.00%) (11733/12928)
Epoch: 105 | Batch_idx: 110 |  Loss: (0.2652) |  Loss2: (0.0000) | Acc: (90.00%) (12893/14208)
Epoch: 105 | Batch_idx: 120 |  Loss: (0.2642) |  Loss2: (0.0000) | Acc: (90.00%) (14076/15488)
Epoch: 105 | Batch_idx: 130 |  Loss: (0.2660) |  Loss2: (0.0000) | Acc: (90.00%) (15229/16768)
Epoch: 105 | Batch_idx: 140 |  Loss: (0.2657) |  Loss2: (0.0000) | Acc: (90.00%) (16391/18048)
Epoch: 105 | Batch_idx: 150 |  Loss: (0.2666) |  Loss2: (0.0000) | Acc: (90.00%) (17555/19328)
Epoch: 105 | Batch_idx: 160 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (18717/20608)
Epoch: 105 | Batch_idx: 170 |  Loss: (0.2655) |  Loss2: (0.0000) | Acc: (90.00%) (19889/21888)
Epoch: 105 | Batch_idx: 180 |  Loss: (0.2633) |  Loss2: (0.0000) | Acc: (90.00%) (21067/23168)
Epoch: 105 | Batch_idx: 190 |  Loss: (0.2613) |  Loss2: (0.0000) | Acc: (90.00%) (22238/24448)
Epoch: 105 | Batch_idx: 200 |  Loss: (0.2614) |  Loss2: (0.0000) | Acc: (90.00%) (23408/25728)
Epoch: 105 | Batch_idx: 210 |  Loss: (0.2599) |  Loss2: (0.0000) | Acc: (91.00%) (24589/27008)
Epoch: 105 | Batch_idx: 220 |  Loss: (0.2591) |  Loss2: (0.0000) | Acc: (91.00%) (25760/28288)
Epoch: 105 | Batch_idx: 230 |  Loss: (0.2577) |  Loss2: (0.0000) | Acc: (91.00%) (26937/29568)
Epoch: 105 | Batch_idx: 240 |  Loss: (0.2574) |  Loss2: (0.0000) | Acc: (91.00%) (28101/30848)
Epoch: 105 | Batch_idx: 250 |  Loss: (0.2577) |  Loss2: (0.0000) | Acc: (91.00%) (29250/32128)
Epoch: 105 | Batch_idx: 260 |  Loss: (0.2575) |  Loss2: (0.0000) | Acc: (91.00%) (30412/33408)
Epoch: 105 | Batch_idx: 270 |  Loss: (0.2571) |  Loss2: (0.0000) | Acc: (91.00%) (31568/34688)
Epoch: 105 | Batch_idx: 280 |  Loss: (0.2577) |  Loss2: (0.0000) | Acc: (90.00%) (32720/35968)
Epoch: 105 | Batch_idx: 290 |  Loss: (0.2570) |  Loss2: (0.0000) | Acc: (90.00%) (33892/37248)
Epoch: 105 | Batch_idx: 300 |  Loss: (0.2568) |  Loss2: (0.0000) | Acc: (90.00%) (35049/38528)
Epoch: 105 | Batch_idx: 310 |  Loss: (0.2553) |  Loss2: (0.0000) | Acc: (90.00%) (36225/39808)
Epoch: 105 | Batch_idx: 320 |  Loss: (0.2544) |  Loss2: (0.0000) | Acc: (91.00%) (37406/41088)
Epoch: 105 | Batch_idx: 330 |  Loss: (0.2534) |  Loss2: (0.0000) | Acc: (91.00%) (38587/42368)
Epoch: 105 | Batch_idx: 340 |  Loss: (0.2532) |  Loss2: (0.0000) | Acc: (91.00%) (39758/43648)
Epoch: 105 | Batch_idx: 350 |  Loss: (0.2529) |  Loss2: (0.0000) | Acc: (91.00%) (40933/44928)
Epoch: 105 | Batch_idx: 360 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (42100/46208)
Epoch: 105 | Batch_idx: 370 |  Loss: (0.2518) |  Loss2: (0.0000) | Acc: (91.00%) (43281/47488)
Epoch: 105 | Batch_idx: 380 |  Loss: (0.2514) |  Loss2: (0.0000) | Acc: (91.00%) (44453/48768)
Epoch: 105 | Batch_idx: 390 |  Loss: (0.2503) |  Loss2: (0.0000) | Acc: (91.00%) (45599/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_105.pth.tar'
# TEST : Loss: (0.4373) | Acc: (86.00%) (8628/10000)
percent tensor([0.5555, 0.5781, 0.5626, 0.5561, 0.5682, 0.5467, 0.5819, 0.5697, 0.5685,
        0.5693, 0.5653, 0.5690, 0.5600, 0.5809, 0.5637, 0.5568],
       device='cuda:0') torch.Size([16])
percent tensor([0.5506, 0.5503, 0.5344, 0.5302, 0.5380, 0.5298, 0.5520, 0.5427, 0.5444,
        0.5457, 0.5458, 0.5440, 0.5530, 0.5435, 0.5373, 0.5428],
       device='cuda:0') torch.Size([16])
percent tensor([0.5789, 0.5871, 0.5627, 0.6014, 0.6321, 0.6076, 0.6158, 0.6495, 0.5560,
        0.5282, 0.5282, 0.5601, 0.5404, 0.6022, 0.6440, 0.5825],
       device='cuda:0') torch.Size([16])
percent tensor([0.7031, 0.6521, 0.6730, 0.6783, 0.6942, 0.7024, 0.6931, 0.6913, 0.6571,
        0.6672, 0.6691, 0.6527, 0.6497, 0.6679, 0.7055, 0.6969],
       device='cuda:0') torch.Size([16])
percent tensor([0.5563, 0.5715, 0.5644, 0.5875, 0.5808, 0.5798, 0.5617, 0.5739, 0.5790,
        0.5683, 0.5565, 0.5792, 0.5553, 0.5885, 0.5498, 0.5894],
       device='cuda:0') torch.Size([16])
percent tensor([0.6412, 0.6586, 0.6768, 0.7205, 0.6987, 0.6713, 0.6849, 0.6887, 0.7020,
        0.6560, 0.6869, 0.7083, 0.6445, 0.7318, 0.6497, 0.6833],
       device='cuda:0') torch.Size([16])
percent tensor([0.5681, 0.5440, 0.6256, 0.7018, 0.5831, 0.8111, 0.5740, 0.4962, 0.6793,
        0.5548, 0.6327, 0.5348, 0.5604, 0.6734, 0.4413, 0.6088],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9993, 0.9996, 0.9994, 0.9998, 0.9990, 0.9994, 0.9997, 0.9998,
        0.9996, 0.9998, 0.9998, 0.9996, 0.9990, 0.9997, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 106 | Batch_idx: 0 |  Loss: (0.2346) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 106 | Batch_idx: 10 |  Loss: (0.2350) |  Loss2: (0.0000) | Acc: (91.00%) (1289/1408)
Epoch: 106 | Batch_idx: 20 |  Loss: (0.2399) |  Loss2: (0.0000) | Acc: (91.00%) (2456/2688)
Epoch: 106 | Batch_idx: 30 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (91.00%) (3639/3968)
Epoch: 106 | Batch_idx: 40 |  Loss: (0.2307) |  Loss2: (0.0000) | Acc: (91.00%) (4817/5248)
Epoch: 106 | Batch_idx: 50 |  Loss: (0.2237) |  Loss2: (0.0000) | Acc: (92.00%) (6017/6528)
Epoch: 106 | Batch_idx: 60 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (7195/7808)
Epoch: 106 | Batch_idx: 70 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (91.00%) (8350/9088)
Epoch: 106 | Batch_idx: 80 |  Loss: (0.2269) |  Loss2: (0.0000) | Acc: (91.00%) (9535/10368)
Epoch: 106 | Batch_idx: 90 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (91.00%) (10715/11648)
Epoch: 106 | Batch_idx: 100 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (92.00%) (11897/12928)
Epoch: 106 | Batch_idx: 110 |  Loss: (0.2242) |  Loss2: (0.0000) | Acc: (92.00%) (13081/14208)
Epoch: 106 | Batch_idx: 120 |  Loss: (0.2245) |  Loss2: (0.0000) | Acc: (92.00%) (14257/15488)
Epoch: 106 | Batch_idx: 130 |  Loss: (0.2272) |  Loss2: (0.0000) | Acc: (91.00%) (15413/16768)
Epoch: 106 | Batch_idx: 140 |  Loss: (0.2284) |  Loss2: (0.0000) | Acc: (91.00%) (16580/18048)
Epoch: 106 | Batch_idx: 150 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (91.00%) (17748/19328)
Epoch: 106 | Batch_idx: 160 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (91.00%) (18936/20608)
Epoch: 106 | Batch_idx: 170 |  Loss: (0.2272) |  Loss2: (0.0000) | Acc: (91.00%) (20120/21888)
Epoch: 106 | Batch_idx: 180 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (91.00%) (21290/23168)
Epoch: 106 | Batch_idx: 190 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (91.00%) (22482/24448)
Epoch: 106 | Batch_idx: 200 |  Loss: (0.2264) |  Loss2: (0.0000) | Acc: (91.00%) (23663/25728)
Epoch: 106 | Batch_idx: 210 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (91.00%) (24834/27008)
Epoch: 106 | Batch_idx: 220 |  Loss: (0.2268) |  Loss2: (0.0000) | Acc: (91.00%) (26018/28288)
Epoch: 106 | Batch_idx: 230 |  Loss: (0.2274) |  Loss2: (0.0000) | Acc: (91.00%) (27202/29568)
Epoch: 106 | Batch_idx: 240 |  Loss: (0.2271) |  Loss2: (0.0000) | Acc: (92.00%) (28384/30848)
Epoch: 106 | Batch_idx: 250 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (29561/32128)
Epoch: 106 | Batch_idx: 260 |  Loss: (0.2266) |  Loss2: (0.0000) | Acc: (92.00%) (30747/33408)
Epoch: 106 | Batch_idx: 270 |  Loss: (0.2259) |  Loss2: (0.0000) | Acc: (92.00%) (31932/34688)
Epoch: 106 | Batch_idx: 280 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (92.00%) (33139/35968)
Epoch: 106 | Batch_idx: 290 |  Loss: (0.2237) |  Loss2: (0.0000) | Acc: (92.00%) (34336/37248)
Epoch: 106 | Batch_idx: 300 |  Loss: (0.2242) |  Loss2: (0.0000) | Acc: (92.00%) (35512/38528)
Epoch: 106 | Batch_idx: 310 |  Loss: (0.2252) |  Loss2: (0.0000) | Acc: (92.00%) (36671/39808)
Epoch: 106 | Batch_idx: 320 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (37860/41088)
Epoch: 106 | Batch_idx: 330 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (39031/42368)
Epoch: 106 | Batch_idx: 340 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (92.00%) (40217/43648)
Epoch: 106 | Batch_idx: 350 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (41394/44928)
Epoch: 106 | Batch_idx: 360 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (42594/46208)
Epoch: 106 | Batch_idx: 370 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (43777/47488)
Epoch: 106 | Batch_idx: 380 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (44962/48768)
Epoch: 106 | Batch_idx: 390 |  Loss: (0.2226) |  Loss2: (0.0000) | Acc: (92.00%) (46110/50000)
# TEST : Loss: (0.4058) | Acc: (87.00%) (8711/10000)
percent tensor([0.5587, 0.5830, 0.5656, 0.5593, 0.5716, 0.5490, 0.5867, 0.5734, 0.5724,
        0.5734, 0.5691, 0.5726, 0.5637, 0.5860, 0.5674, 0.5601],
       device='cuda:0') torch.Size([16])
percent tensor([0.5491, 0.5486, 0.5322, 0.5272, 0.5351, 0.5260, 0.5500, 0.5404, 0.5424,
        0.5442, 0.5440, 0.5423, 0.5523, 0.5409, 0.5342, 0.5404],
       device='cuda:0') torch.Size([16])
percent tensor([0.5737, 0.5833, 0.5577, 0.5992, 0.6290, 0.6047, 0.6131, 0.6479, 0.5517,
        0.5216, 0.5222, 0.5563, 0.5370, 0.5977, 0.6417, 0.5787],
       device='cuda:0') torch.Size([16])
percent tensor([0.7053, 0.6545, 0.6730, 0.6772, 0.6938, 0.7044, 0.6949, 0.6910, 0.6575,
        0.6689, 0.6711, 0.6525, 0.6537, 0.6688, 0.7069, 0.6992],
       device='cuda:0') torch.Size([16])
percent tensor([0.5586, 0.5732, 0.5670, 0.5859, 0.5851, 0.5840, 0.5607, 0.5752, 0.5793,
        0.5672, 0.5521, 0.5759, 0.5568, 0.5848, 0.5496, 0.5890],
       device='cuda:0') torch.Size([16])
percent tensor([0.6390, 0.6591, 0.6721, 0.7084, 0.6896, 0.6666, 0.6784, 0.6773, 0.6983,
        0.6551, 0.6831, 0.6984, 0.6461, 0.7281, 0.6431, 0.6748],
       device='cuda:0') torch.Size([16])
percent tensor([0.5975, 0.5695, 0.6574, 0.7281, 0.6135, 0.8269, 0.6038, 0.5169, 0.7060,
        0.5885, 0.6704, 0.5593, 0.5787, 0.7050, 0.4625, 0.6274],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9994, 0.9997, 0.9995, 0.9999, 0.9990, 0.9994, 0.9996, 0.9997,
        0.9996, 0.9998, 0.9998, 0.9996, 0.9989, 0.9997, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 107 | Batch_idx: 0 |  Loss: (0.2203) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 107 | Batch_idx: 10 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (1304/1408)
Epoch: 107 | Batch_idx: 20 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (2494/2688)
Epoch: 107 | Batch_idx: 30 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (92.00%) (3679/3968)
Epoch: 107 | Batch_idx: 40 |  Loss: (0.2065) |  Loss2: (0.0000) | Acc: (92.00%) (4875/5248)
Epoch: 107 | Batch_idx: 50 |  Loss: (0.2032) |  Loss2: (0.0000) | Acc: (93.00%) (6074/6528)
Epoch: 107 | Batch_idx: 60 |  Loss: (0.2029) |  Loss2: (0.0000) | Acc: (92.00%) (7257/7808)
Epoch: 107 | Batch_idx: 70 |  Loss: (0.2035) |  Loss2: (0.0000) | Acc: (92.00%) (8437/9088)
Epoch: 107 | Batch_idx: 80 |  Loss: (0.2041) |  Loss2: (0.0000) | Acc: (92.00%) (9623/10368)
Epoch: 107 | Batch_idx: 90 |  Loss: (0.2054) |  Loss2: (0.0000) | Acc: (92.00%) (10812/11648)
Epoch: 107 | Batch_idx: 100 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (92.00%) (11986/12928)
Epoch: 107 | Batch_idx: 110 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (13167/14208)
Epoch: 107 | Batch_idx: 120 |  Loss: (0.2070) |  Loss2: (0.0000) | Acc: (92.00%) (14368/15488)
Epoch: 107 | Batch_idx: 130 |  Loss: (0.2070) |  Loss2: (0.0000) | Acc: (92.00%) (15559/16768)
Epoch: 107 | Batch_idx: 140 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (92.00%) (16747/18048)
Epoch: 107 | Batch_idx: 150 |  Loss: (0.2054) |  Loss2: (0.0000) | Acc: (92.00%) (17947/19328)
Epoch: 107 | Batch_idx: 160 |  Loss: (0.2065) |  Loss2: (0.0000) | Acc: (92.00%) (19135/20608)
Epoch: 107 | Batch_idx: 170 |  Loss: (0.2077) |  Loss2: (0.0000) | Acc: (92.00%) (20308/21888)
Epoch: 107 | Batch_idx: 180 |  Loss: (0.2076) |  Loss2: (0.0000) | Acc: (92.00%) (21490/23168)
Epoch: 107 | Batch_idx: 190 |  Loss: (0.2078) |  Loss2: (0.0000) | Acc: (92.00%) (22679/24448)
Epoch: 107 | Batch_idx: 200 |  Loss: (0.2072) |  Loss2: (0.0000) | Acc: (92.00%) (23868/25728)
Epoch: 107 | Batch_idx: 210 |  Loss: (0.2076) |  Loss2: (0.0000) | Acc: (92.00%) (25046/27008)
Epoch: 107 | Batch_idx: 220 |  Loss: (0.2084) |  Loss2: (0.0000) | Acc: (92.00%) (26225/28288)
Epoch: 107 | Batch_idx: 230 |  Loss: (0.2074) |  Loss2: (0.0000) | Acc: (92.00%) (27423/29568)
Epoch: 107 | Batch_idx: 240 |  Loss: (0.2071) |  Loss2: (0.0000) | Acc: (92.00%) (28618/30848)
Epoch: 107 | Batch_idx: 250 |  Loss: (0.2061) |  Loss2: (0.0000) | Acc: (92.00%) (29821/32128)
Epoch: 107 | Batch_idx: 260 |  Loss: (0.2055) |  Loss2: (0.0000) | Acc: (92.00%) (31016/33408)
Epoch: 107 | Batch_idx: 270 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (92.00%) (32201/34688)
Epoch: 107 | Batch_idx: 280 |  Loss: (0.2062) |  Loss2: (0.0000) | Acc: (92.00%) (33389/35968)
Epoch: 107 | Batch_idx: 290 |  Loss: (0.2050) |  Loss2: (0.0000) | Acc: (92.00%) (34594/37248)
Epoch: 107 | Batch_idx: 300 |  Loss: (0.2046) |  Loss2: (0.0000) | Acc: (92.00%) (35791/38528)
Epoch: 107 | Batch_idx: 310 |  Loss: (0.2049) |  Loss2: (0.0000) | Acc: (92.00%) (36972/39808)
Epoch: 107 | Batch_idx: 320 |  Loss: (0.2043) |  Loss2: (0.0000) | Acc: (92.00%) (38169/41088)
Epoch: 107 | Batch_idx: 330 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (92.00%) (39370/42368)
Epoch: 107 | Batch_idx: 340 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (92.00%) (40572/43648)
Epoch: 107 | Batch_idx: 350 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (92.00%) (41763/44928)
Epoch: 107 | Batch_idx: 360 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (92.00%) (42955/46208)
Epoch: 107 | Batch_idx: 370 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (92.00%) (44143/47488)
Epoch: 107 | Batch_idx: 380 |  Loss: (0.2038) |  Loss2: (0.0000) | Acc: (92.00%) (45316/48768)
Epoch: 107 | Batch_idx: 390 |  Loss: (0.2038) |  Loss2: (0.0000) | Acc: (92.00%) (46456/50000)
# TEST : Loss: (0.3845) | Acc: (87.00%) (8775/10000)
percent tensor([0.5594, 0.5842, 0.5662, 0.5598, 0.5722, 0.5494, 0.5878, 0.5741, 0.5732,
        0.5743, 0.5699, 0.5733, 0.5647, 0.5872, 0.5682, 0.5608],
       device='cuda:0') torch.Size([16])
percent tensor([0.5500, 0.5501, 0.5329, 0.5275, 0.5356, 0.5259, 0.5513, 0.5411, 0.5433,
        0.5457, 0.5454, 0.5435, 0.5542, 0.5414, 0.5352, 0.5413],
       device='cuda:0') torch.Size([16])
percent tensor([0.5787, 0.5855, 0.5638, 0.6078, 0.6347, 0.6123, 0.6165, 0.6548, 0.5567,
        0.5237, 0.5251, 0.5615, 0.5395, 0.6037, 0.6461, 0.5837],
       device='cuda:0') torch.Size([16])
percent tensor([0.7137, 0.6631, 0.6791, 0.6820, 0.7001, 0.7118, 0.7034, 0.6983, 0.6640,
        0.6767, 0.6787, 0.6587, 0.6632, 0.6767, 0.7145, 0.7073],
       device='cuda:0') torch.Size([16])
percent tensor([0.5668, 0.5809, 0.5757, 0.5932, 0.5967, 0.5914, 0.5668, 0.5844, 0.5867,
        0.5733, 0.5555, 0.5811, 0.5633, 0.5897, 0.5561, 0.5964],
       device='cuda:0') torch.Size([16])
percent tensor([0.6413, 0.6652, 0.6720, 0.7039, 0.6873, 0.6661, 0.6792, 0.6737, 0.7004,
        0.6593, 0.6856, 0.6971, 0.6525, 0.7300, 0.6433, 0.6741],
       device='cuda:0') torch.Size([16])
percent tensor([0.5862, 0.5608, 0.6531, 0.7366, 0.6099, 0.8269, 0.6008, 0.5094, 0.7011,
        0.5813, 0.6685, 0.5501, 0.5612, 0.7040, 0.4530, 0.6247],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9994, 0.9997, 0.9995, 0.9999, 0.9991, 0.9994, 0.9996, 0.9997,
        0.9995, 0.9998, 0.9998, 0.9996, 0.9989, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 108 | Batch_idx: 0 |  Loss: (0.2052) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 108 | Batch_idx: 10 |  Loss: (0.2062) |  Loss2: (0.0000) | Acc: (93.00%) (1310/1408)
Epoch: 108 | Batch_idx: 20 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (92.00%) (2499/2688)
Epoch: 108 | Batch_idx: 30 |  Loss: (0.2034) |  Loss2: (0.0000) | Acc: (92.00%) (3689/3968)
Epoch: 108 | Batch_idx: 40 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (92.00%) (4868/5248)
Epoch: 108 | Batch_idx: 50 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (92.00%) (6053/6528)
Epoch: 108 | Batch_idx: 60 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (92.00%) (7247/7808)
Epoch: 108 | Batch_idx: 70 |  Loss: (0.2069) |  Loss2: (0.0000) | Acc: (92.00%) (8419/9088)
Epoch: 108 | Batch_idx: 80 |  Loss: (0.2051) |  Loss2: (0.0000) | Acc: (92.00%) (9614/10368)
Epoch: 108 | Batch_idx: 90 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (92.00%) (10808/11648)
Epoch: 108 | Batch_idx: 100 |  Loss: (0.2069) |  Loss2: (0.0000) | Acc: (92.00%) (11989/12928)
Epoch: 108 | Batch_idx: 110 |  Loss: (0.2043) |  Loss2: (0.0000) | Acc: (92.00%) (13187/14208)
Epoch: 108 | Batch_idx: 120 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (92.00%) (14370/15488)
Epoch: 108 | Batch_idx: 130 |  Loss: (0.2040) |  Loss2: (0.0000) | Acc: (92.00%) (15558/16768)
Epoch: 108 | Batch_idx: 140 |  Loss: (0.2021) |  Loss2: (0.0000) | Acc: (92.00%) (16766/18048)
Epoch: 108 | Batch_idx: 150 |  Loss: (0.2022) |  Loss2: (0.0000) | Acc: (92.00%) (17955/19328)
Epoch: 108 | Batch_idx: 160 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (92.00%) (19150/20608)
Epoch: 108 | Batch_idx: 170 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (92.00%) (20347/21888)
Epoch: 108 | Batch_idx: 180 |  Loss: (0.1998) |  Loss2: (0.0000) | Acc: (92.00%) (21541/23168)
Epoch: 108 | Batch_idx: 190 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (92.00%) (22732/24448)
Epoch: 108 | Batch_idx: 200 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (92.00%) (23919/25728)
Epoch: 108 | Batch_idx: 210 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (92.00%) (25115/27008)
Epoch: 108 | Batch_idx: 220 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (93.00%) (26314/28288)
Epoch: 108 | Batch_idx: 230 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (27499/29568)
Epoch: 108 | Batch_idx: 240 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (93.00%) (28694/30848)
Epoch: 108 | Batch_idx: 250 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (93.00%) (29889/32128)
Epoch: 108 | Batch_idx: 260 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (93.00%) (31074/33408)
Epoch: 108 | Batch_idx: 270 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (93.00%) (32275/34688)
Epoch: 108 | Batch_idx: 280 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (33483/35968)
Epoch: 108 | Batch_idx: 290 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (34676/37248)
Epoch: 108 | Batch_idx: 300 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (35853/38528)
Epoch: 108 | Batch_idx: 310 |  Loss: (0.1958) |  Loss2: (0.0000) | Acc: (93.00%) (37054/39808)
Epoch: 108 | Batch_idx: 320 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (93.00%) (38233/41088)
Epoch: 108 | Batch_idx: 330 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (39423/42368)
Epoch: 108 | Batch_idx: 340 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (93.00%) (40611/43648)
Epoch: 108 | Batch_idx: 350 |  Loss: (0.1963) |  Loss2: (0.0000) | Acc: (93.00%) (41813/44928)
Epoch: 108 | Batch_idx: 360 |  Loss: (0.1954) |  Loss2: (0.0000) | Acc: (93.00%) (43020/46208)
Epoch: 108 | Batch_idx: 370 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (93.00%) (44195/47488)
Epoch: 108 | Batch_idx: 380 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (45388/48768)
Epoch: 108 | Batch_idx: 390 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (93.00%) (46536/50000)
# TEST : Loss: (0.3769) | Acc: (87.00%) (8797/10000)
percent tensor([0.5570, 0.5818, 0.5638, 0.5574, 0.5696, 0.5470, 0.5853, 0.5715, 0.5709,
        0.5718, 0.5677, 0.5709, 0.5624, 0.5849, 0.5657, 0.5583],
       device='cuda:0') torch.Size([16])
percent tensor([0.5519, 0.5528, 0.5347, 0.5285, 0.5372, 0.5265, 0.5539, 0.5430, 0.5453,
        0.5484, 0.5479, 0.5458, 0.5570, 0.5434, 0.5368, 0.5431],
       device='cuda:0') torch.Size([16])
percent tensor([0.5733, 0.5799, 0.5612, 0.6059, 0.6332, 0.6059, 0.6128, 0.6537, 0.5539,
        0.5184, 0.5184, 0.5603, 0.5343, 0.5994, 0.6417, 0.5779],
       device='cuda:0') torch.Size([16])
percent tensor([0.7072, 0.6568, 0.6720, 0.6748, 0.6926, 0.7058, 0.6963, 0.6907, 0.6566,
        0.6698, 0.6717, 0.6510, 0.6572, 0.6700, 0.7074, 0.7011],
       device='cuda:0') torch.Size([16])
percent tensor([0.5664, 0.5797, 0.5773, 0.5923, 0.5977, 0.5941, 0.5637, 0.5833, 0.5864,
        0.5718, 0.5528, 0.5788, 0.5631, 0.5854, 0.5530, 0.5954],
       device='cuda:0') torch.Size([16])
percent tensor([0.6395, 0.6650, 0.6709, 0.6978, 0.6835, 0.6652, 0.6757, 0.6693, 0.7000,
        0.6582, 0.6842, 0.6926, 0.6533, 0.7279, 0.6392, 0.6694],
       device='cuda:0') torch.Size([16])
percent tensor([0.5848, 0.5606, 0.6612, 0.7474, 0.6217, 0.8312, 0.6066, 0.5175, 0.7053,
        0.5861, 0.6744, 0.5540, 0.5544, 0.7038, 0.4569, 0.6265],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9994, 0.9997, 0.9995, 0.9999, 0.9992, 0.9994, 0.9996, 0.9997,
        0.9995, 0.9998, 0.9998, 0.9996, 0.9989, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 109 | Batch_idx: 0 |  Loss: (0.2098) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 109 | Batch_idx: 10 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (93.00%) (1310/1408)
Epoch: 109 | Batch_idx: 20 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (2500/2688)
Epoch: 109 | Batch_idx: 30 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (3694/3968)
Epoch: 109 | Batch_idx: 40 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (93.00%) (4881/5248)
Epoch: 109 | Batch_idx: 50 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (6092/6528)
Epoch: 109 | Batch_idx: 60 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (7288/7808)
Epoch: 109 | Batch_idx: 70 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (8476/9088)
Epoch: 109 | Batch_idx: 80 |  Loss: (0.1954) |  Loss2: (0.0000) | Acc: (93.00%) (9676/10368)
Epoch: 109 | Batch_idx: 90 |  Loss: (0.1948) |  Loss2: (0.0000) | Acc: (93.00%) (10871/11648)
Epoch: 109 | Batch_idx: 100 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (12071/12928)
Epoch: 109 | Batch_idx: 110 |  Loss: (0.1930) |  Loss2: (0.0000) | Acc: (93.00%) (13262/14208)
Epoch: 109 | Batch_idx: 120 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (14462/15488)
Epoch: 109 | Batch_idx: 130 |  Loss: (0.1923) |  Loss2: (0.0000) | Acc: (93.00%) (15655/16768)
Epoch: 109 | Batch_idx: 140 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (16852/18048)
Epoch: 109 | Batch_idx: 150 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (18058/19328)
Epoch: 109 | Batch_idx: 160 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (19250/20608)
Epoch: 109 | Batch_idx: 170 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (20451/21888)
Epoch: 109 | Batch_idx: 180 |  Loss: (0.1909) |  Loss2: (0.0000) | Acc: (93.00%) (21644/23168)
Epoch: 109 | Batch_idx: 190 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (22830/24448)
Epoch: 109 | Batch_idx: 200 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (24031/25728)
Epoch: 109 | Batch_idx: 210 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (25223/27008)
Epoch: 109 | Batch_idx: 220 |  Loss: (0.1917) |  Loss2: (0.0000) | Acc: (93.00%) (26414/28288)
Epoch: 109 | Batch_idx: 230 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (27619/29568)
Epoch: 109 | Batch_idx: 240 |  Loss: (0.1896) |  Loss2: (0.0000) | Acc: (93.00%) (28815/30848)
Epoch: 109 | Batch_idx: 250 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (30015/32128)
Epoch: 109 | Batch_idx: 260 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (31221/33408)
Epoch: 109 | Batch_idx: 270 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (32417/34688)
Epoch: 109 | Batch_idx: 280 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (33602/35968)
Epoch: 109 | Batch_idx: 290 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (34794/37248)
Epoch: 109 | Batch_idx: 300 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (35990/38528)
Epoch: 109 | Batch_idx: 310 |  Loss: (0.1896) |  Loss2: (0.0000) | Acc: (93.00%) (37180/39808)
Epoch: 109 | Batch_idx: 320 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (38369/41088)
Epoch: 109 | Batch_idx: 330 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (39574/42368)
Epoch: 109 | Batch_idx: 340 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (40760/43648)
Epoch: 109 | Batch_idx: 350 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (41964/44928)
Epoch: 109 | Batch_idx: 360 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (43172/46208)
Epoch: 109 | Batch_idx: 370 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (44363/47488)
Epoch: 109 | Batch_idx: 380 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (45566/48768)
Epoch: 109 | Batch_idx: 390 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (46718/50000)
# TEST : Loss: (0.3718) | Acc: (88.00%) (8822/10000)
percent tensor([0.5582, 0.5836, 0.5648, 0.5584, 0.5707, 0.5479, 0.5870, 0.5728, 0.5725,
        0.5734, 0.5692, 0.5722, 0.5639, 0.5870, 0.5671, 0.5596],
       device='cuda:0') torch.Size([16])
percent tensor([0.5485, 0.5492, 0.5314, 0.5249, 0.5333, 0.5227, 0.5502, 0.5393, 0.5419,
        0.5450, 0.5444, 0.5425, 0.5541, 0.5396, 0.5331, 0.5395],
       device='cuda:0') torch.Size([16])
percent tensor([0.5713, 0.5780, 0.5633, 0.6089, 0.6333, 0.6027, 0.6116, 0.6554, 0.5545,
        0.5179, 0.5175, 0.5619, 0.5325, 0.6004, 0.6392, 0.5760],
       device='cuda:0') torch.Size([16])
percent tensor([0.7030, 0.6521, 0.6682, 0.6695, 0.6879, 0.7020, 0.6912, 0.6861, 0.6525,
        0.6655, 0.6670, 0.6461, 0.6535, 0.6652, 0.7016, 0.6967],
       device='cuda:0') torch.Size([16])
percent tensor([0.5647, 0.5796, 0.5774, 0.5931, 0.5993, 0.5942, 0.5609, 0.5825, 0.5865,
        0.5711, 0.5505, 0.5772, 0.5626, 0.5842, 0.5505, 0.5937],
       device='cuda:0') torch.Size([16])
percent tensor([0.6289, 0.6574, 0.6602, 0.6862, 0.6726, 0.6563, 0.6645, 0.6557, 0.6913,
        0.6481, 0.6746, 0.6808, 0.6456, 0.7193, 0.6269, 0.6571],
       device='cuda:0') torch.Size([16])
percent tensor([0.5944, 0.5758, 0.6714, 0.7580, 0.6297, 0.8382, 0.6211, 0.5212, 0.7126,
        0.5965, 0.6872, 0.5660, 0.5657, 0.7103, 0.4654, 0.6383],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9995, 0.9997, 0.9996, 0.9999, 0.9992, 0.9994, 0.9996, 0.9997,
        0.9995, 0.9998, 0.9998, 0.9996, 0.9990, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 110 | Batch_idx: 0 |  Loss: (0.2135) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 110 | Batch_idx: 10 |  Loss: (0.1732) |  Loss2: (0.0000) | Acc: (94.00%) (1327/1408)
Epoch: 110 | Batch_idx: 20 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (2522/2688)
Epoch: 110 | Batch_idx: 30 |  Loss: (0.1814) |  Loss2: (0.0000) | Acc: (93.00%) (3719/3968)
Epoch: 110 | Batch_idx: 40 |  Loss: (0.1802) |  Loss2: (0.0000) | Acc: (93.00%) (4927/5248)
Epoch: 110 | Batch_idx: 50 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (6130/6528)
Epoch: 110 | Batch_idx: 60 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (7333/7808)
Epoch: 110 | Batch_idx: 70 |  Loss: (0.1802) |  Loss2: (0.0000) | Acc: (93.00%) (8530/9088)
Epoch: 110 | Batch_idx: 80 |  Loss: (0.1820) |  Loss2: (0.0000) | Acc: (93.00%) (9722/10368)
Epoch: 110 | Batch_idx: 90 |  Loss: (0.1836) |  Loss2: (0.0000) | Acc: (93.00%) (10916/11648)
Epoch: 110 | Batch_idx: 100 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (12107/12928)
Epoch: 110 | Batch_idx: 110 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (13297/14208)
Epoch: 110 | Batch_idx: 120 |  Loss: (0.1888) |  Loss2: (0.0000) | Acc: (93.00%) (14481/15488)
Epoch: 110 | Batch_idx: 130 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (15673/16768)
Epoch: 110 | Batch_idx: 140 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (16866/18048)
Epoch: 110 | Batch_idx: 150 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (18054/19328)
Epoch: 110 | Batch_idx: 160 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (19229/20608)
Epoch: 110 | Batch_idx: 170 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (20420/21888)
Epoch: 110 | Batch_idx: 180 |  Loss: (0.1929) |  Loss2: (0.0000) | Acc: (93.00%) (21602/23168)
Epoch: 110 | Batch_idx: 190 |  Loss: (0.1932) |  Loss2: (0.0000) | Acc: (93.00%) (22799/24448)
Epoch: 110 | Batch_idx: 200 |  Loss: (0.1939) |  Loss2: (0.0000) | Acc: (93.00%) (23990/25728)
Epoch: 110 | Batch_idx: 210 |  Loss: (0.1942) |  Loss2: (0.0000) | Acc: (93.00%) (25184/27008)
Epoch: 110 | Batch_idx: 220 |  Loss: (0.1941) |  Loss2: (0.0000) | Acc: (93.00%) (26380/28288)
Epoch: 110 | Batch_idx: 230 |  Loss: (0.1948) |  Loss2: (0.0000) | Acc: (93.00%) (27567/29568)
Epoch: 110 | Batch_idx: 240 |  Loss: (0.1947) |  Loss2: (0.0000) | Acc: (93.00%) (28760/30848)
Epoch: 110 | Batch_idx: 250 |  Loss: (0.1951) |  Loss2: (0.0000) | Acc: (93.00%) (29946/32128)
Epoch: 110 | Batch_idx: 260 |  Loss: (0.1946) |  Loss2: (0.0000) | Acc: (93.00%) (31141/33408)
Epoch: 110 | Batch_idx: 270 |  Loss: (0.1954) |  Loss2: (0.0000) | Acc: (93.00%) (32319/34688)
Epoch: 110 | Batch_idx: 280 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (93.00%) (33519/35968)
Epoch: 110 | Batch_idx: 290 |  Loss: (0.1948) |  Loss2: (0.0000) | Acc: (93.00%) (34717/37248)
Epoch: 110 | Batch_idx: 300 |  Loss: (0.1953) |  Loss2: (0.0000) | Acc: (93.00%) (35909/38528)
Epoch: 110 | Batch_idx: 310 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (37089/39808)
Epoch: 110 | Batch_idx: 320 |  Loss: (0.1951) |  Loss2: (0.0000) | Acc: (93.00%) (38291/41088)
Epoch: 110 | Batch_idx: 330 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (93.00%) (39495/42368)
Epoch: 110 | Batch_idx: 340 |  Loss: (0.1939) |  Loss2: (0.0000) | Acc: (93.00%) (40687/43648)
Epoch: 110 | Batch_idx: 350 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (41885/44928)
Epoch: 110 | Batch_idx: 360 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (43075/46208)
Epoch: 110 | Batch_idx: 370 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (44272/47488)
Epoch: 110 | Batch_idx: 380 |  Loss: (0.1949) |  Loss2: (0.0000) | Acc: (93.00%) (45456/48768)
Epoch: 110 | Batch_idx: 390 |  Loss: (0.1955) |  Loss2: (0.0000) | Acc: (93.00%) (46597/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_110.pth.tar'
# TEST : Loss: (0.4234) | Acc: (86.00%) (8644/10000)
percent tensor([0.5586, 0.5846, 0.5656, 0.5594, 0.5716, 0.5478, 0.5879, 0.5740, 0.5735,
        0.5743, 0.5699, 0.5732, 0.5649, 0.5885, 0.5677, 0.5604],
       device='cuda:0') torch.Size([16])
percent tensor([0.5477, 0.5490, 0.5291, 0.5227, 0.5319, 0.5216, 0.5493, 0.5376, 0.5412,
        0.5434, 0.5437, 0.5416, 0.5534, 0.5382, 0.5325, 0.5383],
       device='cuda:0') torch.Size([16])
percent tensor([0.5715, 0.5882, 0.5634, 0.6276, 0.6374, 0.6083, 0.6241, 0.6652, 0.5589,
        0.5333, 0.5263, 0.5790, 0.5335, 0.6130, 0.6482, 0.5822],
       device='cuda:0') torch.Size([16])
percent tensor([0.6993, 0.6573, 0.6764, 0.6746, 0.6904, 0.6964, 0.6968, 0.6876, 0.6524,
        0.6688, 0.6676, 0.6494, 0.6527, 0.6677, 0.7034, 0.6963],
       device='cuda:0') torch.Size([16])
percent tensor([0.5671, 0.5743, 0.5717, 0.5927, 0.5991, 0.5996, 0.5553, 0.5880, 0.5876,
        0.5688, 0.5544, 0.5799, 0.5636, 0.5809, 0.5469, 0.5921],
       device='cuda:0') torch.Size([16])
percent tensor([0.6255, 0.6559, 0.6642, 0.6824, 0.6839, 0.6571, 0.6630, 0.6563, 0.6932,
        0.6434, 0.6735, 0.6849, 0.6449, 0.7187, 0.6271, 0.6550],
       device='cuda:0') torch.Size([16])
percent tensor([0.5740, 0.5862, 0.6870, 0.7126, 0.6280, 0.8333, 0.6233, 0.5474, 0.7129,
        0.6188, 0.6861, 0.5790, 0.6098, 0.7256, 0.4606, 0.6186],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9993, 0.9997, 0.9995, 0.9999, 0.9987, 0.9995, 0.9997, 0.9997,
        0.9997, 0.9999, 0.9999, 0.9997, 0.9989, 0.9998, 0.9990],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(175.1420, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(812.2287, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(813.4279, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1528.9988, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(489.3783, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2239.3770, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4263.7041, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1396.5718, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6174.7358, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11831.5000, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3935.0979, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16565.7695, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 111 | Batch_idx: 0 |  Loss: (0.2023) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 111 | Batch_idx: 10 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (1321/1408)
Epoch: 111 | Batch_idx: 20 |  Loss: (0.1868) |  Loss2: (0.0000) | Acc: (93.00%) (2510/2688)
Epoch: 111 | Batch_idx: 30 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (3714/3968)
Epoch: 111 | Batch_idx: 40 |  Loss: (0.1908) |  Loss2: (0.0000) | Acc: (93.00%) (4905/5248)
Epoch: 111 | Batch_idx: 50 |  Loss: (0.1934) |  Loss2: (0.0000) | Acc: (93.00%) (6094/6528)
Epoch: 111 | Batch_idx: 60 |  Loss: (0.1912) |  Loss2: (0.0000) | Acc: (93.00%) (7298/7808)
Epoch: 111 | Batch_idx: 70 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (8510/9088)
Epoch: 111 | Batch_idx: 80 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (9712/10368)
Epoch: 111 | Batch_idx: 90 |  Loss: (0.1896) |  Loss2: (0.0000) | Acc: (93.00%) (10900/11648)
Epoch: 111 | Batch_idx: 100 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (12099/12928)
Epoch: 111 | Batch_idx: 110 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (13302/14208)
Epoch: 111 | Batch_idx: 120 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (14501/15488)
Epoch: 111 | Batch_idx: 130 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (15678/16768)
Epoch: 111 | Batch_idx: 140 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (16877/18048)
Epoch: 111 | Batch_idx: 150 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (18071/19328)
Epoch: 111 | Batch_idx: 160 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (19259/20608)
Epoch: 111 | Batch_idx: 170 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (20457/21888)
Epoch: 111 | Batch_idx: 180 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (21664/23168)
Epoch: 111 | Batch_idx: 190 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (22862/24448)
Epoch: 111 | Batch_idx: 200 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (24054/25728)
Epoch: 111 | Batch_idx: 210 |  Loss: (0.1865) |  Loss2: (0.0000) | Acc: (93.00%) (25253/27008)
Epoch: 111 | Batch_idx: 220 |  Loss: (0.1865) |  Loss2: (0.0000) | Acc: (93.00%) (26454/28288)
Epoch: 111 | Batch_idx: 230 |  Loss: (0.1861) |  Loss2: (0.0000) | Acc: (93.00%) (27650/29568)
Epoch: 111 | Batch_idx: 240 |  Loss: (0.1860) |  Loss2: (0.0000) | Acc: (93.00%) (28851/30848)
Epoch: 111 | Batch_idx: 250 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (30050/32128)
Epoch: 111 | Batch_idx: 260 |  Loss: (0.1860) |  Loss2: (0.0000) | Acc: (93.00%) (31247/33408)
Epoch: 111 | Batch_idx: 270 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (93.00%) (32431/34688)
Epoch: 111 | Batch_idx: 280 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (33635/35968)
Epoch: 111 | Batch_idx: 290 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (34817/37248)
Epoch: 111 | Batch_idx: 300 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (36016/38528)
Epoch: 111 | Batch_idx: 310 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (37219/39808)
Epoch: 111 | Batch_idx: 320 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (38403/41088)
Epoch: 111 | Batch_idx: 330 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (39596/42368)
Epoch: 111 | Batch_idx: 340 |  Loss: (0.1901) |  Loss2: (0.0000) | Acc: (93.00%) (40771/43648)
Epoch: 111 | Batch_idx: 350 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (41952/44928)
Epoch: 111 | Batch_idx: 360 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (43150/46208)
Epoch: 111 | Batch_idx: 370 |  Loss: (0.1917) |  Loss2: (0.0000) | Acc: (93.00%) (44345/47488)
Epoch: 111 | Batch_idx: 380 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (45528/48768)
Epoch: 111 | Batch_idx: 390 |  Loss: (0.1929) |  Loss2: (0.0000) | Acc: (93.00%) (46662/50000)
# TEST : Loss: (0.4100) | Acc: (87.00%) (8719/10000)
percent tensor([0.5590, 0.5831, 0.5675, 0.5590, 0.5726, 0.5485, 0.5877, 0.5739, 0.5733,
        0.5742, 0.5694, 0.5745, 0.5646, 0.5856, 0.5673, 0.5596],
       device='cuda:0') torch.Size([16])
percent tensor([0.5459, 0.5476, 0.5295, 0.5235, 0.5317, 0.5186, 0.5482, 0.5372, 0.5385,
        0.5437, 0.5417, 0.5418, 0.5519, 0.5357, 0.5317, 0.5374],
       device='cuda:0') torch.Size([16])
percent tensor([0.5566, 0.5770, 0.5476, 0.6077, 0.6174, 0.6015, 0.6043, 0.6497, 0.5560,
        0.5114, 0.5139, 0.5554, 0.5215, 0.6096, 0.6339, 0.5666],
       device='cuda:0') torch.Size([16])
percent tensor([0.6966, 0.6548, 0.6686, 0.6744, 0.6831, 0.6896, 0.6902, 0.6807, 0.6542,
        0.6665, 0.6674, 0.6475, 0.6515, 0.6696, 0.6965, 0.6917],
       device='cuda:0') torch.Size([16])
percent tensor([0.5677, 0.5813, 0.5759, 0.5877, 0.5943, 0.6037, 0.5609, 0.5845, 0.5948,
        0.5682, 0.5551, 0.5773, 0.5683, 0.5815, 0.5475, 0.5941],
       device='cuda:0') torch.Size([16])
percent tensor([0.6257, 0.6588, 0.6504, 0.6775, 0.6608, 0.6444, 0.6585, 0.6538, 0.6769,
        0.6445, 0.6722, 0.6819, 0.6381, 0.7122, 0.6285, 0.6508],
       device='cuda:0') torch.Size([16])
percent tensor([0.5904, 0.5937, 0.6801, 0.7343, 0.6087, 0.8231, 0.6173, 0.5295, 0.7001,
        0.6335, 0.7136, 0.5969, 0.5845, 0.7109, 0.4692, 0.6238],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9996, 0.9998, 0.9997, 0.9999, 0.9984, 0.9993, 0.9996, 0.9996,
        0.9997, 0.9999, 0.9999, 0.9997, 0.9992, 0.9997, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 112 | Batch_idx: 0 |  Loss: (0.2557) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 112 | Batch_idx: 10 |  Loss: (0.1945) |  Loss2: (0.0000) | Acc: (93.00%) (1311/1408)
Epoch: 112 | Batch_idx: 20 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (2521/2688)
Epoch: 112 | Batch_idx: 30 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (3720/3968)
Epoch: 112 | Batch_idx: 40 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (4913/5248)
Epoch: 112 | Batch_idx: 50 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (6127/6528)
Epoch: 112 | Batch_idx: 60 |  Loss: (0.1791) |  Loss2: (0.0000) | Acc: (93.00%) (7332/7808)
Epoch: 112 | Batch_idx: 70 |  Loss: (0.1791) |  Loss2: (0.0000) | Acc: (93.00%) (8537/9088)
Epoch: 112 | Batch_idx: 80 |  Loss: (0.1789) |  Loss2: (0.0000) | Acc: (93.00%) (9740/10368)
Epoch: 112 | Batch_idx: 90 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (10935/11648)
Epoch: 112 | Batch_idx: 100 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (12131/12928)
Epoch: 112 | Batch_idx: 110 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (13332/14208)
Epoch: 112 | Batch_idx: 120 |  Loss: (0.1830) |  Loss2: (0.0000) | Acc: (93.00%) (14540/15488)
Epoch: 112 | Batch_idx: 130 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (15732/16768)
Epoch: 112 | Batch_idx: 140 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (16916/18048)
Epoch: 112 | Batch_idx: 150 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (18115/19328)
Epoch: 112 | Batch_idx: 160 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (19316/20608)
Epoch: 112 | Batch_idx: 170 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (20505/21888)
Epoch: 112 | Batch_idx: 180 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (21706/23168)
Epoch: 112 | Batch_idx: 190 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (22894/24448)
Epoch: 112 | Batch_idx: 200 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (24100/25728)
Epoch: 112 | Batch_idx: 210 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (25304/27008)
Epoch: 112 | Batch_idx: 220 |  Loss: (0.1853) |  Loss2: (0.0000) | Acc: (93.00%) (26489/28288)
Epoch: 112 | Batch_idx: 230 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (27679/29568)
Epoch: 112 | Batch_idx: 240 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (28874/30848)
Epoch: 112 | Batch_idx: 250 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (30074/32128)
Epoch: 112 | Batch_idx: 260 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (31280/33408)
Epoch: 112 | Batch_idx: 270 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (32461/34688)
Epoch: 112 | Batch_idx: 280 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (33665/35968)
Epoch: 112 | Batch_idx: 290 |  Loss: (0.1853) |  Loss2: (0.0000) | Acc: (93.00%) (34879/37248)
Epoch: 112 | Batch_idx: 300 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (36067/38528)
Epoch: 112 | Batch_idx: 310 |  Loss: (0.1867) |  Loss2: (0.0000) | Acc: (93.00%) (37251/39808)
Epoch: 112 | Batch_idx: 320 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (38449/41088)
Epoch: 112 | Batch_idx: 330 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (39648/42368)
Epoch: 112 | Batch_idx: 340 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (40843/43648)
Epoch: 112 | Batch_idx: 350 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (42040/44928)
Epoch: 112 | Batch_idx: 360 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (43238/46208)
Epoch: 112 | Batch_idx: 370 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (93.00%) (44437/47488)
Epoch: 112 | Batch_idx: 380 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (45626/48768)
Epoch: 112 | Batch_idx: 390 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (46767/50000)
# TEST : Loss: (0.3910) | Acc: (87.00%) (8778/10000)
percent tensor([0.5601, 0.5828, 0.5691, 0.5599, 0.5732, 0.5501, 0.5878, 0.5745, 0.5730,
        0.5745, 0.5696, 0.5754, 0.5652, 0.5843, 0.5678, 0.5603],
       device='cuda:0') torch.Size([16])
percent tensor([0.5477, 0.5500, 0.5326, 0.5264, 0.5339, 0.5192, 0.5512, 0.5403, 0.5412,
        0.5453, 0.5430, 0.5430, 0.5543, 0.5388, 0.5333, 0.5401],
       device='cuda:0') torch.Size([16])
percent tensor([0.5620, 0.5684, 0.5502, 0.6158, 0.6197, 0.6075, 0.5952, 0.6544, 0.5576,
        0.5094, 0.5170, 0.5498, 0.5242, 0.5953, 0.6361, 0.5681],
       device='cuda:0') torch.Size([16])
percent tensor([0.7012, 0.6503, 0.6709, 0.6713, 0.6869, 0.6946, 0.6878, 0.6823, 0.6528,
        0.6642, 0.6652, 0.6456, 0.6523, 0.6628, 0.6977, 0.6929],
       device='cuda:0') torch.Size([16])
percent tensor([0.5668, 0.5819, 0.5728, 0.5954, 0.5873, 0.5982, 0.5617, 0.5869, 0.5934,
        0.5729, 0.5571, 0.5749, 0.5614, 0.5868, 0.5516, 0.5951],
       device='cuda:0') torch.Size([16])
percent tensor([0.6200, 0.6573, 0.6635, 0.6817, 0.6772, 0.6473, 0.6613, 0.6622, 0.6822,
        0.6466, 0.6720, 0.6858, 0.6407, 0.7110, 0.6256, 0.6555],
       device='cuda:0') torch.Size([16])
percent tensor([0.5714, 0.5691, 0.7025, 0.7239, 0.6328, 0.8275, 0.6016, 0.5228, 0.6840,
        0.6328, 0.6918, 0.6522, 0.6072, 0.7176, 0.4588, 0.6352],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9995, 0.9997, 0.9996, 0.9999, 0.9985, 0.9994, 0.9994, 0.9996,
        0.9996, 0.9998, 0.9998, 0.9997, 0.9989, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 113 | Batch_idx: 0 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 113 | Batch_idx: 10 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 113 | Batch_idx: 20 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (95.00%) (2557/2688)
Epoch: 113 | Batch_idx: 30 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (3757/3968)
Epoch: 113 | Batch_idx: 40 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (4959/5248)
Epoch: 113 | Batch_idx: 50 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (6168/6528)
Epoch: 113 | Batch_idx: 60 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (7383/7808)
Epoch: 113 | Batch_idx: 70 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (8589/9088)
Epoch: 113 | Batch_idx: 80 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (94.00%) (9791/10368)
Epoch: 113 | Batch_idx: 90 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (10978/11648)
Epoch: 113 | Batch_idx: 100 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (12182/12928)
Epoch: 113 | Batch_idx: 110 |  Loss: (0.1699) |  Loss2: (0.0000) | Acc: (94.00%) (13383/14208)
Epoch: 113 | Batch_idx: 120 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (94.00%) (14578/15488)
Epoch: 113 | Batch_idx: 130 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (15784/16768)
Epoch: 113 | Batch_idx: 140 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (16980/18048)
Epoch: 113 | Batch_idx: 150 |  Loss: (0.1740) |  Loss2: (0.0000) | Acc: (94.00%) (18175/19328)
Epoch: 113 | Batch_idx: 160 |  Loss: (0.1747) |  Loss2: (0.0000) | Acc: (94.00%) (19380/20608)
Epoch: 113 | Batch_idx: 170 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (94.00%) (20602/21888)
Epoch: 113 | Batch_idx: 180 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (21823/23168)
Epoch: 113 | Batch_idx: 190 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (23033/24448)
Epoch: 113 | Batch_idx: 200 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (94.00%) (24234/25728)
Epoch: 113 | Batch_idx: 210 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (94.00%) (25418/27008)
Epoch: 113 | Batch_idx: 220 |  Loss: (0.1740) |  Loss2: (0.0000) | Acc: (94.00%) (26617/28288)
Epoch: 113 | Batch_idx: 230 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (94.00%) (27806/29568)
Epoch: 113 | Batch_idx: 240 |  Loss: (0.1744) |  Loss2: (0.0000) | Acc: (94.00%) (29017/30848)
Epoch: 113 | Batch_idx: 250 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (94.00%) (30214/32128)
Epoch: 113 | Batch_idx: 260 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (94.00%) (31410/33408)
Epoch: 113 | Batch_idx: 270 |  Loss: (0.1750) |  Loss2: (0.0000) | Acc: (93.00%) (32602/34688)
Epoch: 113 | Batch_idx: 280 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (93.00%) (33786/35968)
Epoch: 113 | Batch_idx: 290 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (93.00%) (34969/37248)
Epoch: 113 | Batch_idx: 300 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (36174/38528)
Epoch: 113 | Batch_idx: 310 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (37349/39808)
Epoch: 113 | Batch_idx: 320 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (38549/41088)
Epoch: 113 | Batch_idx: 330 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (39759/42368)
Epoch: 113 | Batch_idx: 340 |  Loss: (0.1784) |  Loss2: (0.0000) | Acc: (93.00%) (40947/43648)
Epoch: 113 | Batch_idx: 350 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (42145/44928)
Epoch: 113 | Batch_idx: 360 |  Loss: (0.1793) |  Loss2: (0.0000) | Acc: (93.00%) (43332/46208)
Epoch: 113 | Batch_idx: 370 |  Loss: (0.1794) |  Loss2: (0.0000) | Acc: (93.00%) (44526/47488)
Epoch: 113 | Batch_idx: 380 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (45719/48768)
Epoch: 113 | Batch_idx: 390 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (46875/50000)
# TEST : Loss: (0.4196) | Acc: (87.00%) (8701/10000)
percent tensor([0.5593, 0.5828, 0.5670, 0.5593, 0.5725, 0.5492, 0.5874, 0.5735, 0.5729,
        0.5741, 0.5693, 0.5744, 0.5646, 0.5852, 0.5676, 0.5601],
       device='cuda:0') torch.Size([16])
percent tensor([0.5485, 0.5505, 0.5329, 0.5266, 0.5344, 0.5222, 0.5515, 0.5400, 0.5416,
        0.5460, 0.5447, 0.5447, 0.5547, 0.5396, 0.5344, 0.5404],
       device='cuda:0') torch.Size([16])
percent tensor([0.5595, 0.5736, 0.5759, 0.6154, 0.6397, 0.5939, 0.6106, 0.6647, 0.5659,
        0.5214, 0.5168, 0.5759, 0.5263, 0.6079, 0.6325, 0.5695],
       device='cuda:0') torch.Size([16])
percent tensor([0.7005, 0.6528, 0.6759, 0.6766, 0.6908, 0.6966, 0.6910, 0.6868, 0.6557,
        0.6688, 0.6670, 0.6516, 0.6554, 0.6647, 0.6963, 0.6953],
       device='cuda:0') torch.Size([16])
percent tensor([0.5580, 0.5710, 0.5798, 0.5949, 0.5954, 0.5968, 0.5546, 0.5866, 0.5878,
        0.5623, 0.5443, 0.5755, 0.5541, 0.5773, 0.5467, 0.5879],
       device='cuda:0') torch.Size([16])
percent tensor([0.6236, 0.6616, 0.6611, 0.6926, 0.6764, 0.6543, 0.6664, 0.6579, 0.6838,
        0.6451, 0.6748, 0.6862, 0.6381, 0.7185, 0.6259, 0.6551],
       device='cuda:0') torch.Size([16])
percent tensor([0.5724, 0.6105, 0.6962, 0.7319, 0.6233, 0.8325, 0.6234, 0.5375, 0.6818,
        0.6223, 0.6936, 0.5965, 0.5897, 0.7170, 0.4749, 0.6343],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9996, 0.9998, 0.9996, 0.9998, 0.9991, 0.9996, 0.9995, 0.9998,
        0.9996, 0.9999, 0.9999, 0.9997, 0.9990, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 114 | Batch_idx: 0 |  Loss: (0.1845) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 114 | Batch_idx: 10 |  Loss: (0.1632) |  Loss2: (0.0000) | Acc: (94.00%) (1337/1408)
Epoch: 114 | Batch_idx: 20 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (2547/2688)
Epoch: 114 | Batch_idx: 30 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (3742/3968)
Epoch: 114 | Batch_idx: 40 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (4949/5248)
Epoch: 114 | Batch_idx: 50 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (94.00%) (6169/6528)
Epoch: 114 | Batch_idx: 60 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (7374/7808)
Epoch: 114 | Batch_idx: 70 |  Loss: (0.1633) |  Loss2: (0.0000) | Acc: (94.00%) (8588/9088)
Epoch: 114 | Batch_idx: 80 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (94.00%) (9795/10368)
Epoch: 114 | Batch_idx: 90 |  Loss: (0.1640) |  Loss2: (0.0000) | Acc: (94.00%) (11005/11648)
Epoch: 114 | Batch_idx: 100 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (12208/12928)
Epoch: 114 | Batch_idx: 110 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (13400/14208)
Epoch: 114 | Batch_idx: 120 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (14590/15488)
Epoch: 114 | Batch_idx: 130 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (94.00%) (15783/16768)
Epoch: 114 | Batch_idx: 140 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (16995/18048)
Epoch: 114 | Batch_idx: 150 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (18202/19328)
Epoch: 114 | Batch_idx: 160 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (19408/20608)
Epoch: 114 | Batch_idx: 170 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (94.00%) (20601/21888)
Epoch: 114 | Batch_idx: 180 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (94.00%) (21796/23168)
Epoch: 114 | Batch_idx: 190 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (94.00%) (22985/24448)
Epoch: 114 | Batch_idx: 200 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (93.00%) (24182/25728)
Epoch: 114 | Batch_idx: 210 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (94.00%) (25391/27008)
Epoch: 114 | Batch_idx: 220 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (94.00%) (26597/28288)
Epoch: 114 | Batch_idx: 230 |  Loss: (0.1747) |  Loss2: (0.0000) | Acc: (94.00%) (27801/29568)
Epoch: 114 | Batch_idx: 240 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (94.00%) (29010/30848)
Epoch: 114 | Batch_idx: 250 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (94.00%) (30208/32128)
Epoch: 114 | Batch_idx: 260 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (94.00%) (31404/33408)
Epoch: 114 | Batch_idx: 270 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (94.00%) (32614/34688)
Epoch: 114 | Batch_idx: 280 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (94.00%) (33810/35968)
Epoch: 114 | Batch_idx: 290 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (94.00%) (35019/37248)
Epoch: 114 | Batch_idx: 300 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (36195/38528)
Epoch: 114 | Batch_idx: 310 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (37388/39808)
Epoch: 114 | Batch_idx: 320 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (38580/41088)
Epoch: 114 | Batch_idx: 330 |  Loss: (0.1802) |  Loss2: (0.0000) | Acc: (93.00%) (39764/42368)
Epoch: 114 | Batch_idx: 340 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (93.00%) (40960/43648)
Epoch: 114 | Batch_idx: 350 |  Loss: (0.1798) |  Loss2: (0.0000) | Acc: (93.00%) (42167/44928)
Epoch: 114 | Batch_idx: 360 |  Loss: (0.1800) |  Loss2: (0.0000) | Acc: (93.00%) (43366/46208)
Epoch: 114 | Batch_idx: 370 |  Loss: (0.1799) |  Loss2: (0.0000) | Acc: (93.00%) (44570/47488)
Epoch: 114 | Batch_idx: 380 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (45771/48768)
Epoch: 114 | Batch_idx: 390 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (93.00%) (46922/50000)
# TEST : Loss: (0.4057) | Acc: (87.00%) (8752/10000)
percent tensor([0.5588, 0.5837, 0.5663, 0.5592, 0.5723, 0.5487, 0.5877, 0.5737, 0.5729,
        0.5741, 0.5692, 0.5735, 0.5644, 0.5862, 0.5677, 0.5600],
       device='cuda:0') torch.Size([16])
percent tensor([0.5484, 0.5492, 0.5329, 0.5265, 0.5340, 0.5226, 0.5500, 0.5393, 0.5397,
        0.5450, 0.5435, 0.5439, 0.5543, 0.5371, 0.5343, 0.5405],
       device='cuda:0') torch.Size([16])
percent tensor([0.5719, 0.5895, 0.5734, 0.6268, 0.6405, 0.6086, 0.6230, 0.6685, 0.5676,
        0.5317, 0.5252, 0.5766, 0.5311, 0.6275, 0.6473, 0.5839],
       device='cuda:0') torch.Size([16])
percent tensor([0.7015, 0.6559, 0.6756, 0.6815, 0.6912, 0.7013, 0.6908, 0.6897, 0.6567,
        0.6684, 0.6695, 0.6499, 0.6543, 0.6654, 0.7020, 0.7020],
       device='cuda:0') torch.Size([16])
percent tensor([0.5676, 0.5799, 0.5754, 0.5857, 0.5937, 0.5959, 0.5686, 0.5835, 0.5936,
        0.5713, 0.5563, 0.5796, 0.5664, 0.5911, 0.5494, 0.5919],
       device='cuda:0') torch.Size([16])
percent tensor([0.6210, 0.6606, 0.6520, 0.6815, 0.6699, 0.6465, 0.6654, 0.6567, 0.6818,
        0.6450, 0.6762, 0.6799, 0.6406, 0.7183, 0.6288, 0.6503],
       device='cuda:0') torch.Size([16])
percent tensor([0.5691, 0.6325, 0.6605, 0.7237, 0.6100, 0.8099, 0.6393, 0.5424, 0.6882,
        0.6346, 0.7162, 0.5727, 0.6168, 0.7217, 0.4894, 0.6275],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9995, 0.9997, 0.9995, 0.9999, 0.9991, 0.9996, 0.9995, 0.9997,
        0.9998, 0.9998, 0.9999, 0.9995, 0.9989, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 115 | Batch_idx: 0 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 115 | Batch_idx: 10 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (1328/1408)
Epoch: 115 | Batch_idx: 20 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (2518/2688)
Epoch: 115 | Batch_idx: 30 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (3712/3968)
Epoch: 115 | Batch_idx: 40 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (4906/5248)
Epoch: 115 | Batch_idx: 50 |  Loss: (0.1975) |  Loss2: (0.0000) | Acc: (93.00%) (6086/6528)
Epoch: 115 | Batch_idx: 60 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (92.00%) (7261/7808)
Epoch: 115 | Batch_idx: 70 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (8459/9088)
Epoch: 115 | Batch_idx: 80 |  Loss: (0.2007) |  Loss2: (0.0000) | Acc: (93.00%) (9647/10368)
Epoch: 115 | Batch_idx: 90 |  Loss: (0.2031) |  Loss2: (0.0000) | Acc: (92.00%) (10824/11648)
Epoch: 115 | Batch_idx: 100 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (92.00%) (12013/12928)
Epoch: 115 | Batch_idx: 110 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (93.00%) (13214/14208)
Epoch: 115 | Batch_idx: 120 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (92.00%) (14399/15488)
Epoch: 115 | Batch_idx: 130 |  Loss: (0.2031) |  Loss2: (0.0000) | Acc: (92.00%) (15575/16768)
Epoch: 115 | Batch_idx: 140 |  Loss: (0.2051) |  Loss2: (0.0000) | Acc: (92.00%) (16743/18048)
Epoch: 115 | Batch_idx: 150 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (92.00%) (17930/19328)
Epoch: 115 | Batch_idx: 160 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (92.00%) (19108/20608)
Epoch: 115 | Batch_idx: 170 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (92.00%) (20277/21888)
Epoch: 115 | Batch_idx: 180 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (21463/23168)
Epoch: 115 | Batch_idx: 190 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (22644/24448)
Epoch: 115 | Batch_idx: 200 |  Loss: (0.2084) |  Loss2: (0.0000) | Acc: (92.00%) (23845/25728)
Epoch: 115 | Batch_idx: 210 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (25021/27008)
Epoch: 115 | Batch_idx: 220 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (26214/28288)
Epoch: 115 | Batch_idx: 230 |  Loss: (0.2074) |  Loss2: (0.0000) | Acc: (92.00%) (27417/29568)
Epoch: 115 | Batch_idx: 240 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (92.00%) (28600/30848)
Epoch: 115 | Batch_idx: 250 |  Loss: (0.2066) |  Loss2: (0.0000) | Acc: (92.00%) (29797/32128)
Epoch: 115 | Batch_idx: 260 |  Loss: (0.2071) |  Loss2: (0.0000) | Acc: (92.00%) (30972/33408)
Epoch: 115 | Batch_idx: 270 |  Loss: (0.2069) |  Loss2: (0.0000) | Acc: (92.00%) (32153/34688)
Epoch: 115 | Batch_idx: 280 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (92.00%) (33354/35968)
Epoch: 115 | Batch_idx: 290 |  Loss: (0.2061) |  Loss2: (0.0000) | Acc: (92.00%) (34544/37248)
Epoch: 115 | Batch_idx: 300 |  Loss: (0.2055) |  Loss2: (0.0000) | Acc: (92.00%) (35741/38528)
Epoch: 115 | Batch_idx: 310 |  Loss: (0.2052) |  Loss2: (0.0000) | Acc: (92.00%) (36930/39808)
Epoch: 115 | Batch_idx: 320 |  Loss: (0.2046) |  Loss2: (0.0000) | Acc: (92.00%) (38132/41088)
Epoch: 115 | Batch_idx: 330 |  Loss: (0.2043) |  Loss2: (0.0000) | Acc: (92.00%) (39328/42368)
Epoch: 115 | Batch_idx: 340 |  Loss: (0.2038) |  Loss2: (0.0000) | Acc: (92.00%) (40527/43648)
Epoch: 115 | Batch_idx: 350 |  Loss: (0.2041) |  Loss2: (0.0000) | Acc: (92.00%) (41714/44928)
Epoch: 115 | Batch_idx: 360 |  Loss: (0.2045) |  Loss2: (0.0000) | Acc: (92.00%) (42903/46208)
Epoch: 115 | Batch_idx: 370 |  Loss: (0.2039) |  Loss2: (0.0000) | Acc: (92.00%) (44097/47488)
Epoch: 115 | Batch_idx: 380 |  Loss: (0.2034) |  Loss2: (0.0000) | Acc: (92.00%) (45295/48768)
Epoch: 115 | Batch_idx: 390 |  Loss: (0.2035) |  Loss2: (0.0000) | Acc: (92.00%) (46437/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_115.pth.tar'
# TEST : Loss: (0.4004) | Acc: (87.00%) (8737/10000)
percent tensor([0.5645, 0.5894, 0.5736, 0.5648, 0.5798, 0.5543, 0.5944, 0.5799, 0.5787,
        0.5803, 0.5747, 0.5812, 0.5701, 0.5917, 0.5735, 0.5655],
       device='cuda:0') torch.Size([16])
percent tensor([0.5604, 0.5619, 0.5492, 0.5419, 0.5500, 0.5340, 0.5648, 0.5535, 0.5530,
        0.5594, 0.5570, 0.5603, 0.5676, 0.5499, 0.5471, 0.5532],
       device='cuda:0') torch.Size([16])
percent tensor([0.5556, 0.5843, 0.5349, 0.5890, 0.6116, 0.5839, 0.6090, 0.6468, 0.5385,
        0.5164, 0.5095, 0.5421, 0.5291, 0.5981, 0.6340, 0.5684],
       device='cuda:0') torch.Size([16])
percent tensor([0.7320, 0.6884, 0.7031, 0.7164, 0.7197, 0.7268, 0.7232, 0.7214, 0.6916,
        0.7020, 0.7066, 0.6821, 0.6870, 0.7007, 0.7350, 0.7321],
       device='cuda:0') torch.Size([16])
percent tensor([0.5436, 0.5576, 0.5614, 0.5757, 0.5797, 0.5731, 0.5472, 0.5650, 0.5818,
        0.5526, 0.5453, 0.5748, 0.5491, 0.5817, 0.5280, 0.5687],
       device='cuda:0') torch.Size([16])
percent tensor([0.6147, 0.6579, 0.6503, 0.6840, 0.6716, 0.6461, 0.6615, 0.6486, 0.6776,
        0.6484, 0.6756, 0.6779, 0.6364, 0.7187, 0.6168, 0.6478],
       device='cuda:0') torch.Size([16])
percent tensor([0.5553, 0.6393, 0.6626, 0.7141, 0.5895, 0.8145, 0.6265, 0.5305, 0.6794,
        0.6319, 0.7089, 0.5859, 0.6113, 0.7161, 0.4643, 0.6125],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9996, 0.9997, 0.9997, 0.9999, 0.9991, 0.9996, 0.9995, 0.9996,
        0.9998, 0.9999, 0.9998, 0.9996, 0.9990, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 116 | Batch_idx: 0 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 116 | Batch_idx: 10 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (93.00%) (1317/1408)
Epoch: 116 | Batch_idx: 20 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (93.00%) (2520/2688)
Epoch: 116 | Batch_idx: 30 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (3721/3968)
Epoch: 116 | Batch_idx: 40 |  Loss: (0.1744) |  Loss2: (0.0000) | Acc: (93.00%) (4931/5248)
Epoch: 116 | Batch_idx: 50 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (94.00%) (6137/6528)
Epoch: 116 | Batch_idx: 60 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (93.00%) (7325/7808)
Epoch: 116 | Batch_idx: 70 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (93.00%) (8529/9088)
Epoch: 116 | Batch_idx: 80 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (9717/10368)
Epoch: 116 | Batch_idx: 90 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (93.00%) (10916/11648)
Epoch: 116 | Batch_idx: 100 |  Loss: (0.1784) |  Loss2: (0.0000) | Acc: (93.00%) (12112/12928)
Epoch: 116 | Batch_idx: 110 |  Loss: (0.1806) |  Loss2: (0.0000) | Acc: (93.00%) (13303/14208)
Epoch: 116 | Batch_idx: 120 |  Loss: (0.1816) |  Loss2: (0.0000) | Acc: (93.00%) (14490/15488)
Epoch: 116 | Batch_idx: 130 |  Loss: (0.1806) |  Loss2: (0.0000) | Acc: (93.00%) (15704/16768)
Epoch: 116 | Batch_idx: 140 |  Loss: (0.1819) |  Loss2: (0.0000) | Acc: (93.00%) (16891/18048)
Epoch: 116 | Batch_idx: 150 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (18090/19328)
Epoch: 116 | Batch_idx: 160 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (19281/20608)
Epoch: 116 | Batch_idx: 170 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (20495/21888)
Epoch: 116 | Batch_idx: 180 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (21683/23168)
Epoch: 116 | Batch_idx: 190 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (22877/24448)
Epoch: 116 | Batch_idx: 200 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (24071/25728)
Epoch: 116 | Batch_idx: 210 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (25276/27008)
Epoch: 116 | Batch_idx: 220 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (93.00%) (26481/28288)
Epoch: 116 | Batch_idx: 230 |  Loss: (0.1830) |  Loss2: (0.0000) | Acc: (93.00%) (27678/29568)
Epoch: 116 | Batch_idx: 240 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (28880/30848)
Epoch: 116 | Batch_idx: 250 |  Loss: (0.1823) |  Loss2: (0.0000) | Acc: (93.00%) (30089/32128)
Epoch: 116 | Batch_idx: 260 |  Loss: (0.1818) |  Loss2: (0.0000) | Acc: (93.00%) (31289/33408)
Epoch: 116 | Batch_idx: 270 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (32487/34688)
Epoch: 116 | Batch_idx: 280 |  Loss: (0.1819) |  Loss2: (0.0000) | Acc: (93.00%) (33688/35968)
Epoch: 116 | Batch_idx: 290 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (34876/37248)
Epoch: 116 | Batch_idx: 300 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (36085/38528)
Epoch: 116 | Batch_idx: 310 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (37300/39808)
Epoch: 116 | Batch_idx: 320 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (38511/41088)
Epoch: 116 | Batch_idx: 330 |  Loss: (0.1806) |  Loss2: (0.0000) | Acc: (93.00%) (39710/42368)
Epoch: 116 | Batch_idx: 340 |  Loss: (0.1802) |  Loss2: (0.0000) | Acc: (93.00%) (40917/43648)
Epoch: 116 | Batch_idx: 350 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (42122/44928)
Epoch: 116 | Batch_idx: 360 |  Loss: (0.1799) |  Loss2: (0.0000) | Acc: (93.00%) (43323/46208)
Epoch: 116 | Batch_idx: 370 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (44523/47488)
Epoch: 116 | Batch_idx: 380 |  Loss: (0.1794) |  Loss2: (0.0000) | Acc: (93.00%) (45728/48768)
Epoch: 116 | Batch_idx: 390 |  Loss: (0.1798) |  Loss2: (0.0000) | Acc: (93.00%) (46881/50000)
# TEST : Loss: (0.3885) | Acc: (88.00%) (8802/10000)
percent tensor([0.5675, 0.5919, 0.5773, 0.5681, 0.5834, 0.5572, 0.5974, 0.5832, 0.5813,
        0.5832, 0.5771, 0.5849, 0.5728, 0.5938, 0.5764, 0.5684],
       device='cuda:0') torch.Size([16])
percent tensor([0.5608, 0.5624, 0.5512, 0.5443, 0.5516, 0.5357, 0.5656, 0.5547, 0.5547,
        0.5604, 0.5582, 0.5619, 0.5683, 0.5508, 0.5483, 0.5546],
       device='cuda:0') torch.Size([16])
percent tensor([0.5597, 0.5865, 0.5384, 0.5926, 0.6141, 0.5865, 0.6108, 0.6504, 0.5408,
        0.5191, 0.5104, 0.5434, 0.5326, 0.6005, 0.6357, 0.5715],
       device='cuda:0') torch.Size([16])
percent tensor([0.7364, 0.6940, 0.7094, 0.7212, 0.7243, 0.7301, 0.7286, 0.7254, 0.6986,
        0.7084, 0.7137, 0.6900, 0.6935, 0.7081, 0.7397, 0.7359],
       device='cuda:0') torch.Size([16])
percent tensor([0.5391, 0.5566, 0.5603, 0.5832, 0.5778, 0.5704, 0.5461, 0.5631, 0.5850,
        0.5515, 0.5484, 0.5826, 0.5496, 0.5847, 0.5273, 0.5661],
       device='cuda:0') torch.Size([16])
percent tensor([0.6139, 0.6579, 0.6527, 0.6896, 0.6741, 0.6472, 0.6622, 0.6472, 0.6813,
        0.6522, 0.6811, 0.6804, 0.6369, 0.7244, 0.6151, 0.6474],
       device='cuda:0') torch.Size([16])
percent tensor([0.5642, 0.6464, 0.6836, 0.7286, 0.6028, 0.8209, 0.6371, 0.5420, 0.6902,
        0.6407, 0.7251, 0.6034, 0.6214, 0.7242, 0.4758, 0.6145],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9996, 0.9997, 0.9997, 0.9999, 0.9992, 0.9996, 0.9995, 0.9996,
        0.9998, 0.9999, 0.9999, 0.9997, 0.9990, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 117 | Batch_idx: 0 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 117 | Batch_idx: 10 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (1313/1408)
Epoch: 117 | Batch_idx: 20 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (93.00%) (2521/2688)
Epoch: 117 | Batch_idx: 30 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (93.00%) (3726/3968)
Epoch: 117 | Batch_idx: 40 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (4930/5248)
Epoch: 117 | Batch_idx: 50 |  Loss: (0.1690) |  Loss2: (0.0000) | Acc: (94.00%) (6146/6528)
Epoch: 117 | Batch_idx: 60 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (93.00%) (7334/7808)
Epoch: 117 | Batch_idx: 70 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (94.00%) (8550/9088)
Epoch: 117 | Batch_idx: 80 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (9752/10368)
Epoch: 117 | Batch_idx: 90 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (10960/11648)
Epoch: 117 | Batch_idx: 100 |  Loss: (0.1733) |  Loss2: (0.0000) | Acc: (94.00%) (12159/12928)
Epoch: 117 | Batch_idx: 110 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (13357/14208)
Epoch: 117 | Batch_idx: 120 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (93.00%) (14552/15488)
Epoch: 117 | Batch_idx: 130 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (94.00%) (15763/16768)
Epoch: 117 | Batch_idx: 140 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (94.00%) (16973/18048)
Epoch: 117 | Batch_idx: 150 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (94.00%) (18174/19328)
Epoch: 117 | Batch_idx: 160 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (94.00%) (19383/20608)
Epoch: 117 | Batch_idx: 170 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (94.00%) (20599/21888)
Epoch: 117 | Batch_idx: 180 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (21816/23168)
Epoch: 117 | Batch_idx: 190 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (23028/24448)
Epoch: 117 | Batch_idx: 200 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (24221/25728)
Epoch: 117 | Batch_idx: 210 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (25436/27008)
Epoch: 117 | Batch_idx: 220 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (94.00%) (26652/28288)
Epoch: 117 | Batch_idx: 230 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (94.00%) (27838/29568)
Epoch: 117 | Batch_idx: 240 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (94.00%) (29021/30848)
Epoch: 117 | Batch_idx: 250 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (94.00%) (30236/32128)
Epoch: 117 | Batch_idx: 260 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (94.00%) (31445/33408)
Epoch: 117 | Batch_idx: 270 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (94.00%) (32645/34688)
Epoch: 117 | Batch_idx: 280 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (94.00%) (33849/35968)
Epoch: 117 | Batch_idx: 290 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (94.00%) (35055/37248)
Epoch: 117 | Batch_idx: 300 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (36258/38528)
Epoch: 117 | Batch_idx: 310 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (94.00%) (37463/39808)
Epoch: 117 | Batch_idx: 320 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (38680/41088)
Epoch: 117 | Batch_idx: 330 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (39881/42368)
Epoch: 117 | Batch_idx: 340 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (94.00%) (41073/43648)
Epoch: 117 | Batch_idx: 350 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (94.00%) (42269/44928)
Epoch: 117 | Batch_idx: 360 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (43476/46208)
Epoch: 117 | Batch_idx: 370 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (94.00%) (44673/47488)
Epoch: 117 | Batch_idx: 380 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (45861/48768)
Epoch: 117 | Batch_idx: 390 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (94.00%) (47029/50000)
# TEST : Loss: (0.3794) | Acc: (88.00%) (8839/10000)
percent tensor([0.5658, 0.5894, 0.5761, 0.5665, 0.5819, 0.5558, 0.5952, 0.5813, 0.5792,
        0.5812, 0.5750, 0.5835, 0.5709, 0.5909, 0.5745, 0.5665],
       device='cuda:0') torch.Size([16])
percent tensor([0.5594, 0.5611, 0.5509, 0.5436, 0.5508, 0.5343, 0.5645, 0.5537, 0.5543,
        0.5597, 0.5575, 0.5614, 0.5673, 0.5504, 0.5468, 0.5533],
       device='cuda:0') torch.Size([16])
percent tensor([0.5577, 0.5802, 0.5374, 0.5919, 0.6129, 0.5861, 0.6057, 0.6494, 0.5372,
        0.5133, 0.5037, 0.5385, 0.5259, 0.5971, 0.6321, 0.5686],
       device='cuda:0') torch.Size([16])
percent tensor([0.7316, 0.6894, 0.7052, 0.7165, 0.7189, 0.7250, 0.7238, 0.7193, 0.6948,
        0.7046, 0.7097, 0.6858, 0.6894, 0.7046, 0.7346, 0.7309],
       device='cuda:0') torch.Size([16])
percent tensor([0.5399, 0.5599, 0.5639, 0.5904, 0.5791, 0.5700, 0.5495, 0.5659, 0.5901,
        0.5543, 0.5538, 0.5922, 0.5548, 0.5895, 0.5312, 0.5671],
       device='cuda:0') torch.Size([16])
percent tensor([0.6050, 0.6496, 0.6475, 0.6857, 0.6691, 0.6426, 0.6544, 0.6385, 0.6751,
        0.6449, 0.6761, 0.6740, 0.6293, 0.7187, 0.6044, 0.6386],
       device='cuda:0') torch.Size([16])
percent tensor([0.5524, 0.6340, 0.6894, 0.7351, 0.6099, 0.8231, 0.6276, 0.5435, 0.6808,
        0.6287, 0.7190, 0.6020, 0.6097, 0.7137, 0.4706, 0.6061],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9996, 0.9997, 0.9997, 0.9999, 0.9992, 0.9996, 0.9995, 0.9996,
        0.9998, 0.9999, 0.9999, 0.9996, 0.9991, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 118 | Batch_idx: 0 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 118 | Batch_idx: 10 |  Loss: (0.1853) |  Loss2: (0.0000) | Acc: (94.00%) (1324/1408)
Epoch: 118 | Batch_idx: 20 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (2521/2688)
Epoch: 118 | Batch_idx: 30 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (3711/3968)
Epoch: 118 | Batch_idx: 40 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (4921/5248)
Epoch: 118 | Batch_idx: 50 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (93.00%) (6115/6528)
Epoch: 118 | Batch_idx: 60 |  Loss: (0.1740) |  Loss2: (0.0000) | Acc: (93.00%) (7327/7808)
Epoch: 118 | Batch_idx: 70 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (8547/9088)
Epoch: 118 | Batch_idx: 80 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (9752/10368)
Epoch: 118 | Batch_idx: 90 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (94.00%) (10962/11648)
Epoch: 118 | Batch_idx: 100 |  Loss: (0.1714) |  Loss2: (0.0000) | Acc: (94.00%) (12168/12928)
Epoch: 118 | Batch_idx: 110 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (13382/14208)
Epoch: 118 | Batch_idx: 120 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (14597/15488)
Epoch: 118 | Batch_idx: 130 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (94.00%) (15794/16768)
Epoch: 118 | Batch_idx: 140 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (16997/18048)
Epoch: 118 | Batch_idx: 150 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (18183/19328)
Epoch: 118 | Batch_idx: 160 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (94.00%) (19380/20608)
Epoch: 118 | Batch_idx: 170 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (94.00%) (20585/21888)
Epoch: 118 | Batch_idx: 180 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (94.00%) (21783/23168)
Epoch: 118 | Batch_idx: 190 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (93.00%) (22976/24448)
Epoch: 118 | Batch_idx: 200 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (94.00%) (24185/25728)
Epoch: 118 | Batch_idx: 210 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (94.00%) (25404/27008)
Epoch: 118 | Batch_idx: 220 |  Loss: (0.1720) |  Loss2: (0.0000) | Acc: (94.00%) (26607/28288)
Epoch: 118 | Batch_idx: 230 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (94.00%) (27814/29568)
Epoch: 118 | Batch_idx: 240 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (94.00%) (29019/30848)
Epoch: 118 | Batch_idx: 250 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (30224/32128)
Epoch: 118 | Batch_idx: 260 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (31428/33408)
Epoch: 118 | Batch_idx: 270 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (32634/34688)
Epoch: 118 | Batch_idx: 280 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (33841/35968)
Epoch: 118 | Batch_idx: 290 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (35058/37248)
Epoch: 118 | Batch_idx: 300 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (36286/38528)
Epoch: 118 | Batch_idx: 310 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (37494/39808)
Epoch: 118 | Batch_idx: 320 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (38702/41088)
Epoch: 118 | Batch_idx: 330 |  Loss: (0.1685) |  Loss2: (0.0000) | Acc: (94.00%) (39914/42368)
Epoch: 118 | Batch_idx: 340 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (94.00%) (41133/43648)
Epoch: 118 | Batch_idx: 350 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (42341/44928)
Epoch: 118 | Batch_idx: 360 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (43560/46208)
Epoch: 118 | Batch_idx: 370 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (44760/47488)
Epoch: 118 | Batch_idx: 380 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (45962/48768)
Epoch: 118 | Batch_idx: 390 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (47125/50000)
# TEST : Loss: (0.3743) | Acc: (88.00%) (8840/10000)
percent tensor([0.5653, 0.5884, 0.5760, 0.5661, 0.5815, 0.5555, 0.5944, 0.5807, 0.5784,
        0.5804, 0.5741, 0.5831, 0.5702, 0.5898, 0.5739, 0.5658],
       device='cuda:0') torch.Size([16])
percent tensor([0.5632, 0.5657, 0.5562, 0.5493, 0.5564, 0.5386, 0.5697, 0.5589, 0.5596,
        0.5649, 0.5623, 0.5669, 0.5717, 0.5553, 0.5518, 0.5579],
       device='cuda:0') torch.Size([16])
percent tensor([0.5590, 0.5817, 0.5385, 0.5932, 0.6146, 0.5869, 0.6070, 0.6514, 0.5384,
        0.5152, 0.5054, 0.5402, 0.5258, 0.5993, 0.6331, 0.5695],
       device='cuda:0') torch.Size([16])
percent tensor([0.7207, 0.6795, 0.6946, 0.7051, 0.7069, 0.7142, 0.7131, 0.7081, 0.6851,
        0.6945, 0.6994, 0.6759, 0.6794, 0.6955, 0.7234, 0.7192],
       device='cuda:0') torch.Size([16])
percent tensor([0.5382, 0.5594, 0.5665, 0.5979, 0.5804, 0.5702, 0.5496, 0.5655, 0.5927,
        0.5541, 0.5563, 0.5974, 0.5562, 0.5908, 0.5319, 0.5664],
       device='cuda:0') torch.Size([16])
percent tensor([0.6065, 0.6519, 0.6517, 0.6907, 0.6741, 0.6447, 0.6564, 0.6411, 0.6798,
        0.6497, 0.6806, 0.6776, 0.6312, 0.7231, 0.6060, 0.6398],
       device='cuda:0') torch.Size([16])
percent tensor([0.5565, 0.6374, 0.6987, 0.7423, 0.6213, 0.8287, 0.6334, 0.5550, 0.6813,
        0.6316, 0.7210, 0.6105, 0.6096, 0.7114, 0.4761, 0.6075],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9997, 0.9997, 0.9997, 0.9999, 0.9993, 0.9996, 0.9995, 0.9997,
        0.9998, 0.9999, 0.9999, 0.9997, 0.9992, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 119 | Batch_idx: 0 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 119 | Batch_idx: 10 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (95.00%) (1348/1408)
Epoch: 119 | Batch_idx: 20 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (94.00%) (2549/2688)
Epoch: 119 | Batch_idx: 30 |  Loss: (0.1633) |  Loss2: (0.0000) | Acc: (94.00%) (3769/3968)
Epoch: 119 | Batch_idx: 40 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (4979/5248)
Epoch: 119 | Batch_idx: 50 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (6192/6528)
Epoch: 119 | Batch_idx: 60 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (7409/7808)
Epoch: 119 | Batch_idx: 70 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (8628/9088)
Epoch: 119 | Batch_idx: 80 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (9837/10368)
Epoch: 119 | Batch_idx: 90 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (11060/11648)
Epoch: 119 | Batch_idx: 100 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (12261/12928)
Epoch: 119 | Batch_idx: 110 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (13475/14208)
Epoch: 119 | Batch_idx: 120 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (14684/15488)
Epoch: 119 | Batch_idx: 130 |  Loss: (0.1560) |  Loss2: (0.0000) | Acc: (94.00%) (15897/16768)
Epoch: 119 | Batch_idx: 140 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (17098/18048)
Epoch: 119 | Batch_idx: 150 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (18310/19328)
Epoch: 119 | Batch_idx: 160 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (19523/20608)
Epoch: 119 | Batch_idx: 170 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (20716/21888)
Epoch: 119 | Batch_idx: 180 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (21929/23168)
Epoch: 119 | Batch_idx: 190 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (23147/24448)
Epoch: 119 | Batch_idx: 200 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (24341/25728)
Epoch: 119 | Batch_idx: 210 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (25545/27008)
Epoch: 119 | Batch_idx: 220 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (26752/28288)
Epoch: 119 | Batch_idx: 230 |  Loss: (0.1608) |  Loss2: (0.0000) | Acc: (94.00%) (27964/29568)
Epoch: 119 | Batch_idx: 240 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (29181/30848)
Epoch: 119 | Batch_idx: 250 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (30393/32128)
Epoch: 119 | Batch_idx: 260 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (31584/33408)
Epoch: 119 | Batch_idx: 270 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (32797/34688)
Epoch: 119 | Batch_idx: 280 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (34015/35968)
Epoch: 119 | Batch_idx: 290 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (35228/37248)
Epoch: 119 | Batch_idx: 300 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (36439/38528)
Epoch: 119 | Batch_idx: 310 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (37650/39808)
Epoch: 119 | Batch_idx: 320 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (38856/41088)
Epoch: 119 | Batch_idx: 330 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (40075/42368)
Epoch: 119 | Batch_idx: 340 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (41286/43648)
Epoch: 119 | Batch_idx: 350 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (42479/44928)
Epoch: 119 | Batch_idx: 360 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (43680/46208)
Epoch: 119 | Batch_idx: 370 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (44890/47488)
Epoch: 119 | Batch_idx: 380 |  Loss: (0.1624) |  Loss2: (0.0000) | Acc: (94.00%) (46086/48768)
Epoch: 119 | Batch_idx: 390 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (94.00%) (47241/50000)
# TEST : Loss: (0.3709) | Acc: (88.00%) (8840/10000)
percent tensor([0.5635, 0.5858, 0.5742, 0.5644, 0.5795, 0.5541, 0.5919, 0.5786, 0.5763,
        0.5781, 0.5719, 0.5811, 0.5681, 0.5873, 0.5718, 0.5639],
       device='cuda:0') torch.Size([16])
percent tensor([0.5620, 0.5643, 0.5551, 0.5483, 0.5550, 0.5370, 0.5681, 0.5576, 0.5584,
        0.5636, 0.5610, 0.5657, 0.5704, 0.5541, 0.5501, 0.5563],
       device='cuda:0') torch.Size([16])
percent tensor([0.5671, 0.5865, 0.5460, 0.6048, 0.6225, 0.5983, 0.6112, 0.6591, 0.5438,
        0.5201, 0.5097, 0.5448, 0.5289, 0.6067, 0.6410, 0.5783],
       device='cuda:0') torch.Size([16])
percent tensor([0.7270, 0.6862, 0.7004, 0.7100, 0.7122, 0.7191, 0.7195, 0.7132, 0.6916,
        0.7018, 0.7066, 0.6826, 0.6866, 0.7020, 0.7295, 0.7256],
       device='cuda:0') torch.Size([16])
percent tensor([0.5454, 0.5673, 0.5732, 0.6061, 0.5858, 0.5751, 0.5585, 0.5717, 0.6007,
        0.5608, 0.5639, 0.6067, 0.5659, 0.5976, 0.5413, 0.5724],
       device='cuda:0') torch.Size([16])
percent tensor([0.6115, 0.6591, 0.6572, 0.6953, 0.6805, 0.6483, 0.6631, 0.6452, 0.6863,
        0.6576, 0.6871, 0.6839, 0.6377, 0.7305, 0.6109, 0.6449],
       device='cuda:0') torch.Size([16])
percent tensor([0.5556, 0.6415, 0.7026, 0.7453, 0.6321, 0.8247, 0.6388, 0.5664, 0.6814,
        0.6328, 0.7237, 0.6248, 0.6105, 0.7119, 0.4858, 0.6086],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9996, 0.9998, 0.9997, 0.9999, 0.9992, 0.9996, 0.9995, 0.9997,
        0.9998, 0.9999, 0.9999, 0.9996, 0.9991, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 120 | Batch_idx: 0 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 120 | Batch_idx: 10 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (93.00%) (1322/1408)
Epoch: 120 | Batch_idx: 20 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (2535/2688)
Epoch: 120 | Batch_idx: 30 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (3736/3968)
Epoch: 120 | Batch_idx: 40 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (94.00%) (4936/5248)
Epoch: 120 | Batch_idx: 50 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (93.00%) (6134/6528)
Epoch: 120 | Batch_idx: 60 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (93.00%) (7339/7808)
Epoch: 120 | Batch_idx: 70 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (8548/9088)
Epoch: 120 | Batch_idx: 80 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (93.00%) (9733/10368)
Epoch: 120 | Batch_idx: 90 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (94.00%) (10952/11648)
Epoch: 120 | Batch_idx: 100 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (93.00%) (12148/12928)
Epoch: 120 | Batch_idx: 110 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (13351/14208)
Epoch: 120 | Batch_idx: 120 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (93.00%) (14555/15488)
Epoch: 120 | Batch_idx: 130 |  Loss: (0.1740) |  Loss2: (0.0000) | Acc: (94.00%) (15768/16768)
Epoch: 120 | Batch_idx: 140 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (94.00%) (16976/18048)
Epoch: 120 | Batch_idx: 150 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (94.00%) (18183/19328)
Epoch: 120 | Batch_idx: 160 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (94.00%) (19389/20608)
Epoch: 120 | Batch_idx: 170 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (94.00%) (20588/21888)
Epoch: 120 | Batch_idx: 180 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (21795/23168)
Epoch: 120 | Batch_idx: 190 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (94.00%) (22983/24448)
Epoch: 120 | Batch_idx: 200 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (93.00%) (24157/25728)
Epoch: 120 | Batch_idx: 210 |  Loss: (0.1750) |  Loss2: (0.0000) | Acc: (93.00%) (25354/27008)
Epoch: 120 | Batch_idx: 220 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (93.00%) (26571/28288)
Epoch: 120 | Batch_idx: 230 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (93.00%) (27767/29568)
Epoch: 120 | Batch_idx: 240 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (93.00%) (28987/30848)
Epoch: 120 | Batch_idx: 250 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (93.00%) (30186/32128)
Epoch: 120 | Batch_idx: 260 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (93.00%) (31394/33408)
Epoch: 120 | Batch_idx: 270 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (93.00%) (32589/34688)
Epoch: 120 | Batch_idx: 280 |  Loss: (0.1732) |  Loss2: (0.0000) | Acc: (93.00%) (33800/35968)
Epoch: 120 | Batch_idx: 290 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (93.00%) (34995/37248)
Epoch: 120 | Batch_idx: 300 |  Loss: (0.1733) |  Loss2: (0.0000) | Acc: (93.00%) (36205/38528)
Epoch: 120 | Batch_idx: 310 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (93.00%) (37406/39808)
Epoch: 120 | Batch_idx: 320 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (93.00%) (38605/41088)
Epoch: 120 | Batch_idx: 330 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (93.00%) (39813/42368)
Epoch: 120 | Batch_idx: 340 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (93.00%) (41025/43648)
Epoch: 120 | Batch_idx: 350 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (93.00%) (42227/44928)
Epoch: 120 | Batch_idx: 360 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (93.00%) (43431/46208)
Epoch: 120 | Batch_idx: 370 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (93.00%) (44605/47488)
Epoch: 120 | Batch_idx: 380 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (93.00%) (45806/48768)
Epoch: 120 | Batch_idx: 390 |  Loss: (0.1740) |  Loss2: (0.0000) | Acc: (93.00%) (46959/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_120.pth.tar'
# TEST : Loss: (0.4106) | Acc: (86.00%) (8668/10000)
percent tensor([0.5626, 0.5851, 0.5726, 0.5637, 0.5780, 0.5525, 0.5904, 0.5782, 0.5749,
        0.5772, 0.5706, 0.5791, 0.5673, 0.5862, 0.5710, 0.5633],
       device='cuda:0') torch.Size([16])
percent tensor([0.5615, 0.5642, 0.5553, 0.5476, 0.5550, 0.5363, 0.5670, 0.5583, 0.5595,
        0.5628, 0.5607, 0.5653, 0.5698, 0.5528, 0.5503, 0.5556],
       device='cuda:0') torch.Size([16])
percent tensor([0.5727, 0.5816, 0.5601, 0.6080, 0.6327, 0.6146, 0.6111, 0.6572, 0.5547,
        0.5210, 0.5154, 0.5580, 0.5274, 0.5996, 0.6445, 0.5861],
       device='cuda:0') torch.Size([16])
percent tensor([0.7267, 0.6859, 0.6999, 0.7013, 0.7131, 0.7213, 0.7185, 0.7112, 0.6927,
        0.7019, 0.7054, 0.6817, 0.6861, 0.7026, 0.7276, 0.7237],
       device='cuda:0') torch.Size([16])
percent tensor([0.5403, 0.5639, 0.5621, 0.6120, 0.5772, 0.5724, 0.5518, 0.5688, 0.5902,
        0.5555, 0.5555, 0.6027, 0.5614, 0.5917, 0.5399, 0.5735],
       device='cuda:0') torch.Size([16])
percent tensor([0.6035, 0.6491, 0.6503, 0.6865, 0.6780, 0.6457, 0.6491, 0.6471, 0.6817,
        0.6415, 0.6776, 0.6717, 0.6285, 0.7258, 0.6018, 0.6398],
       device='cuda:0') torch.Size([16])
percent tensor([0.5512, 0.6063, 0.7047, 0.7177, 0.6649, 0.8379, 0.6085, 0.5425, 0.6780,
        0.6084, 0.6943, 0.5669, 0.5823, 0.7020, 0.4654, 0.6183],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9996, 0.9998, 0.9998, 0.9999, 0.9989, 0.9996, 0.9991, 0.9999,
        0.9998, 0.9999, 0.9999, 0.9997, 0.9994, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(175.7690, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(813.9413, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(816.2553, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1528.3988, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(487.7741, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2246.0378, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4261.1626, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1391.4222, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6188.1108, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11796.7275, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3919.8633, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16499.0312, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 121 | Batch_idx: 0 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 121 | Batch_idx: 10 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (1329/1408)
Epoch: 121 | Batch_idx: 20 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (2547/2688)
Epoch: 121 | Batch_idx: 30 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (3765/3968)
Epoch: 121 | Batch_idx: 40 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (94.00%) (4970/5248)
Epoch: 121 | Batch_idx: 50 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (6174/6528)
Epoch: 121 | Batch_idx: 60 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (7392/7808)
Epoch: 121 | Batch_idx: 70 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (8603/9088)
Epoch: 121 | Batch_idx: 80 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (9805/10368)
Epoch: 121 | Batch_idx: 90 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (11020/11648)
Epoch: 121 | Batch_idx: 100 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (12237/12928)
Epoch: 121 | Batch_idx: 110 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (13445/14208)
Epoch: 121 | Batch_idx: 120 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (14645/15488)
Epoch: 121 | Batch_idx: 130 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (15855/16768)
Epoch: 121 | Batch_idx: 140 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (17056/18048)
Epoch: 121 | Batch_idx: 150 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (94.00%) (18257/19328)
Epoch: 121 | Batch_idx: 160 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (19441/20608)
Epoch: 121 | Batch_idx: 170 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (20641/21888)
Epoch: 121 | Batch_idx: 180 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (21834/23168)
Epoch: 121 | Batch_idx: 190 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (23015/24448)
Epoch: 121 | Batch_idx: 200 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (24202/25728)
Epoch: 121 | Batch_idx: 210 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (25412/27008)
Epoch: 121 | Batch_idx: 220 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (26610/28288)
Epoch: 121 | Batch_idx: 230 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (27800/29568)
Epoch: 121 | Batch_idx: 240 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (94.00%) (29010/30848)
Epoch: 121 | Batch_idx: 250 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (93.00%) (30195/32128)
Epoch: 121 | Batch_idx: 260 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (93.00%) (31400/33408)
Epoch: 121 | Batch_idx: 270 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (93.00%) (32601/34688)
Epoch: 121 | Batch_idx: 280 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (33812/35968)
Epoch: 121 | Batch_idx: 290 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (93.00%) (34999/37248)
Epoch: 121 | Batch_idx: 300 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (93.00%) (36198/38528)
Epoch: 121 | Batch_idx: 310 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (93.00%) (37401/39808)
Epoch: 121 | Batch_idx: 320 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (93.00%) (38599/41088)
Epoch: 121 | Batch_idx: 330 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (93.00%) (39801/42368)
Epoch: 121 | Batch_idx: 340 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (93.00%) (41017/43648)
Epoch: 121 | Batch_idx: 350 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (42239/44928)
Epoch: 121 | Batch_idx: 360 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (43452/46208)
Epoch: 121 | Batch_idx: 370 |  Loss: (0.1720) |  Loss2: (0.0000) | Acc: (94.00%) (44644/47488)
Epoch: 121 | Batch_idx: 380 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (93.00%) (45841/48768)
Epoch: 121 | Batch_idx: 390 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (93.00%) (46994/50000)
# TEST : Loss: (0.4537) | Acc: (86.00%) (8612/10000)
percent tensor([0.5622, 0.5834, 0.5725, 0.5634, 0.5779, 0.5522, 0.5889, 0.5773, 0.5743,
        0.5760, 0.5696, 0.5786, 0.5669, 0.5838, 0.5699, 0.5627],
       device='cuda:0') torch.Size([16])
percent tensor([0.5614, 0.5645, 0.5539, 0.5488, 0.5544, 0.5352, 0.5679, 0.5595, 0.5599,
        0.5630, 0.5606, 0.5650, 0.5699, 0.5546, 0.5499, 0.5563],
       device='cuda:0') torch.Size([16])
percent tensor([0.5727, 0.5852, 0.5677, 0.6177, 0.6404, 0.6229, 0.6116, 0.6637, 0.5585,
        0.5213, 0.5156, 0.5549, 0.5292, 0.6051, 0.6456, 0.5880],
       device='cuda:0') torch.Size([16])
percent tensor([0.7251, 0.6868, 0.6927, 0.6994, 0.7070, 0.7174, 0.7201, 0.7119, 0.6873,
        0.6984, 0.7073, 0.6826, 0.6876, 0.7045, 0.7315, 0.7208],
       device='cuda:0') torch.Size([16])
percent tensor([0.5444, 0.5682, 0.5725, 0.6142, 0.5849, 0.5788, 0.5574, 0.5691, 0.5970,
        0.5617, 0.5580, 0.6083, 0.5636, 0.6003, 0.5389, 0.5764],
       device='cuda:0') torch.Size([16])
percent tensor([0.6107, 0.6521, 0.6614, 0.6952, 0.6805, 0.6389, 0.6691, 0.6492, 0.6838,
        0.6508, 0.6863, 0.6872, 0.6341, 0.7370, 0.6054, 0.6424],
       device='cuda:0') torch.Size([16])
percent tensor([0.5713, 0.6287, 0.7276, 0.7602, 0.6519, 0.8189, 0.6629, 0.5643, 0.6949,
        0.6384, 0.7237, 0.6274, 0.6057, 0.7563, 0.4721, 0.6046],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9997, 0.9998, 0.9998, 0.9999, 0.9993, 0.9996, 0.9997, 0.9999,
        0.9998, 0.9999, 0.9999, 0.9997, 0.9992, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 122 | Batch_idx: 0 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 122 | Batch_idx: 10 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 122 | Batch_idx: 20 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (2542/2688)
Epoch: 122 | Batch_idx: 30 |  Loss: (0.1527) |  Loss2: (0.0000) | Acc: (94.00%) (3756/3968)
Epoch: 122 | Batch_idx: 40 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (4953/5248)
Epoch: 122 | Batch_idx: 50 |  Loss: (0.1610) |  Loss2: (0.0000) | Acc: (94.00%) (6166/6528)
Epoch: 122 | Batch_idx: 60 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (7373/7808)
Epoch: 122 | Batch_idx: 70 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (8593/9088)
Epoch: 122 | Batch_idx: 80 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (9793/10368)
Epoch: 122 | Batch_idx: 90 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (11010/11648)
Epoch: 122 | Batch_idx: 100 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (12206/12928)
Epoch: 122 | Batch_idx: 110 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (13417/14208)
Epoch: 122 | Batch_idx: 120 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (14631/15488)
Epoch: 122 | Batch_idx: 130 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (15834/16768)
Epoch: 122 | Batch_idx: 140 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (17058/18048)
Epoch: 122 | Batch_idx: 150 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (18271/19328)
Epoch: 122 | Batch_idx: 160 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (19482/20608)
Epoch: 122 | Batch_idx: 170 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (20702/21888)
Epoch: 122 | Batch_idx: 180 |  Loss: (0.1591) |  Loss2: (0.0000) | Acc: (94.00%) (21914/23168)
Epoch: 122 | Batch_idx: 190 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (23114/24448)
Epoch: 122 | Batch_idx: 200 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (24313/25728)
Epoch: 122 | Batch_idx: 210 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (25528/27008)
Epoch: 122 | Batch_idx: 220 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (26722/28288)
Epoch: 122 | Batch_idx: 230 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (27937/29568)
Epoch: 122 | Batch_idx: 240 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (29136/30848)
Epoch: 122 | Batch_idx: 250 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (30338/32128)
Epoch: 122 | Batch_idx: 260 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (31533/33408)
Epoch: 122 | Batch_idx: 270 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (32732/34688)
Epoch: 122 | Batch_idx: 280 |  Loss: (0.1629) |  Loss2: (0.0000) | Acc: (94.00%) (33930/35968)
Epoch: 122 | Batch_idx: 290 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (35127/37248)
Epoch: 122 | Batch_idx: 300 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (36341/38528)
Epoch: 122 | Batch_idx: 310 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (94.00%) (37547/39808)
Epoch: 122 | Batch_idx: 320 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (38749/41088)
Epoch: 122 | Batch_idx: 330 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (39952/42368)
Epoch: 122 | Batch_idx: 340 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (41156/43648)
Epoch: 122 | Batch_idx: 350 |  Loss: (0.1629) |  Loss2: (0.0000) | Acc: (94.00%) (42363/44928)
Epoch: 122 | Batch_idx: 360 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (43574/46208)
Epoch: 122 | Batch_idx: 370 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (44771/47488)
Epoch: 122 | Batch_idx: 380 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (45966/48768)
Epoch: 122 | Batch_idx: 390 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (47127/50000)
# TEST : Loss: (0.4267) | Acc: (87.00%) (8718/10000)
percent tensor([0.5626, 0.5841, 0.5720, 0.5627, 0.5771, 0.5529, 0.5896, 0.5774, 0.5748,
        0.5764, 0.5709, 0.5784, 0.5673, 0.5852, 0.5704, 0.5627],
       device='cuda:0') torch.Size([16])
percent tensor([0.5619, 0.5650, 0.5505, 0.5459, 0.5511, 0.5365, 0.5675, 0.5555, 0.5605,
        0.5615, 0.5618, 0.5620, 0.5700, 0.5574, 0.5501, 0.5560],
       device='cuda:0') torch.Size([16])
percent tensor([0.5743, 0.5885, 0.5726, 0.6140, 0.6412, 0.6154, 0.6182, 0.6713, 0.5647,
        0.5263, 0.5178, 0.5613, 0.5340, 0.6068, 0.6501, 0.5851],
       device='cuda:0') torch.Size([16])
percent tensor([0.7309, 0.6870, 0.7039, 0.7078, 0.7159, 0.7201, 0.7218, 0.7126, 0.6901,
        0.7018, 0.7052, 0.6835, 0.6873, 0.7054, 0.7324, 0.7252],
       device='cuda:0') torch.Size([16])
percent tensor([0.5364, 0.5674, 0.5665, 0.6055, 0.5798, 0.5710, 0.5538, 0.5726, 0.5979,
        0.5587, 0.5598, 0.6038, 0.5625, 0.5911, 0.5379, 0.5703],
       device='cuda:0') torch.Size([16])
percent tensor([0.6106, 0.6490, 0.6612, 0.6812, 0.6858, 0.6428, 0.6595, 0.6513, 0.6868,
        0.6474, 0.6793, 0.6825, 0.6414, 0.7287, 0.6044, 0.6390],
       device='cuda:0') torch.Size([16])
percent tensor([0.5747, 0.6281, 0.7091, 0.7184, 0.6360, 0.8270, 0.6454, 0.5548, 0.6938,
        0.6203, 0.7137, 0.6409, 0.6531, 0.7254, 0.4698, 0.6052],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9994, 0.9999, 0.9998, 0.9998, 0.9992, 0.9995, 0.9997, 0.9997,
        0.9997, 0.9998, 0.9999, 0.9997, 0.9991, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 123 | Batch_idx: 0 |  Loss: (0.2040) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 123 | Batch_idx: 10 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (1322/1408)
Epoch: 123 | Batch_idx: 20 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (2521/2688)
Epoch: 123 | Batch_idx: 30 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (94.00%) (3731/3968)
Epoch: 123 | Batch_idx: 40 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (94.00%) (4936/5248)
Epoch: 123 | Batch_idx: 50 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (94.00%) (6146/6528)
Epoch: 123 | Batch_idx: 60 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (7348/7808)
Epoch: 123 | Batch_idx: 70 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (94.00%) (8562/9088)
Epoch: 123 | Batch_idx: 80 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (9785/10368)
Epoch: 123 | Batch_idx: 90 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (10983/11648)
Epoch: 123 | Batch_idx: 100 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (12175/12928)
Epoch: 123 | Batch_idx: 110 |  Loss: (0.1690) |  Loss2: (0.0000) | Acc: (94.00%) (13371/14208)
Epoch: 123 | Batch_idx: 120 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (94.00%) (14580/15488)
Epoch: 123 | Batch_idx: 130 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (15786/16768)
Epoch: 123 | Batch_idx: 140 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (16993/18048)
Epoch: 123 | Batch_idx: 150 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (18186/19328)
Epoch: 123 | Batch_idx: 160 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (19398/20608)
Epoch: 123 | Batch_idx: 170 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (20597/21888)
Epoch: 123 | Batch_idx: 180 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (21813/23168)
Epoch: 123 | Batch_idx: 190 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (23019/24448)
Epoch: 123 | Batch_idx: 200 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (24226/25728)
Epoch: 123 | Batch_idx: 210 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (25427/27008)
Epoch: 123 | Batch_idx: 220 |  Loss: (0.1672) |  Loss2: (0.0000) | Acc: (94.00%) (26630/28288)
Epoch: 123 | Batch_idx: 230 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (27853/29568)
Epoch: 123 | Batch_idx: 240 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (29054/30848)
Epoch: 123 | Batch_idx: 250 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (30269/32128)
Epoch: 123 | Batch_idx: 260 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (31480/33408)
Epoch: 123 | Batch_idx: 270 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (32702/34688)
Epoch: 123 | Batch_idx: 280 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (33903/35968)
Epoch: 123 | Batch_idx: 290 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (35106/37248)
Epoch: 123 | Batch_idx: 300 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (94.00%) (36311/38528)
Epoch: 123 | Batch_idx: 310 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (37506/39808)
Epoch: 123 | Batch_idx: 320 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (38717/41088)
Epoch: 123 | Batch_idx: 330 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (39916/42368)
Epoch: 123 | Batch_idx: 340 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (41134/43648)
Epoch: 123 | Batch_idx: 350 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (42341/44928)
Epoch: 123 | Batch_idx: 360 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (43540/46208)
Epoch: 123 | Batch_idx: 370 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (44758/47488)
Epoch: 123 | Batch_idx: 380 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (94.00%) (45975/48768)
Epoch: 123 | Batch_idx: 390 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (47120/50000)
# TEST : Loss: (0.4356) | Acc: (86.00%) (8656/10000)
percent tensor([0.5631, 0.5844, 0.5730, 0.5634, 0.5783, 0.5534, 0.5903, 0.5777, 0.5752,
        0.5767, 0.5713, 0.5794, 0.5678, 0.5853, 0.5708, 0.5629],
       device='cuda:0') torch.Size([16])
percent tensor([0.5609, 0.5648, 0.5528, 0.5484, 0.5524, 0.5347, 0.5673, 0.5587, 0.5591,
        0.5631, 0.5607, 0.5640, 0.5693, 0.5552, 0.5499, 0.5555],
       device='cuda:0') torch.Size([16])
percent tensor([0.5669, 0.5828, 0.5658, 0.6058, 0.6302, 0.6030, 0.6138, 0.6645, 0.5551,
        0.5178, 0.5068, 0.5618, 0.5222, 0.6053, 0.6355, 0.5739],
       device='cuda:0') torch.Size([16])
percent tensor([0.7263, 0.6824, 0.6958, 0.7046, 0.7086, 0.7108, 0.7194, 0.7115, 0.6887,
        0.7012, 0.7022, 0.6826, 0.6816, 0.7054, 0.7275, 0.7191],
       device='cuda:0') torch.Size([16])
percent tensor([0.5449, 0.5731, 0.5726, 0.6081, 0.5851, 0.5914, 0.5546, 0.5692, 0.5969,
        0.5611, 0.5636, 0.6063, 0.5662, 0.5880, 0.5441, 0.5762],
       device='cuda:0') torch.Size([16])
percent tensor([0.6047, 0.6488, 0.6612, 0.6825, 0.6739, 0.6501, 0.6523, 0.6486, 0.6785,
        0.6459, 0.6791, 0.6741, 0.6337, 0.7303, 0.6003, 0.6470],
       device='cuda:0') torch.Size([16])
percent tensor([0.5552, 0.5788, 0.7164, 0.7171, 0.6196, 0.8286, 0.5913, 0.5520, 0.6508,
        0.5826, 0.6700, 0.5758, 0.5967, 0.6697, 0.4489, 0.5813],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9996, 0.9999, 0.9998, 0.9999, 0.9988, 0.9995, 0.9996, 0.9999,
        0.9998, 0.9999, 0.9999, 0.9997, 0.9996, 0.9998, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 124 | Batch_idx: 0 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 124 | Batch_idx: 10 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (1335/1408)
Epoch: 124 | Batch_idx: 20 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (2553/2688)
Epoch: 124 | Batch_idx: 30 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (3759/3968)
Epoch: 124 | Batch_idx: 40 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (4976/5248)
Epoch: 124 | Batch_idx: 50 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (6193/6528)
Epoch: 124 | Batch_idx: 60 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (7413/7808)
Epoch: 124 | Batch_idx: 70 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (95.00%) (8636/9088)
Epoch: 124 | Batch_idx: 80 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (9847/10368)
Epoch: 124 | Batch_idx: 90 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (95.00%) (11069/11648)
Epoch: 124 | Batch_idx: 100 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (94.00%) (12281/12928)
Epoch: 124 | Batch_idx: 110 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (95.00%) (13512/14208)
Epoch: 124 | Batch_idx: 120 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (14710/15488)
Epoch: 124 | Batch_idx: 130 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (15910/16768)
Epoch: 124 | Batch_idx: 140 |  Loss: (0.1528) |  Loss2: (0.0000) | Acc: (94.00%) (17112/18048)
Epoch: 124 | Batch_idx: 150 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (18325/19328)
Epoch: 124 | Batch_idx: 160 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (19541/20608)
Epoch: 124 | Batch_idx: 170 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (20746/21888)
Epoch: 124 | Batch_idx: 180 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (21964/23168)
Epoch: 124 | Batch_idx: 190 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (23176/24448)
Epoch: 124 | Batch_idx: 200 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (24393/25728)
Epoch: 124 | Batch_idx: 210 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (25602/27008)
Epoch: 124 | Batch_idx: 220 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (26823/28288)
Epoch: 124 | Batch_idx: 230 |  Loss: (0.1528) |  Loss2: (0.0000) | Acc: (94.00%) (28022/29568)
Epoch: 124 | Batch_idx: 240 |  Loss: (0.1538) |  Loss2: (0.0000) | Acc: (94.00%) (29226/30848)
Epoch: 124 | Batch_idx: 250 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (30438/32128)
Epoch: 124 | Batch_idx: 260 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (31638/33408)
Epoch: 124 | Batch_idx: 270 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (32845/34688)
Epoch: 124 | Batch_idx: 280 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (34044/35968)
Epoch: 124 | Batch_idx: 290 |  Loss: (0.1550) |  Loss2: (0.0000) | Acc: (94.00%) (35258/37248)
Epoch: 124 | Batch_idx: 300 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (36458/38528)
Epoch: 124 | Batch_idx: 310 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (37657/39808)
Epoch: 124 | Batch_idx: 320 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (38859/41088)
Epoch: 124 | Batch_idx: 330 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (40063/42368)
Epoch: 124 | Batch_idx: 340 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (41273/43648)
Epoch: 124 | Batch_idx: 350 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (42484/44928)
Epoch: 124 | Batch_idx: 360 |  Loss: (0.1559) |  Loss2: (0.0000) | Acc: (94.00%) (43705/46208)
Epoch: 124 | Batch_idx: 370 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (44900/47488)
Epoch: 124 | Batch_idx: 380 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (46099/48768)
Epoch: 124 | Batch_idx: 390 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (47263/50000)
# TEST : Loss: (0.4639) | Acc: (86.00%) (8659/10000)
percent tensor([0.5625, 0.5841, 0.5705, 0.5622, 0.5762, 0.5527, 0.5893, 0.5765, 0.5753,
        0.5759, 0.5714, 0.5770, 0.5674, 0.5852, 0.5702, 0.5629],
       device='cuda:0') torch.Size([16])
percent tensor([0.5613, 0.5638, 0.5517, 0.5474, 0.5519, 0.5342, 0.5671, 0.5586, 0.5587,
        0.5628, 0.5603, 0.5622, 0.5692, 0.5562, 0.5496, 0.5563],
       device='cuda:0') torch.Size([16])
percent tensor([0.5755, 0.5848, 0.5603, 0.6099, 0.6287, 0.6287, 0.6129, 0.6549, 0.5675,
        0.5161, 0.5238, 0.5560, 0.5319, 0.6117, 0.6441, 0.5799],
       device='cuda:0') torch.Size([16])
percent tensor([0.7268, 0.6826, 0.7015, 0.7039, 0.7130, 0.7195, 0.7201, 0.7145, 0.6892,
        0.6979, 0.7029, 0.6792, 0.6825, 0.7032, 0.7287, 0.7227],
       device='cuda:0') torch.Size([16])
percent tensor([0.5499, 0.5743, 0.5742, 0.6119, 0.5864, 0.5826, 0.5582, 0.5742, 0.5961,
        0.5648, 0.5632, 0.6100, 0.5671, 0.5939, 0.5441, 0.5795],
       device='cuda:0') torch.Size([16])
percent tensor([0.6160, 0.6613, 0.6686, 0.6918, 0.6882, 0.6417, 0.6624, 0.6518, 0.6883,
        0.6607, 0.6890, 0.6960, 0.6412, 0.7338, 0.6031, 0.6488],
       device='cuda:0') torch.Size([16])
percent tensor([0.6064, 0.6653, 0.7311, 0.7644, 0.6709, 0.8205, 0.6506, 0.5610, 0.6998,
        0.6495, 0.7501, 0.6793, 0.6408, 0.7487, 0.4888, 0.6195],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9997, 0.9999, 0.9998, 0.9999, 0.9995, 0.9995, 0.9997, 0.9996,
        0.9998, 0.9999, 0.9999, 0.9997, 0.9991, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 125 | Batch_idx: 0 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 125 | Batch_idx: 10 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (1334/1408)
Epoch: 125 | Batch_idx: 20 |  Loss: (0.1860) |  Loss2: (0.0000) | Acc: (94.00%) (2530/2688)
Epoch: 125 | Batch_idx: 30 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (3727/3968)
Epoch: 125 | Batch_idx: 40 |  Loss: (0.1929) |  Loss2: (0.0000) | Acc: (93.00%) (4918/5248)
Epoch: 125 | Batch_idx: 50 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (93.00%) (6101/6528)
Epoch: 125 | Batch_idx: 60 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (7280/7808)
Epoch: 125 | Batch_idx: 70 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (8484/9088)
Epoch: 125 | Batch_idx: 80 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (93.00%) (9676/10368)
Epoch: 125 | Batch_idx: 90 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (93.00%) (10869/11648)
Epoch: 125 | Batch_idx: 100 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (12086/12928)
Epoch: 125 | Batch_idx: 110 |  Loss: (0.1951) |  Loss2: (0.0000) | Acc: (93.00%) (13274/14208)
Epoch: 125 | Batch_idx: 120 |  Loss: (0.1952) |  Loss2: (0.0000) | Acc: (93.00%) (14459/15488)
Epoch: 125 | Batch_idx: 130 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (15662/16768)
Epoch: 125 | Batch_idx: 140 |  Loss: (0.1949) |  Loss2: (0.0000) | Acc: (93.00%) (16842/18048)
Epoch: 125 | Batch_idx: 150 |  Loss: (0.1952) |  Loss2: (0.0000) | Acc: (93.00%) (18034/19328)
Epoch: 125 | Batch_idx: 160 |  Loss: (0.1947) |  Loss2: (0.0000) | Acc: (93.00%) (19229/20608)
Epoch: 125 | Batch_idx: 170 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (20432/21888)
Epoch: 125 | Batch_idx: 180 |  Loss: (0.1923) |  Loss2: (0.0000) | Acc: (93.00%) (21641/23168)
Epoch: 125 | Batch_idx: 190 |  Loss: (0.1919) |  Loss2: (0.0000) | Acc: (93.00%) (22835/24448)
Epoch: 125 | Batch_idx: 200 |  Loss: (0.1919) |  Loss2: (0.0000) | Acc: (93.00%) (24029/25728)
Epoch: 125 | Batch_idx: 210 |  Loss: (0.1907) |  Loss2: (0.0000) | Acc: (93.00%) (25236/27008)
Epoch: 125 | Batch_idx: 220 |  Loss: (0.1912) |  Loss2: (0.0000) | Acc: (93.00%) (26436/28288)
Epoch: 125 | Batch_idx: 230 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (27622/29568)
Epoch: 125 | Batch_idx: 240 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (28826/30848)
Epoch: 125 | Batch_idx: 250 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (30018/32128)
Epoch: 125 | Batch_idx: 260 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (31225/33408)
Epoch: 125 | Batch_idx: 270 |  Loss: (0.1901) |  Loss2: (0.0000) | Acc: (93.00%) (32422/34688)
Epoch: 125 | Batch_idx: 280 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (33617/35968)
Epoch: 125 | Batch_idx: 290 |  Loss: (0.1896) |  Loss2: (0.0000) | Acc: (93.00%) (34814/37248)
Epoch: 125 | Batch_idx: 300 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (36001/38528)
Epoch: 125 | Batch_idx: 310 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (37208/39808)
Epoch: 125 | Batch_idx: 320 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (38407/41088)
Epoch: 125 | Batch_idx: 330 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (39600/42368)
Epoch: 125 | Batch_idx: 340 |  Loss: (0.1882) |  Loss2: (0.0000) | Acc: (93.00%) (40798/43648)
Epoch: 125 | Batch_idx: 350 |  Loss: (0.1878) |  Loss2: (0.0000) | Acc: (93.00%) (41995/44928)
Epoch: 125 | Batch_idx: 360 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (43190/46208)
Epoch: 125 | Batch_idx: 370 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (44389/47488)
Epoch: 125 | Batch_idx: 380 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (45583/48768)
Epoch: 125 | Batch_idx: 390 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (46748/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_125.pth.tar'
# TEST : Loss: (0.4084) | Acc: (87.00%) (8748/10000)
percent tensor([0.5582, 0.5773, 0.5664, 0.5583, 0.5715, 0.5489, 0.5831, 0.5717, 0.5697,
        0.5706, 0.5663, 0.5723, 0.5626, 0.5782, 0.5650, 0.5583],
       device='cuda:0') torch.Size([16])
percent tensor([0.5657, 0.5702, 0.5576, 0.5539, 0.5576, 0.5365, 0.5729, 0.5658, 0.5666,
        0.5691, 0.5672, 0.5677, 0.5744, 0.5649, 0.5530, 0.5617],
       device='cuda:0') torch.Size([16])
percent tensor([0.5858, 0.6024, 0.5750, 0.6180, 0.6540, 0.6407, 0.6366, 0.6806, 0.5735,
        0.5229, 0.5274, 0.5685, 0.5391, 0.6098, 0.6684, 0.5914],
       device='cuda:0') torch.Size([16])
percent tensor([0.7209, 0.6770, 0.6961, 0.6997, 0.7066, 0.7115, 0.7152, 0.7079, 0.6848,
        0.6944, 0.7000, 0.6745, 0.6758, 0.7002, 0.7222, 0.7157],
       device='cuda:0') torch.Size([16])
percent tensor([0.5595, 0.5889, 0.5781, 0.6140, 0.5895, 0.5922, 0.5677, 0.5803, 0.6084,
        0.5781, 0.5784, 0.6167, 0.5760, 0.6105, 0.5553, 0.5882],
       device='cuda:0') torch.Size([16])
percent tensor([0.5799, 0.6187, 0.6338, 0.6566, 0.6505, 0.6063, 0.6121, 0.6102, 0.6474,
        0.6173, 0.6519, 0.6542, 0.6035, 0.6938, 0.5591, 0.6104],
       device='cuda:0') torch.Size([16])
percent tensor([0.5963, 0.6461, 0.7328, 0.7720, 0.6410, 0.8261, 0.6083, 0.5152, 0.7112,
        0.6519, 0.7707, 0.6702, 0.6416, 0.7466, 0.4416, 0.5961],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9996, 0.9998, 0.9997, 0.9999, 0.9993, 0.9993, 0.9994, 0.9997,
        0.9997, 0.9999, 0.9999, 0.9998, 0.9993, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 126 | Batch_idx: 0 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 126 | Batch_idx: 10 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (1314/1408)
Epoch: 126 | Batch_idx: 20 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (2515/2688)
Epoch: 126 | Batch_idx: 30 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (3742/3968)
Epoch: 126 | Batch_idx: 40 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (4938/5248)
Epoch: 126 | Batch_idx: 50 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (6141/6528)
Epoch: 126 | Batch_idx: 60 |  Loss: (0.1640) |  Loss2: (0.0000) | Acc: (94.00%) (7347/7808)
Epoch: 126 | Batch_idx: 70 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (8556/9088)
Epoch: 126 | Batch_idx: 80 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (9767/10368)
Epoch: 126 | Batch_idx: 90 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (10973/11648)
Epoch: 126 | Batch_idx: 100 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (94.00%) (12178/12928)
Epoch: 126 | Batch_idx: 110 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (13364/14208)
Epoch: 126 | Batch_idx: 120 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (94.00%) (14573/15488)
Epoch: 126 | Batch_idx: 130 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (15789/16768)
Epoch: 126 | Batch_idx: 140 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (16996/18048)
Epoch: 126 | Batch_idx: 150 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (18206/19328)
Epoch: 126 | Batch_idx: 160 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (19402/20608)
Epoch: 126 | Batch_idx: 170 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (20613/21888)
Epoch: 126 | Batch_idx: 180 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (21826/23168)
Epoch: 126 | Batch_idx: 190 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (23027/24448)
Epoch: 126 | Batch_idx: 200 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (94.00%) (24232/25728)
Epoch: 126 | Batch_idx: 210 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (25437/27008)
Epoch: 126 | Batch_idx: 220 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (26654/28288)
Epoch: 126 | Batch_idx: 230 |  Loss: (0.1690) |  Loss2: (0.0000) | Acc: (94.00%) (27869/29568)
Epoch: 126 | Batch_idx: 240 |  Loss: (0.1690) |  Loss2: (0.0000) | Acc: (94.00%) (29074/30848)
Epoch: 126 | Batch_idx: 250 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (30290/32128)
Epoch: 126 | Batch_idx: 260 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (31494/33408)
Epoch: 126 | Batch_idx: 270 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (32697/34688)
Epoch: 126 | Batch_idx: 280 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (33893/35968)
Epoch: 126 | Batch_idx: 290 |  Loss: (0.1672) |  Loss2: (0.0000) | Acc: (94.00%) (35104/37248)
Epoch: 126 | Batch_idx: 300 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (36307/38528)
Epoch: 126 | Batch_idx: 310 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (37498/39808)
Epoch: 126 | Batch_idx: 320 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (38703/41088)
Epoch: 126 | Batch_idx: 330 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (39911/42368)
Epoch: 126 | Batch_idx: 340 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (41131/43648)
Epoch: 126 | Batch_idx: 350 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (42337/44928)
Epoch: 126 | Batch_idx: 360 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (43543/46208)
Epoch: 126 | Batch_idx: 370 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (44754/47488)
Epoch: 126 | Batch_idx: 380 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (45961/48768)
Epoch: 126 | Batch_idx: 390 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (47117/50000)
# TEST : Loss: (0.3897) | Acc: (88.00%) (8808/10000)
percent tensor([0.5564, 0.5741, 0.5654, 0.5565, 0.5701, 0.5474, 0.5803, 0.5698, 0.5673,
        0.5682, 0.5638, 0.5708, 0.5604, 0.5744, 0.5627, 0.5562],
       device='cuda:0') torch.Size([16])
percent tensor([0.5689, 0.5732, 0.5626, 0.5583, 0.5627, 0.5387, 0.5766, 0.5704, 0.5716,
        0.5734, 0.5717, 0.5725, 0.5775, 0.5692, 0.5554, 0.5649],
       device='cuda:0') torch.Size([16])
percent tensor([0.5879, 0.5989, 0.5809, 0.6268, 0.6613, 0.6491, 0.6372, 0.6878, 0.5713,
        0.5165, 0.5214, 0.5701, 0.5342, 0.6052, 0.6735, 0.5946],
       device='cuda:0') torch.Size([16])
percent tensor([0.7209, 0.6757, 0.6966, 0.7020, 0.7081, 0.7101, 0.7156, 0.7092, 0.6861,
        0.6946, 0.7006, 0.6755, 0.6732, 0.7024, 0.7218, 0.7156],
       device='cuda:0') torch.Size([16])
percent tensor([0.5572, 0.5893, 0.5716, 0.6042, 0.5817, 0.5877, 0.5661, 0.5715, 0.6066,
        0.5782, 0.5803, 0.6108, 0.5763, 0.6102, 0.5513, 0.5838],
       device='cuda:0') torch.Size([16])
percent tensor([0.5946, 0.6338, 0.6478, 0.6698, 0.6651, 0.6177, 0.6284, 0.6241, 0.6640,
        0.6331, 0.6678, 0.6681, 0.6185, 0.7096, 0.5725, 0.6242],
       device='cuda:0') torch.Size([16])
percent tensor([0.6009, 0.6602, 0.7469, 0.7814, 0.6500, 0.8277, 0.6172, 0.5115, 0.7307,
        0.6707, 0.7886, 0.6800, 0.6540, 0.7663, 0.4307, 0.5982],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9996, 0.9998, 0.9997, 0.9999, 0.9993, 0.9994, 0.9993, 0.9997,
        0.9997, 0.9999, 0.9999, 0.9998, 0.9993, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 127 | Batch_idx: 0 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 127 | Batch_idx: 10 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (1330/1408)
Epoch: 127 | Batch_idx: 20 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (2544/2688)
Epoch: 127 | Batch_idx: 30 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (3755/3968)
Epoch: 127 | Batch_idx: 40 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (4977/5248)
Epoch: 127 | Batch_idx: 50 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (6184/6528)
Epoch: 127 | Batch_idx: 60 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (7399/7808)
Epoch: 127 | Batch_idx: 70 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (8599/9088)
Epoch: 127 | Batch_idx: 80 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (9801/10368)
Epoch: 127 | Batch_idx: 90 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (11004/11648)
Epoch: 127 | Batch_idx: 100 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (12216/12928)
Epoch: 127 | Batch_idx: 110 |  Loss: (0.1608) |  Loss2: (0.0000) | Acc: (94.00%) (13431/14208)
Epoch: 127 | Batch_idx: 120 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (14640/15488)
Epoch: 127 | Batch_idx: 130 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (15850/16768)
Epoch: 127 | Batch_idx: 140 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (17054/18048)
Epoch: 127 | Batch_idx: 150 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (18278/19328)
Epoch: 127 | Batch_idx: 160 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (19494/20608)
Epoch: 127 | Batch_idx: 170 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (20698/21888)
Epoch: 127 | Batch_idx: 180 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (21908/23168)
Epoch: 127 | Batch_idx: 190 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (23110/24448)
Epoch: 127 | Batch_idx: 200 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (24326/25728)
Epoch: 127 | Batch_idx: 210 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (25545/27008)
Epoch: 127 | Batch_idx: 220 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (26754/28288)
Epoch: 127 | Batch_idx: 230 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (27959/29568)
Epoch: 127 | Batch_idx: 240 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (29187/30848)
Epoch: 127 | Batch_idx: 250 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (30402/32128)
Epoch: 127 | Batch_idx: 260 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (31629/33408)
Epoch: 127 | Batch_idx: 270 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (32849/34688)
Epoch: 127 | Batch_idx: 280 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (34070/35968)
Epoch: 127 | Batch_idx: 290 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (35278/37248)
Epoch: 127 | Batch_idx: 300 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (36492/38528)
Epoch: 127 | Batch_idx: 310 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (37712/39808)
Epoch: 127 | Batch_idx: 320 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (94.00%) (38905/41088)
Epoch: 127 | Batch_idx: 330 |  Loss: (0.1555) |  Loss2: (0.0000) | Acc: (94.00%) (40107/42368)
Epoch: 127 | Batch_idx: 340 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (41328/43648)
Epoch: 127 | Batch_idx: 350 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (94.00%) (42538/44928)
Epoch: 127 | Batch_idx: 360 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (43744/46208)
Epoch: 127 | Batch_idx: 370 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (44951/47488)
Epoch: 127 | Batch_idx: 380 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (46161/48768)
Epoch: 127 | Batch_idx: 390 |  Loss: (0.1550) |  Loss2: (0.0000) | Acc: (94.00%) (47332/50000)
# TEST : Loss: (0.3819) | Acc: (88.00%) (8834/10000)
percent tensor([0.5602, 0.5776, 0.5705, 0.5607, 0.5752, 0.5510, 0.5845, 0.5744, 0.5711,
        0.5723, 0.5673, 0.5757, 0.5642, 0.5773, 0.5665, 0.5601],
       device='cuda:0') torch.Size([16])
percent tensor([0.5694, 0.5736, 0.5634, 0.5586, 0.5635, 0.5379, 0.5771, 0.5710, 0.5729,
        0.5741, 0.5728, 0.5735, 0.5784, 0.5702, 0.5546, 0.5649],
       device='cuda:0') torch.Size([16])
percent tensor([0.5879, 0.5930, 0.5856, 0.6329, 0.6644, 0.6507, 0.6362, 0.6921, 0.5715,
        0.5115, 0.5164, 0.5721, 0.5301, 0.6050, 0.6724, 0.5939],
       device='cuda:0') torch.Size([16])
percent tensor([0.7216, 0.6748, 0.6970, 0.7024, 0.7087, 0.7108, 0.7165, 0.7092, 0.6874,
        0.6945, 0.7019, 0.6754, 0.6721, 0.7043, 0.7227, 0.7157],
       device='cuda:0') torch.Size([16])
percent tensor([0.5629, 0.5945, 0.5752, 0.6059, 0.5847, 0.5950, 0.5717, 0.5744, 0.6108,
        0.5825, 0.5845, 0.6132, 0.5797, 0.6141, 0.5563, 0.5889],
       device='cuda:0') torch.Size([16])
percent tensor([0.5930, 0.6306, 0.6461, 0.6678, 0.6627, 0.6178, 0.6256, 0.6208, 0.6626,
        0.6294, 0.6649, 0.6638, 0.6159, 0.7075, 0.5680, 0.6202],
       device='cuda:0') torch.Size([16])
percent tensor([0.5780, 0.6378, 0.7426, 0.7789, 0.6505, 0.8181, 0.6028, 0.5042, 0.7163,
        0.6597, 0.7751, 0.6639, 0.6259, 0.7462, 0.4114, 0.5798],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9996, 0.9998, 0.9997, 0.9999, 0.9994, 0.9994, 0.9993, 0.9998,
        0.9997, 0.9999, 0.9999, 0.9997, 0.9993, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 128 | Batch_idx: 0 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 128 | Batch_idx: 10 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 128 | Batch_idx: 20 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (95.00%) (2556/2688)
Epoch: 128 | Batch_idx: 30 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (95.00%) (3770/3968)
Epoch: 128 | Batch_idx: 40 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (95.00%) (4990/5248)
Epoch: 128 | Batch_idx: 50 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (6197/6528)
Epoch: 128 | Batch_idx: 60 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (7411/7808)
Epoch: 128 | Batch_idx: 70 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (8612/9088)
Epoch: 128 | Batch_idx: 80 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (9830/10368)
Epoch: 128 | Batch_idx: 90 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (11053/11648)
Epoch: 128 | Batch_idx: 100 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (12268/12928)
Epoch: 128 | Batch_idx: 110 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (13478/14208)
Epoch: 128 | Batch_idx: 120 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (14700/15488)
Epoch: 128 | Batch_idx: 130 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (15907/16768)
Epoch: 128 | Batch_idx: 140 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (17108/18048)
Epoch: 128 | Batch_idx: 150 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (18318/19328)
Epoch: 128 | Batch_idx: 160 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (19525/20608)
Epoch: 128 | Batch_idx: 170 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (20742/21888)
Epoch: 128 | Batch_idx: 180 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (21967/23168)
Epoch: 128 | Batch_idx: 190 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (23200/24448)
Epoch: 128 | Batch_idx: 200 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (24420/25728)
Epoch: 128 | Batch_idx: 210 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (25634/27008)
Epoch: 128 | Batch_idx: 220 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (26843/28288)
Epoch: 128 | Batch_idx: 230 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (28059/29568)
Epoch: 128 | Batch_idx: 240 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (29285/30848)
Epoch: 128 | Batch_idx: 250 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (30485/32128)
Epoch: 128 | Batch_idx: 260 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (31706/33408)
Epoch: 128 | Batch_idx: 270 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (32922/34688)
Epoch: 128 | Batch_idx: 280 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (34147/35968)
Epoch: 128 | Batch_idx: 290 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (35363/37248)
Epoch: 128 | Batch_idx: 300 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (36586/38528)
Epoch: 128 | Batch_idx: 310 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (37803/39808)
Epoch: 128 | Batch_idx: 320 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (39008/41088)
Epoch: 128 | Batch_idx: 330 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (40233/42368)
Epoch: 128 | Batch_idx: 340 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (41448/43648)
Epoch: 128 | Batch_idx: 350 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (42656/44928)
Epoch: 128 | Batch_idx: 360 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (43880/46208)
Epoch: 128 | Batch_idx: 370 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (45094/47488)
Epoch: 128 | Batch_idx: 380 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (46313/48768)
Epoch: 128 | Batch_idx: 390 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (47479/50000)
# TEST : Loss: (0.3777) | Acc: (88.00%) (8841/10000)
percent tensor([0.5623, 0.5797, 0.5732, 0.5629, 0.5780, 0.5529, 0.5870, 0.5769, 0.5732,
        0.5746, 0.5693, 0.5787, 0.5662, 0.5790, 0.5686, 0.5619],
       device='cuda:0') torch.Size([16])
percent tensor([0.5675, 0.5714, 0.5615, 0.5559, 0.5615, 0.5347, 0.5750, 0.5691, 0.5711,
        0.5722, 0.5710, 0.5717, 0.5768, 0.5678, 0.5517, 0.5624],
       device='cuda:0') torch.Size([16])
percent tensor([0.5874, 0.5934, 0.5837, 0.6335, 0.6637, 0.6520, 0.6365, 0.6915, 0.5702,
        0.5102, 0.5153, 0.5726, 0.5278, 0.6083, 0.6732, 0.5939],
       device='cuda:0') torch.Size([16])
percent tensor([0.7193, 0.6712, 0.6945, 0.7002, 0.7066, 0.7081, 0.7136, 0.7069, 0.6857,
        0.6915, 0.6998, 0.6724, 0.6680, 0.7027, 0.7202, 0.7127],
       device='cuda:0') torch.Size([16])
percent tensor([0.5631, 0.5950, 0.5753, 0.6051, 0.5848, 0.5957, 0.5732, 0.5737, 0.6113,
        0.5828, 0.5855, 0.6130, 0.5792, 0.6149, 0.5576, 0.5881],
       device='cuda:0') torch.Size([16])
percent tensor([0.6008, 0.6385, 0.6547, 0.6753, 0.6719, 0.6262, 0.6343, 0.6285, 0.6717,
        0.6364, 0.6724, 0.6707, 0.6235, 0.7161, 0.5753, 0.6274],
       device='cuda:0') torch.Size([16])
percent tensor([0.5953, 0.6631, 0.7562, 0.7873, 0.6648, 0.8265, 0.6192, 0.5112, 0.7351,
        0.6813, 0.7917, 0.6819, 0.6530, 0.7582, 0.4160, 0.5910],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9996, 0.9999, 0.9997, 0.9999, 0.9993, 0.9994, 0.9994, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9998, 0.9994, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 129 | Batch_idx: 0 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 129 | Batch_idx: 10 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (94.00%) (1337/1408)
Epoch: 129 | Batch_idx: 20 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (2534/2688)
Epoch: 129 | Batch_idx: 30 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (3735/3968)
Epoch: 129 | Batch_idx: 40 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (4957/5248)
Epoch: 129 | Batch_idx: 50 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (6177/6528)
Epoch: 129 | Batch_idx: 60 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (7387/7808)
Epoch: 129 | Batch_idx: 70 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (8604/9088)
Epoch: 129 | Batch_idx: 80 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (9815/10368)
Epoch: 129 | Batch_idx: 90 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (11037/11648)
Epoch: 129 | Batch_idx: 100 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (12252/12928)
Epoch: 129 | Batch_idx: 110 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (13468/14208)
Epoch: 129 | Batch_idx: 120 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (14696/15488)
Epoch: 129 | Batch_idx: 130 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (15919/16768)
Epoch: 129 | Batch_idx: 140 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (17126/18048)
Epoch: 129 | Batch_idx: 150 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (18321/19328)
Epoch: 129 | Batch_idx: 160 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (19554/20608)
Epoch: 129 | Batch_idx: 170 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (20773/21888)
Epoch: 129 | Batch_idx: 180 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (21990/23168)
Epoch: 129 | Batch_idx: 190 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (23211/24448)
Epoch: 129 | Batch_idx: 200 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (24413/25728)
Epoch: 129 | Batch_idx: 210 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (25642/27008)
Epoch: 129 | Batch_idx: 220 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (26866/28288)
Epoch: 129 | Batch_idx: 230 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (28075/29568)
Epoch: 129 | Batch_idx: 240 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (29297/30848)
Epoch: 129 | Batch_idx: 250 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (30518/32128)
Epoch: 129 | Batch_idx: 260 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (31735/33408)
Epoch: 129 | Batch_idx: 270 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (32948/34688)
Epoch: 129 | Batch_idx: 280 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (95.00%) (34177/35968)
Epoch: 129 | Batch_idx: 290 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (95.00%) (35386/37248)
Epoch: 129 | Batch_idx: 300 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (95.00%) (36611/38528)
Epoch: 129 | Batch_idx: 310 |  Loss: (0.1463) |  Loss2: (0.0000) | Acc: (95.00%) (37834/39808)
Epoch: 129 | Batch_idx: 320 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (95.00%) (39047/41088)
Epoch: 129 | Batch_idx: 330 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (95.00%) (40266/42368)
Epoch: 129 | Batch_idx: 340 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (95.00%) (41469/43648)
Epoch: 129 | Batch_idx: 350 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (42676/44928)
Epoch: 129 | Batch_idx: 360 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (95.00%) (43904/46208)
Epoch: 129 | Batch_idx: 370 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (95.00%) (45125/47488)
Epoch: 129 | Batch_idx: 380 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (95.00%) (46353/48768)
Epoch: 129 | Batch_idx: 390 |  Loss: (0.1463) |  Loss2: (0.0000) | Acc: (95.00%) (47521/50000)
# TEST : Loss: (0.3739) | Acc: (88.00%) (8839/10000)
percent tensor([0.5646, 0.5820, 0.5764, 0.5655, 0.5811, 0.5548, 0.5896, 0.5798, 0.5756,
        0.5772, 0.5715, 0.5817, 0.5686, 0.5810, 0.5707, 0.5642],
       device='cuda:0') torch.Size([16])
percent tensor([0.5676, 0.5711, 0.5620, 0.5558, 0.5618, 0.5339, 0.5749, 0.5692, 0.5713,
        0.5723, 0.5711, 0.5721, 0.5772, 0.5673, 0.5511, 0.5620],
       device='cuda:0') torch.Size([16])
percent tensor([0.5793, 0.5848, 0.5795, 0.6300, 0.6586, 0.6441, 0.6282, 0.6868, 0.5639,
        0.5024, 0.5080, 0.5679, 0.5203, 0.6004, 0.6658, 0.5864],
       device='cuda:0') torch.Size([16])
percent tensor([0.7182, 0.6691, 0.6930, 0.6984, 0.7050, 0.7075, 0.7118, 0.7046, 0.6849,
        0.6900, 0.6989, 0.6703, 0.6663, 0.7017, 0.7186, 0.7114],
       device='cuda:0') torch.Size([16])
percent tensor([0.5640, 0.5960, 0.5762, 0.6050, 0.5853, 0.5956, 0.5757, 0.5741, 0.6123,
        0.5834, 0.5865, 0.6127, 0.5788, 0.6164, 0.5591, 0.5874],
       device='cuda:0') torch.Size([16])
percent tensor([0.5938, 0.6307, 0.6480, 0.6694, 0.6650, 0.6218, 0.6264, 0.6193, 0.6648,
        0.6273, 0.6650, 0.6622, 0.6154, 0.7097, 0.5648, 0.6189],
       device='cuda:0') torch.Size([16])
percent tensor([0.5862, 0.6540, 0.7529, 0.7884, 0.6667, 0.8249, 0.6102, 0.5035, 0.7248,
        0.6775, 0.7849, 0.6701, 0.6358, 0.7515, 0.4038, 0.5903],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9996, 0.9999, 0.9997, 0.9999, 0.9994, 0.9994, 0.9994, 0.9998,
        0.9998, 0.9999, 1.0000, 0.9998, 0.9994, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 130 | Batch_idx: 0 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 130 | Batch_idx: 10 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (1342/1408)
Epoch: 130 | Batch_idx: 20 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (2563/2688)
Epoch: 130 | Batch_idx: 30 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (3783/3968)
Epoch: 130 | Batch_idx: 40 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (5003/5248)
Epoch: 130 | Batch_idx: 50 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (95.00%) (6204/6528)
Epoch: 130 | Batch_idx: 60 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (95.00%) (7433/7808)
Epoch: 130 | Batch_idx: 70 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (95.00%) (8651/9088)
Epoch: 130 | Batch_idx: 80 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (95.00%) (9878/10368)
Epoch: 130 | Batch_idx: 90 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (95.00%) (11082/11648)
Epoch: 130 | Batch_idx: 100 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (95.00%) (12292/12928)
Epoch: 130 | Batch_idx: 110 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (95.00%) (13519/14208)
Epoch: 130 | Batch_idx: 120 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (95.00%) (14726/15488)
Epoch: 130 | Batch_idx: 130 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (15925/16768)
Epoch: 130 | Batch_idx: 140 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (17126/18048)
Epoch: 130 | Batch_idx: 150 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (18334/19328)
Epoch: 130 | Batch_idx: 160 |  Loss: (0.1540) |  Loss2: (0.0000) | Acc: (94.00%) (19536/20608)
Epoch: 130 | Batch_idx: 170 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (20745/21888)
Epoch: 130 | Batch_idx: 180 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (21956/23168)
Epoch: 130 | Batch_idx: 190 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (23162/24448)
Epoch: 130 | Batch_idx: 200 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (24368/25728)
Epoch: 130 | Batch_idx: 210 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (25568/27008)
Epoch: 130 | Batch_idx: 220 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (26771/28288)
Epoch: 130 | Batch_idx: 230 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (27982/29568)
Epoch: 130 | Batch_idx: 240 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (29193/30848)
Epoch: 130 | Batch_idx: 250 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (30385/32128)
Epoch: 130 | Batch_idx: 260 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (31581/33408)
Epoch: 130 | Batch_idx: 270 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (32785/34688)
Epoch: 130 | Batch_idx: 280 |  Loss: (0.1608) |  Loss2: (0.0000) | Acc: (94.00%) (33982/35968)
Epoch: 130 | Batch_idx: 290 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (35178/37248)
Epoch: 130 | Batch_idx: 300 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (36380/38528)
Epoch: 130 | Batch_idx: 310 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (37590/39808)
Epoch: 130 | Batch_idx: 320 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (38793/41088)
Epoch: 130 | Batch_idx: 330 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (39996/42368)
Epoch: 130 | Batch_idx: 340 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (41190/43648)
Epoch: 130 | Batch_idx: 350 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (42398/44928)
Epoch: 130 | Batch_idx: 360 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (43611/46208)
Epoch: 130 | Batch_idx: 370 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (44818/47488)
Epoch: 130 | Batch_idx: 380 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (46023/48768)
Epoch: 130 | Batch_idx: 390 |  Loss: (0.1629) |  Loss2: (0.0000) | Acc: (94.00%) (47182/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_130.pth.tar'
# TEST : Loss: (0.4177) | Acc: (87.00%) (8707/10000)
percent tensor([0.5636, 0.5806, 0.5765, 0.5634, 0.5804, 0.5545, 0.5891, 0.5783, 0.5753,
        0.5762, 0.5709, 0.5821, 0.5675, 0.5800, 0.5696, 0.5627],
       device='cuda:0') torch.Size([16])
percent tensor([0.5694, 0.5738, 0.5632, 0.5559, 0.5631, 0.5363, 0.5780, 0.5691, 0.5734,
        0.5737, 0.5735, 0.5756, 0.5799, 0.5698, 0.5524, 0.5633],
       device='cuda:0') torch.Size([16])
percent tensor([0.5769, 0.5778, 0.5756, 0.6324, 0.6476, 0.6283, 0.6218, 0.6932, 0.5639,
        0.5066, 0.5071, 0.5601, 0.5208, 0.6090, 0.6544, 0.5841],
       device='cuda:0') torch.Size([16])
percent tensor([0.7210, 0.6698, 0.6987, 0.6991, 0.7095, 0.7097, 0.7138, 0.7058, 0.6896,
        0.6950, 0.7022, 0.6776, 0.6680, 0.7022, 0.7197, 0.7109],
       device='cuda:0') torch.Size([16])
percent tensor([0.5634, 0.5964, 0.5744, 0.6085, 0.5842, 0.5983, 0.5805, 0.5625, 0.6083,
        0.5811, 0.5841, 0.6086, 0.5730, 0.6205, 0.5648, 0.5874],
       device='cuda:0') torch.Size([16])
percent tensor([0.5954, 0.6347, 0.6385, 0.6673, 0.6569, 0.6195, 0.6388, 0.6208, 0.6665,
        0.6242, 0.6617, 0.6528, 0.6148, 0.7140, 0.5759, 0.6133],
       device='cuda:0') torch.Size([16])
percent tensor([0.6029, 0.6644, 0.7313, 0.7737, 0.6643, 0.8180, 0.6677, 0.5382, 0.7138,
        0.6775, 0.7567, 0.6177, 0.6117, 0.7512, 0.4831, 0.5861],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9996, 0.9998, 0.9997, 0.9999, 0.9995, 0.9995, 0.9995, 0.9998,
        0.9998, 0.9998, 0.9999, 0.9998, 0.9992, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(176.3423, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(815.5020, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(819.2433, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1527.8458, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(486.1366, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2252.9446, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4258.6558, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1386.4120, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6201.5293, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11762.4414, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3904.6990, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16432.8262, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 131 | Batch_idx: 0 |  Loss: (0.1796) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 131 | Batch_idx: 10 |  Loss: (0.1450) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 131 | Batch_idx: 20 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (2551/2688)
Epoch: 131 | Batch_idx: 30 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (95.00%) (3771/3968)
Epoch: 131 | Batch_idx: 40 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (95.00%) (4990/5248)
Epoch: 131 | Batch_idx: 50 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (6200/6528)
Epoch: 131 | Batch_idx: 60 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (7411/7808)
Epoch: 131 | Batch_idx: 70 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (8615/9088)
Epoch: 131 | Batch_idx: 80 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (9827/10368)
Epoch: 131 | Batch_idx: 90 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (11040/11648)
Epoch: 131 | Batch_idx: 100 |  Loss: (0.1528) |  Loss2: (0.0000) | Acc: (94.00%) (12246/12928)
Epoch: 131 | Batch_idx: 110 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (13463/14208)
Epoch: 131 | Batch_idx: 120 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (14688/15488)
Epoch: 131 | Batch_idx: 130 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (15901/16768)
Epoch: 131 | Batch_idx: 140 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (17112/18048)
Epoch: 131 | Batch_idx: 150 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (18338/19328)
Epoch: 131 | Batch_idx: 160 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (19545/20608)
Epoch: 131 | Batch_idx: 170 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (20756/21888)
Epoch: 131 | Batch_idx: 180 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (21964/23168)
Epoch: 131 | Batch_idx: 190 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (23168/24448)
Epoch: 131 | Batch_idx: 200 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (24379/25728)
Epoch: 131 | Batch_idx: 210 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (25594/27008)
Epoch: 131 | Batch_idx: 220 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (26810/28288)
Epoch: 131 | Batch_idx: 230 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (28029/29568)
Epoch: 131 | Batch_idx: 240 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (29233/30848)
Epoch: 131 | Batch_idx: 250 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (30443/32128)
Epoch: 131 | Batch_idx: 260 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (31649/33408)
Epoch: 131 | Batch_idx: 270 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (32875/34688)
Epoch: 131 | Batch_idx: 280 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (34087/35968)
Epoch: 131 | Batch_idx: 290 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (35296/37248)
Epoch: 131 | Batch_idx: 300 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (36517/38528)
Epoch: 131 | Batch_idx: 310 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (37727/39808)
Epoch: 131 | Batch_idx: 320 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (38932/41088)
Epoch: 131 | Batch_idx: 330 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (40159/42368)
Epoch: 131 | Batch_idx: 340 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (94.00%) (41360/43648)
Epoch: 131 | Batch_idx: 350 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (42568/44928)
Epoch: 131 | Batch_idx: 360 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (43779/46208)
Epoch: 131 | Batch_idx: 370 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (44989/47488)
Epoch: 131 | Batch_idx: 380 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (46210/48768)
Epoch: 131 | Batch_idx: 390 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (47377/50000)
# TEST : Loss: (0.4000) | Acc: (87.00%) (8756/10000)
percent tensor([0.5638, 0.5812, 0.5764, 0.5639, 0.5806, 0.5547, 0.5895, 0.5786, 0.5748,
        0.5764, 0.5704, 0.5825, 0.5672, 0.5816, 0.5699, 0.5630],
       device='cuda:0') torch.Size([16])
percent tensor([0.5698, 0.5714, 0.5642, 0.5558, 0.5650, 0.5382, 0.5763, 0.5693, 0.5728,
        0.5734, 0.5729, 0.5757, 0.5790, 0.5671, 0.5536, 0.5633],
       device='cuda:0') torch.Size([16])
percent tensor([0.5751, 0.5898, 0.5693, 0.6192, 0.6493, 0.6163, 0.6304, 0.6854, 0.5603,
        0.5121, 0.5061, 0.5687, 0.5254, 0.6066, 0.6514, 0.5769],
       device='cuda:0') torch.Size([16])
percent tensor([0.7200, 0.6725, 0.6926, 0.6950, 0.7042, 0.7075, 0.7135, 0.7016, 0.6852,
        0.6920, 0.6993, 0.6717, 0.6649, 0.7043, 0.7157, 0.7098],
       device='cuda:0') torch.Size([16])
percent tensor([0.5588, 0.5917, 0.5827, 0.6077, 0.5863, 0.5994, 0.5737, 0.5659, 0.6122,
        0.5788, 0.5849, 0.6081, 0.5777, 0.6141, 0.5602, 0.5847],
       device='cuda:0') torch.Size([16])
percent tensor([0.5841, 0.6234, 0.6357, 0.6566, 0.6499, 0.6205, 0.6243, 0.6090, 0.6674,
        0.6211, 0.6602, 0.6503, 0.6115, 0.7075, 0.5742, 0.6077],
       device='cuda:0') torch.Size([16])
percent tensor([0.5638, 0.5930, 0.7218, 0.7491, 0.6438, 0.8060, 0.6140, 0.4976, 0.7313,
        0.6409, 0.7397, 0.5962, 0.6059, 0.7139, 0.4172, 0.5675],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9998, 0.9998, 0.9999, 0.9993, 0.9995, 0.9993, 0.9999,
        0.9998, 0.9999, 0.9999, 0.9997, 0.9995, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 132 | Batch_idx: 0 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 132 | Batch_idx: 10 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (1346/1408)
Epoch: 132 | Batch_idx: 20 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (2560/2688)
Epoch: 132 | Batch_idx: 30 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (3777/3968)
Epoch: 132 | Batch_idx: 40 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (4990/5248)
Epoch: 132 | Batch_idx: 50 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (94.00%) (6199/6528)
Epoch: 132 | Batch_idx: 60 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (94.00%) (7413/7808)
Epoch: 132 | Batch_idx: 70 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (95.00%) (8635/9088)
Epoch: 132 | Batch_idx: 80 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (9863/10368)
Epoch: 132 | Batch_idx: 90 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (11076/11648)
Epoch: 132 | Batch_idx: 100 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (95.00%) (12282/12928)
Epoch: 132 | Batch_idx: 110 |  Loss: (0.1451) |  Loss2: (0.0000) | Acc: (94.00%) (13496/14208)
Epoch: 132 | Batch_idx: 120 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (14699/15488)
Epoch: 132 | Batch_idx: 130 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (94.00%) (15903/16768)
Epoch: 132 | Batch_idx: 140 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (94.00%) (17133/18048)
Epoch: 132 | Batch_idx: 150 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (18366/19328)
Epoch: 132 | Batch_idx: 160 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (19588/20608)
Epoch: 132 | Batch_idx: 170 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (94.00%) (20792/21888)
Epoch: 132 | Batch_idx: 180 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (94.00%) (21990/23168)
Epoch: 132 | Batch_idx: 190 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (94.00%) (23207/24448)
Epoch: 132 | Batch_idx: 200 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (94.00%) (24426/25728)
Epoch: 132 | Batch_idx: 210 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (94.00%) (25641/27008)
Epoch: 132 | Batch_idx: 220 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (94.00%) (26851/28288)
Epoch: 132 | Batch_idx: 230 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (94.00%) (28073/29568)
Epoch: 132 | Batch_idx: 240 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (94.00%) (29296/30848)
Epoch: 132 | Batch_idx: 250 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (94.00%) (30518/32128)
Epoch: 132 | Batch_idx: 260 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (31746/33408)
Epoch: 132 | Batch_idx: 270 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (32967/34688)
Epoch: 132 | Batch_idx: 280 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (34170/35968)
Epoch: 132 | Batch_idx: 290 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (94.00%) (35373/37248)
Epoch: 132 | Batch_idx: 300 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (94.00%) (36565/38528)
Epoch: 132 | Batch_idx: 310 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (94.00%) (37764/39808)
Epoch: 132 | Batch_idx: 320 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (94.00%) (38974/41088)
Epoch: 132 | Batch_idx: 330 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (94.00%) (40198/42368)
Epoch: 132 | Batch_idx: 340 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (94.00%) (41407/43648)
Epoch: 132 | Batch_idx: 350 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (42610/44928)
Epoch: 132 | Batch_idx: 360 |  Loss: (0.1463) |  Loss2: (0.0000) | Acc: (94.00%) (43828/46208)
Epoch: 132 | Batch_idx: 370 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (45039/47488)
Epoch: 132 | Batch_idx: 380 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (46235/48768)
Epoch: 132 | Batch_idx: 390 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (47398/50000)
# TEST : Loss: (0.4047) | Acc: (87.00%) (8766/10000)
percent tensor([0.5636, 0.5803, 0.5758, 0.5636, 0.5799, 0.5542, 0.5877, 0.5783, 0.5740,
        0.5756, 0.5699, 0.5809, 0.5671, 0.5781, 0.5695, 0.5624],
       device='cuda:0') torch.Size([16])
percent tensor([0.5687, 0.5695, 0.5645, 0.5557, 0.5650, 0.5359, 0.5743, 0.5674, 0.5708,
        0.5721, 0.5703, 0.5759, 0.5778, 0.5631, 0.5520, 0.5611],
       device='cuda:0') torch.Size([16])
percent tensor([0.5772, 0.5950, 0.5713, 0.6236, 0.6466, 0.6227, 0.6193, 0.6861, 0.5587,
        0.5148, 0.5137, 0.5649, 0.5246, 0.6093, 0.6576, 0.5838],
       device='cuda:0') torch.Size([16])
percent tensor([0.7158, 0.6740, 0.6846, 0.6942, 0.7013, 0.7022, 0.7107, 0.6986, 0.6851,
        0.6923, 0.6984, 0.6713, 0.6637, 0.7057, 0.7140, 0.7097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5671, 0.5914, 0.5986, 0.6104, 0.5951, 0.6091, 0.5799, 0.5755, 0.6145,
        0.5849, 0.5823, 0.6205, 0.5813, 0.6146, 0.5628, 0.5890],
       device='cuda:0') torch.Size([16])
percent tensor([0.5886, 0.6304, 0.6383, 0.6577, 0.6655, 0.6184, 0.6379, 0.6110, 0.6633,
        0.6214, 0.6645, 0.6523, 0.6116, 0.6951, 0.5759, 0.6110],
       device='cuda:0') torch.Size([16])
percent tensor([0.5982, 0.6601, 0.7496, 0.7802, 0.6930, 0.8254, 0.6768, 0.5302, 0.7178,
        0.6895, 0.7557, 0.6304, 0.6323, 0.7174, 0.4358, 0.5839],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9995, 0.9997, 0.9998, 0.9999, 0.9991, 0.9995, 0.9993, 0.9999,
        0.9998, 0.9999, 0.9999, 0.9997, 0.9989, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 133 | Batch_idx: 0 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 133 | Batch_idx: 10 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (1349/1408)
Epoch: 133 | Batch_idx: 20 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (2577/2688)
Epoch: 133 | Batch_idx: 30 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (3779/3968)
Epoch: 133 | Batch_idx: 40 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (94.00%) (4972/5248)
Epoch: 133 | Batch_idx: 50 |  Loss: (0.1372) |  Loss2: (0.0000) | Acc: (95.00%) (6203/6528)
Epoch: 133 | Batch_idx: 60 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (7422/7808)
Epoch: 133 | Batch_idx: 70 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (8645/9088)
Epoch: 133 | Batch_idx: 80 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (9861/10368)
Epoch: 133 | Batch_idx: 90 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (11074/11648)
Epoch: 133 | Batch_idx: 100 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (12295/12928)
Epoch: 133 | Batch_idx: 110 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (13500/14208)
Epoch: 133 | Batch_idx: 120 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (94.00%) (14704/15488)
Epoch: 133 | Batch_idx: 130 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (94.00%) (15925/16768)
Epoch: 133 | Batch_idx: 140 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (17149/18048)
Epoch: 133 | Batch_idx: 150 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (18368/19328)
Epoch: 133 | Batch_idx: 160 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (94.00%) (19570/20608)
Epoch: 133 | Batch_idx: 170 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (94.00%) (20793/21888)
Epoch: 133 | Batch_idx: 180 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (94.00%) (21998/23168)
Epoch: 133 | Batch_idx: 190 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (94.00%) (23205/24448)
Epoch: 133 | Batch_idx: 200 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (94.00%) (24419/25728)
Epoch: 133 | Batch_idx: 210 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (94.00%) (25626/27008)
Epoch: 133 | Batch_idx: 220 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (94.00%) (26833/28288)
Epoch: 133 | Batch_idx: 230 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (94.00%) (28053/29568)
Epoch: 133 | Batch_idx: 240 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (94.00%) (29276/30848)
Epoch: 133 | Batch_idx: 250 |  Loss: (0.1443) |  Loss2: (0.0000) | Acc: (94.00%) (30486/32128)
Epoch: 133 | Batch_idx: 260 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (94.00%) (31692/33408)
Epoch: 133 | Batch_idx: 270 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (94.00%) (32899/34688)
Epoch: 133 | Batch_idx: 280 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (94.00%) (34108/35968)
Epoch: 133 | Batch_idx: 290 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (94.00%) (35338/37248)
Epoch: 133 | Batch_idx: 300 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (36553/38528)
Epoch: 133 | Batch_idx: 310 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (94.00%) (37775/39808)
Epoch: 133 | Batch_idx: 320 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (38994/41088)
Epoch: 133 | Batch_idx: 330 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (40196/42368)
Epoch: 133 | Batch_idx: 340 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (94.00%) (41403/43648)
Epoch: 133 | Batch_idx: 350 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (94.00%) (42610/44928)
Epoch: 133 | Batch_idx: 360 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (43809/46208)
Epoch: 133 | Batch_idx: 370 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (45018/47488)
Epoch: 133 | Batch_idx: 380 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (46236/48768)
Epoch: 133 | Batch_idx: 390 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (47404/50000)
# TEST : Loss: (0.4295) | Acc: (87.00%) (8713/10000)
percent tensor([0.5624, 0.5821, 0.5734, 0.5628, 0.5786, 0.5527, 0.5889, 0.5777, 0.5748,
        0.5757, 0.5703, 0.5798, 0.5668, 0.5827, 0.5695, 0.5623],
       device='cuda:0') torch.Size([16])
percent tensor([0.5685, 0.5702, 0.5636, 0.5549, 0.5631, 0.5364, 0.5750, 0.5674, 0.5709,
        0.5730, 0.5711, 0.5745, 0.5787, 0.5646, 0.5518, 0.5617],
       device='cuda:0') torch.Size([16])
percent tensor([0.5942, 0.6065, 0.5824, 0.6458, 0.6595, 0.6429, 0.6366, 0.6907, 0.5662,
        0.5252, 0.5268, 0.5882, 0.5393, 0.6132, 0.6737, 0.5984],
       device='cuda:0') torch.Size([16])
percent tensor([0.7169, 0.6738, 0.6908, 0.6955, 0.7034, 0.7036, 0.7125, 0.7013, 0.6863,
        0.6913, 0.6989, 0.6723, 0.6645, 0.7052, 0.7196, 0.7101],
       device='cuda:0') torch.Size([16])
percent tensor([0.5604, 0.5870, 0.5804, 0.6040, 0.5828, 0.6003, 0.5763, 0.5688, 0.6049,
        0.5783, 0.5728, 0.6133, 0.5713, 0.6180, 0.5534, 0.5878],
       device='cuda:0') torch.Size([16])
percent tensor([0.5751, 0.6190, 0.6421, 0.6692, 0.6590, 0.6283, 0.6271, 0.6099, 0.6589,
        0.6120, 0.6493, 0.6418, 0.5967, 0.7072, 0.5676, 0.6122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5731, 0.6338, 0.7408, 0.7660, 0.6810, 0.8315, 0.6410, 0.5109, 0.6879,
        0.6352, 0.7034, 0.5897, 0.6113, 0.7101, 0.4415, 0.5903],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9996, 0.9998, 0.9999, 0.9999, 0.9991, 0.9994, 0.9993, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9998, 0.9996, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 134 | Batch_idx: 0 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 134 | Batch_idx: 10 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (96.00%) (1352/1408)
Epoch: 134 | Batch_idx: 20 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (2570/2688)
Epoch: 134 | Batch_idx: 30 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (3786/3968)
Epoch: 134 | Batch_idx: 40 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (5004/5248)
Epoch: 134 | Batch_idx: 50 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (6220/6528)
Epoch: 134 | Batch_idx: 60 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (7440/7808)
Epoch: 134 | Batch_idx: 70 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (8661/9088)
Epoch: 134 | Batch_idx: 80 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (9886/10368)
Epoch: 134 | Batch_idx: 90 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (11098/11648)
Epoch: 134 | Batch_idx: 100 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (12330/12928)
Epoch: 134 | Batch_idx: 110 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (13550/14208)
Epoch: 134 | Batch_idx: 120 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (14773/15488)
Epoch: 134 | Batch_idx: 130 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (15999/16768)
Epoch: 134 | Batch_idx: 140 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (17211/18048)
Epoch: 134 | Batch_idx: 150 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (18438/19328)
Epoch: 134 | Batch_idx: 160 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (19665/20608)
Epoch: 134 | Batch_idx: 170 |  Loss: (0.1357) |  Loss2: (0.0000) | Acc: (95.00%) (20859/21888)
Epoch: 134 | Batch_idx: 180 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (22084/23168)
Epoch: 134 | Batch_idx: 190 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (23307/24448)
Epoch: 134 | Batch_idx: 200 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (24531/25728)
Epoch: 134 | Batch_idx: 210 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (25746/27008)
Epoch: 134 | Batch_idx: 220 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (26960/28288)
Epoch: 134 | Batch_idx: 230 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (28174/29568)
Epoch: 134 | Batch_idx: 240 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (29392/30848)
Epoch: 134 | Batch_idx: 250 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (30608/32128)
Epoch: 134 | Batch_idx: 260 |  Loss: (0.1366) |  Loss2: (0.0000) | Acc: (95.00%) (31828/33408)
Epoch: 134 | Batch_idx: 270 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (33033/34688)
Epoch: 134 | Batch_idx: 280 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (34245/35968)
Epoch: 134 | Batch_idx: 290 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (35459/37248)
Epoch: 134 | Batch_idx: 300 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (36675/38528)
Epoch: 134 | Batch_idx: 310 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (37896/39808)
Epoch: 134 | Batch_idx: 320 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (39107/41088)
Epoch: 134 | Batch_idx: 330 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (40319/42368)
Epoch: 134 | Batch_idx: 340 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (41538/43648)
Epoch: 134 | Batch_idx: 350 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (42735/44928)
Epoch: 134 | Batch_idx: 360 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (43945/46208)
Epoch: 134 | Batch_idx: 370 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (45149/47488)
Epoch: 134 | Batch_idx: 380 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (46363/48768)
Epoch: 134 | Batch_idx: 390 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (47531/50000)
# TEST : Loss: (0.4198) | Acc: (87.00%) (8741/10000)
percent tensor([0.5623, 0.5816, 0.5747, 0.5630, 0.5789, 0.5527, 0.5888, 0.5780, 0.5748,
        0.5759, 0.5701, 0.5806, 0.5666, 0.5815, 0.5696, 0.5621],
       device='cuda:0') torch.Size([16])
percent tensor([0.5707, 0.5709, 0.5648, 0.5555, 0.5657, 0.5380, 0.5755, 0.5659, 0.5717,
        0.5735, 0.5720, 0.5761, 0.5795, 0.5631, 0.5528, 0.5627],
       device='cuda:0') torch.Size([16])
percent tensor([0.5893, 0.5903, 0.5866, 0.6367, 0.6587, 0.6382, 0.6277, 0.6828, 0.5617,
        0.5153, 0.5170, 0.5791, 0.5323, 0.6039, 0.6645, 0.5915],
       device='cuda:0') torch.Size([16])
percent tensor([0.7182, 0.6709, 0.6929, 0.6936, 0.7052, 0.7031, 0.7106, 0.7043, 0.6873,
        0.6900, 0.7005, 0.6744, 0.6650, 0.7032, 0.7173, 0.7062],
       device='cuda:0') torch.Size([16])
percent tensor([0.5552, 0.5864, 0.5777, 0.6079, 0.5822, 0.5968, 0.5726, 0.5629, 0.6031,
        0.5811, 0.5778, 0.6060, 0.5703, 0.6154, 0.5549, 0.5897],
       device='cuda:0') torch.Size([16])
percent tensor([0.5867, 0.6237, 0.6368, 0.6677, 0.6484, 0.6249, 0.6295, 0.6099, 0.6666,
        0.6226, 0.6616, 0.6602, 0.6126, 0.7120, 0.5779, 0.6104],
       device='cuda:0') torch.Size([16])
percent tensor([0.5697, 0.6344, 0.7126, 0.7477, 0.6408, 0.8188, 0.6165, 0.4993, 0.7115,
        0.6545, 0.7292, 0.6401, 0.6357, 0.7547, 0.4357, 0.5723],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9997, 0.9999, 0.9998, 0.9999, 0.9986, 0.9997, 0.9994, 0.9998,
        0.9999, 0.9999, 1.0000, 0.9999, 0.9996, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 135 | Batch_idx: 0 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 135 | Batch_idx: 10 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (1329/1408)
Epoch: 135 | Batch_idx: 20 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (2541/2688)
Epoch: 135 | Batch_idx: 30 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (3758/3968)
Epoch: 135 | Batch_idx: 40 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (4961/5248)
Epoch: 135 | Batch_idx: 50 |  Loss: (0.1651) |  Loss2: (0.0000) | Acc: (94.00%) (6161/6528)
Epoch: 135 | Batch_idx: 60 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (7362/7808)
Epoch: 135 | Batch_idx: 70 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (8561/9088)
Epoch: 135 | Batch_idx: 80 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (9769/10368)
Epoch: 135 | Batch_idx: 90 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (10978/11648)
Epoch: 135 | Batch_idx: 100 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (12185/12928)
Epoch: 135 | Batch_idx: 110 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (13383/14208)
Epoch: 135 | Batch_idx: 120 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (94.00%) (14606/15488)
Epoch: 135 | Batch_idx: 130 |  Loss: (0.1691) |  Loss2: (0.0000) | Acc: (94.00%) (15795/16768)
Epoch: 135 | Batch_idx: 140 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (94.00%) (16994/18048)
Epoch: 135 | Batch_idx: 150 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (18200/19328)
Epoch: 135 | Batch_idx: 160 |  Loss: (0.1704) |  Loss2: (0.0000) | Acc: (94.00%) (19395/20608)
Epoch: 135 | Batch_idx: 170 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (94.00%) (20595/21888)
Epoch: 135 | Batch_idx: 180 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (21804/23168)
Epoch: 135 | Batch_idx: 190 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (94.00%) (22998/24448)
Epoch: 135 | Batch_idx: 200 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (24210/25728)
Epoch: 135 | Batch_idx: 210 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (25428/27008)
Epoch: 135 | Batch_idx: 220 |  Loss: (0.1691) |  Loss2: (0.0000) | Acc: (94.00%) (26633/28288)
Epoch: 135 | Batch_idx: 230 |  Loss: (0.1685) |  Loss2: (0.0000) | Acc: (94.00%) (27848/29568)
Epoch: 135 | Batch_idx: 240 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (29080/30848)
Epoch: 135 | Batch_idx: 250 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (30300/32128)
Epoch: 135 | Batch_idx: 260 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (31509/33408)
Epoch: 135 | Batch_idx: 270 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (32714/34688)
Epoch: 135 | Batch_idx: 280 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (33920/35968)
Epoch: 135 | Batch_idx: 290 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (35130/37248)
Epoch: 135 | Batch_idx: 300 |  Loss: (0.1651) |  Loss2: (0.0000) | Acc: (94.00%) (36345/38528)
Epoch: 135 | Batch_idx: 310 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (37535/39808)
Epoch: 135 | Batch_idx: 320 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (38747/41088)
Epoch: 135 | Batch_idx: 330 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (39946/42368)
Epoch: 135 | Batch_idx: 340 |  Loss: (0.1640) |  Loss2: (0.0000) | Acc: (94.00%) (41163/43648)
Epoch: 135 | Batch_idx: 350 |  Loss: (0.1640) |  Loss2: (0.0000) | Acc: (94.00%) (42369/44928)
Epoch: 135 | Batch_idx: 360 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (43584/46208)
Epoch: 135 | Batch_idx: 370 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (44781/47488)
Epoch: 135 | Batch_idx: 380 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (45986/48768)
Epoch: 135 | Batch_idx: 390 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (47149/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_135.pth.tar'
# TEST : Loss: (0.4028) | Acc: (87.00%) (8786/10000)
percent tensor([0.5678, 0.5888, 0.5811, 0.5687, 0.5858, 0.5579, 0.5963, 0.5849, 0.5816,
        0.5823, 0.5765, 0.5875, 0.5727, 0.5895, 0.5757, 0.5681],
       device='cuda:0') torch.Size([16])
percent tensor([0.5625, 0.5587, 0.5537, 0.5470, 0.5545, 0.5309, 0.5643, 0.5563, 0.5606,
        0.5618, 0.5597, 0.5644, 0.5685, 0.5529, 0.5426, 0.5533],
       device='cuda:0') torch.Size([16])
percent tensor([0.6197, 0.6226, 0.5897, 0.6521, 0.6652, 0.6698, 0.6524, 0.6935, 0.5929,
        0.5418, 0.5596, 0.5955, 0.5676, 0.6450, 0.6925, 0.6240],
       device='cuda:0') torch.Size([16])
percent tensor([0.7165, 0.6662, 0.6947, 0.6971, 0.7083, 0.7021, 0.7110, 0.7086, 0.6851,
        0.6848, 0.6944, 0.6735, 0.6547, 0.7045, 0.7151, 0.7022],
       device='cuda:0') torch.Size([16])
percent tensor([0.5492, 0.5727, 0.5761, 0.6053, 0.5784, 0.5841, 0.5628, 0.5580, 0.5979,
        0.5735, 0.5667, 0.6018, 0.5637, 0.6015, 0.5456, 0.5785],
       device='cuda:0') torch.Size([16])
percent tensor([0.6329, 0.6664, 0.6774, 0.7122, 0.6977, 0.6731, 0.6745, 0.6636, 0.7058,
        0.6687, 0.6992, 0.6964, 0.6454, 0.7470, 0.6294, 0.6676],
       device='cuda:0') torch.Size([16])
percent tensor([0.5581, 0.6045, 0.7016, 0.7360, 0.6373, 0.8152, 0.6025, 0.5245, 0.6832,
        0.6187, 0.7065, 0.6124, 0.6164, 0.7232, 0.4489, 0.5607],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9997, 0.9998, 0.9998, 0.9999, 0.9985, 0.9996, 0.9995, 0.9998,
        0.9998, 0.9999, 1.0000, 0.9999, 0.9996, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 136 | Batch_idx: 0 |  Loss: (0.1963) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 136 | Batch_idx: 10 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (1312/1408)
Epoch: 136 | Batch_idx: 20 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (93.00%) (2525/2688)
Epoch: 136 | Batch_idx: 30 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (3730/3968)
Epoch: 136 | Batch_idx: 40 |  Loss: (0.1633) |  Loss2: (0.0000) | Acc: (94.00%) (4936/5248)
Epoch: 136 | Batch_idx: 50 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (6144/6528)
Epoch: 136 | Batch_idx: 60 |  Loss: (0.1624) |  Loss2: (0.0000) | Acc: (94.00%) (7363/7808)
Epoch: 136 | Batch_idx: 70 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (8584/9088)
Epoch: 136 | Batch_idx: 80 |  Loss: (0.1591) |  Loss2: (0.0000) | Acc: (94.00%) (9790/10368)
Epoch: 136 | Batch_idx: 90 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (10998/11648)
Epoch: 136 | Batch_idx: 100 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (12220/12928)
Epoch: 136 | Batch_idx: 110 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (13419/14208)
Epoch: 136 | Batch_idx: 120 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (14641/15488)
Epoch: 136 | Batch_idx: 130 |  Loss: (0.1560) |  Loss2: (0.0000) | Acc: (94.00%) (15857/16768)
Epoch: 136 | Batch_idx: 140 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (17066/18048)
Epoch: 136 | Batch_idx: 150 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (18264/19328)
Epoch: 136 | Batch_idx: 160 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (19476/20608)
Epoch: 136 | Batch_idx: 170 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (20681/21888)
Epoch: 136 | Batch_idx: 180 |  Loss: (0.1559) |  Loss2: (0.0000) | Acc: (94.00%) (21905/23168)
Epoch: 136 | Batch_idx: 190 |  Loss: (0.1555) |  Loss2: (0.0000) | Acc: (94.00%) (23122/24448)
Epoch: 136 | Batch_idx: 200 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (24320/25728)
Epoch: 136 | Batch_idx: 210 |  Loss: (0.1560) |  Loss2: (0.0000) | Acc: (94.00%) (25541/27008)
Epoch: 136 | Batch_idx: 220 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (26762/28288)
Epoch: 136 | Batch_idx: 230 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (27958/29568)
Epoch: 136 | Batch_idx: 240 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (29161/30848)
Epoch: 136 | Batch_idx: 250 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (30391/32128)
Epoch: 136 | Batch_idx: 260 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (31607/33408)
Epoch: 136 | Batch_idx: 270 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (32831/34688)
Epoch: 136 | Batch_idx: 280 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (34049/35968)
Epoch: 136 | Batch_idx: 290 |  Loss: (0.1527) |  Loss2: (0.0000) | Acc: (94.00%) (35268/37248)
Epoch: 136 | Batch_idx: 300 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (36488/38528)
Epoch: 136 | Batch_idx: 310 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (37703/39808)
Epoch: 136 | Batch_idx: 320 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (38920/41088)
Epoch: 136 | Batch_idx: 330 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (40136/42368)
Epoch: 136 | Batch_idx: 340 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (41345/43648)
Epoch: 136 | Batch_idx: 350 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (42567/44928)
Epoch: 136 | Batch_idx: 360 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (43782/46208)
Epoch: 136 | Batch_idx: 370 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (45005/47488)
Epoch: 136 | Batch_idx: 380 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (46225/48768)
Epoch: 136 | Batch_idx: 390 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (94.00%) (47406/50000)
# TEST : Loss: (0.3888) | Acc: (88.00%) (8840/10000)
percent tensor([0.5666, 0.5876, 0.5793, 0.5676, 0.5841, 0.5572, 0.5948, 0.5832, 0.5805,
        0.5807, 0.5754, 0.5857, 0.5715, 0.5890, 0.5746, 0.5671],
       device='cuda:0') torch.Size([16])
percent tensor([0.5567, 0.5513, 0.5475, 0.5410, 0.5477, 0.5259, 0.5569, 0.5503, 0.5541,
        0.5545, 0.5523, 0.5570, 0.5612, 0.5466, 0.5362, 0.5471],
       device='cuda:0') torch.Size([16])
percent tensor([0.6110, 0.6169, 0.5797, 0.6476, 0.6563, 0.6695, 0.6450, 0.6835, 0.5851,
        0.5342, 0.5526, 0.5873, 0.5607, 0.6409, 0.6880, 0.6188],
       device='cuda:0') torch.Size([16])
percent tensor([0.7180, 0.6652, 0.6973, 0.6993, 0.7107, 0.7030, 0.7110, 0.7120, 0.6870,
        0.6842, 0.6942, 0.6743, 0.6534, 0.7049, 0.7158, 0.7019],
       device='cuda:0') torch.Size([16])
percent tensor([0.5476, 0.5698, 0.5766, 0.6089, 0.5811, 0.5823, 0.5645, 0.5609, 0.5995,
        0.5707, 0.5658, 0.6038, 0.5581, 0.6073, 0.5459, 0.5755],
       device='cuda:0') torch.Size([16])
percent tensor([0.6291, 0.6604, 0.6779, 0.7151, 0.7002, 0.6754, 0.6697, 0.6623, 0.7018,
        0.6626, 0.6918, 0.6925, 0.6364, 0.7453, 0.6223, 0.6682],
       device='cuda:0') torch.Size([16])
percent tensor([0.5576, 0.6022, 0.7109, 0.7414, 0.6431, 0.8230, 0.6070, 0.5280, 0.6800,
        0.6100, 0.7010, 0.6113, 0.6106, 0.7225, 0.4467, 0.5630],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9996, 0.9998, 0.9998, 0.9999, 0.9987, 0.9996, 0.9995, 0.9998,
        0.9998, 0.9999, 1.0000, 0.9999, 0.9996, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 137 | Batch_idx: 0 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 137 | Batch_idx: 10 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (1349/1408)
Epoch: 137 | Batch_idx: 20 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (2570/2688)
Epoch: 137 | Batch_idx: 30 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (95.00%) (3790/3968)
Epoch: 137 | Batch_idx: 40 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (5013/5248)
Epoch: 137 | Batch_idx: 50 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (6218/6528)
Epoch: 137 | Batch_idx: 60 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (7443/7808)
Epoch: 137 | Batch_idx: 70 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (8664/9088)
Epoch: 137 | Batch_idx: 80 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (9886/10368)
Epoch: 137 | Batch_idx: 90 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (11106/11648)
Epoch: 137 | Batch_idx: 100 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (12316/12928)
Epoch: 137 | Batch_idx: 110 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (13534/14208)
Epoch: 137 | Batch_idx: 120 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (14747/15488)
Epoch: 137 | Batch_idx: 130 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (15975/16768)
Epoch: 137 | Batch_idx: 140 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (17199/18048)
Epoch: 137 | Batch_idx: 150 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (18422/19328)
Epoch: 137 | Batch_idx: 160 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (19634/20608)
Epoch: 137 | Batch_idx: 170 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (20847/21888)
Epoch: 137 | Batch_idx: 180 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (22071/23168)
Epoch: 137 | Batch_idx: 190 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (23284/24448)
Epoch: 137 | Batch_idx: 200 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (24513/25728)
Epoch: 137 | Batch_idx: 210 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (25738/27008)
Epoch: 137 | Batch_idx: 220 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (26962/28288)
Epoch: 137 | Batch_idx: 230 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (28192/29568)
Epoch: 137 | Batch_idx: 240 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (29412/30848)
Epoch: 137 | Batch_idx: 250 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (30622/32128)
Epoch: 137 | Batch_idx: 260 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (31848/33408)
Epoch: 137 | Batch_idx: 270 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (33060/34688)
Epoch: 137 | Batch_idx: 280 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (34275/35968)
Epoch: 137 | Batch_idx: 290 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (35484/37248)
Epoch: 137 | Batch_idx: 300 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (36699/38528)
Epoch: 137 | Batch_idx: 310 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (37916/39808)
Epoch: 137 | Batch_idx: 320 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (39137/41088)
Epoch: 137 | Batch_idx: 330 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (40350/42368)
Epoch: 137 | Batch_idx: 340 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (41559/43648)
Epoch: 137 | Batch_idx: 350 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (42775/44928)
Epoch: 137 | Batch_idx: 360 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (43995/46208)
Epoch: 137 | Batch_idx: 370 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (45197/47488)
Epoch: 137 | Batch_idx: 380 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (46413/48768)
Epoch: 137 | Batch_idx: 390 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (47594/50000)
# TEST : Loss: (0.3806) | Acc: (88.00%) (8862/10000)
percent tensor([0.5674, 0.5878, 0.5804, 0.5682, 0.5852, 0.5581, 0.5954, 0.5840, 0.5811,
        0.5813, 0.5760, 0.5865, 0.5722, 0.5888, 0.5752, 0.5678],
       device='cuda:0') torch.Size([16])
percent tensor([0.5597, 0.5533, 0.5507, 0.5442, 0.5508, 0.5292, 0.5595, 0.5537, 0.5567,
        0.5567, 0.5544, 0.5597, 0.5634, 0.5491, 0.5390, 0.5499],
       device='cuda:0') torch.Size([16])
percent tensor([0.6091, 0.6177, 0.5752, 0.6437, 0.6536, 0.6679, 0.6452, 0.6792, 0.5829,
        0.5323, 0.5525, 0.5848, 0.5619, 0.6386, 0.6881, 0.6172],
       device='cuda:0') torch.Size([16])
percent tensor([0.7181, 0.6642, 0.6986, 0.6995, 0.7113, 0.7021, 0.7109, 0.7132, 0.6874,
        0.6836, 0.6938, 0.6743, 0.6526, 0.7047, 0.7154, 0.7008],
       device='cuda:0') torch.Size([16])
percent tensor([0.5444, 0.5671, 0.5737, 0.6082, 0.5785, 0.5771, 0.5631, 0.5598, 0.5993,
        0.5673, 0.5646, 0.6036, 0.5532, 0.6097, 0.5451, 0.5703],
       device='cuda:0') torch.Size([16])
percent tensor([0.6288, 0.6574, 0.6798, 0.7193, 0.7035, 0.6804, 0.6682, 0.6650, 0.7002,
        0.6602, 0.6885, 0.6916, 0.6337, 0.7418, 0.6205, 0.6709],
       device='cuda:0') torch.Size([16])
percent tensor([0.5733, 0.6155, 0.7231, 0.7472, 0.6540, 0.8306, 0.6226, 0.5450, 0.6885,
        0.6176, 0.7085, 0.6230, 0.6248, 0.7214, 0.4666, 0.5740],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9997, 0.9998, 0.9998, 0.9999, 0.9987, 0.9996, 0.9995, 0.9998,
        0.9998, 0.9999, 1.0000, 0.9999, 0.9996, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 138 | Batch_idx: 0 |  Loss: (0.1878) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 138 | Batch_idx: 10 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (1343/1408)
Epoch: 138 | Batch_idx: 20 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (2565/2688)
Epoch: 138 | Batch_idx: 30 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (3788/3968)
Epoch: 138 | Batch_idx: 40 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (5018/5248)
Epoch: 138 | Batch_idx: 50 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (6226/6528)
Epoch: 138 | Batch_idx: 60 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (7448/7808)
Epoch: 138 | Batch_idx: 70 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (8671/9088)
Epoch: 138 | Batch_idx: 80 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (9899/10368)
Epoch: 138 | Batch_idx: 90 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (11122/11648)
Epoch: 138 | Batch_idx: 100 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (12348/12928)
Epoch: 138 | Batch_idx: 110 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (13567/14208)
Epoch: 138 | Batch_idx: 120 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (14783/15488)
Epoch: 138 | Batch_idx: 130 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (16007/16768)
Epoch: 138 | Batch_idx: 140 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (17230/18048)
Epoch: 138 | Batch_idx: 150 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (18453/19328)
Epoch: 138 | Batch_idx: 160 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (19669/20608)
Epoch: 138 | Batch_idx: 170 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (20891/21888)
Epoch: 138 | Batch_idx: 180 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (22119/23168)
Epoch: 138 | Batch_idx: 190 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (95.00%) (23322/24448)
Epoch: 138 | Batch_idx: 200 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (24543/25728)
Epoch: 138 | Batch_idx: 210 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (25777/27008)
Epoch: 138 | Batch_idx: 220 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (27007/28288)
Epoch: 138 | Batch_idx: 230 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (28229/29568)
Epoch: 138 | Batch_idx: 240 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (29447/30848)
Epoch: 138 | Batch_idx: 250 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (30665/32128)
Epoch: 138 | Batch_idx: 260 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (31874/33408)
Epoch: 138 | Batch_idx: 270 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (33101/34688)
Epoch: 138 | Batch_idx: 280 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (34318/35968)
Epoch: 138 | Batch_idx: 290 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (35535/37248)
Epoch: 138 | Batch_idx: 300 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (36732/38528)
Epoch: 138 | Batch_idx: 310 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (37945/39808)
Epoch: 138 | Batch_idx: 320 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (39153/41088)
Epoch: 138 | Batch_idx: 330 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (40382/42368)
Epoch: 138 | Batch_idx: 340 |  Loss: (0.1366) |  Loss2: (0.0000) | Acc: (95.00%) (41598/43648)
Epoch: 138 | Batch_idx: 350 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (42831/44928)
Epoch: 138 | Batch_idx: 360 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (44062/46208)
Epoch: 138 | Batch_idx: 370 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (45273/47488)
Epoch: 138 | Batch_idx: 380 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (46493/48768)
Epoch: 138 | Batch_idx: 390 |  Loss: (0.1357) |  Loss2: (0.0000) | Acc: (95.00%) (47670/50000)
# TEST : Loss: (0.3731) | Acc: (88.00%) (8872/10000)
percent tensor([0.5669, 0.5872, 0.5794, 0.5676, 0.5843, 0.5578, 0.5947, 0.5832, 0.5804,
        0.5805, 0.5754, 0.5857, 0.5717, 0.5884, 0.5748, 0.5673],
       device='cuda:0') torch.Size([16])
percent tensor([0.5602, 0.5530, 0.5511, 0.5449, 0.5512, 0.5305, 0.5594, 0.5543, 0.5569,
        0.5564, 0.5542, 0.5597, 0.5630, 0.5494, 0.5396, 0.5503],
       device='cuda:0') torch.Size([16])
percent tensor([0.6113, 0.6196, 0.5774, 0.6473, 0.6563, 0.6698, 0.6476, 0.6809, 0.5848,
        0.5331, 0.5528, 0.5863, 0.5637, 0.6412, 0.6906, 0.6190],
       device='cuda:0') torch.Size([16])
percent tensor([0.7121, 0.6589, 0.6935, 0.6933, 0.7057, 0.6961, 0.7051, 0.7076, 0.6818,
        0.6783, 0.6885, 0.6686, 0.6468, 0.6992, 0.7098, 0.6945],
       device='cuda:0') torch.Size([16])
percent tensor([0.5415, 0.5658, 0.5715, 0.6078, 0.5770, 0.5741, 0.5626, 0.5584, 0.5987,
        0.5656, 0.5646, 0.6044, 0.5497, 0.6118, 0.5440, 0.5667],
       device='cuda:0') torch.Size([16])
percent tensor([0.6175, 0.6461, 0.6715, 0.7133, 0.6966, 0.6740, 0.6564, 0.6549, 0.6899,
        0.6488, 0.6774, 0.6812, 0.6215, 0.7336, 0.6069, 0.6631],
       device='cuda:0') torch.Size([16])
percent tensor([0.5737, 0.6124, 0.7258, 0.7527, 0.6547, 0.8332, 0.6227, 0.5429, 0.6847,
        0.6153, 0.7088, 0.6194, 0.6219, 0.7238, 0.4640, 0.5774],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9996, 0.9998, 0.9998, 0.9999, 0.9988, 0.9996, 0.9995, 0.9998,
        0.9998, 0.9999, 1.0000, 0.9999, 0.9996, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 139 | Batch_idx: 0 |  Loss: (0.1264) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 139 | Batch_idx: 10 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (1324/1408)
Epoch: 139 | Batch_idx: 20 |  Loss: (0.1452) |  Loss2: (0.0000) | Acc: (94.00%) (2545/2688)
Epoch: 139 | Batch_idx: 30 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (94.00%) (3764/3968)
Epoch: 139 | Batch_idx: 40 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (94.00%) (4975/5248)
Epoch: 139 | Batch_idx: 50 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (6202/6528)
Epoch: 139 | Batch_idx: 60 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (7425/7808)
Epoch: 139 | Batch_idx: 70 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (8650/9088)
Epoch: 139 | Batch_idx: 80 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (9871/10368)
Epoch: 139 | Batch_idx: 90 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (11073/11648)
Epoch: 139 | Batch_idx: 100 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (12304/12928)
Epoch: 139 | Batch_idx: 110 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (13536/14208)
Epoch: 139 | Batch_idx: 120 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (14754/15488)
Epoch: 139 | Batch_idx: 130 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (15977/16768)
Epoch: 139 | Batch_idx: 140 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (17188/18048)
Epoch: 139 | Batch_idx: 150 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (18399/19328)
Epoch: 139 | Batch_idx: 160 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (19625/20608)
Epoch: 139 | Batch_idx: 170 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (20837/21888)
Epoch: 139 | Batch_idx: 180 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (22076/23168)
Epoch: 139 | Batch_idx: 190 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (23294/24448)
Epoch: 139 | Batch_idx: 200 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (24519/25728)
Epoch: 139 | Batch_idx: 210 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (25746/27008)
Epoch: 139 | Batch_idx: 220 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (26968/28288)
Epoch: 139 | Batch_idx: 230 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (28200/29568)
Epoch: 139 | Batch_idx: 240 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (29432/30848)
Epoch: 139 | Batch_idx: 250 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (30647/32128)
Epoch: 139 | Batch_idx: 260 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (31875/33408)
Epoch: 139 | Batch_idx: 270 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (33067/34688)
Epoch: 139 | Batch_idx: 280 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (34298/35968)
Epoch: 139 | Batch_idx: 290 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (35519/37248)
Epoch: 139 | Batch_idx: 300 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (36746/38528)
Epoch: 139 | Batch_idx: 310 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (37976/39808)
Epoch: 139 | Batch_idx: 320 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (39205/41088)
Epoch: 139 | Batch_idx: 330 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (40429/42368)
Epoch: 139 | Batch_idx: 340 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (41642/43648)
Epoch: 139 | Batch_idx: 350 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (42876/44928)
Epoch: 139 | Batch_idx: 360 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (44102/46208)
Epoch: 139 | Batch_idx: 370 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (45320/47488)
Epoch: 139 | Batch_idx: 380 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (46541/48768)
Epoch: 139 | Batch_idx: 390 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (47709/50000)
# TEST : Loss: (0.3717) | Acc: (88.00%) (8878/10000)
percent tensor([0.5677, 0.5882, 0.5804, 0.5684, 0.5853, 0.5588, 0.5957, 0.5841, 0.5813,
        0.5815, 0.5763, 0.5866, 0.5726, 0.5892, 0.5758, 0.5682],
       device='cuda:0') torch.Size([16])
percent tensor([0.5627, 0.5549, 0.5535, 0.5478, 0.5537, 0.5336, 0.5617, 0.5571, 0.5592,
        0.5582, 0.5561, 0.5617, 0.5649, 0.5517, 0.5422, 0.5530],
       device='cuda:0') torch.Size([16])
percent tensor([0.6093, 0.6196, 0.5779, 0.6486, 0.6578, 0.6673, 0.6481, 0.6818, 0.5850,
        0.5325, 0.5502, 0.5887, 0.5637, 0.6411, 0.6906, 0.6158],
       device='cuda:0') torch.Size([16])
percent tensor([0.7195, 0.6661, 0.7004, 0.7006, 0.7129, 0.7035, 0.7125, 0.7160, 0.6892,
        0.6855, 0.6962, 0.6760, 0.6534, 0.7069, 0.7178, 0.7020],
       device='cuda:0') torch.Size([16])
percent tensor([0.5492, 0.5752, 0.5784, 0.6113, 0.5840, 0.5788, 0.5731, 0.5650, 0.6070,
        0.5745, 0.5735, 0.6131, 0.5576, 0.6212, 0.5539, 0.5721],
       device='cuda:0') torch.Size([16])
percent tensor([0.6119, 0.6400, 0.6688, 0.7110, 0.6935, 0.6710, 0.6506, 0.6500, 0.6851,
        0.6424, 0.6708, 0.6749, 0.6153, 0.7280, 0.5986, 0.6593],
       device='cuda:0') torch.Size([16])
percent tensor([0.5876, 0.6293, 0.7376, 0.7571, 0.6577, 0.8439, 0.6365, 0.5479, 0.6977,
        0.6275, 0.7206, 0.6261, 0.6402, 0.7366, 0.4713, 0.5908],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9996, 0.9998, 0.9998, 0.9999, 0.9989, 0.9997, 0.9995, 0.9998,
        0.9998, 0.9999, 1.0000, 0.9999, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 140 | Batch_idx: 0 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 140 | Batch_idx: 10 |  Loss: (0.1280) |  Loss2: (0.0000) | Acc: (95.00%) (1343/1408)
Epoch: 140 | Batch_idx: 20 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (2556/2688)
Epoch: 140 | Batch_idx: 30 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (3780/3968)
Epoch: 140 | Batch_idx: 40 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (5003/5248)
Epoch: 140 | Batch_idx: 50 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (95.00%) (6218/6528)
Epoch: 140 | Batch_idx: 60 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (7443/7808)
Epoch: 140 | Batch_idx: 70 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (8668/9088)
Epoch: 140 | Batch_idx: 80 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (9885/10368)
Epoch: 140 | Batch_idx: 90 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (11091/11648)
Epoch: 140 | Batch_idx: 100 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (12316/12928)
Epoch: 140 | Batch_idx: 110 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (13530/14208)
Epoch: 140 | Batch_idx: 120 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (14761/15488)
Epoch: 140 | Batch_idx: 130 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (15957/16768)
Epoch: 140 | Batch_idx: 140 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (17166/18048)
Epoch: 140 | Batch_idx: 150 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (18395/19328)
Epoch: 140 | Batch_idx: 160 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (19617/20608)
Epoch: 140 | Batch_idx: 170 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (20843/21888)
Epoch: 140 | Batch_idx: 180 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (22061/23168)
Epoch: 140 | Batch_idx: 190 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (23285/24448)
Epoch: 140 | Batch_idx: 200 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (24502/25728)
Epoch: 140 | Batch_idx: 210 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (25718/27008)
Epoch: 140 | Batch_idx: 220 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (26936/28288)
Epoch: 140 | Batch_idx: 230 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (28162/29568)
Epoch: 140 | Batch_idx: 240 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (29382/30848)
Epoch: 140 | Batch_idx: 250 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (30599/32128)
Epoch: 140 | Batch_idx: 260 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (31794/33408)
Epoch: 140 | Batch_idx: 270 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (33008/34688)
Epoch: 140 | Batch_idx: 280 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (34239/35968)
Epoch: 140 | Batch_idx: 290 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (35448/37248)
Epoch: 140 | Batch_idx: 300 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (36666/38528)
Epoch: 140 | Batch_idx: 310 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (37876/39808)
Epoch: 140 | Batch_idx: 320 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (39099/41088)
Epoch: 140 | Batch_idx: 330 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (40327/42368)
Epoch: 140 | Batch_idx: 340 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (41545/43648)
Epoch: 140 | Batch_idx: 350 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (42762/44928)
Epoch: 140 | Batch_idx: 360 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (43964/46208)
Epoch: 140 | Batch_idx: 370 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (45199/47488)
Epoch: 140 | Batch_idx: 380 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (46404/48768)
Epoch: 140 | Batch_idx: 390 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (47571/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_140.pth.tar'
# TEST : Loss: (0.4279) | Acc: (87.00%) (8729/10000)
percent tensor([0.5683, 0.5866, 0.5823, 0.5690, 0.5866, 0.5594, 0.5951, 0.5840, 0.5811,
        0.5813, 0.5758, 0.5880, 0.5729, 0.5862, 0.5754, 0.5676],
       device='cuda:0') torch.Size([16])
percent tensor([0.5621, 0.5568, 0.5549, 0.5484, 0.5542, 0.5315, 0.5626, 0.5593, 0.5601,
        0.5597, 0.5562, 0.5639, 0.5648, 0.5565, 0.5424, 0.5525],
       device='cuda:0') torch.Size([16])
percent tensor([0.5996, 0.6145, 0.5928, 0.6447, 0.6632, 0.6551, 0.6426, 0.6875, 0.5810,
        0.5381, 0.5371, 0.5910, 0.5553, 0.6233, 0.6883, 0.6055],
       device='cuda:0') torch.Size([16])
percent tensor([0.7198, 0.6692, 0.7047, 0.7024, 0.7137, 0.7050, 0.7152, 0.7135, 0.6920,
        0.6920, 0.7036, 0.6790, 0.6609, 0.7077, 0.7187, 0.7034],
       device='cuda:0') torch.Size([16])
percent tensor([0.5460, 0.5694, 0.5714, 0.6123, 0.5844, 0.5748, 0.5616, 0.5594, 0.6019,
        0.5589, 0.5643, 0.6038, 0.5531, 0.6044, 0.5490, 0.5677],
       device='cuda:0') torch.Size([16])
percent tensor([0.6082, 0.6520, 0.6609, 0.7013, 0.6917, 0.6662, 0.6493, 0.6366, 0.6778,
        0.6441, 0.6711, 0.6798, 0.6288, 0.7230, 0.5921, 0.6535],
       device='cuda:0') torch.Size([16])
percent tensor([0.5607, 0.6457, 0.7082, 0.7475, 0.6596, 0.8303, 0.6235, 0.5042, 0.6846,
        0.6333, 0.6985, 0.6358, 0.6267, 0.7087, 0.4523, 0.5820],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9997, 0.9998, 0.9999, 0.9999, 0.9987, 0.9996, 0.9995, 0.9999,
        0.9998, 0.9999, 1.0000, 0.9999, 0.9995, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(176.7619, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(816.9793, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(821.5773, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1527.3280, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(484.4613, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2258.9299, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4256.3799, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1381.4415, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6214.4038, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11728.6035, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3889.5366, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16366.4697, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 141 | Batch_idx: 0 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 141 | Batch_idx: 10 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (1344/1408)
Epoch: 141 | Batch_idx: 20 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (2564/2688)
Epoch: 141 | Batch_idx: 30 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (3806/3968)
Epoch: 141 | Batch_idx: 40 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (5013/5248)
Epoch: 141 | Batch_idx: 50 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (6228/6528)
Epoch: 141 | Batch_idx: 60 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (7441/7808)
Epoch: 141 | Batch_idx: 70 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (8664/9088)
Epoch: 141 | Batch_idx: 80 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (9875/10368)
Epoch: 141 | Batch_idx: 90 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (11086/11648)
Epoch: 141 | Batch_idx: 100 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (12305/12928)
Epoch: 141 | Batch_idx: 110 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (13527/14208)
Epoch: 141 | Batch_idx: 120 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (14747/15488)
Epoch: 141 | Batch_idx: 130 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (15970/16768)
Epoch: 141 | Batch_idx: 140 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (17187/18048)
Epoch: 141 | Batch_idx: 150 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (18421/19328)
Epoch: 141 | Batch_idx: 160 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (19654/20608)
Epoch: 141 | Batch_idx: 170 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (20872/21888)
Epoch: 141 | Batch_idx: 180 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (22091/23168)
Epoch: 141 | Batch_idx: 190 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (23325/24448)
Epoch: 141 | Batch_idx: 200 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (24545/25728)
Epoch: 141 | Batch_idx: 210 |  Loss: (0.1366) |  Loss2: (0.0000) | Acc: (95.00%) (25763/27008)
Epoch: 141 | Batch_idx: 220 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (26991/28288)
Epoch: 141 | Batch_idx: 230 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (28217/29568)
Epoch: 141 | Batch_idx: 240 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (29442/30848)
Epoch: 141 | Batch_idx: 250 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (30649/32128)
Epoch: 141 | Batch_idx: 260 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (31877/33408)
Epoch: 141 | Batch_idx: 270 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (33091/34688)
Epoch: 141 | Batch_idx: 280 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (34311/35968)
Epoch: 141 | Batch_idx: 290 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (35521/37248)
Epoch: 141 | Batch_idx: 300 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (36733/38528)
Epoch: 141 | Batch_idx: 310 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (37945/39808)
Epoch: 141 | Batch_idx: 320 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (39152/41088)
Epoch: 141 | Batch_idx: 330 |  Loss: (0.1372) |  Loss2: (0.0000) | Acc: (95.00%) (40378/42368)
Epoch: 141 | Batch_idx: 340 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (41602/43648)
Epoch: 141 | Batch_idx: 350 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (42811/44928)
Epoch: 141 | Batch_idx: 360 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (44028/46208)
Epoch: 141 | Batch_idx: 370 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (45254/47488)
Epoch: 141 | Batch_idx: 380 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (46457/48768)
Epoch: 141 | Batch_idx: 390 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (47619/50000)
# TEST : Loss: (0.4617) | Acc: (86.00%) (8647/10000)
percent tensor([0.5684, 0.5880, 0.5805, 0.5691, 0.5852, 0.5600, 0.5953, 0.5841, 0.5799,
        0.5819, 0.5760, 0.5867, 0.5729, 0.5877, 0.5765, 0.5683],
       device='cuda:0') torch.Size([16])
percent tensor([0.5608, 0.5576, 0.5506, 0.5482, 0.5513, 0.5324, 0.5629, 0.5577, 0.5588,
        0.5583, 0.5562, 0.5599, 0.5632, 0.5598, 0.5428, 0.5532],
       device='cuda:0') torch.Size([16])
percent tensor([0.6037, 0.6088, 0.5917, 0.6539, 0.6638, 0.6496, 0.6395, 0.6946, 0.5809,
        0.5336, 0.5343, 0.5861, 0.5569, 0.6314, 0.6826, 0.6095],
       device='cuda:0') torch.Size([16])
percent tensor([0.7216, 0.6672, 0.6977, 0.7014, 0.7140, 0.7045, 0.7112, 0.7099, 0.6849,
        0.6906, 0.7023, 0.6745, 0.6578, 0.7033, 0.7188, 0.7073],
       device='cuda:0') torch.Size([16])
percent tensor([0.5436, 0.5778, 0.5766, 0.6048, 0.5892, 0.5743, 0.5742, 0.5754, 0.6058,
        0.5647, 0.5655, 0.6052, 0.5559, 0.6159, 0.5547, 0.5640],
       device='cuda:0') torch.Size([16])
percent tensor([0.6026, 0.6499, 0.6615, 0.6989, 0.6923, 0.6613, 0.6594, 0.6436, 0.6837,
        0.6473, 0.6736, 0.6756, 0.6202, 0.7210, 0.5944, 0.6479],
       device='cuda:0') torch.Size([16])
percent tensor([0.5766, 0.6679, 0.7200, 0.7440, 0.6803, 0.8309, 0.6736, 0.5378, 0.7156,
        0.6815, 0.7540, 0.6392, 0.6507, 0.7071, 0.4855, 0.5910],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9997, 0.9999, 0.9998, 0.9999, 0.9994, 0.9997, 0.9994, 0.9997,
        0.9998, 0.9999, 0.9999, 0.9998, 0.9995, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 142 | Batch_idx: 0 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 142 | Batch_idx: 10 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (1351/1408)
Epoch: 142 | Batch_idx: 20 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (2578/2688)
Epoch: 142 | Batch_idx: 30 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (3801/3968)
Epoch: 142 | Batch_idx: 40 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (5017/5248)
Epoch: 142 | Batch_idx: 50 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (6240/6528)
Epoch: 142 | Batch_idx: 60 |  Loss: (0.1279) |  Loss2: (0.0000) | Acc: (95.00%) (7470/7808)
Epoch: 142 | Batch_idx: 70 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (8688/9088)
Epoch: 142 | Batch_idx: 80 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (9893/10368)
Epoch: 142 | Batch_idx: 90 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (11122/11648)
Epoch: 142 | Batch_idx: 100 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (12335/12928)
Epoch: 142 | Batch_idx: 110 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (13554/14208)
Epoch: 142 | Batch_idx: 120 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (14781/15488)
Epoch: 142 | Batch_idx: 130 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (16004/16768)
Epoch: 142 | Batch_idx: 140 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (17217/18048)
Epoch: 142 | Batch_idx: 150 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (18443/19328)
Epoch: 142 | Batch_idx: 160 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (19663/20608)
Epoch: 142 | Batch_idx: 170 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (20889/21888)
Epoch: 142 | Batch_idx: 180 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (22110/23168)
Epoch: 142 | Batch_idx: 190 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (23327/24448)
Epoch: 142 | Batch_idx: 200 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (24559/25728)
Epoch: 142 | Batch_idx: 210 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (25773/27008)
Epoch: 142 | Batch_idx: 220 |  Loss: (0.1323) |  Loss2: (0.0000) | Acc: (95.00%) (26996/28288)
Epoch: 142 | Batch_idx: 230 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (28213/29568)
Epoch: 142 | Batch_idx: 240 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (29437/30848)
Epoch: 142 | Batch_idx: 250 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (30663/32128)
Epoch: 142 | Batch_idx: 260 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (31884/33408)
Epoch: 142 | Batch_idx: 270 |  Loss: (0.1323) |  Loss2: (0.0000) | Acc: (95.00%) (33110/34688)
Epoch: 142 | Batch_idx: 280 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (34327/35968)
Epoch: 142 | Batch_idx: 290 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (35542/37248)
Epoch: 142 | Batch_idx: 300 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (36765/38528)
Epoch: 142 | Batch_idx: 310 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (37986/39808)
Epoch: 142 | Batch_idx: 320 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (39196/41088)
Epoch: 142 | Batch_idx: 330 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (40404/42368)
Epoch: 142 | Batch_idx: 340 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (41623/43648)
Epoch: 142 | Batch_idx: 350 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (42839/44928)
Epoch: 142 | Batch_idx: 360 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (44058/46208)
Epoch: 142 | Batch_idx: 370 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (45279/47488)
Epoch: 142 | Batch_idx: 380 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (46491/48768)
Epoch: 142 | Batch_idx: 390 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (95.00%) (47667/50000)
# TEST : Loss: (0.4090) | Acc: (87.00%) (8755/10000)
percent tensor([0.5683, 0.5879, 0.5813, 0.5684, 0.5863, 0.5598, 0.5955, 0.5837, 0.5805,
        0.5819, 0.5759, 0.5874, 0.5729, 0.5867, 0.5763, 0.5678],
       device='cuda:0') torch.Size([16])
percent tensor([0.5617, 0.5539, 0.5538, 0.5485, 0.5544, 0.5323, 0.5615, 0.5582, 0.5595,
        0.5584, 0.5565, 0.5614, 0.5647, 0.5533, 0.5421, 0.5536],
       device='cuda:0') torch.Size([16])
percent tensor([0.6000, 0.6180, 0.5794, 0.6537, 0.6508, 0.6459, 0.6398, 0.6794, 0.5765,
        0.5295, 0.5263, 0.5864, 0.5539, 0.6284, 0.6804, 0.6032],
       device='cuda:0') torch.Size([16])
percent tensor([0.7192, 0.6674, 0.6961, 0.6989, 0.7113, 0.7063, 0.7112, 0.7102, 0.6891,
        0.6906, 0.6979, 0.6755, 0.6601, 0.7030, 0.7151, 0.7075],
       device='cuda:0') torch.Size([16])
percent tensor([0.5475, 0.5730, 0.5694, 0.6132, 0.5812, 0.5798, 0.5669, 0.5649, 0.5993,
        0.5615, 0.5693, 0.6034, 0.5508, 0.6184, 0.5563, 0.5693],
       device='cuda:0') torch.Size([16])
percent tensor([0.6043, 0.6403, 0.6693, 0.6982, 0.6865, 0.6681, 0.6415, 0.6336, 0.6785,
        0.6368, 0.6701, 0.6769, 0.6215, 0.7178, 0.5838, 0.6548],
       device='cuda:0') torch.Size([16])
percent tensor([0.5624, 0.6337, 0.7368, 0.7131, 0.6463, 0.8176, 0.6219, 0.5366, 0.7137,
        0.6553, 0.7123, 0.6319, 0.6250, 0.7364, 0.4452, 0.5959],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9999, 0.9998, 0.9999, 0.9988, 0.9994, 0.9996, 0.9998,
        0.9999, 0.9999, 1.0000, 0.9998, 0.9995, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 143 | Batch_idx: 0 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 143 | Batch_idx: 10 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (95.00%) (1351/1408)
Epoch: 143 | Batch_idx: 20 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (96.00%) (2581/2688)
Epoch: 143 | Batch_idx: 30 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (95.00%) (3802/3968)
Epoch: 143 | Batch_idx: 40 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (5039/5248)
Epoch: 143 | Batch_idx: 50 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (6270/6528)
Epoch: 143 | Batch_idx: 60 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (95.00%) (7495/7808)
Epoch: 143 | Batch_idx: 70 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (95.00%) (8719/9088)
Epoch: 143 | Batch_idx: 80 |  Loss: (0.1166) |  Loss2: (0.0000) | Acc: (95.00%) (9942/10368)
Epoch: 143 | Batch_idx: 90 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (95.00%) (11168/11648)
Epoch: 143 | Batch_idx: 100 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (12386/12928)
Epoch: 143 | Batch_idx: 110 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (13601/14208)
Epoch: 143 | Batch_idx: 120 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (14824/15488)
Epoch: 143 | Batch_idx: 130 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (16051/16768)
Epoch: 143 | Batch_idx: 140 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (17284/18048)
Epoch: 143 | Batch_idx: 150 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (18509/19328)
Epoch: 143 | Batch_idx: 160 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (19721/20608)
Epoch: 143 | Batch_idx: 170 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (20930/21888)
Epoch: 143 | Batch_idx: 180 |  Loss: (0.1289) |  Loss2: (0.0000) | Acc: (95.00%) (22136/23168)
Epoch: 143 | Batch_idx: 190 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (23351/24448)
Epoch: 143 | Batch_idx: 200 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (24579/25728)
Epoch: 143 | Batch_idx: 210 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (25817/27008)
Epoch: 143 | Batch_idx: 220 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (27047/28288)
Epoch: 143 | Batch_idx: 230 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (28259/29568)
Epoch: 143 | Batch_idx: 240 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (29485/30848)
Epoch: 143 | Batch_idx: 250 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (30709/32128)
Epoch: 143 | Batch_idx: 260 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (31925/33408)
Epoch: 143 | Batch_idx: 270 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (33144/34688)
Epoch: 143 | Batch_idx: 280 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (34371/35968)
Epoch: 143 | Batch_idx: 290 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (35610/37248)
Epoch: 143 | Batch_idx: 300 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (36834/38528)
Epoch: 143 | Batch_idx: 310 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (38061/39808)
Epoch: 143 | Batch_idx: 320 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (39284/41088)
Epoch: 143 | Batch_idx: 330 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (40500/42368)
Epoch: 143 | Batch_idx: 340 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (41714/43648)
Epoch: 143 | Batch_idx: 350 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (42931/44928)
Epoch: 143 | Batch_idx: 360 |  Loss: (0.1291) |  Loss2: (0.0000) | Acc: (95.00%) (44146/46208)
Epoch: 143 | Batch_idx: 370 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (45359/47488)
Epoch: 143 | Batch_idx: 380 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (46570/48768)
Epoch: 143 | Batch_idx: 390 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (47745/50000)
# TEST : Loss: (0.3886) | Acc: (88.00%) (8861/10000)
percent tensor([0.5678, 0.5873, 0.5811, 0.5692, 0.5857, 0.5591, 0.5950, 0.5847, 0.5795,
        0.5815, 0.5747, 0.5870, 0.5723, 0.5877, 0.5756, 0.5679],
       device='cuda:0') torch.Size([16])
percent tensor([0.5607, 0.5551, 0.5551, 0.5486, 0.5545, 0.5318, 0.5628, 0.5578, 0.5585,
        0.5581, 0.5552, 0.5625, 0.5632, 0.5548, 0.5418, 0.5524],
       device='cuda:0') torch.Size([16])
percent tensor([0.6010, 0.6168, 0.5936, 0.6592, 0.6636, 0.6533, 0.6491, 0.6910, 0.5731,
        0.5424, 0.5320, 0.5985, 0.5544, 0.6273, 0.6869, 0.6085],
       device='cuda:0') torch.Size([16])
percent tensor([0.7188, 0.6628, 0.7020, 0.6966, 0.7159, 0.7053, 0.7115, 0.7138, 0.6890,
        0.6891, 0.7002, 0.6745, 0.6590, 0.6968, 0.7166, 0.7040],
       device='cuda:0') torch.Size([16])
percent tensor([0.5506, 0.5805, 0.5696, 0.6102, 0.5878, 0.5796, 0.5701, 0.5698, 0.6033,
        0.5656, 0.5774, 0.6096, 0.5563, 0.6116, 0.5640, 0.5708],
       device='cuda:0') torch.Size([16])
percent tensor([0.6098, 0.6390, 0.6722, 0.6998, 0.6968, 0.6708, 0.6354, 0.6345, 0.6785,
        0.6315, 0.6654, 0.6750, 0.6211, 0.7199, 0.5821, 0.6489],
       device='cuda:0') torch.Size([16])
percent tensor([0.5957, 0.6063, 0.7599, 0.7705, 0.6915, 0.8452, 0.6158, 0.5327, 0.7024,
        0.6560, 0.7126, 0.6111, 0.6371, 0.7010, 0.4338, 0.6101],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9998, 0.9998, 0.9999, 0.9993, 0.9996, 0.9994, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9994, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 144 | Batch_idx: 0 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 144 | Batch_idx: 10 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (1354/1408)
Epoch: 144 | Batch_idx: 20 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (2596/2688)
Epoch: 144 | Batch_idx: 30 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (96.00%) (3825/3968)
Epoch: 144 | Batch_idx: 40 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (5049/5248)
Epoch: 144 | Batch_idx: 50 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (96.00%) (6277/6528)
Epoch: 144 | Batch_idx: 60 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (7511/7808)
Epoch: 144 | Batch_idx: 70 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (8738/9088)
Epoch: 144 | Batch_idx: 80 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (9975/10368)
Epoch: 144 | Batch_idx: 90 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (96.00%) (11194/11648)
Epoch: 144 | Batch_idx: 100 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (96.00%) (12419/12928)
Epoch: 144 | Batch_idx: 110 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (96.00%) (13648/14208)
Epoch: 144 | Batch_idx: 120 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (14889/15488)
Epoch: 144 | Batch_idx: 130 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (96.00%) (16115/16768)
Epoch: 144 | Batch_idx: 140 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (96.00%) (17335/18048)
Epoch: 144 | Batch_idx: 150 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (96.00%) (18564/19328)
Epoch: 144 | Batch_idx: 160 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (19783/20608)
Epoch: 144 | Batch_idx: 170 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (96.00%) (21015/21888)
Epoch: 144 | Batch_idx: 180 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (22236/23168)
Epoch: 144 | Batch_idx: 190 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (23457/24448)
Epoch: 144 | Batch_idx: 200 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (24680/25728)
Epoch: 144 | Batch_idx: 210 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (25884/27008)
Epoch: 144 | Batch_idx: 220 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (27104/28288)
Epoch: 144 | Batch_idx: 230 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (28324/29568)
Epoch: 144 | Batch_idx: 240 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (29554/30848)
Epoch: 144 | Batch_idx: 250 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (30777/32128)
Epoch: 144 | Batch_idx: 260 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (32000/33408)
Epoch: 144 | Batch_idx: 270 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (33223/34688)
Epoch: 144 | Batch_idx: 280 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (34447/35968)
Epoch: 144 | Batch_idx: 290 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (35671/37248)
Epoch: 144 | Batch_idx: 300 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (36868/38528)
Epoch: 144 | Batch_idx: 310 |  Loss: (0.1258) |  Loss2: (0.0000) | Acc: (95.00%) (38081/39808)
Epoch: 144 | Batch_idx: 320 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (39297/41088)
Epoch: 144 | Batch_idx: 330 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (40503/42368)
Epoch: 144 | Batch_idx: 340 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (41709/43648)
Epoch: 144 | Batch_idx: 350 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (42926/44928)
Epoch: 144 | Batch_idx: 360 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (44152/46208)
Epoch: 144 | Batch_idx: 370 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (45365/47488)
Epoch: 144 | Batch_idx: 380 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (46583/48768)
Epoch: 144 | Batch_idx: 390 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (47762/50000)
# TEST : Loss: (0.4257) | Acc: (87.00%) (8741/10000)
percent tensor([0.5684, 0.5881, 0.5796, 0.5688, 0.5852, 0.5590, 0.5951, 0.5839, 0.5805,
        0.5816, 0.5760, 0.5861, 0.5728, 0.5883, 0.5761, 0.5683],
       device='cuda:0') torch.Size([16])
percent tensor([0.5625, 0.5562, 0.5537, 0.5490, 0.5541, 0.5335, 0.5627, 0.5587, 0.5602,
        0.5575, 0.5566, 0.5599, 0.5642, 0.5552, 0.5435, 0.5542],
       device='cuda:0') torch.Size([16])
percent tensor([0.6064, 0.6067, 0.5929, 0.6476, 0.6647, 0.6511, 0.6440, 0.6839, 0.5817,
        0.5347, 0.5319, 0.5974, 0.5493, 0.6204, 0.6811, 0.6010],
       device='cuda:0') torch.Size([16])
percent tensor([0.7207, 0.6658, 0.6933, 0.7022, 0.7077, 0.7043, 0.7120, 0.7102, 0.6849,
        0.6882, 0.6984, 0.6722, 0.6602, 0.7060, 0.7169, 0.7044],
       device='cuda:0') torch.Size([16])
percent tensor([0.5497, 0.5818, 0.5848, 0.6186, 0.5939, 0.5795, 0.5740, 0.5694, 0.6063,
        0.5746, 0.5754, 0.6273, 0.5566, 0.6195, 0.5644, 0.5705],
       device='cuda:0') torch.Size([16])
percent tensor([0.6127, 0.6475, 0.6704, 0.7009, 0.6878, 0.6683, 0.6565, 0.6404, 0.6844,
        0.6475, 0.6777, 0.6795, 0.6350, 0.7310, 0.5882, 0.6499],
       device='cuda:0') torch.Size([16])
percent tensor([0.5932, 0.6522, 0.7446, 0.7264, 0.6320, 0.8374, 0.6478, 0.5211, 0.6981,
        0.6676, 0.7128, 0.6368, 0.6652, 0.7258, 0.4343, 0.5933],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9997, 0.9998, 0.9996, 0.9999, 0.9993, 0.9997, 0.9993, 0.9999,
        0.9999, 0.9999, 1.0000, 0.9999, 0.9995, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 145 | Batch_idx: 0 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 145 | Batch_idx: 10 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (93.00%) (1316/1408)
Epoch: 145 | Batch_idx: 20 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (93.00%) (2526/2688)
Epoch: 145 | Batch_idx: 30 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (3736/3968)
Epoch: 145 | Batch_idx: 40 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (4936/5248)
Epoch: 145 | Batch_idx: 50 |  Loss: (0.1629) |  Loss2: (0.0000) | Acc: (93.00%) (6132/6528)
Epoch: 145 | Batch_idx: 60 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (93.00%) (7339/7808)
Epoch: 145 | Batch_idx: 70 |  Loss: (0.1624) |  Loss2: (0.0000) | Acc: (93.00%) (8542/9088)
Epoch: 145 | Batch_idx: 80 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (9753/10368)
Epoch: 145 | Batch_idx: 90 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (10961/11648)
Epoch: 145 | Batch_idx: 100 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (12171/12928)
Epoch: 145 | Batch_idx: 110 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (13358/14208)
Epoch: 145 | Batch_idx: 120 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (14576/15488)
Epoch: 145 | Batch_idx: 130 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (15784/16768)
Epoch: 145 | Batch_idx: 140 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (17001/18048)
Epoch: 145 | Batch_idx: 150 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (18220/19328)
Epoch: 145 | Batch_idx: 160 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (19419/20608)
Epoch: 145 | Batch_idx: 170 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (20639/21888)
Epoch: 145 | Batch_idx: 180 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (21848/23168)
Epoch: 145 | Batch_idx: 190 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (23060/24448)
Epoch: 145 | Batch_idx: 200 |  Loss: (0.1560) |  Loss2: (0.0000) | Acc: (94.00%) (24283/25728)
Epoch: 145 | Batch_idx: 210 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (25492/27008)
Epoch: 145 | Batch_idx: 220 |  Loss: (0.1555) |  Loss2: (0.0000) | Acc: (94.00%) (26715/28288)
Epoch: 145 | Batch_idx: 230 |  Loss: (0.1550) |  Loss2: (0.0000) | Acc: (94.00%) (27938/29568)
Epoch: 145 | Batch_idx: 240 |  Loss: (0.1548) |  Loss2: (0.0000) | Acc: (94.00%) (29150/30848)
Epoch: 145 | Batch_idx: 250 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (30374/32128)
Epoch: 145 | Batch_idx: 260 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (31590/33408)
Epoch: 145 | Batch_idx: 270 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (32805/34688)
Epoch: 145 | Batch_idx: 280 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (34020/35968)
Epoch: 145 | Batch_idx: 290 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (35239/37248)
Epoch: 145 | Batch_idx: 300 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (36460/38528)
Epoch: 145 | Batch_idx: 310 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (37686/39808)
Epoch: 145 | Batch_idx: 320 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (38896/41088)
Epoch: 145 | Batch_idx: 330 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (40122/42368)
Epoch: 145 | Batch_idx: 340 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (41346/43648)
Epoch: 145 | Batch_idx: 350 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (42571/44928)
Epoch: 145 | Batch_idx: 360 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (43790/46208)
Epoch: 145 | Batch_idx: 370 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (45008/47488)
Epoch: 145 | Batch_idx: 380 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (46221/48768)
Epoch: 145 | Batch_idx: 390 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (47397/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_145.pth.tar'
# TEST : Loss: (0.3954) | Acc: (88.00%) (8838/10000)
percent tensor([0.5784, 0.5993, 0.5903, 0.5785, 0.5967, 0.5678, 0.6069, 0.5950, 0.5912,
        0.5929, 0.5866, 0.5978, 0.5835, 0.5986, 0.5866, 0.5782],
       device='cuda:0') torch.Size([16])
percent tensor([0.5527, 0.5461, 0.5401, 0.5372, 0.5411, 0.5231, 0.5517, 0.5466, 0.5503,
        0.5470, 0.5473, 0.5479, 0.5555, 0.5466, 0.5327, 0.5436],
       device='cuda:0') torch.Size([16])
percent tensor([0.6137, 0.6200, 0.5909, 0.6533, 0.6622, 0.6583, 0.6489, 0.6784, 0.5890,
        0.5487, 0.5500, 0.5991, 0.5626, 0.6398, 0.6848, 0.6146],
       device='cuda:0') torch.Size([16])
percent tensor([0.7498, 0.6929, 0.7192, 0.7315, 0.7348, 0.7382, 0.7411, 0.7373, 0.7126,
        0.7152, 0.7260, 0.6986, 0.6875, 0.7332, 0.7479, 0.7360],
       device='cuda:0') torch.Size([16])
percent tensor([0.5394, 0.5633, 0.5865, 0.6175, 0.5939, 0.5795, 0.5593, 0.5669, 0.5942,
        0.5575, 0.5552, 0.6119, 0.5355, 0.6032, 0.5496, 0.5628],
       device='cuda:0') torch.Size([16])
percent tensor([0.6769, 0.7117, 0.7210, 0.7544, 0.7474, 0.7183, 0.7189, 0.7011, 0.7439,
        0.7175, 0.7416, 0.7468, 0.6966, 0.7891, 0.6657, 0.7114],
       device='cuda:0') torch.Size([16])
percent tensor([0.5528, 0.6112, 0.7135, 0.6944, 0.6181, 0.8137, 0.6260, 0.5198, 0.6599,
        0.6316, 0.6882, 0.6159, 0.5976, 0.7077, 0.4129, 0.5620],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9998, 0.9998, 0.9995, 0.9998, 0.9993, 0.9997, 0.9992, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9995, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 146 | Batch_idx: 0 |  Loss: (0.1986) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 146 | Batch_idx: 10 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (95.00%) (1350/1408)
Epoch: 146 | Batch_idx: 20 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (95.00%) (2571/2688)
Epoch: 146 | Batch_idx: 30 |  Loss: (0.1256) |  Loss2: (0.0000) | Acc: (95.00%) (3793/3968)
Epoch: 146 | Batch_idx: 40 |  Loss: (0.1311) |  Loss2: (0.0000) | Acc: (95.00%) (5008/5248)
Epoch: 146 | Batch_idx: 50 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (6239/6528)
Epoch: 146 | Batch_idx: 60 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (7458/7808)
Epoch: 146 | Batch_idx: 70 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (8679/9088)
Epoch: 146 | Batch_idx: 80 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (95.00%) (9886/10368)
Epoch: 146 | Batch_idx: 90 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (11105/11648)
Epoch: 146 | Batch_idx: 100 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (12329/12928)
Epoch: 146 | Batch_idx: 110 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (13554/14208)
Epoch: 146 | Batch_idx: 120 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (14774/15488)
Epoch: 146 | Batch_idx: 130 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (15995/16768)
Epoch: 146 | Batch_idx: 140 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (17222/18048)
Epoch: 146 | Batch_idx: 150 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (18430/19328)
Epoch: 146 | Batch_idx: 160 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (19653/20608)
Epoch: 146 | Batch_idx: 170 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (20879/21888)
Epoch: 146 | Batch_idx: 180 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (22116/23168)
Epoch: 146 | Batch_idx: 190 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (23338/24448)
Epoch: 146 | Batch_idx: 200 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (24541/25728)
Epoch: 146 | Batch_idx: 210 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (25765/27008)
Epoch: 146 | Batch_idx: 220 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (26989/28288)
Epoch: 146 | Batch_idx: 230 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (28214/29568)
Epoch: 146 | Batch_idx: 240 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (29436/30848)
Epoch: 146 | Batch_idx: 250 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (30666/32128)
Epoch: 146 | Batch_idx: 260 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (31886/33408)
Epoch: 146 | Batch_idx: 270 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (33123/34688)
Epoch: 146 | Batch_idx: 280 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (34356/35968)
Epoch: 146 | Batch_idx: 290 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (35576/37248)
Epoch: 146 | Batch_idx: 300 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (36797/38528)
Epoch: 146 | Batch_idx: 310 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (38029/39808)
Epoch: 146 | Batch_idx: 320 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (39245/41088)
Epoch: 146 | Batch_idx: 330 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (40470/42368)
Epoch: 146 | Batch_idx: 340 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (41688/43648)
Epoch: 146 | Batch_idx: 350 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (42890/44928)
Epoch: 146 | Batch_idx: 360 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (44107/46208)
Epoch: 146 | Batch_idx: 370 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (45338/47488)
Epoch: 146 | Batch_idx: 380 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (46573/48768)
Epoch: 146 | Batch_idx: 390 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (47750/50000)
# TEST : Loss: (0.3835) | Acc: (88.00%) (8841/10000)
percent tensor([0.5764, 0.5970, 0.5876, 0.5765, 0.5940, 0.5660, 0.6043, 0.5926, 0.5891,
        0.5906, 0.5847, 0.5952, 0.5815, 0.5966, 0.5844, 0.5762],
       device='cuda:0') torch.Size([16])
percent tensor([0.5546, 0.5486, 0.5422, 0.5388, 0.5438, 0.5251, 0.5542, 0.5490, 0.5528,
        0.5495, 0.5500, 0.5506, 0.5580, 0.5487, 0.5352, 0.5454],
       device='cuda:0') torch.Size([16])
percent tensor([0.6088, 0.6188, 0.5907, 0.6552, 0.6599, 0.6549, 0.6450, 0.6755, 0.5871,
        0.5495, 0.5487, 0.5996, 0.5608, 0.6408, 0.6809, 0.6125],
       device='cuda:0') torch.Size([16])
percent tensor([0.7455, 0.6880, 0.7175, 0.7294, 0.7325, 0.7362, 0.7357, 0.7342, 0.7082,
        0.7100, 0.7206, 0.6929, 0.6815, 0.7285, 0.7439, 0.7314],
       device='cuda:0') torch.Size([16])
percent tensor([0.5530, 0.5716, 0.5992, 0.6301, 0.6062, 0.5978, 0.5713, 0.5811, 0.6039,
        0.5655, 0.5626, 0.6203, 0.5431, 0.6130, 0.5606, 0.5774],
       device='cuda:0') torch.Size([16])
percent tensor([0.6777, 0.7144, 0.7189, 0.7530, 0.7445, 0.7145, 0.7206, 0.7003, 0.7454,
        0.7202, 0.7453, 0.7492, 0.6991, 0.7942, 0.6684, 0.7084],
       device='cuda:0') torch.Size([16])
percent tensor([0.5728, 0.6261, 0.7283, 0.7107, 0.6310, 0.8228, 0.6500, 0.5427, 0.6759,
        0.6423, 0.7069, 0.6397, 0.6141, 0.7214, 0.4229, 0.5854],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9998, 0.9998, 0.9996, 0.9998, 0.9992, 0.9997, 0.9993, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9995, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 147 | Batch_idx: 0 |  Loss: (0.2501) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 147 | Batch_idx: 10 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (1346/1408)
Epoch: 147 | Batch_idx: 20 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (2566/2688)
Epoch: 147 | Batch_idx: 30 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (3794/3968)
Epoch: 147 | Batch_idx: 40 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (5013/5248)
Epoch: 147 | Batch_idx: 50 |  Loss: (0.1267) |  Loss2: (0.0000) | Acc: (95.00%) (6236/6528)
Epoch: 147 | Batch_idx: 60 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (7463/7808)
Epoch: 147 | Batch_idx: 70 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (8697/9088)
Epoch: 147 | Batch_idx: 80 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (9912/10368)
Epoch: 147 | Batch_idx: 90 |  Loss: (0.1255) |  Loss2: (0.0000) | Acc: (95.00%) (11135/11648)
Epoch: 147 | Batch_idx: 100 |  Loss: (0.1255) |  Loss2: (0.0000) | Acc: (95.00%) (12365/12928)
Epoch: 147 | Batch_idx: 110 |  Loss: (0.1255) |  Loss2: (0.0000) | Acc: (95.00%) (13591/14208)
Epoch: 147 | Batch_idx: 120 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (14802/15488)
Epoch: 147 | Batch_idx: 130 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (16023/16768)
Epoch: 147 | Batch_idx: 140 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (17252/18048)
Epoch: 147 | Batch_idx: 150 |  Loss: (0.1267) |  Loss2: (0.0000) | Acc: (95.00%) (18481/19328)
Epoch: 147 | Batch_idx: 160 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (19712/20608)
Epoch: 147 | Batch_idx: 170 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (20947/21888)
Epoch: 147 | Batch_idx: 180 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (22173/23168)
Epoch: 147 | Batch_idx: 190 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (23393/24448)
Epoch: 147 | Batch_idx: 200 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (24629/25728)
Epoch: 147 | Batch_idx: 210 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (25851/27008)
Epoch: 147 | Batch_idx: 220 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (27062/28288)
Epoch: 147 | Batch_idx: 230 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (28277/29568)
Epoch: 147 | Batch_idx: 240 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (29506/30848)
Epoch: 147 | Batch_idx: 250 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (30746/32128)
Epoch: 147 | Batch_idx: 260 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (31969/33408)
Epoch: 147 | Batch_idx: 270 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (33190/34688)
Epoch: 147 | Batch_idx: 280 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (34426/35968)
Epoch: 147 | Batch_idx: 290 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (35652/37248)
Epoch: 147 | Batch_idx: 300 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (36880/38528)
Epoch: 147 | Batch_idx: 310 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (38109/39808)
Epoch: 147 | Batch_idx: 320 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (39334/41088)
Epoch: 147 | Batch_idx: 330 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (40566/42368)
Epoch: 147 | Batch_idx: 340 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (41794/43648)
Epoch: 147 | Batch_idx: 350 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (43023/44928)
Epoch: 147 | Batch_idx: 360 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (44257/46208)
Epoch: 147 | Batch_idx: 370 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (45493/47488)
Epoch: 147 | Batch_idx: 380 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (46724/48768)
Epoch: 147 | Batch_idx: 390 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (47897/50000)
# TEST : Loss: (0.3749) | Acc: (88.00%) (8857/10000)
percent tensor([0.5724, 0.5917, 0.5828, 0.5722, 0.5891, 0.5624, 0.5989, 0.5875, 0.5846,
        0.5857, 0.5803, 0.5903, 0.5772, 0.5913, 0.5798, 0.5721],
       device='cuda:0') torch.Size([16])
percent tensor([0.5558, 0.5503, 0.5442, 0.5400, 0.5460, 0.5265, 0.5560, 0.5510, 0.5547,
        0.5512, 0.5519, 0.5526, 0.5595, 0.5503, 0.5369, 0.5466],
       device='cuda:0') torch.Size([16])
percent tensor([0.6022, 0.6132, 0.5831, 0.6474, 0.6513, 0.6489, 0.6367, 0.6658, 0.5776,
        0.5451, 0.5429, 0.5922, 0.5546, 0.6334, 0.6734, 0.6070],
       device='cuda:0') torch.Size([16])
percent tensor([0.7434, 0.6853, 0.7183, 0.7298, 0.7325, 0.7363, 0.7332, 0.7329, 0.7063,
        0.7075, 0.7176, 0.6901, 0.6780, 0.7258, 0.7419, 0.7293],
       device='cuda:0') torch.Size([16])
percent tensor([0.5584, 0.5749, 0.6026, 0.6326, 0.6091, 0.6055, 0.5747, 0.5844, 0.6063,
        0.5684, 0.5652, 0.6197, 0.5469, 0.6154, 0.5618, 0.5832],
       device='cuda:0') torch.Size([16])
percent tensor([0.6724, 0.7103, 0.7131, 0.7473, 0.7390, 0.7071, 0.7157, 0.6943, 0.7420,
        0.7158, 0.7420, 0.7449, 0.6951, 0.7921, 0.6625, 0.7004],
       device='cuda:0') torch.Size([16])
percent tensor([0.5761, 0.6258, 0.7380, 0.7216, 0.6438, 0.8275, 0.6619, 0.5546, 0.6819,
        0.6408, 0.7124, 0.6491, 0.6112, 0.7251, 0.4273, 0.5994],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9998, 0.9995, 0.9998, 0.9992, 0.9997, 0.9992, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9999, 0.9995, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 148 | Batch_idx: 0 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 148 | Batch_idx: 10 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (96.00%) (1354/1408)
Epoch: 148 | Batch_idx: 20 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (96.00%) (2585/2688)
Epoch: 148 | Batch_idx: 30 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (96.00%) (3815/3968)
Epoch: 148 | Batch_idx: 40 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (5035/5248)
Epoch: 148 | Batch_idx: 50 |  Loss: (0.1190) |  Loss2: (0.0000) | Acc: (95.00%) (6258/6528)
Epoch: 148 | Batch_idx: 60 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (7485/7808)
Epoch: 148 | Batch_idx: 70 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (8723/9088)
Epoch: 148 | Batch_idx: 80 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (9952/10368)
Epoch: 148 | Batch_idx: 90 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (11172/11648)
Epoch: 148 | Batch_idx: 100 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (12401/12928)
Epoch: 148 | Batch_idx: 110 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (13634/14208)
Epoch: 148 | Batch_idx: 120 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (14867/15488)
Epoch: 148 | Batch_idx: 130 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (16091/16768)
Epoch: 148 | Batch_idx: 140 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (17320/18048)
Epoch: 148 | Batch_idx: 150 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (18551/19328)
Epoch: 148 | Batch_idx: 160 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (19779/20608)
Epoch: 148 | Batch_idx: 170 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (21000/21888)
Epoch: 148 | Batch_idx: 180 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (22230/23168)
Epoch: 148 | Batch_idx: 190 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (23458/24448)
Epoch: 148 | Batch_idx: 200 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (24685/25728)
Epoch: 148 | Batch_idx: 210 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (25912/27008)
Epoch: 148 | Batch_idx: 220 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (27129/28288)
Epoch: 148 | Batch_idx: 230 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (28356/29568)
Epoch: 148 | Batch_idx: 240 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (29572/30848)
Epoch: 148 | Batch_idx: 250 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (30786/32128)
Epoch: 148 | Batch_idx: 260 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (32020/33408)
Epoch: 148 | Batch_idx: 270 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (33250/34688)
Epoch: 148 | Batch_idx: 280 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (34466/35968)
Epoch: 148 | Batch_idx: 290 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (35694/37248)
Epoch: 148 | Batch_idx: 300 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (36924/38528)
Epoch: 148 | Batch_idx: 310 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (38155/39808)
Epoch: 148 | Batch_idx: 320 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (39385/41088)
Epoch: 148 | Batch_idx: 330 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (40614/42368)
Epoch: 148 | Batch_idx: 340 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (41846/43648)
Epoch: 148 | Batch_idx: 350 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (43086/44928)
Epoch: 148 | Batch_idx: 360 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (44313/46208)
Epoch: 148 | Batch_idx: 370 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (45543/47488)
Epoch: 148 | Batch_idx: 380 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (46775/48768)
Epoch: 148 | Batch_idx: 390 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (47965/50000)
# TEST : Loss: (0.3704) | Acc: (88.00%) (8865/10000)
percent tensor([0.5751, 0.5948, 0.5853, 0.5745, 0.5920, 0.5648, 0.6020, 0.5902, 0.5875,
        0.5886, 0.5833, 0.5931, 0.5800, 0.5944, 0.5825, 0.5746],
       device='cuda:0') torch.Size([16])
percent tensor([0.5591, 0.5537, 0.5479, 0.5434, 0.5501, 0.5294, 0.5598, 0.5548, 0.5585,
        0.5549, 0.5557, 0.5567, 0.5630, 0.5534, 0.5403, 0.5498],
       device='cuda:0') torch.Size([16])
percent tensor([0.6056, 0.6144, 0.5855, 0.6522, 0.6533, 0.6548, 0.6383, 0.6674, 0.5799,
        0.5471, 0.5455, 0.5947, 0.5547, 0.6383, 0.6762, 0.6107],
       device='cuda:0') torch.Size([16])
percent tensor([0.7360, 0.6771, 0.7119, 0.7229, 0.7256, 0.7303, 0.7246, 0.7256, 0.6991,
        0.6997, 0.7100, 0.6813, 0.6696, 0.7180, 0.7340, 0.7214],
       device='cuda:0') torch.Size([16])
percent tensor([0.5523, 0.5692, 0.5981, 0.6273, 0.6039, 0.6029, 0.5687, 0.5788, 0.6008,
        0.5630, 0.5596, 0.6129, 0.5408, 0.6106, 0.5531, 0.5799],
       device='cuda:0') torch.Size([16])
percent tensor([0.6681, 0.7078, 0.7079, 0.7437, 0.7341, 0.7004, 0.7114, 0.6887, 0.7390,
        0.7130, 0.7400, 0.7421, 0.6918, 0.7908, 0.6589, 0.6940],
       device='cuda:0') torch.Size([16])
percent tensor([0.5636, 0.6170, 0.7324, 0.7197, 0.6405, 0.8214, 0.6581, 0.5505, 0.6767,
        0.6290, 0.7050, 0.6411, 0.5988, 0.7148, 0.4182, 0.5921],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9998, 0.9996, 0.9999, 0.9992, 0.9997, 0.9993, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9995, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 149 | Batch_idx: 0 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 149 | Batch_idx: 10 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (1354/1408)
Epoch: 149 | Batch_idx: 20 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (95.00%) (2580/2688)
Epoch: 149 | Batch_idx: 30 |  Loss: (0.1133) |  Loss2: (0.0000) | Acc: (96.00%) (3813/3968)
Epoch: 149 | Batch_idx: 40 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (95.00%) (5031/5248)
Epoch: 149 | Batch_idx: 50 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (95.00%) (6255/6528)
Epoch: 149 | Batch_idx: 60 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (95.00%) (7483/7808)
Epoch: 149 | Batch_idx: 70 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (95.00%) (8721/9088)
Epoch: 149 | Batch_idx: 80 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (9957/10368)
Epoch: 149 | Batch_idx: 90 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (96.00%) (11185/11648)
Epoch: 149 | Batch_idx: 100 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (96.00%) (12422/12928)
Epoch: 149 | Batch_idx: 110 |  Loss: (0.1185) |  Loss2: (0.0000) | Acc: (96.00%) (13652/14208)
Epoch: 149 | Batch_idx: 120 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (96.00%) (14900/15488)
Epoch: 149 | Batch_idx: 130 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (16131/16768)
Epoch: 149 | Batch_idx: 140 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (96.00%) (17362/18048)
Epoch: 149 | Batch_idx: 150 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (96.00%) (18600/19328)
Epoch: 149 | Batch_idx: 160 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (96.00%) (19851/20608)
Epoch: 149 | Batch_idx: 170 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (21077/21888)
Epoch: 149 | Batch_idx: 180 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (22311/23168)
Epoch: 149 | Batch_idx: 190 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (23543/24448)
Epoch: 149 | Batch_idx: 200 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (24781/25728)
Epoch: 149 | Batch_idx: 210 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (26010/27008)
Epoch: 149 | Batch_idx: 220 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (27236/28288)
Epoch: 149 | Batch_idx: 230 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (28470/29568)
Epoch: 149 | Batch_idx: 240 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (96.00%) (29691/30848)
Epoch: 149 | Batch_idx: 250 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (30921/32128)
Epoch: 149 | Batch_idx: 260 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (32157/33408)
Epoch: 149 | Batch_idx: 270 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (33401/34688)
Epoch: 149 | Batch_idx: 280 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (34627/35968)
Epoch: 149 | Batch_idx: 290 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (35862/37248)
Epoch: 149 | Batch_idx: 300 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (37096/38528)
Epoch: 149 | Batch_idx: 310 |  Loss: (0.1145) |  Loss2: (0.0000) | Acc: (96.00%) (38326/39808)
Epoch: 149 | Batch_idx: 320 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (39557/41088)
Epoch: 149 | Batch_idx: 330 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (40793/42368)
Epoch: 149 | Batch_idx: 340 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (42023/43648)
Epoch: 149 | Batch_idx: 350 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (43257/44928)
Epoch: 149 | Batch_idx: 360 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (44487/46208)
Epoch: 149 | Batch_idx: 370 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (45714/47488)
Epoch: 149 | Batch_idx: 380 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (46950/48768)
Epoch: 149 | Batch_idx: 390 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (48132/50000)
# TEST : Loss: (0.3677) | Acc: (88.00%) (8889/10000)
percent tensor([0.5726, 0.5911, 0.5827, 0.5718, 0.5892, 0.5624, 0.5985, 0.5872, 0.5847,
        0.5854, 0.5802, 0.5902, 0.5773, 0.5908, 0.5794, 0.5718],
       device='cuda:0') torch.Size([16])
percent tensor([0.5584, 0.5526, 0.5470, 0.5424, 0.5493, 0.5293, 0.5588, 0.5539, 0.5579,
        0.5538, 0.5549, 0.5556, 0.5622, 0.5526, 0.5397, 0.5490],
       device='cuda:0') torch.Size([16])
percent tensor([0.6067, 0.6167, 0.5846, 0.6519, 0.6536, 0.6565, 0.6393, 0.6675, 0.5804,
        0.5490, 0.5470, 0.5950, 0.5547, 0.6415, 0.6769, 0.6116],
       device='cuda:0') torch.Size([16])
percent tensor([0.7367, 0.6791, 0.7124, 0.7231, 0.7261, 0.7319, 0.7259, 0.7260, 0.7002,
        0.7009, 0.7117, 0.6822, 0.6713, 0.7197, 0.7352, 0.7225],
       device='cuda:0') torch.Size([16])
percent tensor([0.5584, 0.5758, 0.6022, 0.6305, 0.6081, 0.6084, 0.5747, 0.5832, 0.6063,
        0.5695, 0.5657, 0.6171, 0.5465, 0.6174, 0.5577, 0.5870],
       device='cuda:0') torch.Size([16])
percent tensor([0.6597, 0.6987, 0.7002, 0.7350, 0.7251, 0.6911, 0.7024, 0.6785, 0.7315,
        0.7044, 0.7306, 0.7337, 0.6838, 0.7828, 0.6491, 0.6850],
       device='cuda:0') torch.Size([16])
percent tensor([0.5748, 0.6193, 0.7413, 0.7277, 0.6478, 0.8248, 0.6708, 0.5550, 0.6847,
        0.6356, 0.7095, 0.6457, 0.6034, 0.7160, 0.4258, 0.6062],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9998, 0.9996, 0.9999, 0.9993, 0.9997, 0.9993, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 150 | Batch_idx: 0 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 150 | Batch_idx: 10 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (1356/1408)
Epoch: 150 | Batch_idx: 20 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (2584/2688)
Epoch: 150 | Batch_idx: 30 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (3821/3968)
Epoch: 150 | Batch_idx: 40 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (5051/5248)
Epoch: 150 | Batch_idx: 50 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (6285/6528)
Epoch: 150 | Batch_idx: 60 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (7513/7808)
Epoch: 150 | Batch_idx: 70 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (8740/9088)
Epoch: 150 | Batch_idx: 80 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (96.00%) (9963/10368)
Epoch: 150 | Batch_idx: 90 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (96.00%) (11186/11648)
Epoch: 150 | Batch_idx: 100 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (96.00%) (12414/12928)
Epoch: 150 | Batch_idx: 110 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (13653/14208)
Epoch: 150 | Batch_idx: 120 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (96.00%) (14888/15488)
Epoch: 150 | Batch_idx: 130 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (16113/16768)
Epoch: 150 | Batch_idx: 140 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (96.00%) (17337/18048)
Epoch: 150 | Batch_idx: 150 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (18569/19328)
Epoch: 150 | Batch_idx: 160 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (19795/20608)
Epoch: 150 | Batch_idx: 170 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (96.00%) (21019/21888)
Epoch: 150 | Batch_idx: 180 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (22237/23168)
Epoch: 150 | Batch_idx: 190 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (23447/24448)
Epoch: 150 | Batch_idx: 200 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (24651/25728)
Epoch: 150 | Batch_idx: 210 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (25873/27008)
Epoch: 150 | Batch_idx: 220 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (27094/28288)
Epoch: 150 | Batch_idx: 230 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (28319/29568)
Epoch: 150 | Batch_idx: 240 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (29545/30848)
Epoch: 150 | Batch_idx: 250 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (95.00%) (30764/32128)
Epoch: 150 | Batch_idx: 260 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (95.00%) (31990/33408)
Epoch: 150 | Batch_idx: 270 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (33207/34688)
Epoch: 150 | Batch_idx: 280 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (34417/35968)
Epoch: 150 | Batch_idx: 290 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (35644/37248)
Epoch: 150 | Batch_idx: 300 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (36869/38528)
Epoch: 150 | Batch_idx: 310 |  Loss: (0.1255) |  Loss2: (0.0000) | Acc: (95.00%) (38081/39808)
Epoch: 150 | Batch_idx: 320 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (39306/41088)
Epoch: 150 | Batch_idx: 330 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (40527/42368)
Epoch: 150 | Batch_idx: 340 |  Loss: (0.1258) |  Loss2: (0.0000) | Acc: (95.00%) (41763/43648)
Epoch: 150 | Batch_idx: 350 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (42976/44928)
Epoch: 150 | Batch_idx: 360 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (44199/46208)
Epoch: 150 | Batch_idx: 370 |  Loss: (0.1264) |  Loss2: (0.0000) | Acc: (95.00%) (45421/47488)
Epoch: 150 | Batch_idx: 380 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (46626/48768)
Epoch: 150 | Batch_idx: 390 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (47801/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_150.pth.tar'
# TEST : Loss: (0.4179) | Acc: (87.00%) (8754/10000)
percent tensor([0.5729, 0.5920, 0.5838, 0.5727, 0.5898, 0.5627, 0.5997, 0.5881, 0.5856,
        0.5863, 0.5808, 0.5912, 0.5778, 0.5923, 0.5799, 0.5725],
       device='cuda:0') torch.Size([16])
percent tensor([0.5571, 0.5525, 0.5471, 0.5412, 0.5476, 0.5274, 0.5585, 0.5547, 0.5573,
        0.5537, 0.5548, 0.5546, 0.5618, 0.5532, 0.5392, 0.5485],
       device='cuda:0') torch.Size([16])
percent tensor([0.6032, 0.6205, 0.5831, 0.6508, 0.6581, 0.6611, 0.6432, 0.6707, 0.5822,
        0.5528, 0.5495, 0.6070, 0.5574, 0.6381, 0.6824, 0.6112],
       device='cuda:0') torch.Size([16])
percent tensor([0.7363, 0.6828, 0.7070, 0.7116, 0.7260, 0.7320, 0.7223, 0.7251, 0.7021,
        0.7029, 0.7153, 0.6771, 0.6723, 0.7194, 0.7360, 0.7265],
       device='cuda:0') torch.Size([16])
percent tensor([0.5544, 0.5774, 0.5932, 0.6202, 0.5995, 0.6050, 0.5781, 0.5782, 0.6019,
        0.5696, 0.5629, 0.6141, 0.5476, 0.6219, 0.5481, 0.5884],
       device='cuda:0') torch.Size([16])
percent tensor([0.6530, 0.6984, 0.6973, 0.7320, 0.7180, 0.6737, 0.6963, 0.6777, 0.7259,
        0.7012, 0.7163, 0.7203, 0.6779, 0.7793, 0.6439, 0.6786],
       device='cuda:0') torch.Size([16])
percent tensor([0.5702, 0.6390, 0.7422, 0.7371, 0.6393, 0.8121, 0.6677, 0.5402, 0.6728,
        0.6577, 0.7063, 0.6026, 0.6219, 0.6960, 0.4616, 0.6199],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9999, 0.9997, 0.9999, 0.9994, 0.9996, 0.9993, 0.9998,
        0.9998, 0.9999, 1.0000, 0.9999, 0.9994, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(177.1855, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(818.1518, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(823.8156, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1526.2037, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(482.7249, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2264.9822, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4253.8760, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1376.4491, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6227.5957, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11694.6768, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3874.5417, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16300.8672, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 151 | Batch_idx: 0 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 151 | Batch_idx: 10 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 151 | Batch_idx: 20 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (2557/2688)
Epoch: 151 | Batch_idx: 30 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (3778/3968)
Epoch: 151 | Batch_idx: 40 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (5015/5248)
Epoch: 151 | Batch_idx: 50 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (6234/6528)
Epoch: 151 | Batch_idx: 60 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (7460/7808)
Epoch: 151 | Batch_idx: 70 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (8693/9088)
Epoch: 151 | Batch_idx: 80 |  Loss: (0.1258) |  Loss2: (0.0000) | Acc: (95.00%) (9912/10368)
Epoch: 151 | Batch_idx: 90 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (11153/11648)
Epoch: 151 | Batch_idx: 100 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (12373/12928)
Epoch: 151 | Batch_idx: 110 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (13595/14208)
Epoch: 151 | Batch_idx: 120 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (14814/15488)
Epoch: 151 | Batch_idx: 130 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (16047/16768)
Epoch: 151 | Batch_idx: 140 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (17261/18048)
Epoch: 151 | Batch_idx: 150 |  Loss: (0.1258) |  Loss2: (0.0000) | Acc: (95.00%) (18468/19328)
Epoch: 151 | Batch_idx: 160 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (19678/20608)
Epoch: 151 | Batch_idx: 170 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (20907/21888)
Epoch: 151 | Batch_idx: 180 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (22118/23168)
Epoch: 151 | Batch_idx: 190 |  Loss: (0.1291) |  Loss2: (0.0000) | Acc: (95.00%) (23327/24448)
Epoch: 151 | Batch_idx: 200 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (24554/25728)
Epoch: 151 | Batch_idx: 210 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (25767/27008)
Epoch: 151 | Batch_idx: 220 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (27003/28288)
Epoch: 151 | Batch_idx: 230 |  Loss: (0.1280) |  Loss2: (0.0000) | Acc: (95.00%) (28230/29568)
Epoch: 151 | Batch_idx: 240 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (29455/30848)
Epoch: 151 | Batch_idx: 250 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (30673/32128)
Epoch: 151 | Batch_idx: 260 |  Loss: (0.1279) |  Loss2: (0.0000) | Acc: (95.00%) (31901/33408)
Epoch: 151 | Batch_idx: 270 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (33131/34688)
Epoch: 151 | Batch_idx: 280 |  Loss: (0.1279) |  Loss2: (0.0000) | Acc: (95.00%) (34351/35968)
Epoch: 151 | Batch_idx: 290 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (35581/37248)
Epoch: 151 | Batch_idx: 300 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (36808/38528)
Epoch: 151 | Batch_idx: 310 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (38021/39808)
Epoch: 151 | Batch_idx: 320 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (39240/41088)
Epoch: 151 | Batch_idx: 330 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (40454/42368)
Epoch: 151 | Batch_idx: 340 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (41674/43648)
Epoch: 151 | Batch_idx: 350 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (42910/44928)
Epoch: 151 | Batch_idx: 360 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (44121/46208)
Epoch: 151 | Batch_idx: 370 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (45346/47488)
Epoch: 151 | Batch_idx: 380 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (46555/48768)
Epoch: 151 | Batch_idx: 390 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (47731/50000)
# TEST : Loss: (0.4231) | Acc: (87.00%) (8756/10000)
percent tensor([0.5732, 0.5925, 0.5835, 0.5726, 0.5902, 0.5632, 0.5998, 0.5877, 0.5854,
        0.5860, 0.5811, 0.5910, 0.5777, 0.5921, 0.5804, 0.5723],
       device='cuda:0') torch.Size([16])
percent tensor([0.5579, 0.5529, 0.5510, 0.5438, 0.5513, 0.5281, 0.5598, 0.5554, 0.5571,
        0.5545, 0.5533, 0.5585, 0.5615, 0.5520, 0.5391, 0.5479],
       device='cuda:0') torch.Size([16])
percent tensor([0.6120, 0.6165, 0.5905, 0.6554, 0.6579, 0.6607, 0.6393, 0.6810, 0.5877,
        0.5567, 0.5521, 0.6036, 0.5655, 0.6336, 0.6808, 0.6207],
       device='cuda:0') torch.Size([16])
percent tensor([0.7390, 0.6846, 0.7131, 0.7224, 0.7298, 0.7343, 0.7269, 0.7245, 0.7053,
        0.7087, 0.7227, 0.6852, 0.6749, 0.7260, 0.7362, 0.7298],
       device='cuda:0') torch.Size([16])
percent tensor([0.5484, 0.5763, 0.5774, 0.6109, 0.5953, 0.6005, 0.5739, 0.5746, 0.5995,
        0.5574, 0.5609, 0.5985, 0.5446, 0.6193, 0.5513, 0.5785],
       device='cuda:0') torch.Size([16])
percent tensor([0.6519, 0.7037, 0.7075, 0.7367, 0.7154, 0.6733, 0.7022, 0.6730, 0.7244,
        0.7027, 0.7217, 0.7336, 0.6775, 0.7863, 0.6480, 0.6721],
       device='cuda:0') torch.Size([16])
percent tensor([0.5272, 0.6326, 0.7298, 0.7310, 0.6272, 0.7836, 0.6700, 0.5113, 0.6737,
        0.6336, 0.6802, 0.6125, 0.5904, 0.6860, 0.4295, 0.5525],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9998, 0.9997, 0.9999, 0.9991, 0.9996, 0.9994, 0.9998,
        0.9999, 0.9999, 1.0000, 0.9999, 0.9997, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 152 | Batch_idx: 0 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 152 | Batch_idx: 10 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (95.00%) (1347/1408)
Epoch: 152 | Batch_idx: 20 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (2575/2688)
Epoch: 152 | Batch_idx: 30 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (95.00%) (3805/3968)
Epoch: 152 | Batch_idx: 40 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (95.00%) (5038/5248)
Epoch: 152 | Batch_idx: 50 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (6274/6528)
Epoch: 152 | Batch_idx: 60 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (95.00%) (7494/7808)
Epoch: 152 | Batch_idx: 70 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (8734/9088)
Epoch: 152 | Batch_idx: 80 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (96.00%) (9958/10368)
Epoch: 152 | Batch_idx: 90 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (96.00%) (11192/11648)
Epoch: 152 | Batch_idx: 100 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (12425/12928)
Epoch: 152 | Batch_idx: 110 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (13660/14208)
Epoch: 152 | Batch_idx: 120 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (14879/15488)
Epoch: 152 | Batch_idx: 130 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (96.00%) (16104/16768)
Epoch: 152 | Batch_idx: 140 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (96.00%) (17329/18048)
Epoch: 152 | Batch_idx: 150 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (95.00%) (18554/19328)
Epoch: 152 | Batch_idx: 160 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (95.00%) (19782/20608)
Epoch: 152 | Batch_idx: 170 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (95.00%) (21012/21888)
Epoch: 152 | Batch_idx: 180 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (96.00%) (22245/23168)
Epoch: 152 | Batch_idx: 190 |  Loss: (0.1157) |  Loss2: (0.0000) | Acc: (96.00%) (23472/24448)
Epoch: 152 | Batch_idx: 200 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (24699/25728)
Epoch: 152 | Batch_idx: 210 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (95.00%) (25924/27008)
Epoch: 152 | Batch_idx: 220 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (95.00%) (27149/28288)
Epoch: 152 | Batch_idx: 230 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (95.00%) (28376/29568)
Epoch: 152 | Batch_idx: 240 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (95.00%) (29605/30848)
Epoch: 152 | Batch_idx: 250 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (95.00%) (30837/32128)
Epoch: 152 | Batch_idx: 260 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (95.00%) (32064/33408)
Epoch: 152 | Batch_idx: 270 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (96.00%) (33302/34688)
Epoch: 152 | Batch_idx: 280 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (95.00%) (34525/35968)
Epoch: 152 | Batch_idx: 290 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (95.00%) (35748/37248)
Epoch: 152 | Batch_idx: 300 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (95.00%) (36982/38528)
Epoch: 152 | Batch_idx: 310 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (95.00%) (38207/39808)
Epoch: 152 | Batch_idx: 320 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (95.00%) (39423/41088)
Epoch: 152 | Batch_idx: 330 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (40643/42368)
Epoch: 152 | Batch_idx: 340 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (95.00%) (41866/43648)
Epoch: 152 | Batch_idx: 350 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (95.00%) (43090/44928)
Epoch: 152 | Batch_idx: 360 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (95.00%) (44309/46208)
Epoch: 152 | Batch_idx: 370 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (95.00%) (45537/47488)
Epoch: 152 | Batch_idx: 380 |  Loss: (0.1185) |  Loss2: (0.0000) | Acc: (95.00%) (46750/48768)
Epoch: 152 | Batch_idx: 390 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (47921/50000)
# TEST : Loss: (0.4360) | Acc: (87.00%) (8723/10000)
percent tensor([0.5738, 0.5920, 0.5850, 0.5730, 0.5909, 0.5632, 0.5997, 0.5885, 0.5852,
        0.5863, 0.5807, 0.5918, 0.5780, 0.5903, 0.5802, 0.5723],
       device='cuda:0') torch.Size([16])
percent tensor([0.5598, 0.5536, 0.5537, 0.5459, 0.5534, 0.5294, 0.5603, 0.5575, 0.5587,
        0.5565, 0.5553, 0.5604, 0.5637, 0.5514, 0.5407, 0.5511],
       device='cuda:0') torch.Size([16])
percent tensor([0.5956, 0.6118, 0.5874, 0.6445, 0.6557, 0.6468, 0.6303, 0.6737, 0.5742,
        0.5454, 0.5395, 0.5997, 0.5490, 0.6164, 0.6727, 0.6008],
       device='cuda:0') torch.Size([16])
percent tensor([0.7352, 0.6812, 0.7174, 0.7223, 0.7305, 0.7271, 0.7240, 0.7322, 0.7019,
        0.7000, 0.7152, 0.6872, 0.6733, 0.7217, 0.7334, 0.7233],
       device='cuda:0') torch.Size([16])
percent tensor([0.5533, 0.5747, 0.5849, 0.6145, 0.5964, 0.6034, 0.5700, 0.5714, 0.6045,
        0.5636, 0.5671, 0.5967, 0.5454, 0.6178, 0.5475, 0.5817],
       device='cuda:0') torch.Size([16])
percent tensor([0.6575, 0.7094, 0.7034, 0.7328, 0.7184, 0.6788, 0.6992, 0.6814, 0.7279,
        0.7054, 0.7344, 0.7300, 0.6850, 0.7843, 0.6538, 0.6887],
       device='cuda:0') torch.Size([16])
percent tensor([0.5425, 0.6517, 0.7323, 0.7290, 0.6229, 0.7988, 0.6413, 0.5360, 0.6960,
        0.6631, 0.7162, 0.6224, 0.6237, 0.7121, 0.4442, 0.5998],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9996, 0.9998, 0.9998, 0.9999, 0.9993, 0.9997, 0.9994, 0.9998,
        0.9998, 0.9999, 1.0000, 0.9998, 0.9997, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 153 | Batch_idx: 0 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 153 | Batch_idx: 10 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (1359/1408)
Epoch: 153 | Batch_idx: 20 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (2585/2688)
Epoch: 153 | Batch_idx: 30 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (3817/3968)
Epoch: 153 | Batch_idx: 40 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (5047/5248)
Epoch: 153 | Batch_idx: 50 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (6283/6528)
Epoch: 153 | Batch_idx: 60 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (7513/7808)
Epoch: 153 | Batch_idx: 70 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (8743/9088)
Epoch: 153 | Batch_idx: 80 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (9978/10368)
Epoch: 153 | Batch_idx: 90 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (11221/11648)
Epoch: 153 | Batch_idx: 100 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (12453/12928)
Epoch: 153 | Batch_idx: 110 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (13685/14208)
Epoch: 153 | Batch_idx: 120 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (14907/15488)
Epoch: 153 | Batch_idx: 130 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (16142/16768)
Epoch: 153 | Batch_idx: 140 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (96.00%) (17381/18048)
Epoch: 153 | Batch_idx: 150 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (18616/19328)
Epoch: 153 | Batch_idx: 160 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (19846/20608)
Epoch: 153 | Batch_idx: 170 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (21078/21888)
Epoch: 153 | Batch_idx: 180 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (22312/23168)
Epoch: 153 | Batch_idx: 190 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (23543/24448)
Epoch: 153 | Batch_idx: 200 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (24768/25728)
Epoch: 153 | Batch_idx: 210 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (96.00%) (26004/27008)
Epoch: 153 | Batch_idx: 220 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (27230/28288)
Epoch: 153 | Batch_idx: 230 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (96.00%) (28451/29568)
Epoch: 153 | Batch_idx: 240 |  Loss: (0.1127) |  Loss2: (0.0000) | Acc: (96.00%) (29681/30848)
Epoch: 153 | Batch_idx: 250 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (30905/32128)
Epoch: 153 | Batch_idx: 260 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (32141/33408)
Epoch: 153 | Batch_idx: 270 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (33376/34688)
Epoch: 153 | Batch_idx: 280 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (34609/35968)
Epoch: 153 | Batch_idx: 290 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (35828/37248)
Epoch: 153 | Batch_idx: 300 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (96.00%) (37053/38528)
Epoch: 153 | Batch_idx: 310 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (38287/39808)
Epoch: 153 | Batch_idx: 320 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (39502/41088)
Epoch: 153 | Batch_idx: 330 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (40730/42368)
Epoch: 153 | Batch_idx: 340 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (41965/43648)
Epoch: 153 | Batch_idx: 350 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (43192/44928)
Epoch: 153 | Batch_idx: 360 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (44425/46208)
Epoch: 153 | Batch_idx: 370 |  Loss: (0.1145) |  Loss2: (0.0000) | Acc: (96.00%) (45653/47488)
Epoch: 153 | Batch_idx: 380 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (46882/48768)
Epoch: 153 | Batch_idx: 390 |  Loss: (0.1157) |  Loss2: (0.0000) | Acc: (96.00%) (48055/50000)
# TEST : Loss: (0.3992) | Acc: (88.00%) (8800/10000)
percent tensor([0.5719, 0.5906, 0.5821, 0.5713, 0.5885, 0.5619, 0.5982, 0.5869, 0.5838,
        0.5852, 0.5797, 0.5896, 0.5765, 0.5899, 0.5788, 0.5713],
       device='cuda:0') torch.Size([16])
percent tensor([0.5589, 0.5536, 0.5515, 0.5453, 0.5516, 0.5298, 0.5605, 0.5575, 0.5567,
        0.5560, 0.5541, 0.5590, 0.5621, 0.5528, 0.5410, 0.5508],
       device='cuda:0') torch.Size([16])
percent tensor([0.5950, 0.6128, 0.5839, 0.6438, 0.6535, 0.6432, 0.6362, 0.6746, 0.5710,
        0.5461, 0.5373, 0.6003, 0.5501, 0.6334, 0.6693, 0.5987],
       device='cuda:0') torch.Size([16])
percent tensor([0.7322, 0.6798, 0.7115, 0.7123, 0.7230, 0.7280, 0.7211, 0.7258, 0.7018,
        0.7027, 0.7159, 0.6836, 0.6681, 0.7203, 0.7327, 0.7212],
       device='cuda:0') torch.Size([16])
percent tensor([0.5578, 0.5752, 0.5857, 0.6173, 0.5996, 0.6065, 0.5723, 0.5684, 0.6048,
        0.5688, 0.5683, 0.5990, 0.5520, 0.6161, 0.5471, 0.5864],
       device='cuda:0') torch.Size([16])
percent tensor([0.6613, 0.7077, 0.7055, 0.7343, 0.7258, 0.6864, 0.7093, 0.6749, 0.7255,
        0.7121, 0.7290, 0.7327, 0.6839, 0.7827, 0.6528, 0.6959],
       device='cuda:0') torch.Size([16])
percent tensor([0.6011, 0.6767, 0.7463, 0.7515, 0.6556, 0.8240, 0.6675, 0.5557, 0.7086,
        0.6912, 0.7576, 0.6190, 0.6543, 0.7287, 0.4739, 0.6466],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9997, 0.9999, 0.9999, 0.9999, 0.9993, 0.9997, 0.9998, 0.9998,
        0.9998, 0.9999, 1.0000, 0.9998, 0.9995, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 154 | Batch_idx: 0 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 154 | Batch_idx: 10 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (1346/1408)
Epoch: 154 | Batch_idx: 20 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (2587/2688)
Epoch: 154 | Batch_idx: 30 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (3820/3968)
Epoch: 154 | Batch_idx: 40 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (5055/5248)
Epoch: 154 | Batch_idx: 50 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (6300/6528)
Epoch: 154 | Batch_idx: 60 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (7533/7808)
Epoch: 154 | Batch_idx: 70 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (8768/9088)
Epoch: 154 | Batch_idx: 80 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (10000/10368)
Epoch: 154 | Batch_idx: 90 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (11229/11648)
Epoch: 154 | Batch_idx: 100 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (12461/12928)
Epoch: 154 | Batch_idx: 110 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (13677/14208)
Epoch: 154 | Batch_idx: 120 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (14917/15488)
Epoch: 154 | Batch_idx: 130 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (16145/16768)
Epoch: 154 | Batch_idx: 140 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (17374/18048)
Epoch: 154 | Batch_idx: 150 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (18596/19328)
Epoch: 154 | Batch_idx: 160 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (19827/20608)
Epoch: 154 | Batch_idx: 170 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (21061/21888)
Epoch: 154 | Batch_idx: 180 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (22297/23168)
Epoch: 154 | Batch_idx: 190 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (23528/24448)
Epoch: 154 | Batch_idx: 200 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (24753/25728)
Epoch: 154 | Batch_idx: 210 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (25979/27008)
Epoch: 154 | Batch_idx: 220 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (27214/28288)
Epoch: 154 | Batch_idx: 230 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (28456/29568)
Epoch: 154 | Batch_idx: 240 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (29689/30848)
Epoch: 154 | Batch_idx: 250 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (30919/32128)
Epoch: 154 | Batch_idx: 260 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (96.00%) (32149/33408)
Epoch: 154 | Batch_idx: 270 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (33373/34688)
Epoch: 154 | Batch_idx: 280 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (34607/35968)
Epoch: 154 | Batch_idx: 290 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (35834/37248)
Epoch: 154 | Batch_idx: 300 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (37064/38528)
Epoch: 154 | Batch_idx: 310 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (38297/39808)
Epoch: 154 | Batch_idx: 320 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (39517/41088)
Epoch: 154 | Batch_idx: 330 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (40755/42368)
Epoch: 154 | Batch_idx: 340 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (41980/43648)
Epoch: 154 | Batch_idx: 350 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (96.00%) (43216/44928)
Epoch: 154 | Batch_idx: 360 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (96.00%) (44441/46208)
Epoch: 154 | Batch_idx: 370 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (45675/47488)
Epoch: 154 | Batch_idx: 380 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (46895/48768)
Epoch: 154 | Batch_idx: 390 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (96.00%) (48082/50000)
# TEST : Loss: (0.4006) | Acc: (88.00%) (8817/10000)
percent tensor([0.5726, 0.5909, 0.5836, 0.5720, 0.5904, 0.5631, 0.5989, 0.5869, 0.5844,
        0.5854, 0.5801, 0.5911, 0.5772, 0.5894, 0.5796, 0.5716],
       device='cuda:0') torch.Size([16])
percent tensor([0.5584, 0.5527, 0.5497, 0.5426, 0.5500, 0.5292, 0.5584, 0.5551, 0.5575,
        0.5551, 0.5554, 0.5575, 0.5623, 0.5492, 0.5401, 0.5493],
       device='cuda:0') torch.Size([16])
percent tensor([0.6025, 0.6131, 0.5750, 0.6383, 0.6492, 0.6565, 0.6318, 0.6695, 0.5841,
        0.5388, 0.5409, 0.5903, 0.5585, 0.6411, 0.6738, 0.6068],
       device='cuda:0') torch.Size([16])
percent tensor([0.7331, 0.6807, 0.7139, 0.7187, 0.7261, 0.7312, 0.7230, 0.7263, 0.7028,
        0.7006, 0.7149, 0.6824, 0.6701, 0.7272, 0.7318, 0.7232],
       device='cuda:0') torch.Size([16])
percent tensor([0.5601, 0.5795, 0.5939, 0.6216, 0.6084, 0.6106, 0.5815, 0.5845, 0.6070,
        0.5659, 0.5682, 0.6054, 0.5462, 0.6185, 0.5586, 0.5859],
       device='cuda:0') torch.Size([16])
percent tensor([0.6551, 0.7034, 0.6978, 0.7162, 0.7160, 0.6715, 0.6984, 0.6783, 0.7158,
        0.6987, 0.7235, 0.7184, 0.6771, 0.7783, 0.6465, 0.6739],
       device='cuda:0') torch.Size([16])
percent tensor([0.5885, 0.6644, 0.7329, 0.7117, 0.6579, 0.8124, 0.6558, 0.5282, 0.6595,
        0.6616, 0.7127, 0.5739, 0.6336, 0.7011, 0.4563, 0.6031],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9999, 0.9998, 0.9998, 0.9994, 0.9997, 0.9995, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9998, 0.9995, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 155 | Batch_idx: 0 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 155 | Batch_idx: 10 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (1354/1408)
Epoch: 155 | Batch_idx: 20 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (95.00%) (2579/2688)
Epoch: 155 | Batch_idx: 30 |  Loss: (0.1165) |  Loss2: (0.0000) | Acc: (95.00%) (3799/3968)
Epoch: 155 | Batch_idx: 40 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (95.00%) (5029/5248)
Epoch: 155 | Batch_idx: 50 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (95.00%) (6252/6528)
Epoch: 155 | Batch_idx: 60 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (95.00%) (7462/7808)
Epoch: 155 | Batch_idx: 70 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (8690/9088)
Epoch: 155 | Batch_idx: 80 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (9912/10368)
Epoch: 155 | Batch_idx: 90 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (11129/11648)
Epoch: 155 | Batch_idx: 100 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (12355/12928)
Epoch: 155 | Batch_idx: 110 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (95.00%) (13577/14208)
Epoch: 155 | Batch_idx: 120 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (14801/15488)
Epoch: 155 | Batch_idx: 130 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (95.00%) (16016/16768)
Epoch: 155 | Batch_idx: 140 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (17241/18048)
Epoch: 155 | Batch_idx: 150 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (18481/19328)
Epoch: 155 | Batch_idx: 160 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (19706/20608)
Epoch: 155 | Batch_idx: 170 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (20920/21888)
Epoch: 155 | Batch_idx: 180 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (22151/23168)
Epoch: 155 | Batch_idx: 190 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (23379/24448)
Epoch: 155 | Batch_idx: 200 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (24597/25728)
Epoch: 155 | Batch_idx: 210 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (25817/27008)
Epoch: 155 | Batch_idx: 220 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (27038/28288)
Epoch: 155 | Batch_idx: 230 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (28254/29568)
Epoch: 155 | Batch_idx: 240 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (29483/30848)
Epoch: 155 | Batch_idx: 250 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (30695/32128)
Epoch: 155 | Batch_idx: 260 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (31914/33408)
Epoch: 155 | Batch_idx: 270 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (33155/34688)
Epoch: 155 | Batch_idx: 280 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (34377/35968)
Epoch: 155 | Batch_idx: 290 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (35612/37248)
Epoch: 155 | Batch_idx: 300 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (36842/38528)
Epoch: 155 | Batch_idx: 310 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (38070/39808)
Epoch: 155 | Batch_idx: 320 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (39307/41088)
Epoch: 155 | Batch_idx: 330 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (40537/42368)
Epoch: 155 | Batch_idx: 340 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (41768/43648)
Epoch: 155 | Batch_idx: 350 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (42991/44928)
Epoch: 155 | Batch_idx: 360 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (44227/46208)
Epoch: 155 | Batch_idx: 370 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (45459/47488)
Epoch: 155 | Batch_idx: 380 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (46681/48768)
Epoch: 155 | Batch_idx: 390 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (47861/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_155.pth.tar'
# TEST : Loss: (0.4046) | Acc: (88.00%) (8831/10000)
percent tensor([0.5776, 0.5968, 0.5876, 0.5763, 0.5953, 0.5677, 0.6050, 0.5917, 0.5900,
        0.5905, 0.5858, 0.5959, 0.5823, 0.5957, 0.5849, 0.5766],
       device='cuda:0') torch.Size([16])
percent tensor([0.5514, 0.5451, 0.5393, 0.5318, 0.5397, 0.5217, 0.5506, 0.5457, 0.5485,
        0.5466, 0.5477, 0.5473, 0.5552, 0.5412, 0.5318, 0.5423],
       device='cuda:0') torch.Size([16])
percent tensor([0.5943, 0.6041, 0.5834, 0.6443, 0.6567, 0.6529, 0.6281, 0.6755, 0.5913,
        0.5330, 0.5338, 0.5953, 0.5488, 0.6391, 0.6674, 0.5991],
       device='cuda:0') torch.Size([16])
percent tensor([0.7437, 0.6977, 0.7168, 0.7202, 0.7294, 0.7393, 0.7367, 0.7331, 0.7119,
        0.7152, 0.7312, 0.6925, 0.6876, 0.7392, 0.7453, 0.7342],
       device='cuda:0') torch.Size([16])
percent tensor([0.5532, 0.5767, 0.5851, 0.6076, 0.5957, 0.5946, 0.5765, 0.5678, 0.6009,
        0.5641, 0.5664, 0.6007, 0.5462, 0.6105, 0.5493, 0.5735],
       device='cuda:0') torch.Size([16])
percent tensor([0.6412, 0.6895, 0.6938, 0.7088, 0.7071, 0.6691, 0.6823, 0.6635, 0.7056,
        0.6865, 0.7143, 0.7093, 0.6717, 0.7670, 0.6288, 0.6620],
       device='cuda:0') torch.Size([16])
percent tensor([0.6328, 0.6906, 0.7735, 0.7464, 0.6949, 0.8280, 0.7003, 0.5688, 0.7137,
        0.7010, 0.7495, 0.6450, 0.6672, 0.7258, 0.5063, 0.6290],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9999, 0.9998, 0.9998, 0.9995, 0.9998, 0.9995, 0.9999,
        0.9999, 0.9999, 1.0000, 0.9999, 0.9996, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])


Files already downloaded and verified
USE 1 GPUs!
=> loading checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_155.pth.tar'
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 156 | Batch_idx: 0 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 156 | Batch_idx: 10 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (1357/1408)
Epoch: 156 | Batch_idx: 20 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (2577/2688)
Epoch: 156 | Batch_idx: 30 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (96.00%) (3813/3968)
Epoch: 156 | Batch_idx: 40 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (96.00%) (5040/5248)
Epoch: 156 | Batch_idx: 50 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (6263/6528)
Epoch: 156 | Batch_idx: 60 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (7485/7808)
Epoch: 156 | Batch_idx: 70 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (8715/9088)
Epoch: 156 | Batch_idx: 80 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (9943/10368)
Epoch: 156 | Batch_idx: 90 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (96.00%) (11183/11648)
Epoch: 156 | Batch_idx: 100 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (96.00%) (12411/12928)
Epoch: 156 | Batch_idx: 110 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (95.00%) (13633/14208)
Epoch: 156 | Batch_idx: 120 |  Loss: (0.1169) |  Loss2: (0.0000) | Acc: (96.00%) (14876/15488)
Epoch: 156 | Batch_idx: 130 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (96.00%) (16102/16768)
Epoch: 156 | Batch_idx: 140 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (96.00%) (17347/18048)
Epoch: 156 | Batch_idx: 150 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (18584/19328)
Epoch: 156 | Batch_idx: 160 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (19805/20608)
Epoch: 156 | Batch_idx: 170 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (21046/21888)
Epoch: 156 | Batch_idx: 180 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (22280/23168)
Epoch: 156 | Batch_idx: 190 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (23497/24448)
Epoch: 156 | Batch_idx: 200 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (24723/25728)
Epoch: 156 | Batch_idx: 210 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (25959/27008)
Epoch: 156 | Batch_idx: 220 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (27195/28288)
Epoch: 156 | Batch_idx: 230 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (28426/29568)
Epoch: 156 | Batch_idx: 240 |  Loss: (0.1133) |  Loss2: (0.0000) | Acc: (96.00%) (29669/30848)
Epoch: 156 | Batch_idx: 250 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (30882/32128)
Epoch: 156 | Batch_idx: 260 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (32107/33408)
Epoch: 156 | Batch_idx: 270 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (33335/34688)
Epoch: 156 | Batch_idx: 280 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (34564/35968)
Epoch: 156 | Batch_idx: 290 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (35793/37248)
Epoch: 156 | Batch_idx: 300 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (96.00%) (37018/38528)
Epoch: 156 | Batch_idx: 310 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (38255/39808)
Epoch: 156 | Batch_idx: 320 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (39484/41088)
Epoch: 156 | Batch_idx: 330 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (96.00%) (40715/42368)
Epoch: 156 | Batch_idx: 340 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (41930/43648)
Epoch: 156 | Batch_idx: 350 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (43166/44928)
Epoch: 156 | Batch_idx: 360 |  Loss: (0.1149) |  Loss2: (0.0000) | Acc: (96.00%) (44390/46208)
Epoch: 156 | Batch_idx: 370 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (45622/47488)
Epoch: 156 | Batch_idx: 380 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (46857/48768)
Epoch: 156 | Batch_idx: 390 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (48044/50000)
# TEST : Loss: (0.3899) | Acc: (88.00%) (8873/10000)
percent tensor([0.5705, 0.5890, 0.5802, 0.5695, 0.5873, 0.5614, 0.5968, 0.5839, 0.5825,
        0.5827, 0.5783, 0.5879, 0.5750, 0.5884, 0.5776, 0.5696],
       device='cuda:0') torch.Size([16])
percent tensor([0.5487, 0.5427, 0.5348, 0.5265, 0.5352, 0.5174, 0.5482, 0.5421, 0.5452,
        0.5440, 0.5452, 0.5435, 0.5530, 0.5387, 0.5281, 0.5394],
       device='cuda:0') torch.Size([16])
percent tensor([0.6002, 0.6071, 0.5929, 0.6550, 0.6665, 0.6657, 0.6319, 0.6856, 0.5976,
        0.5357, 0.5347, 0.6021, 0.5516, 0.6419, 0.6758, 0.6074],
       device='cuda:0') torch.Size([16])
percent tensor([0.7471, 0.7030, 0.7169, 0.7184, 0.7289, 0.7405, 0.7404, 0.7335, 0.7130,
        0.7195, 0.7347, 0.6944, 0.6930, 0.7415, 0.7486, 0.7372],
       device='cuda:0') torch.Size([16])
percent tensor([0.5534, 0.5803, 0.5830, 0.6037, 0.5907, 0.5883, 0.5776, 0.5628, 0.6025,
        0.5661, 0.5728, 0.6029, 0.5509, 0.6148, 0.5488, 0.5706],
       device='cuda:0') torch.Size([16])
percent tensor([0.6333, 0.6859, 0.6921, 0.7040, 0.7022, 0.6671, 0.6754, 0.6556, 0.7022,
        0.6797, 0.7123, 0.7057, 0.6706, 0.7662, 0.6168, 0.6544],
       device='cuda:0') torch.Size([16])
percent tensor([0.6158, 0.6746, 0.7716, 0.7443, 0.6927, 0.8194, 0.6848, 0.5637, 0.7031,
        0.6832, 0.7401, 0.6370, 0.6502, 0.7182, 0.4913, 0.6127],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9999, 0.9999, 0.9999, 0.9995, 0.9997, 0.9995, 0.9999,
        0.9998, 0.9999, 1.0000, 0.9999, 0.9995, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 157 | Batch_idx: 0 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 157 | Batch_idx: 10 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 157 | Batch_idx: 20 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (2597/2688)
Epoch: 157 | Batch_idx: 30 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (3832/3968)
Epoch: 157 | Batch_idx: 40 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (5061/5248)
Epoch: 157 | Batch_idx: 50 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (6297/6528)
Epoch: 157 | Batch_idx: 60 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (7532/7808)
Epoch: 157 | Batch_idx: 70 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (8767/9088)
Epoch: 157 | Batch_idx: 80 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (10009/10368)
Epoch: 157 | Batch_idx: 90 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (11252/11648)
Epoch: 157 | Batch_idx: 100 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (12487/12928)
Epoch: 157 | Batch_idx: 110 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (13713/14208)
Epoch: 157 | Batch_idx: 120 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (14933/15488)
Epoch: 157 | Batch_idx: 130 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (16160/16768)
Epoch: 157 | Batch_idx: 140 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (17388/18048)
Epoch: 157 | Batch_idx: 150 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (18615/19328)
Epoch: 157 | Batch_idx: 160 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (19848/20608)
Epoch: 157 | Batch_idx: 170 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (21084/21888)
Epoch: 157 | Batch_idx: 180 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (22321/23168)
Epoch: 157 | Batch_idx: 190 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (23562/24448)
Epoch: 157 | Batch_idx: 200 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (24793/25728)
Epoch: 157 | Batch_idx: 210 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (26032/27008)
Epoch: 157 | Batch_idx: 220 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (27259/28288)
Epoch: 157 | Batch_idx: 230 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (28491/29568)
Epoch: 157 | Batch_idx: 240 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (29725/30848)
Epoch: 157 | Batch_idx: 250 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (30960/32128)
Epoch: 157 | Batch_idx: 260 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (32198/33408)
Epoch: 157 | Batch_idx: 270 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (33419/34688)
Epoch: 157 | Batch_idx: 280 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (34653/35968)
Epoch: 157 | Batch_idx: 290 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (35886/37248)
Epoch: 157 | Batch_idx: 300 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (37120/38528)
Epoch: 157 | Batch_idx: 310 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (38351/39808)
Epoch: 157 | Batch_idx: 320 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (39591/41088)
Epoch: 157 | Batch_idx: 330 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (40820/42368)
Epoch: 157 | Batch_idx: 340 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (42054/43648)
Epoch: 157 | Batch_idx: 350 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (43299/44928)
Epoch: 157 | Batch_idx: 360 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (44532/46208)
Epoch: 157 | Batch_idx: 370 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (45766/47488)
Epoch: 157 | Batch_idx: 380 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (47005/48768)
Epoch: 157 | Batch_idx: 390 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (48184/50000)
# TEST : Loss: (0.3868) | Acc: (88.00%) (8896/10000)
percent tensor([0.5689, 0.5876, 0.5784, 0.5680, 0.5854, 0.5599, 0.5952, 0.5821, 0.5809,
        0.5811, 0.5767, 0.5861, 0.5733, 0.5873, 0.5761, 0.5681],
       device='cuda:0') torch.Size([16])
percent tensor([0.5494, 0.5433, 0.5349, 0.5259, 0.5352, 0.5172, 0.5490, 0.5423, 0.5455,
        0.5445, 0.5457, 0.5437, 0.5538, 0.5389, 0.5284, 0.5398],
       device='cuda:0') torch.Size([16])
percent tensor([0.5915, 0.5945, 0.5923, 0.6544, 0.6634, 0.6613, 0.6213, 0.6839, 0.5908,
        0.5241, 0.5228, 0.5956, 0.5406, 0.6310, 0.6677, 0.5993],
       device='cuda:0') torch.Size([16])
percent tensor([0.7457, 0.7024, 0.7151, 0.7154, 0.7262, 0.7391, 0.7390, 0.7309, 0.7114,
        0.7189, 0.7340, 0.6931, 0.6933, 0.7401, 0.7467, 0.7360],
       device='cuda:0') torch.Size([16])
percent tensor([0.5547, 0.5839, 0.5815, 0.6019, 0.5873, 0.5869, 0.5797, 0.5594, 0.6038,
        0.5676, 0.5770, 0.6034, 0.5531, 0.6189, 0.5507, 0.5689],
       device='cuda:0') torch.Size([16])
percent tensor([0.6338, 0.6889, 0.6942, 0.7055, 0.7030, 0.6686, 0.6758, 0.6552, 0.7041,
        0.6809, 0.7154, 0.7068, 0.6738, 0.7683, 0.6154, 0.6540],
       device='cuda:0') torch.Size([16])
percent tensor([0.6276, 0.6814, 0.7776, 0.7507, 0.7044, 0.8176, 0.6955, 0.5748, 0.7122,
        0.6946, 0.7521, 0.6535, 0.6573, 0.7268, 0.5039, 0.6212],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9999, 0.9998, 0.9999, 0.9995, 0.9997, 0.9995, 0.9999,
        0.9998, 0.9999, 1.0000, 0.9999, 0.9995, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 158 | Batch_idx: 0 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 158 | Batch_idx: 10 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 158 | Batch_idx: 20 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (97.00%) (2608/2688)
Epoch: 158 | Batch_idx: 30 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (3837/3968)
Epoch: 158 | Batch_idx: 40 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (5065/5248)
Epoch: 158 | Batch_idx: 50 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (6312/6528)
Epoch: 158 | Batch_idx: 60 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (7539/7808)
Epoch: 158 | Batch_idx: 70 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (8780/9088)
Epoch: 158 | Batch_idx: 80 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (10018/10368)
Epoch: 158 | Batch_idx: 90 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (11245/11648)
Epoch: 158 | Batch_idx: 100 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (12482/12928)
Epoch: 158 | Batch_idx: 110 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (13713/14208)
Epoch: 158 | Batch_idx: 120 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (14947/15488)
Epoch: 158 | Batch_idx: 130 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (16181/16768)
Epoch: 158 | Batch_idx: 140 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (17397/18048)
Epoch: 158 | Batch_idx: 150 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (18632/19328)
Epoch: 158 | Batch_idx: 160 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (19874/20608)
Epoch: 158 | Batch_idx: 170 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (21109/21888)
Epoch: 158 | Batch_idx: 180 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (22355/23168)
Epoch: 158 | Batch_idx: 190 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (23585/24448)
Epoch: 158 | Batch_idx: 200 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (24798/25728)
Epoch: 158 | Batch_idx: 210 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (26032/27008)
Epoch: 158 | Batch_idx: 220 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (27274/28288)
Epoch: 158 | Batch_idx: 230 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (28494/29568)
Epoch: 158 | Batch_idx: 240 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (29721/30848)
Epoch: 158 | Batch_idx: 250 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (30959/32128)
Epoch: 158 | Batch_idx: 260 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (32195/33408)
Epoch: 158 | Batch_idx: 270 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (33433/34688)
Epoch: 158 | Batch_idx: 280 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (34680/35968)
Epoch: 158 | Batch_idx: 290 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (35917/37248)
Epoch: 158 | Batch_idx: 300 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (37152/38528)
Epoch: 158 | Batch_idx: 310 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (38398/39808)
Epoch: 158 | Batch_idx: 320 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (39625/41088)
Epoch: 158 | Batch_idx: 330 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (40854/42368)
Epoch: 158 | Batch_idx: 340 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (42088/43648)
Epoch: 158 | Batch_idx: 350 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (43330/44928)
Epoch: 158 | Batch_idx: 360 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (44559/46208)
Epoch: 158 | Batch_idx: 370 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (45803/47488)
Epoch: 158 | Batch_idx: 380 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (47021/48768)
Epoch: 158 | Batch_idx: 390 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (48210/50000)
# TEST : Loss: (0.3846) | Acc: (88.00%) (8894/10000)
percent tensor([0.5718, 0.5916, 0.5816, 0.5711, 0.5888, 0.5627, 0.5992, 0.5857, 0.5840,
        0.5846, 0.5800, 0.5896, 0.5765, 0.5910, 0.5796, 0.5713],
       device='cuda:0') torch.Size([16])
percent tensor([0.5498, 0.5439, 0.5348, 0.5252, 0.5351, 0.5162, 0.5499, 0.5427, 0.5458,
        0.5450, 0.5461, 0.5440, 0.5547, 0.5391, 0.5279, 0.5400],
       device='cuda:0') torch.Size([16])
percent tensor([0.5893, 0.5946, 0.5920, 0.6521, 0.6628, 0.6580, 0.6205, 0.6842, 0.5887,
        0.5232, 0.5205, 0.5949, 0.5419, 0.6260, 0.6672, 0.5978],
       device='cuda:0') torch.Size([16])
percent tensor([0.7452, 0.7015, 0.7128, 0.7122, 0.7237, 0.7387, 0.7376, 0.7282, 0.7095,
        0.7174, 0.7334, 0.6906, 0.6926, 0.7384, 0.7455, 0.7348],
       device='cuda:0') torch.Size([16])
percent tensor([0.5526, 0.5828, 0.5781, 0.5981, 0.5824, 0.5841, 0.5791, 0.5554, 0.6015,
        0.5662, 0.5766, 0.6010, 0.5510, 0.6199, 0.5494, 0.5663],
       device='cuda:0') torch.Size([16])
percent tensor([0.6329, 0.6901, 0.6965, 0.7079, 0.7048, 0.6710, 0.6747, 0.6557, 0.7062,
        0.6811, 0.7177, 0.7079, 0.6750, 0.7701, 0.6129, 0.6535],
       device='cuda:0') torch.Size([16])
percent tensor([0.6224, 0.6760, 0.7769, 0.7497, 0.7097, 0.8143, 0.6919, 0.5771, 0.7119,
        0.6919, 0.7470, 0.6522, 0.6477, 0.7221, 0.5012, 0.6174],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9999, 0.9999, 0.9999, 0.9995, 0.9997, 0.9995, 0.9999,
        0.9998, 0.9999, 1.0000, 0.9999, 0.9995, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 159 | Batch_idx: 0 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 159 | Batch_idx: 10 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (97.00%) (1370/1408)
Epoch: 159 | Batch_idx: 20 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (2606/2688)
Epoch: 159 | Batch_idx: 30 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (97.00%) (3851/3968)
Epoch: 159 | Batch_idx: 40 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (5085/5248)
Epoch: 159 | Batch_idx: 50 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (6323/6528)
Epoch: 159 | Batch_idx: 60 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (7561/7808)
Epoch: 159 | Batch_idx: 70 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (8795/9088)
Epoch: 159 | Batch_idx: 80 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (10043/10368)
Epoch: 159 | Batch_idx: 90 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (11275/11648)
Epoch: 159 | Batch_idx: 100 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (12515/12928)
Epoch: 159 | Batch_idx: 110 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (13748/14208)
Epoch: 159 | Batch_idx: 120 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (14977/15488)
Epoch: 159 | Batch_idx: 130 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (16211/16768)
Epoch: 159 | Batch_idx: 140 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (17450/18048)
Epoch: 159 | Batch_idx: 150 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (18691/19328)
Epoch: 159 | Batch_idx: 160 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (19936/20608)
Epoch: 159 | Batch_idx: 170 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (21173/21888)
Epoch: 159 | Batch_idx: 180 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (22406/23168)
Epoch: 159 | Batch_idx: 190 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (23629/24448)
Epoch: 159 | Batch_idx: 200 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (24869/25728)
Epoch: 159 | Batch_idx: 210 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (26107/27008)
Epoch: 159 | Batch_idx: 220 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (27347/28288)
Epoch: 159 | Batch_idx: 230 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (28575/29568)
Epoch: 159 | Batch_idx: 240 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (29818/30848)
Epoch: 159 | Batch_idx: 250 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (31050/32128)
Epoch: 159 | Batch_idx: 260 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (32290/33408)
Epoch: 159 | Batch_idx: 270 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (33518/34688)
Epoch: 159 | Batch_idx: 280 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (34763/35968)
Epoch: 159 | Batch_idx: 290 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (36007/37248)
Epoch: 159 | Batch_idx: 300 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (37246/38528)
Epoch: 159 | Batch_idx: 310 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (38478/39808)
Epoch: 159 | Batch_idx: 320 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (39714/41088)
Epoch: 159 | Batch_idx: 330 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (40945/42368)
Epoch: 159 | Batch_idx: 340 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (42179/43648)
Epoch: 159 | Batch_idx: 350 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (43418/44928)
Epoch: 159 | Batch_idx: 360 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (44657/46208)
Epoch: 159 | Batch_idx: 370 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (45890/47488)
Epoch: 159 | Batch_idx: 380 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (47131/48768)
Epoch: 159 | Batch_idx: 390 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (48318/50000)
# TEST : Loss: (0.3769) | Acc: (89.00%) (8907/10000)
percent tensor([0.5719, 0.5923, 0.5818, 0.5714, 0.5890, 0.5629, 0.5997, 0.5859, 0.5842,
        0.5850, 0.5804, 0.5899, 0.5767, 0.5917, 0.5801, 0.5715],
       device='cuda:0') torch.Size([16])
percent tensor([0.5477, 0.5419, 0.5324, 0.5223, 0.5326, 0.5136, 0.5480, 0.5405, 0.5436,
        0.5429, 0.5440, 0.5416, 0.5526, 0.5373, 0.5252, 0.5378],
       device='cuda:0') torch.Size([16])
percent tensor([0.5975, 0.6022, 0.5989, 0.6610, 0.6693, 0.6665, 0.6269, 0.6912, 0.5966,
        0.5311, 0.5281, 0.6020, 0.5493, 0.6350, 0.6743, 0.6072],
       device='cuda:0') torch.Size([16])
percent tensor([0.7424, 0.6980, 0.7098, 0.7080, 0.7200, 0.7353, 0.7341, 0.7248, 0.7061,
        0.7141, 0.7297, 0.6869, 0.6893, 0.7352, 0.7416, 0.7313],
       device='cuda:0') torch.Size([16])
percent tensor([0.5499, 0.5818, 0.5762, 0.5973, 0.5797, 0.5807, 0.5773, 0.5526, 0.6010,
        0.5652, 0.5767, 0.6016, 0.5495, 0.6215, 0.5460, 0.5638],
       device='cuda:0') torch.Size([16])
percent tensor([0.6336, 0.6920, 0.6998, 0.7112, 0.7081, 0.6734, 0.6763, 0.6566, 0.7089,
        0.6832, 0.7215, 0.7113, 0.6781, 0.7734, 0.6133, 0.6548],
       device='cuda:0') torch.Size([16])
percent tensor([0.6273, 0.6835, 0.7811, 0.7528, 0.7126, 0.8138, 0.6956, 0.5735, 0.7179,
        0.6978, 0.7545, 0.6551, 0.6562, 0.7265, 0.5050, 0.6156],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9999, 0.9999, 0.9999, 0.9995, 0.9997, 0.9995, 0.9999,
        0.9998, 0.9999, 1.0000, 0.9999, 0.9995, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 160 | Batch_idx: 0 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 160 | Batch_idx: 10 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 160 | Batch_idx: 20 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (2599/2688)
Epoch: 160 | Batch_idx: 30 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (3835/3968)
Epoch: 160 | Batch_idx: 40 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (5073/5248)
Epoch: 160 | Batch_idx: 50 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (6304/6528)
Epoch: 160 | Batch_idx: 60 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (7533/7808)
Epoch: 160 | Batch_idx: 70 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (8758/9088)
Epoch: 160 | Batch_idx: 80 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (9987/10368)
Epoch: 160 | Batch_idx: 90 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (11221/11648)
Epoch: 160 | Batch_idx: 100 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (12444/12928)
Epoch: 160 | Batch_idx: 110 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (13661/14208)
Epoch: 160 | Batch_idx: 120 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (14890/15488)
Epoch: 160 | Batch_idx: 130 |  Loss: (0.1133) |  Loss2: (0.0000) | Acc: (96.00%) (16118/16768)
Epoch: 160 | Batch_idx: 140 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (17346/18048)
Epoch: 160 | Batch_idx: 150 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (18585/19328)
Epoch: 160 | Batch_idx: 160 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (19813/20608)
Epoch: 160 | Batch_idx: 170 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (21045/21888)
Epoch: 160 | Batch_idx: 180 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (22274/23168)
Epoch: 160 | Batch_idx: 190 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (23513/24448)
Epoch: 160 | Batch_idx: 200 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (24751/25728)
Epoch: 160 | Batch_idx: 210 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (96.00%) (25990/27008)
Epoch: 160 | Batch_idx: 220 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (27217/28288)
Epoch: 160 | Batch_idx: 230 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (96.00%) (28448/29568)
Epoch: 160 | Batch_idx: 240 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (29683/30848)
Epoch: 160 | Batch_idx: 250 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (30906/32128)
Epoch: 160 | Batch_idx: 260 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (32133/33408)
Epoch: 160 | Batch_idx: 270 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (33361/34688)
Epoch: 160 | Batch_idx: 280 |  Loss: (0.1133) |  Loss2: (0.0000) | Acc: (96.00%) (34580/35968)
Epoch: 160 | Batch_idx: 290 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (35810/37248)
Epoch: 160 | Batch_idx: 300 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (37034/38528)
Epoch: 160 | Batch_idx: 310 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (38253/39808)
Epoch: 160 | Batch_idx: 320 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (39480/41088)
Epoch: 160 | Batch_idx: 330 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (40699/42368)
Epoch: 160 | Batch_idx: 340 |  Loss: (0.1149) |  Loss2: (0.0000) | Acc: (96.00%) (41927/43648)
Epoch: 160 | Batch_idx: 350 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (43155/44928)
Epoch: 160 | Batch_idx: 360 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (44383/46208)
Epoch: 160 | Batch_idx: 370 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (45617/47488)
Epoch: 160 | Batch_idx: 380 |  Loss: (0.1145) |  Loss2: (0.0000) | Acc: (96.00%) (46839/48768)
Epoch: 160 | Batch_idx: 390 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (48026/50000)
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type _Gate. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_160.pth.tar'
# TEST : Loss: (0.3976) | Acc: (88.00%) (8812/10000)
percent tensor([0.5717, 0.5919, 0.5830, 0.5724, 0.5888, 0.5630, 0.5990, 0.5869, 0.5838,
        0.5852, 0.5801, 0.5899, 0.5765, 0.5911, 0.5800, 0.5721],
       device='cuda:0') torch.Size([16])
percent tensor([0.5477, 0.5413, 0.5365, 0.5250, 0.5354, 0.5143, 0.5481, 0.5423, 0.5440,
        0.5439, 0.5434, 0.5440, 0.5529, 0.5371, 0.5253, 0.5379],
       device='cuda:0') torch.Size([16])
percent tensor([0.5996, 0.6031, 0.6037, 0.6675, 0.6686, 0.6678, 0.6253, 0.6880, 0.5830,
        0.5359, 0.5254, 0.6050, 0.5477, 0.6237, 0.6791, 0.6105],
       device='cuda:0') torch.Size([16])
percent tensor([0.7450, 0.6932, 0.7071, 0.7054, 0.7199, 0.7374, 0.7293, 0.7190, 0.7062,
        0.7117, 0.7276, 0.6851, 0.6896, 0.7263, 0.7409, 0.7314],
       device='cuda:0') torch.Size([16])
percent tensor([0.5467, 0.5818, 0.5754, 0.6014, 0.5757, 0.5743, 0.5764, 0.5586, 0.6010,
        0.5650, 0.5744, 0.6018, 0.5502, 0.6148, 0.5451, 0.5660],
       device='cuda:0') torch.Size([16])
percent tensor([0.6173, 0.6959, 0.7079, 0.7285, 0.7133, 0.6621, 0.6864, 0.6515, 0.7179,
        0.6835, 0.7253, 0.7245, 0.6801, 0.7712, 0.6073, 0.6464],
       device='cuda:0') torch.Size([16])
percent tensor([0.5848, 0.6736, 0.7942, 0.7776, 0.6950, 0.8060, 0.6861, 0.5630, 0.7140,
        0.6722, 0.7463, 0.6637, 0.6380, 0.6678, 0.4755, 0.6001],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9999, 0.9999, 0.9999, 0.9994, 0.9997, 0.9996, 0.9998,
        0.9998, 0.9999, 1.0000, 0.9998, 0.9995, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(177.7907, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(820.4592, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(827.3372, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1527.6284, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(481.9097, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2273.6628, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4257.4385, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1373.7377, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6250.1455, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11678.4521, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3865.5620, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16261.0439, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 161 | Batch_idx: 0 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 161 | Batch_idx: 10 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (1354/1408)
Epoch: 161 | Batch_idx: 20 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (2581/2688)
Epoch: 161 | Batch_idx: 30 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (3828/3968)
Epoch: 161 | Batch_idx: 40 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (5057/5248)
Epoch: 161 | Batch_idx: 50 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (6284/6528)
Epoch: 161 | Batch_idx: 60 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (7519/7808)
Epoch: 161 | Batch_idx: 70 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (8763/9088)
Epoch: 161 | Batch_idx: 80 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (9987/10368)
Epoch: 161 | Batch_idx: 90 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (11227/11648)
Epoch: 161 | Batch_idx: 100 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (12464/12928)
Epoch: 161 | Batch_idx: 110 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (13690/14208)
Epoch: 161 | Batch_idx: 120 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (14928/15488)
Epoch: 161 | Batch_idx: 130 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (16169/16768)
Epoch: 161 | Batch_idx: 140 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (17401/18048)
Epoch: 161 | Batch_idx: 150 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (18632/19328)
Epoch: 161 | Batch_idx: 160 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (19873/20608)
Epoch: 161 | Batch_idx: 170 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (21115/21888)
Epoch: 161 | Batch_idx: 180 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (22336/23168)
Epoch: 161 | Batch_idx: 190 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (23562/24448)
Epoch: 161 | Batch_idx: 200 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (24788/25728)
Epoch: 161 | Batch_idx: 210 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (26018/27008)
Epoch: 161 | Batch_idx: 220 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (27237/28288)
Epoch: 161 | Batch_idx: 230 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (28475/29568)
Epoch: 161 | Batch_idx: 240 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (29711/30848)
Epoch: 161 | Batch_idx: 250 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (30945/32128)
Epoch: 161 | Batch_idx: 260 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (32184/33408)
Epoch: 161 | Batch_idx: 270 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (33418/34688)
Epoch: 161 | Batch_idx: 280 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (34646/35968)
Epoch: 161 | Batch_idx: 290 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (35875/37248)
Epoch: 161 | Batch_idx: 300 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (37104/38528)
Epoch: 161 | Batch_idx: 310 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (96.00%) (38318/39808)
Epoch: 161 | Batch_idx: 320 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (39545/41088)
Epoch: 161 | Batch_idx: 330 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (40782/42368)
Epoch: 161 | Batch_idx: 340 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (42012/43648)
Epoch: 161 | Batch_idx: 350 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (43246/44928)
Epoch: 161 | Batch_idx: 360 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (44467/46208)
Epoch: 161 | Batch_idx: 370 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (45700/47488)
Epoch: 161 | Batch_idx: 380 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (96.00%) (46911/48768)
Epoch: 161 | Batch_idx: 390 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (96.00%) (48099/50000)
# TEST : Loss: (0.4070) | Acc: (88.00%) (8880/10000)
percent tensor([0.5721, 0.5916, 0.5822, 0.5718, 0.5883, 0.5633, 0.5989, 0.5870, 0.5840,
        0.5846, 0.5801, 0.5892, 0.5770, 0.5912, 0.5799, 0.5723],
       device='cuda:0') torch.Size([16])
percent tensor([0.5464, 0.5432, 0.5343, 0.5277, 0.5331, 0.5137, 0.5487, 0.5439, 0.5431,
        0.5438, 0.5424, 0.5425, 0.5527, 0.5419, 0.5264, 0.5380],
       device='cuda:0') torch.Size([16])
percent tensor([0.6011, 0.6050, 0.6000, 0.6774, 0.6710, 0.6700, 0.6292, 0.6897, 0.5815,
        0.5381, 0.5305, 0.6027, 0.5480, 0.6349, 0.6797, 0.6157],
       device='cuda:0') torch.Size([16])
percent tensor([0.7419, 0.7022, 0.7117, 0.7116, 0.7236, 0.7282, 0.7383, 0.7261, 0.7085,
        0.7164, 0.7300, 0.6900, 0.6929, 0.7342, 0.7429, 0.7321],
       device='cuda:0') torch.Size([16])
percent tensor([0.5539, 0.5765, 0.5744, 0.5876, 0.5766, 0.5852, 0.5714, 0.5518, 0.5995,
        0.5677, 0.5737, 0.5976, 0.5473, 0.6175, 0.5411, 0.5688],
       device='cuda:0') torch.Size([16])
percent tensor([0.6270, 0.6855, 0.6965, 0.7324, 0.7099, 0.6851, 0.6732, 0.6484, 0.7152,
        0.6880, 0.7252, 0.7190, 0.6752, 0.7689, 0.6049, 0.6647],
       device='cuda:0') torch.Size([16])
percent tensor([0.5929, 0.6949, 0.7744, 0.7674, 0.7058, 0.8246, 0.6798, 0.5536, 0.7004,
        0.6970, 0.7631, 0.6661, 0.6590, 0.7067, 0.4835, 0.6195],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9999, 0.9999, 1.0000, 0.9995, 0.9996, 0.9996, 0.9998,
        0.9999, 0.9999, 1.0000, 0.9998, 0.9994, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 162 | Batch_idx: 0 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 162 | Batch_idx: 10 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (1356/1408)
Epoch: 162 | Batch_idx: 20 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (2588/2688)
Epoch: 162 | Batch_idx: 30 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (3832/3968)
Epoch: 162 | Batch_idx: 40 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (5067/5248)
Epoch: 162 | Batch_idx: 50 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (6317/6528)
Epoch: 162 | Batch_idx: 60 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (7557/7808)
Epoch: 162 | Batch_idx: 70 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (8791/9088)
Epoch: 162 | Batch_idx: 80 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (10015/10368)
Epoch: 162 | Batch_idx: 90 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (11247/11648)
Epoch: 162 | Batch_idx: 100 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (12469/12928)
Epoch: 162 | Batch_idx: 110 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (13706/14208)
Epoch: 162 | Batch_idx: 120 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (14937/15488)
Epoch: 162 | Batch_idx: 130 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (16175/16768)
Epoch: 162 | Batch_idx: 140 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (17408/18048)
Epoch: 162 | Batch_idx: 150 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (18641/19328)
Epoch: 162 | Batch_idx: 160 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (19877/20608)
Epoch: 162 | Batch_idx: 170 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (21116/21888)
Epoch: 162 | Batch_idx: 180 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (22346/23168)
Epoch: 162 | Batch_idx: 190 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (23581/24448)
Epoch: 162 | Batch_idx: 200 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (24812/25728)
Epoch: 162 | Batch_idx: 210 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (26041/27008)
Epoch: 162 | Batch_idx: 220 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (27274/28288)
Epoch: 162 | Batch_idx: 230 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (28514/29568)
Epoch: 162 | Batch_idx: 240 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (29739/30848)
Epoch: 162 | Batch_idx: 250 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (30978/32128)
Epoch: 162 | Batch_idx: 260 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (32215/33408)
Epoch: 162 | Batch_idx: 270 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (33449/34688)
Epoch: 162 | Batch_idx: 280 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (34682/35968)
Epoch: 162 | Batch_idx: 290 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (35919/37248)
Epoch: 162 | Batch_idx: 300 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (37154/38528)
Epoch: 162 | Batch_idx: 310 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (38394/39808)
Epoch: 162 | Batch_idx: 320 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (39628/41088)
Epoch: 162 | Batch_idx: 330 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (40878/42368)
Epoch: 162 | Batch_idx: 340 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (42122/43648)
Epoch: 162 | Batch_idx: 350 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (43355/44928)
Epoch: 162 | Batch_idx: 360 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (44583/46208)
Epoch: 162 | Batch_idx: 370 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (45815/47488)
Epoch: 162 | Batch_idx: 380 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (47045/48768)
Epoch: 162 | Batch_idx: 390 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (48233/50000)
# TEST : Loss: (0.3969) | Acc: (88.00%) (8826/10000)
percent tensor([0.5723, 0.5927, 0.5818, 0.5720, 0.5882, 0.5628, 0.5991, 0.5867, 0.5837,
        0.5853, 0.5806, 0.5894, 0.5773, 0.5912, 0.5803, 0.5723],
       device='cuda:0') torch.Size([16])
percent tensor([0.5477, 0.5405, 0.5389, 0.5247, 0.5364, 0.5146, 0.5482, 0.5445, 0.5443,
        0.5429, 0.5432, 0.5447, 0.5528, 0.5348, 0.5256, 0.5373],
       device='cuda:0') torch.Size([16])
percent tensor([0.5946, 0.6127, 0.5907, 0.6634, 0.6651, 0.6591, 0.6295, 0.6837, 0.5760,
        0.5405, 0.5241, 0.5968, 0.5457, 0.6412, 0.6767, 0.6109],
       device='cuda:0') torch.Size([16])
percent tensor([0.7409, 0.6932, 0.7030, 0.7115, 0.7191, 0.7303, 0.7305, 0.7199, 0.7004,
        0.7103, 0.7235, 0.6860, 0.6847, 0.7302, 0.7405, 0.7275],
       device='cuda:0') torch.Size([16])
percent tensor([0.5503, 0.5896, 0.5916, 0.5993, 0.5893, 0.5761, 0.5857, 0.5675, 0.6038,
        0.5722, 0.5783, 0.6061, 0.5584, 0.6176, 0.5478, 0.5716],
       device='cuda:0') torch.Size([16])
percent tensor([0.6160, 0.7037, 0.7101, 0.7240, 0.7082, 0.6709, 0.6894, 0.6492, 0.7195,
        0.7040, 0.7268, 0.7229, 0.6867, 0.7679, 0.6004, 0.6648],
       device='cuda:0') torch.Size([16])
percent tensor([0.5643, 0.6919, 0.7833, 0.7672, 0.6812, 0.8215, 0.6852, 0.5535, 0.7049,
        0.7040, 0.7488, 0.6423, 0.6768, 0.6757, 0.4817, 0.6301],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9998, 0.9999, 0.9996, 0.9996, 0.9995, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9993, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 163 | Batch_idx: 0 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 163 | Batch_idx: 10 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (97.00%) (1366/1408)
Epoch: 163 | Batch_idx: 20 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (2605/2688)
Epoch: 163 | Batch_idx: 30 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (3833/3968)
Epoch: 163 | Batch_idx: 40 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (5081/5248)
Epoch: 163 | Batch_idx: 50 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (6319/6528)
Epoch: 163 | Batch_idx: 60 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (7548/7808)
Epoch: 163 | Batch_idx: 70 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (8796/9088)
Epoch: 163 | Batch_idx: 80 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (10026/10368)
Epoch: 163 | Batch_idx: 90 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (11266/11648)
Epoch: 163 | Batch_idx: 100 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (12499/12928)
Epoch: 163 | Batch_idx: 110 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (13725/14208)
Epoch: 163 | Batch_idx: 120 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (14958/15488)
Epoch: 163 | Batch_idx: 130 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (16193/16768)
Epoch: 163 | Batch_idx: 140 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (17422/18048)
Epoch: 163 | Batch_idx: 150 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (18658/19328)
Epoch: 163 | Batch_idx: 160 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (19890/20608)
Epoch: 163 | Batch_idx: 170 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (21126/21888)
Epoch: 163 | Batch_idx: 180 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (22359/23168)
Epoch: 163 | Batch_idx: 190 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (23585/24448)
Epoch: 163 | Batch_idx: 200 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (24816/25728)
Epoch: 163 | Batch_idx: 210 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (26049/27008)
Epoch: 163 | Batch_idx: 220 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (27271/28288)
Epoch: 163 | Batch_idx: 230 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (28510/29568)
Epoch: 163 | Batch_idx: 240 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (29748/30848)
Epoch: 163 | Batch_idx: 250 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (30967/32128)
Epoch: 163 | Batch_idx: 260 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (32191/33408)
Epoch: 163 | Batch_idx: 270 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (33420/34688)
Epoch: 163 | Batch_idx: 280 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (34653/35968)
Epoch: 163 | Batch_idx: 290 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (35892/37248)
Epoch: 163 | Batch_idx: 300 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (37117/38528)
Epoch: 163 | Batch_idx: 310 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (38338/39808)
Epoch: 163 | Batch_idx: 320 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (39572/41088)
Epoch: 163 | Batch_idx: 330 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (40800/42368)
Epoch: 163 | Batch_idx: 340 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (42022/43648)
Epoch: 163 | Batch_idx: 350 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (43270/44928)
Epoch: 163 | Batch_idx: 360 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (44497/46208)
Epoch: 163 | Batch_idx: 370 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (45717/47488)
Epoch: 163 | Batch_idx: 380 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (46943/48768)
Epoch: 163 | Batch_idx: 390 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (48136/50000)
# TEST : Loss: (0.4318) | Acc: (87.00%) (8777/10000)
percent tensor([0.5722, 0.5922, 0.5817, 0.5713, 0.5883, 0.5633, 0.5992, 0.5861, 0.5845,
        0.5853, 0.5808, 0.5897, 0.5773, 0.5915, 0.5800, 0.5721],
       device='cuda:0') torch.Size([16])
percent tensor([0.5461, 0.5409, 0.5326, 0.5218, 0.5317, 0.5142, 0.5478, 0.5409, 0.5418,
        0.5418, 0.5422, 0.5418, 0.5531, 0.5374, 0.5243, 0.5359],
       device='cuda:0') torch.Size([16])
percent tensor([0.6009, 0.6091, 0.6012, 0.6652, 0.6734, 0.6652, 0.6340, 0.6886, 0.5834,
        0.5395, 0.5272, 0.6034, 0.5517, 0.6306, 0.6827, 0.6112],
       device='cuda:0') torch.Size([16])
percent tensor([0.7416, 0.6925, 0.7159, 0.7133, 0.7211, 0.7263, 0.7324, 0.7263, 0.7069,
        0.7161, 0.7293, 0.6895, 0.6890, 0.7274, 0.7372, 0.7285],
       device='cuda:0') torch.Size([16])
percent tensor([0.5474, 0.5837, 0.5688, 0.6012, 0.5809, 0.5880, 0.5733, 0.5525, 0.5989,
        0.5604, 0.5743, 0.5992, 0.5479, 0.6216, 0.5455, 0.5679],
       device='cuda:0') torch.Size([16])
percent tensor([0.6223, 0.6850, 0.6970, 0.7266, 0.7084, 0.6669, 0.6770, 0.6451, 0.7153,
        0.6737, 0.7120, 0.7119, 0.6713, 0.7682, 0.6021, 0.6541],
       device='cuda:0') torch.Size([16])
percent tensor([0.5865, 0.6710, 0.7861, 0.7815, 0.6889, 0.8035, 0.6960, 0.5728, 0.7245,
        0.6762, 0.7102, 0.6309, 0.6496, 0.6588, 0.4682, 0.6025],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9999, 0.9998, 1.0000, 0.9993, 0.9997, 0.9996, 0.9997,
        0.9998, 0.9999, 1.0000, 0.9999, 0.9992, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 164 | Batch_idx: 0 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 164 | Batch_idx: 10 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 164 | Batch_idx: 20 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (2595/2688)
Epoch: 164 | Batch_idx: 30 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (3840/3968)
Epoch: 164 | Batch_idx: 40 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (5074/5248)
Epoch: 164 | Batch_idx: 50 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (6315/6528)
Epoch: 164 | Batch_idx: 60 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (7558/7808)
Epoch: 164 | Batch_idx: 70 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (8802/9088)
Epoch: 164 | Batch_idx: 80 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (10037/10368)
Epoch: 164 | Batch_idx: 90 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (11273/11648)
Epoch: 164 | Batch_idx: 100 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (12513/12928)
Epoch: 164 | Batch_idx: 110 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (13753/14208)
Epoch: 164 | Batch_idx: 120 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (14993/15488)
Epoch: 164 | Batch_idx: 130 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (16232/16768)
Epoch: 164 | Batch_idx: 140 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (17480/18048)
Epoch: 164 | Batch_idx: 150 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (18700/19328)
Epoch: 164 | Batch_idx: 160 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (19938/20608)
Epoch: 164 | Batch_idx: 170 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (21162/21888)
Epoch: 164 | Batch_idx: 180 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (22404/23168)
Epoch: 164 | Batch_idx: 190 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (23634/24448)
Epoch: 164 | Batch_idx: 200 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (24853/25728)
Epoch: 164 | Batch_idx: 210 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (26085/27008)
Epoch: 164 | Batch_idx: 220 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (27313/28288)
Epoch: 164 | Batch_idx: 230 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (28551/29568)
Epoch: 164 | Batch_idx: 240 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (29776/30848)
Epoch: 164 | Batch_idx: 250 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (31008/32128)
Epoch: 164 | Batch_idx: 260 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (32233/33408)
Epoch: 164 | Batch_idx: 270 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (33470/34688)
Epoch: 164 | Batch_idx: 280 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (34712/35968)
Epoch: 164 | Batch_idx: 290 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (35939/37248)
Epoch: 164 | Batch_idx: 300 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (37161/38528)
Epoch: 164 | Batch_idx: 310 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (38369/39808)
Epoch: 164 | Batch_idx: 320 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (39595/41088)
Epoch: 164 | Batch_idx: 330 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (40837/42368)
Epoch: 164 | Batch_idx: 340 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (42080/43648)
Epoch: 164 | Batch_idx: 350 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (43301/44928)
Epoch: 164 | Batch_idx: 360 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (44548/46208)
Epoch: 164 | Batch_idx: 370 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (45787/47488)
Epoch: 164 | Batch_idx: 380 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (47020/48768)
Epoch: 164 | Batch_idx: 390 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (48201/50000)
# TEST : Loss: (0.4425) | Acc: (87.00%) (8740/10000)
percent tensor([0.5722, 0.5915, 0.5829, 0.5718, 0.5886, 0.5627, 0.5989, 0.5868, 0.5839,
        0.5850, 0.5797, 0.5898, 0.5768, 0.5900, 0.5797, 0.5717],
       device='cuda:0') torch.Size([16])
percent tensor([0.5471, 0.5435, 0.5343, 0.5232, 0.5333, 0.5127, 0.5504, 0.5422, 0.5432,
        0.5449, 0.5443, 0.5446, 0.5539, 0.5400, 0.5263, 0.5369],
       device='cuda:0') torch.Size([16])
percent tensor([0.5931, 0.5975, 0.5980, 0.6609, 0.6675, 0.6650, 0.6222, 0.6841, 0.5734,
        0.5260, 0.5214, 0.5913, 0.5405, 0.6261, 0.6712, 0.6006],
       device='cuda:0') torch.Size([16])
percent tensor([0.7435, 0.6923, 0.7156, 0.7067, 0.7257, 0.7322, 0.7347, 0.7290, 0.7087,
        0.7118, 0.7286, 0.6879, 0.6884, 0.7258, 0.7389, 0.7264],
       device='cuda:0') torch.Size([16])
percent tensor([0.5469, 0.5872, 0.5666, 0.6013, 0.5702, 0.5804, 0.5737, 0.5574, 0.5973,
        0.5656, 0.5729, 0.5941, 0.5524, 0.6260, 0.5526, 0.5706],
       device='cuda:0') torch.Size([16])
percent tensor([0.6292, 0.7017, 0.6955, 0.7234, 0.7089, 0.6765, 0.6928, 0.6617, 0.7191,
        0.6966, 0.7232, 0.7187, 0.6834, 0.7699, 0.6171, 0.6652],
       device='cuda:0') torch.Size([16])
percent tensor([0.5888, 0.7054, 0.7634, 0.7799, 0.6869, 0.8133, 0.7062, 0.5701, 0.7196,
        0.7255, 0.7549, 0.6247, 0.6603, 0.6961, 0.5048, 0.6380],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9997, 0.9999, 0.9995, 0.9995, 0.9995, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9998, 0.9996, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 165 | Batch_idx: 0 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 165 | Batch_idx: 10 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (1362/1408)
Epoch: 165 | Batch_idx: 20 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (2588/2688)
Epoch: 165 | Batch_idx: 30 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (3825/3968)
Epoch: 165 | Batch_idx: 40 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (5053/5248)
Epoch: 165 | Batch_idx: 50 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (6275/6528)
Epoch: 165 | Batch_idx: 60 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (7513/7808)
Epoch: 165 | Batch_idx: 70 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (8735/9088)
Epoch: 165 | Batch_idx: 80 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (9969/10368)
Epoch: 165 | Batch_idx: 90 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (11216/11648)
Epoch: 165 | Batch_idx: 100 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (12460/12928)
Epoch: 165 | Batch_idx: 110 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (13698/14208)
Epoch: 165 | Batch_idx: 120 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (14932/15488)
Epoch: 165 | Batch_idx: 130 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (16164/16768)
Epoch: 165 | Batch_idx: 140 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (17402/18048)
Epoch: 165 | Batch_idx: 150 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (18633/19328)
Epoch: 165 | Batch_idx: 160 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (19865/20608)
Epoch: 165 | Batch_idx: 170 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (21103/21888)
Epoch: 165 | Batch_idx: 180 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (22332/23168)
Epoch: 165 | Batch_idx: 190 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (23577/24448)
Epoch: 165 | Batch_idx: 200 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (24819/25728)
Epoch: 165 | Batch_idx: 210 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (26049/27008)
Epoch: 165 | Batch_idx: 220 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (27284/28288)
Epoch: 165 | Batch_idx: 230 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (28520/29568)
Epoch: 165 | Batch_idx: 240 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (29760/30848)
Epoch: 165 | Batch_idx: 250 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (31009/32128)
Epoch: 165 | Batch_idx: 260 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (32246/33408)
Epoch: 165 | Batch_idx: 270 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (33482/34688)
Epoch: 165 | Batch_idx: 280 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (34691/35968)
Epoch: 165 | Batch_idx: 290 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (35931/37248)
Epoch: 165 | Batch_idx: 300 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (37160/38528)
Epoch: 165 | Batch_idx: 310 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (38405/39808)
Epoch: 165 | Batch_idx: 320 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (39648/41088)
Epoch: 165 | Batch_idx: 330 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (40884/42368)
Epoch: 165 | Batch_idx: 340 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (42126/43648)
Epoch: 165 | Batch_idx: 350 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (43374/44928)
Epoch: 165 | Batch_idx: 360 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (44610/46208)
Epoch: 165 | Batch_idx: 370 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (45850/47488)
Epoch: 165 | Batch_idx: 380 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (47085/48768)
Epoch: 165 | Batch_idx: 390 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (48282/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_165.pth.tar'
# TEST : Loss: (0.3823) | Acc: (89.00%) (8914/10000)
percent tensor([0.5714, 0.5912, 0.5823, 0.5712, 0.5881, 0.5613, 0.5987, 0.5862, 0.5835,
        0.5847, 0.5790, 0.5898, 0.5761, 0.5899, 0.5790, 0.5709],
       device='cuda:0') torch.Size([16])
percent tensor([0.5403, 0.5378, 0.5257, 0.5162, 0.5255, 0.5079, 0.5436, 0.5351, 0.5361,
        0.5382, 0.5375, 0.5371, 0.5471, 0.5352, 0.5205, 0.5308],
       device='cuda:0') torch.Size([16])
percent tensor([0.6072, 0.6080, 0.6141, 0.6769, 0.6869, 0.6774, 0.6366, 0.6975, 0.5889,
        0.5398, 0.5342, 0.6044, 0.5517, 0.6365, 0.6823, 0.6142],
       device='cuda:0') torch.Size([16])
percent tensor([0.7493, 0.7007, 0.7191, 0.7108, 0.7293, 0.7362, 0.7428, 0.7348, 0.7127,
        0.7195, 0.7367, 0.6957, 0.6962, 0.7344, 0.7458, 0.7349],
       device='cuda:0') torch.Size([16])
percent tensor([0.5648, 0.6081, 0.5801, 0.6112, 0.5850, 0.5987, 0.5917, 0.5680, 0.6149,
        0.5860, 0.5926, 0.6139, 0.5739, 0.6448, 0.5677, 0.5878],
       device='cuda:0') torch.Size([16])
percent tensor([0.6280, 0.7004, 0.6922, 0.7266, 0.7107, 0.6805, 0.6896, 0.6587, 0.7165,
        0.6911, 0.7189, 0.7170, 0.6844, 0.7693, 0.6147, 0.6631],
       device='cuda:0') torch.Size([16])
percent tensor([0.5774, 0.6910, 0.7346, 0.7725, 0.6655, 0.7926, 0.6866, 0.5491, 0.7080,
        0.6923, 0.7462, 0.6013, 0.6551, 0.6919, 0.4775, 0.6223],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9999, 0.9997, 0.9999, 0.9995, 0.9996, 0.9995, 0.9999,
        0.9998, 0.9999, 0.9999, 0.9999, 0.9995, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 166 | Batch_idx: 0 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 166 | Batch_idx: 10 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (1357/1408)
Epoch: 166 | Batch_idx: 20 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (2581/2688)
Epoch: 166 | Batch_idx: 30 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (3822/3968)
Epoch: 166 | Batch_idx: 40 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (5059/5248)
Epoch: 166 | Batch_idx: 50 |  Loss: (0.1012) |  Loss2: (0.0000) | Acc: (96.00%) (6292/6528)
Epoch: 166 | Batch_idx: 60 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (7539/7808)
Epoch: 166 | Batch_idx: 70 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (8769/9088)
Epoch: 166 | Batch_idx: 80 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (10010/10368)
Epoch: 166 | Batch_idx: 90 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (11245/11648)
Epoch: 166 | Batch_idx: 100 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (12493/12928)
Epoch: 166 | Batch_idx: 110 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (13726/14208)
Epoch: 166 | Batch_idx: 120 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (14958/15488)
Epoch: 166 | Batch_idx: 130 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (16184/16768)
Epoch: 166 | Batch_idx: 140 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (17427/18048)
Epoch: 166 | Batch_idx: 150 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (18670/19328)
Epoch: 166 | Batch_idx: 160 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (19901/20608)
Epoch: 166 | Batch_idx: 170 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (21124/21888)
Epoch: 166 | Batch_idx: 180 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (22363/23168)
Epoch: 166 | Batch_idx: 190 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (23610/24448)
Epoch: 166 | Batch_idx: 200 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (24838/25728)
Epoch: 166 | Batch_idx: 210 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (26084/27008)
Epoch: 166 | Batch_idx: 220 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (27318/28288)
Epoch: 166 | Batch_idx: 230 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (28554/29568)
Epoch: 166 | Batch_idx: 240 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (29786/30848)
Epoch: 166 | Batch_idx: 250 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (31024/32128)
Epoch: 166 | Batch_idx: 260 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (32266/33408)
Epoch: 166 | Batch_idx: 270 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (33499/34688)
Epoch: 166 | Batch_idx: 280 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (34738/35968)
Epoch: 166 | Batch_idx: 290 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (35980/37248)
Epoch: 166 | Batch_idx: 300 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (37214/38528)
Epoch: 166 | Batch_idx: 310 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (38455/39808)
Epoch: 166 | Batch_idx: 320 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (39695/41088)
Epoch: 166 | Batch_idx: 330 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (40943/42368)
Epoch: 166 | Batch_idx: 340 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (42182/43648)
Epoch: 166 | Batch_idx: 350 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (43421/44928)
Epoch: 166 | Batch_idx: 360 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (44663/46208)
Epoch: 166 | Batch_idx: 370 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (45900/47488)
Epoch: 166 | Batch_idx: 380 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (47143/48768)
Epoch: 166 | Batch_idx: 390 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (48338/50000)
# TEST : Loss: (0.3716) | Acc: (89.00%) (8939/10000)
percent tensor([0.5703, 0.5899, 0.5814, 0.5698, 0.5873, 0.5599, 0.5975, 0.5851, 0.5823,
        0.5836, 0.5777, 0.5890, 0.5750, 0.5882, 0.5777, 0.5694],
       device='cuda:0') torch.Size([16])
percent tensor([0.5362, 0.5342, 0.5218, 0.5118, 0.5213, 0.5037, 0.5396, 0.5310, 0.5321,
        0.5347, 0.5338, 0.5332, 0.5436, 0.5318, 0.5163, 0.5268],
       device='cuda:0') torch.Size([16])
percent tensor([0.6124, 0.6132, 0.6133, 0.6748, 0.6899, 0.6797, 0.6427, 0.6997, 0.5913,
        0.5442, 0.5388, 0.6055, 0.5554, 0.6394, 0.6872, 0.6174],
       device='cuda:0') torch.Size([16])
percent tensor([0.7522, 0.7033, 0.7209, 0.7130, 0.7310, 0.7405, 0.7457, 0.7362, 0.7144,
        0.7219, 0.7389, 0.6975, 0.6983, 0.7374, 0.7485, 0.7383],
       device='cuda:0') torch.Size([16])
percent tensor([0.5588, 0.6031, 0.5738, 0.6057, 0.5787, 0.5940, 0.5835, 0.5608, 0.6091,
        0.5813, 0.5867, 0.6083, 0.5670, 0.6410, 0.5591, 0.5835],
       device='cuda:0') torch.Size([16])
percent tensor([0.6176, 0.6924, 0.6902, 0.7212, 0.7062, 0.6776, 0.6808, 0.6497, 0.7110,
        0.6833, 0.7129, 0.7103, 0.6771, 0.7613, 0.6015, 0.6555],
       device='cuda:0') torch.Size([16])
percent tensor([0.5751, 0.6849, 0.7341, 0.7788, 0.6638, 0.7906, 0.6845, 0.5443, 0.7128,
        0.6914, 0.7516, 0.6115, 0.6563, 0.6909, 0.4668, 0.6229],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9999, 0.9997, 0.9999, 0.9995, 0.9996, 0.9996, 0.9999,
        0.9998, 0.9999, 0.9999, 0.9999, 0.9995, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 167 | Batch_idx: 0 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 167 | Batch_idx: 10 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (97.00%) (1367/1408)
Epoch: 167 | Batch_idx: 20 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (2607/2688)
Epoch: 167 | Batch_idx: 30 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (3847/3968)
Epoch: 167 | Batch_idx: 40 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (97.00%) (5092/5248)
Epoch: 167 | Batch_idx: 50 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (6322/6528)
Epoch: 167 | Batch_idx: 60 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (7569/7808)
Epoch: 167 | Batch_idx: 70 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (8812/9088)
Epoch: 167 | Batch_idx: 80 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (10055/10368)
Epoch: 167 | Batch_idx: 90 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (11287/11648)
Epoch: 167 | Batch_idx: 100 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (12529/12928)
Epoch: 167 | Batch_idx: 110 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (13764/14208)
Epoch: 167 | Batch_idx: 120 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (15010/15488)
Epoch: 167 | Batch_idx: 130 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (16254/16768)
Epoch: 167 | Batch_idx: 140 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (17496/18048)
Epoch: 167 | Batch_idx: 150 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (18744/19328)
Epoch: 167 | Batch_idx: 160 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (19988/20608)
Epoch: 167 | Batch_idx: 170 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (21228/21888)
Epoch: 167 | Batch_idx: 180 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (22467/23168)
Epoch: 167 | Batch_idx: 190 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (23704/24448)
Epoch: 167 | Batch_idx: 200 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (24951/25728)
Epoch: 167 | Batch_idx: 210 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (97.00%) (26201/27008)
Epoch: 167 | Batch_idx: 220 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (27438/28288)
Epoch: 167 | Batch_idx: 230 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (28675/29568)
Epoch: 167 | Batch_idx: 240 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (29921/30848)
Epoch: 167 | Batch_idx: 250 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (31159/32128)
Epoch: 167 | Batch_idx: 260 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (97.00%) (32413/33408)
Epoch: 167 | Batch_idx: 270 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (97.00%) (33653/34688)
Epoch: 167 | Batch_idx: 280 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (97.00%) (34898/35968)
Epoch: 167 | Batch_idx: 290 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (36148/37248)
Epoch: 167 | Batch_idx: 300 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (97.00%) (37374/38528)
Epoch: 167 | Batch_idx: 310 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (97.00%) (38615/39808)
Epoch: 167 | Batch_idx: 320 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (97.00%) (39859/41088)
Epoch: 167 | Batch_idx: 330 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (41102/42368)
Epoch: 167 | Batch_idx: 340 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (42338/43648)
Epoch: 167 | Batch_idx: 350 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (97.00%) (43590/44928)
Epoch: 167 | Batch_idx: 360 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (44819/46208)
Epoch: 167 | Batch_idx: 370 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (46054/47488)
Epoch: 167 | Batch_idx: 380 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (47295/48768)
Epoch: 167 | Batch_idx: 390 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (48490/50000)
# TEST : Loss: (0.3732) | Acc: (89.00%) (8934/10000)
percent tensor([0.5705, 0.5907, 0.5817, 0.5699, 0.5878, 0.5598, 0.5983, 0.5855, 0.5829,
        0.5841, 0.5782, 0.5897, 0.5754, 0.5889, 0.5781, 0.5695],
       device='cuda:0') torch.Size([16])
percent tensor([0.5383, 0.5368, 0.5239, 0.5142, 0.5236, 0.5057, 0.5421, 0.5331, 0.5342,
        0.5372, 0.5359, 0.5356, 0.5459, 0.5338, 0.5187, 0.5292],
       device='cuda:0') torch.Size([16])
percent tensor([0.6066, 0.6081, 0.6063, 0.6661, 0.6848, 0.6728, 0.6386, 0.6940, 0.5852,
        0.5396, 0.5343, 0.5997, 0.5501, 0.6328, 0.6810, 0.6110],
       device='cuda:0') torch.Size([16])
percent tensor([0.7583, 0.7089, 0.7257, 0.7182, 0.7360, 0.7482, 0.7514, 0.7411, 0.7196,
        0.7268, 0.7447, 0.7022, 0.7036, 0.7432, 0.7550, 0.7448],
       device='cuda:0') torch.Size([16])
percent tensor([0.5587, 0.6035, 0.5738, 0.6054, 0.5790, 0.5950, 0.5837, 0.5603, 0.6087,
        0.5811, 0.5859, 0.6086, 0.5655, 0.6419, 0.5589, 0.5825],
       device='cuda:0') torch.Size([16])
percent tensor([0.6220, 0.6967, 0.6983, 0.7273, 0.7123, 0.6843, 0.6858, 0.6563, 0.7163,
        0.6876, 0.7179, 0.7155, 0.6822, 0.7654, 0.6049, 0.6601],
       device='cuda:0') torch.Size([16])
percent tensor([0.5715, 0.6844, 0.7311, 0.7796, 0.6598, 0.7877, 0.6778, 0.5427, 0.7168,
        0.6900, 0.7516, 0.6179, 0.6592, 0.6910, 0.4583, 0.6198],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9999, 0.9998, 0.9999, 0.9995, 0.9996, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 168 | Batch_idx: 0 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 168 | Batch_idx: 10 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (97.00%) (1366/1408)
Epoch: 168 | Batch_idx: 20 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (2611/2688)
Epoch: 168 | Batch_idx: 30 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (3853/3968)
Epoch: 168 | Batch_idx: 40 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (5095/5248)
Epoch: 168 | Batch_idx: 50 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (6330/6528)
Epoch: 168 | Batch_idx: 60 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (97.00%) (7579/7808)
Epoch: 168 | Batch_idx: 70 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (97.00%) (8821/9088)
Epoch: 168 | Batch_idx: 80 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (10064/10368)
Epoch: 168 | Batch_idx: 90 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (97.00%) (11305/11648)
Epoch: 168 | Batch_idx: 100 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (12547/12928)
Epoch: 168 | Batch_idx: 110 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (97.00%) (13788/14208)
Epoch: 168 | Batch_idx: 120 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (97.00%) (15039/15488)
Epoch: 168 | Batch_idx: 130 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (16287/16768)
Epoch: 168 | Batch_idx: 140 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (17530/18048)
Epoch: 168 | Batch_idx: 150 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (18788/19328)
Epoch: 168 | Batch_idx: 160 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (20031/20608)
Epoch: 168 | Batch_idx: 170 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (21273/21888)
Epoch: 168 | Batch_idx: 180 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (22516/23168)
Epoch: 168 | Batch_idx: 190 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (23756/24448)
Epoch: 168 | Batch_idx: 200 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (25004/25728)
Epoch: 168 | Batch_idx: 210 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (26256/27008)
Epoch: 168 | Batch_idx: 220 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (27499/28288)
Epoch: 168 | Batch_idx: 230 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (28739/29568)
Epoch: 168 | Batch_idx: 240 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (29989/30848)
Epoch: 168 | Batch_idx: 250 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (31233/32128)
Epoch: 168 | Batch_idx: 260 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (32482/33408)
Epoch: 168 | Batch_idx: 270 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (33729/34688)
Epoch: 168 | Batch_idx: 280 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (34982/35968)
Epoch: 168 | Batch_idx: 290 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (36230/37248)
Epoch: 168 | Batch_idx: 300 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (37473/38528)
Epoch: 168 | Batch_idx: 310 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (38716/39808)
Epoch: 168 | Batch_idx: 320 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (39952/41088)
Epoch: 168 | Batch_idx: 330 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (41200/42368)
Epoch: 168 | Batch_idx: 340 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (42444/43648)
Epoch: 168 | Batch_idx: 350 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (43686/44928)
Epoch: 168 | Batch_idx: 360 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (44926/46208)
Epoch: 168 | Batch_idx: 370 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (46166/47488)
Epoch: 168 | Batch_idx: 380 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (47413/48768)
Epoch: 168 | Batch_idx: 390 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (48610/50000)
# TEST : Loss: (0.3691) | Acc: (89.00%) (8938/10000)
percent tensor([0.5685, 0.5882, 0.5797, 0.5678, 0.5858, 0.5578, 0.5959, 0.5834, 0.5806,
        0.5819, 0.5758, 0.5877, 0.5733, 0.5861, 0.5759, 0.5673],
       device='cuda:0') torch.Size([16])
percent tensor([0.5372, 0.5362, 0.5227, 0.5130, 0.5225, 0.5046, 0.5411, 0.5318, 0.5331,
        0.5362, 0.5350, 0.5345, 0.5450, 0.5330, 0.5177, 0.5282],
       device='cuda:0') torch.Size([16])
percent tensor([0.6052, 0.6050, 0.6064, 0.6659, 0.6854, 0.6735, 0.6374, 0.6942, 0.5826,
        0.5363, 0.5299, 0.5976, 0.5461, 0.6309, 0.6799, 0.6093],
       device='cuda:0') torch.Size([16])
percent tensor([0.7493, 0.6997, 0.7166, 0.7085, 0.7263, 0.7402, 0.7413, 0.7311, 0.7100,
        0.7168, 0.7349, 0.6917, 0.6937, 0.7339, 0.7451, 0.7358],
       device='cuda:0') torch.Size([16])
percent tensor([0.5547, 0.6001, 0.5718, 0.6035, 0.5757, 0.5943, 0.5783, 0.5564, 0.6050,
        0.5772, 0.5812, 0.6048, 0.5599, 0.6396, 0.5534, 0.5791],
       device='cuda:0') torch.Size([16])
percent tensor([0.6247, 0.7019, 0.7038, 0.7305, 0.7166, 0.6872, 0.6889, 0.6588, 0.7201,
        0.6922, 0.7214, 0.7182, 0.6871, 0.7681, 0.6070, 0.6637],
       device='cuda:0') torch.Size([16])
percent tensor([0.5904, 0.7021, 0.7411, 0.7852, 0.6703, 0.7892, 0.6947, 0.5541, 0.7314,
        0.7061, 0.7648, 0.6413, 0.6811, 0.7013, 0.4764, 0.6324],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9999, 0.9997, 0.9999, 0.9995, 0.9996, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 169 | Batch_idx: 0 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 169 | Batch_idx: 10 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (97.00%) (1372/1408)
Epoch: 169 | Batch_idx: 20 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (97.00%) (2616/2688)
Epoch: 169 | Batch_idx: 30 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (3869/3968)
Epoch: 169 | Batch_idx: 40 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (5106/5248)
Epoch: 169 | Batch_idx: 50 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (6360/6528)
Epoch: 169 | Batch_idx: 60 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (7612/7808)
Epoch: 169 | Batch_idx: 70 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (8854/9088)
Epoch: 169 | Batch_idx: 80 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (10102/10368)
Epoch: 169 | Batch_idx: 90 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (97.00%) (11337/11648)
Epoch: 169 | Batch_idx: 100 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (12590/12928)
Epoch: 169 | Batch_idx: 110 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (13832/14208)
Epoch: 169 | Batch_idx: 120 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (15076/15488)
Epoch: 169 | Batch_idx: 130 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (16322/16768)
Epoch: 169 | Batch_idx: 140 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (17576/18048)
Epoch: 169 | Batch_idx: 150 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (18804/19328)
Epoch: 169 | Batch_idx: 160 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (97.00%) (20046/20608)
Epoch: 169 | Batch_idx: 170 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (97.00%) (21290/21888)
Epoch: 169 | Batch_idx: 180 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (22536/23168)
Epoch: 169 | Batch_idx: 190 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (23782/24448)
Epoch: 169 | Batch_idx: 200 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (25023/25728)
Epoch: 169 | Batch_idx: 210 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (26272/27008)
Epoch: 169 | Batch_idx: 220 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (97.00%) (27503/28288)
Epoch: 169 | Batch_idx: 230 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (97.00%) (28746/29568)
Epoch: 169 | Batch_idx: 240 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (97.00%) (29989/30848)
Epoch: 169 | Batch_idx: 250 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (97.00%) (31232/32128)
Epoch: 169 | Batch_idx: 260 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (32474/33408)
Epoch: 169 | Batch_idx: 270 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (33719/34688)
Epoch: 169 | Batch_idx: 280 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (34964/35968)
Epoch: 169 | Batch_idx: 290 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (36212/37248)
Epoch: 169 | Batch_idx: 300 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (37457/38528)
Epoch: 169 | Batch_idx: 310 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (38696/39808)
Epoch: 169 | Batch_idx: 320 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (39941/41088)
Epoch: 169 | Batch_idx: 330 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (41180/42368)
Epoch: 169 | Batch_idx: 340 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (42422/43648)
Epoch: 169 | Batch_idx: 350 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (43658/44928)
Epoch: 169 | Batch_idx: 360 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (44907/46208)
Epoch: 169 | Batch_idx: 370 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (46152/47488)
Epoch: 169 | Batch_idx: 380 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (47399/48768)
Epoch: 169 | Batch_idx: 390 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (48598/50000)
# TEST : Loss: (0.3633) | Acc: (89.00%) (8958/10000)
percent tensor([0.5715, 0.5922, 0.5830, 0.5710, 0.5893, 0.5606, 0.5999, 0.5870, 0.5840,
        0.5856, 0.5793, 0.5914, 0.5766, 0.5900, 0.5794, 0.5705],
       device='cuda:0') torch.Size([16])
percent tensor([0.5399, 0.5393, 0.5252, 0.5156, 0.5252, 0.5067, 0.5442, 0.5346, 0.5359,
        0.5391, 0.5378, 0.5374, 0.5480, 0.5357, 0.5203, 0.5309],
       device='cuda:0') torch.Size([16])
percent tensor([0.6063, 0.6081, 0.6067, 0.6647, 0.6863, 0.6713, 0.6415, 0.6942, 0.5861,
        0.5404, 0.5340, 0.5996, 0.5493, 0.6348, 0.6801, 0.6096],
       device='cuda:0') torch.Size([16])
percent tensor([0.7527, 0.7024, 0.7194, 0.7118, 0.7294, 0.7451, 0.7442, 0.7338, 0.7128,
        0.7192, 0.7375, 0.6942, 0.6966, 0.7366, 0.7484, 0.7395],
       device='cuda:0') torch.Size([16])
percent tensor([0.5546, 0.6024, 0.5723, 0.6059, 0.5763, 0.5946, 0.5795, 0.5582, 0.6065,
        0.5791, 0.5823, 0.6082, 0.5595, 0.6432, 0.5535, 0.5800],
       device='cuda:0') torch.Size([16])
percent tensor([0.6263, 0.7040, 0.7083, 0.7334, 0.7198, 0.6923, 0.6911, 0.6616, 0.7219,
        0.6931, 0.7230, 0.7196, 0.6887, 0.7697, 0.6085, 0.6663],
       device='cuda:0') torch.Size([16])
percent tensor([0.5799, 0.6934, 0.7368, 0.7806, 0.6597, 0.7881, 0.6839, 0.5406, 0.7213,
        0.6936, 0.7544, 0.6242, 0.6705, 0.6856, 0.4573, 0.6244],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9999, 0.9997, 0.9999, 0.9995, 0.9996, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9995, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 170 | Batch_idx: 0 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 170 | Batch_idx: 10 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 170 | Batch_idx: 20 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (2606/2688)
Epoch: 170 | Batch_idx: 30 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (3832/3968)
Epoch: 170 | Batch_idx: 40 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (5057/5248)
Epoch: 170 | Batch_idx: 50 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (6291/6528)
Epoch: 170 | Batch_idx: 60 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (7529/7808)
Epoch: 170 | Batch_idx: 70 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (8764/9088)
Epoch: 170 | Batch_idx: 80 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (10003/10368)
Epoch: 170 | Batch_idx: 90 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (11237/11648)
Epoch: 170 | Batch_idx: 100 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (12469/12928)
Epoch: 170 | Batch_idx: 110 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (13715/14208)
Epoch: 170 | Batch_idx: 120 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (14948/15488)
Epoch: 170 | Batch_idx: 130 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (16183/16768)
Epoch: 170 | Batch_idx: 140 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (17412/18048)
Epoch: 170 | Batch_idx: 150 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (18657/19328)
Epoch: 170 | Batch_idx: 160 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (19902/20608)
Epoch: 170 | Batch_idx: 170 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (21145/21888)
Epoch: 170 | Batch_idx: 180 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (22378/23168)
Epoch: 170 | Batch_idx: 190 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (23612/24448)
Epoch: 170 | Batch_idx: 200 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (24854/25728)
Epoch: 170 | Batch_idx: 210 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (26100/27008)
Epoch: 170 | Batch_idx: 220 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (27341/28288)
Epoch: 170 | Batch_idx: 230 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (28580/29568)
Epoch: 170 | Batch_idx: 240 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (29817/30848)
Epoch: 170 | Batch_idx: 250 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (31053/32128)
Epoch: 170 | Batch_idx: 260 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (32282/33408)
Epoch: 170 | Batch_idx: 270 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (33525/34688)
Epoch: 170 | Batch_idx: 280 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (34765/35968)
Epoch: 170 | Batch_idx: 290 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (36010/37248)
Epoch: 170 | Batch_idx: 300 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (37237/38528)
Epoch: 170 | Batch_idx: 310 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (38474/39808)
Epoch: 170 | Batch_idx: 320 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (39700/41088)
Epoch: 170 | Batch_idx: 330 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (40929/42368)
Epoch: 170 | Batch_idx: 340 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (42164/43648)
Epoch: 170 | Batch_idx: 350 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (43393/44928)
Epoch: 170 | Batch_idx: 360 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (44623/46208)
Epoch: 170 | Batch_idx: 370 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (45844/47488)
Epoch: 170 | Batch_idx: 380 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (47081/48768)
Epoch: 170 | Batch_idx: 390 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (48268/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_170.pth.tar'
# TEST : Loss: (0.4186) | Acc: (88.00%) (8848/10000)
percent tensor([0.5709, 0.5925, 0.5812, 0.5710, 0.5881, 0.5608, 0.5994, 0.5868, 0.5835,
        0.5851, 0.5790, 0.5896, 0.5762, 0.5915, 0.5798, 0.5708],
       device='cuda:0') torch.Size([16])
percent tensor([0.5404, 0.5382, 0.5272, 0.5140, 0.5267, 0.5080, 0.5438, 0.5340, 0.5372,
        0.5379, 0.5379, 0.5375, 0.5474, 0.5337, 0.5192, 0.5305],
       device='cuda:0') torch.Size([16])
percent tensor([0.6003, 0.6001, 0.6088, 0.6707, 0.6798, 0.6547, 0.6358, 0.6927, 0.5885,
        0.5378, 0.5282, 0.6029, 0.5489, 0.6294, 0.6761, 0.6064],
       device='cuda:0') torch.Size([16])
percent tensor([0.7521, 0.7022, 0.7160, 0.7155, 0.7290, 0.7499, 0.7410, 0.7286, 0.7116,
        0.7202, 0.7359, 0.6912, 0.6957, 0.7334, 0.7478, 0.7427],
       device='cuda:0') torch.Size([16])
percent tensor([0.5554, 0.5975, 0.5802, 0.6034, 0.5840, 0.5892, 0.5856, 0.5639, 0.6119,
        0.5777, 0.5886, 0.6161, 0.5571, 0.6382, 0.5551, 0.5804],
       device='cuda:0') torch.Size([16])
percent tensor([0.6188, 0.7031, 0.7061, 0.7381, 0.7162, 0.7048, 0.6809, 0.6668, 0.7253,
        0.6884, 0.7181, 0.7167, 0.6794, 0.7669, 0.6008, 0.6695],
       device='cuda:0') torch.Size([16])
percent tensor([0.5651, 0.6851, 0.7563, 0.7535, 0.6818, 0.8096, 0.6741, 0.5433, 0.7309,
        0.6564, 0.7328, 0.6151, 0.6679, 0.6414, 0.4259, 0.6105],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9998, 1.0000, 0.9993, 0.9997, 0.9995, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(178.1273, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(821.0616, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(828.7671, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1526.3348, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(480.0593, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2278.3967, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4253.5146, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1368.7269, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6261.0347, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11644.4434, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3850.5039, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16196.1025, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 171 | Batch_idx: 0 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 171 | Batch_idx: 10 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (97.00%) (1375/1408)
Epoch: 171 | Batch_idx: 20 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (97.00%) (2626/2688)
Epoch: 171 | Batch_idx: 30 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (3869/3968)
Epoch: 171 | Batch_idx: 40 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (5111/5248)
Epoch: 171 | Batch_idx: 50 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (6364/6528)
Epoch: 171 | Batch_idx: 60 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (7606/7808)
Epoch: 171 | Batch_idx: 70 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (8858/9088)
Epoch: 171 | Batch_idx: 80 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (10092/10368)
Epoch: 171 | Batch_idx: 90 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (11337/11648)
Epoch: 171 | Batch_idx: 100 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (12582/12928)
Epoch: 171 | Batch_idx: 110 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (13821/14208)
Epoch: 171 | Batch_idx: 120 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (15064/15488)
Epoch: 171 | Batch_idx: 130 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (16302/16768)
Epoch: 171 | Batch_idx: 140 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (17543/18048)
Epoch: 171 | Batch_idx: 150 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (97.00%) (18782/19328)
Epoch: 171 | Batch_idx: 160 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (97.00%) (20019/20608)
Epoch: 171 | Batch_idx: 170 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (21265/21888)
Epoch: 171 | Batch_idx: 180 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (97.00%) (22501/23168)
Epoch: 171 | Batch_idx: 190 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (97.00%) (23733/24448)
Epoch: 171 | Batch_idx: 200 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (97.00%) (24967/25728)
Epoch: 171 | Batch_idx: 210 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (97.00%) (26205/27008)
Epoch: 171 | Batch_idx: 220 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (27436/28288)
Epoch: 171 | Batch_idx: 230 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (28661/29568)
Epoch: 171 | Batch_idx: 240 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (29899/30848)
Epoch: 171 | Batch_idx: 250 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (31124/32128)
Epoch: 171 | Batch_idx: 260 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (32354/33408)
Epoch: 171 | Batch_idx: 270 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (33584/34688)
Epoch: 171 | Batch_idx: 280 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (34813/35968)
Epoch: 171 | Batch_idx: 290 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (36054/37248)
Epoch: 171 | Batch_idx: 300 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (37288/38528)
Epoch: 171 | Batch_idx: 310 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (38517/39808)
Epoch: 171 | Batch_idx: 320 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (39751/41088)
Epoch: 171 | Batch_idx: 330 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (40994/42368)
Epoch: 171 | Batch_idx: 340 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (42230/43648)
Epoch: 171 | Batch_idx: 350 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (96.00%) (43463/44928)
Epoch: 171 | Batch_idx: 360 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (44707/46208)
Epoch: 171 | Batch_idx: 370 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (45931/47488)
Epoch: 171 | Batch_idx: 380 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (47162/48768)
Epoch: 171 | Batch_idx: 390 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (48346/50000)
# TEST : Loss: (0.4149) | Acc: (88.00%) (8829/10000)
percent tensor([0.5714, 0.5920, 0.5834, 0.5718, 0.5903, 0.5613, 0.6000, 0.5875, 0.5832,
        0.5856, 0.5788, 0.5915, 0.5766, 0.5893, 0.5799, 0.5712],
       device='cuda:0') torch.Size([16])
percent tensor([0.5398, 0.5365, 0.5281, 0.5178, 0.5261, 0.5075, 0.5423, 0.5344, 0.5373,
        0.5383, 0.5375, 0.5366, 0.5482, 0.5327, 0.5189, 0.5314],
       device='cuda:0') torch.Size([16])
percent tensor([0.6056, 0.6123, 0.6064, 0.6635, 0.6809, 0.6548, 0.6461, 0.6959, 0.5865,
        0.5487, 0.5381, 0.6130, 0.5577, 0.6359, 0.6774, 0.6095],
       device='cuda:0') torch.Size([16])
percent tensor([0.7533, 0.7080, 0.7208, 0.7177, 0.7340, 0.7508, 0.7433, 0.7295, 0.7163,
        0.7219, 0.7358, 0.6949, 0.6961, 0.7372, 0.7524, 0.7426],
       device='cuda:0') torch.Size([16])
percent tensor([0.5561, 0.5960, 0.5818, 0.5948, 0.5737, 0.5921, 0.5840, 0.5604, 0.6033,
        0.5760, 0.5872, 0.6089, 0.5554, 0.6419, 0.5471, 0.5811],
       device='cuda:0') torch.Size([16])
percent tensor([0.6215, 0.6848, 0.7095, 0.7300, 0.7117, 0.6980, 0.6730, 0.6585, 0.7205,
        0.6861, 0.7260, 0.7201, 0.6766, 0.7690, 0.5916, 0.6684],
       device='cuda:0') torch.Size([16])
percent tensor([0.6111, 0.6740, 0.7550, 0.7445, 0.6321, 0.8020, 0.6468, 0.5158, 0.7327,
        0.6842, 0.7511, 0.6588, 0.6695, 0.7111, 0.4236, 0.6260],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9996, 0.9999, 0.9994, 0.9996, 0.9995, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 172 | Batch_idx: 0 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 172 | Batch_idx: 10 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 172 | Batch_idx: 20 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (2593/2688)
Epoch: 172 | Batch_idx: 30 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (96.00%) (3837/3968)
Epoch: 172 | Batch_idx: 40 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (96.00%) (5076/5248)
Epoch: 172 | Batch_idx: 50 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (96.00%) (6306/6528)
Epoch: 172 | Batch_idx: 60 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (7545/7808)
Epoch: 172 | Batch_idx: 70 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (8790/9088)
Epoch: 172 | Batch_idx: 80 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (10039/10368)
Epoch: 172 | Batch_idx: 90 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (96.00%) (11288/11648)
Epoch: 172 | Batch_idx: 100 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (96.00%) (12534/12928)
Epoch: 172 | Batch_idx: 110 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (96.00%) (13774/14208)
Epoch: 172 | Batch_idx: 120 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (96.00%) (15019/15488)
Epoch: 172 | Batch_idx: 130 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (96.00%) (16260/16768)
Epoch: 172 | Batch_idx: 140 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (96.00%) (17487/18048)
Epoch: 172 | Batch_idx: 150 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (96.00%) (18738/19328)
Epoch: 172 | Batch_idx: 160 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (96.00%) (19968/20608)
Epoch: 172 | Batch_idx: 170 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (96.00%) (21205/21888)
Epoch: 172 | Batch_idx: 180 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (22444/23168)
Epoch: 172 | Batch_idx: 190 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (23678/24448)
Epoch: 172 | Batch_idx: 200 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (24908/25728)
Epoch: 172 | Batch_idx: 210 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (26149/27008)
Epoch: 172 | Batch_idx: 220 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (27380/28288)
Epoch: 172 | Batch_idx: 230 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (28623/29568)
Epoch: 172 | Batch_idx: 240 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (29853/30848)
Epoch: 172 | Batch_idx: 250 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (31094/32128)
Epoch: 172 | Batch_idx: 260 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (32336/33408)
Epoch: 172 | Batch_idx: 270 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (33586/34688)
Epoch: 172 | Batch_idx: 280 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (34827/35968)
Epoch: 172 | Batch_idx: 290 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (36054/37248)
Epoch: 172 | Batch_idx: 300 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (37300/38528)
Epoch: 172 | Batch_idx: 310 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (38541/39808)
Epoch: 172 | Batch_idx: 320 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (39774/41088)
Epoch: 172 | Batch_idx: 330 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (41011/42368)
Epoch: 172 | Batch_idx: 340 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (42244/43648)
Epoch: 172 | Batch_idx: 350 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (43479/44928)
Epoch: 172 | Batch_idx: 360 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (44699/46208)
Epoch: 172 | Batch_idx: 370 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (45931/47488)
Epoch: 172 | Batch_idx: 380 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (47165/48768)
Epoch: 172 | Batch_idx: 390 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (48350/50000)
# TEST : Loss: (0.4231) | Acc: (88.00%) (8819/10000)
percent tensor([0.5702, 0.5937, 0.5801, 0.5700, 0.5874, 0.5599, 0.5998, 0.5863, 0.5838,
        0.5850, 0.5792, 0.5891, 0.5760, 0.5934, 0.5794, 0.5708],
       device='cuda:0') torch.Size([16])
percent tensor([0.5405, 0.5363, 0.5275, 0.5170, 0.5263, 0.5077, 0.5415, 0.5344, 0.5365,
        0.5369, 0.5368, 0.5362, 0.5471, 0.5324, 0.5186, 0.5311],
       device='cuda:0') torch.Size([16])
percent tensor([0.5988, 0.6118, 0.5964, 0.6593, 0.6766, 0.6550, 0.6453, 0.6960, 0.5878,
        0.5430, 0.5338, 0.6051, 0.5514, 0.6511, 0.6760, 0.6032],
       device='cuda:0') torch.Size([16])
percent tensor([0.7519, 0.7010, 0.7188, 0.7172, 0.7285, 0.7441, 0.7414, 0.7297, 0.7132,
        0.7170, 0.7329, 0.6916, 0.6965, 0.7363, 0.7453, 0.7413],
       device='cuda:0') torch.Size([16])
percent tensor([0.5575, 0.5986, 0.5831, 0.5991, 0.5826, 0.5980, 0.5874, 0.5576, 0.6070,
        0.5851, 0.5954, 0.6084, 0.5571, 0.6335, 0.5550, 0.5845],
       device='cuda:0') torch.Size([16])
percent tensor([0.6269, 0.6915, 0.7153, 0.7389, 0.7185, 0.7028, 0.6883, 0.6550, 0.7275,
        0.6894, 0.7287, 0.7126, 0.6694, 0.7590, 0.6066, 0.6633],
       device='cuda:0') torch.Size([16])
percent tensor([0.5979, 0.6737, 0.7442, 0.7677, 0.6731, 0.7997, 0.6566, 0.5148, 0.6922,
        0.6618, 0.7281, 0.6103, 0.6640, 0.6493, 0.4470, 0.6165],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9999, 0.9998, 0.9999, 0.9992, 0.9996, 0.9997, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9994, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 173 | Batch_idx: 0 |  Loss: (0.0327) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 173 | Batch_idx: 10 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (1370/1408)
Epoch: 173 | Batch_idx: 20 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (2616/2688)
Epoch: 173 | Batch_idx: 30 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (3855/3968)
Epoch: 173 | Batch_idx: 40 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (96.00%) (5088/5248)
Epoch: 173 | Batch_idx: 50 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (6333/6528)
Epoch: 173 | Batch_idx: 60 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (7579/7808)
Epoch: 173 | Batch_idx: 70 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (8818/9088)
Epoch: 173 | Batch_idx: 80 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (96.00%) (10055/10368)
Epoch: 173 | Batch_idx: 90 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (11278/11648)
Epoch: 173 | Batch_idx: 100 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (12519/12928)
Epoch: 173 | Batch_idx: 110 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (13759/14208)
Epoch: 173 | Batch_idx: 120 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (15002/15488)
Epoch: 173 | Batch_idx: 130 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (16242/16768)
Epoch: 173 | Batch_idx: 140 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (17477/18048)
Epoch: 173 | Batch_idx: 150 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (18721/19328)
Epoch: 173 | Batch_idx: 160 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (19963/20608)
Epoch: 173 | Batch_idx: 170 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (21203/21888)
Epoch: 173 | Batch_idx: 180 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (22437/23168)
Epoch: 173 | Batch_idx: 190 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (23690/24448)
Epoch: 173 | Batch_idx: 200 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (24932/25728)
Epoch: 173 | Batch_idx: 210 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (26180/27008)
Epoch: 173 | Batch_idx: 220 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (27415/28288)
Epoch: 173 | Batch_idx: 230 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (28650/29568)
Epoch: 173 | Batch_idx: 240 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (29884/30848)
Epoch: 173 | Batch_idx: 250 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (31104/32128)
Epoch: 173 | Batch_idx: 260 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (32336/33408)
Epoch: 173 | Batch_idx: 270 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (33559/34688)
Epoch: 173 | Batch_idx: 280 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (34789/35968)
Epoch: 173 | Batch_idx: 290 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (36029/37248)
Epoch: 173 | Batch_idx: 300 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (37274/38528)
Epoch: 173 | Batch_idx: 310 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (38517/39808)
Epoch: 173 | Batch_idx: 320 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (39753/41088)
Epoch: 173 | Batch_idx: 330 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (40993/42368)
Epoch: 173 | Batch_idx: 340 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (42227/43648)
Epoch: 173 | Batch_idx: 350 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (43461/44928)
Epoch: 173 | Batch_idx: 360 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (44691/46208)
Epoch: 173 | Batch_idx: 370 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (45930/47488)
Epoch: 173 | Batch_idx: 380 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (47171/48768)
Epoch: 173 | Batch_idx: 390 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (48362/50000)
# TEST : Loss: (0.4372) | Acc: (87.00%) (8766/10000)
percent tensor([0.5713, 0.5922, 0.5831, 0.5715, 0.5896, 0.5612, 0.5996, 0.5870, 0.5834,
        0.5855, 0.5790, 0.5913, 0.5767, 0.5894, 0.5795, 0.5711],
       device='cuda:0') torch.Size([16])
percent tensor([0.5402, 0.5383, 0.5259, 0.5172, 0.5244, 0.5079, 0.5425, 0.5331, 0.5372,
        0.5374, 0.5379, 0.5348, 0.5476, 0.5354, 0.5189, 0.5321],
       device='cuda:0') torch.Size([16])
percent tensor([0.6057, 0.6098, 0.6062, 0.6618, 0.6794, 0.6662, 0.6428, 0.6985, 0.5946,
        0.5494, 0.5387, 0.6046, 0.5566, 0.6355, 0.6841, 0.6152],
       device='cuda:0') torch.Size([16])
percent tensor([0.7523, 0.7050, 0.7222, 0.7184, 0.7337, 0.7427, 0.7441, 0.7322, 0.7115,
        0.7212, 0.7361, 0.6956, 0.6981, 0.7410, 0.7494, 0.7417],
       device='cuda:0') torch.Size([16])
percent tensor([0.5589, 0.5960, 0.5811, 0.6082, 0.5813, 0.6007, 0.5808, 0.5603, 0.6089,
        0.5805, 0.5915, 0.6062, 0.5591, 0.6428, 0.5471, 0.5791],
       device='cuda:0') torch.Size([16])
percent tensor([0.6241, 0.6979, 0.7049, 0.7403, 0.7167, 0.6982, 0.6774, 0.6534, 0.7219,
        0.6948, 0.7273, 0.7160, 0.6813, 0.7657, 0.6096, 0.6673],
       device='cuda:0') torch.Size([16])
percent tensor([0.5765, 0.6703, 0.7297, 0.7792, 0.6359, 0.7953, 0.6393, 0.4887, 0.7032,
        0.6757, 0.7286, 0.6440, 0.6619, 0.6831, 0.4415, 0.6009],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9998, 0.9997, 0.9999, 0.9993, 0.9997, 0.9992, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9999, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 174 | Batch_idx: 0 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 174 | Batch_idx: 10 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (1360/1408)
Epoch: 174 | Batch_idx: 20 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (2595/2688)
Epoch: 174 | Batch_idx: 30 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (3842/3968)
Epoch: 174 | Batch_idx: 40 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (5071/5248)
Epoch: 174 | Batch_idx: 50 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (6323/6528)
Epoch: 174 | Batch_idx: 60 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (7559/7808)
Epoch: 174 | Batch_idx: 70 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (8793/9088)
Epoch: 174 | Batch_idx: 80 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (10030/10368)
Epoch: 174 | Batch_idx: 90 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (11272/11648)
Epoch: 174 | Batch_idx: 100 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (12506/12928)
Epoch: 174 | Batch_idx: 110 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (13748/14208)
Epoch: 174 | Batch_idx: 120 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (14995/15488)
Epoch: 174 | Batch_idx: 130 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (16228/16768)
Epoch: 174 | Batch_idx: 140 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (17475/18048)
Epoch: 174 | Batch_idx: 150 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (18723/19328)
Epoch: 174 | Batch_idx: 160 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (19966/20608)
Epoch: 174 | Batch_idx: 170 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (21211/21888)
Epoch: 174 | Batch_idx: 180 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (22453/23168)
Epoch: 174 | Batch_idx: 190 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (23689/24448)
Epoch: 174 | Batch_idx: 200 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (24928/25728)
Epoch: 174 | Batch_idx: 210 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (26177/27008)
Epoch: 174 | Batch_idx: 220 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (27404/28288)
Epoch: 174 | Batch_idx: 230 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (28643/29568)
Epoch: 174 | Batch_idx: 240 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (29884/30848)
Epoch: 174 | Batch_idx: 250 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (31124/32128)
Epoch: 174 | Batch_idx: 260 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (32368/33408)
Epoch: 174 | Batch_idx: 270 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (33616/34688)
Epoch: 174 | Batch_idx: 280 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (34858/35968)
Epoch: 174 | Batch_idx: 290 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (36095/37248)
Epoch: 174 | Batch_idx: 300 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (37333/38528)
Epoch: 174 | Batch_idx: 310 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (38570/39808)
Epoch: 174 | Batch_idx: 320 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (39813/41088)
Epoch: 174 | Batch_idx: 330 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (41048/42368)
Epoch: 174 | Batch_idx: 340 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (42291/43648)
Epoch: 174 | Batch_idx: 350 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (43539/44928)
Epoch: 174 | Batch_idx: 360 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (44781/46208)
Epoch: 174 | Batch_idx: 370 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (46014/47488)
Epoch: 174 | Batch_idx: 380 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (47258/48768)
Epoch: 174 | Batch_idx: 390 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (48451/50000)
# TEST : Loss: (0.3997) | Acc: (88.00%) (8858/10000)
percent tensor([0.5706, 0.5924, 0.5829, 0.5715, 0.5892, 0.5603, 0.5995, 0.5875, 0.5831,
        0.5856, 0.5786, 0.5907, 0.5762, 0.5902, 0.5793, 0.5708],
       device='cuda:0') torch.Size([16])
percent tensor([0.5406, 0.5380, 0.5294, 0.5187, 0.5277, 0.5096, 0.5435, 0.5343, 0.5372,
        0.5386, 0.5385, 0.5383, 0.5478, 0.5335, 0.5195, 0.5318],
       device='cuda:0') torch.Size([16])
percent tensor([0.5980, 0.6127, 0.5929, 0.6552, 0.6791, 0.6510, 0.6427, 0.6942, 0.5814,
        0.5412, 0.5284, 0.6026, 0.5512, 0.6419, 0.6803, 0.6080],
       device='cuda:0') torch.Size([16])
percent tensor([0.7551, 0.7050, 0.7260, 0.7245, 0.7361, 0.7458, 0.7450, 0.7303, 0.7165,
        0.7201, 0.7364, 0.6982, 0.6983, 0.7369, 0.7505, 0.7432],
       device='cuda:0') torch.Size([16])
percent tensor([0.5554, 0.6037, 0.5782, 0.6027, 0.5747, 0.5976, 0.5882, 0.5585, 0.6114,
        0.5866, 0.5967, 0.6101, 0.5616, 0.6529, 0.5528, 0.5790],
       device='cuda:0') torch.Size([16])
percent tensor([0.6368, 0.7054, 0.7193, 0.7340, 0.7256, 0.7043, 0.6910, 0.6742, 0.7310,
        0.6991, 0.7319, 0.7275, 0.6862, 0.7831, 0.6141, 0.6673],
       device='cuda:0') torch.Size([16])
percent tensor([0.6274, 0.6984, 0.7638, 0.7754, 0.6724, 0.8283, 0.6882, 0.5464, 0.7207,
        0.7100, 0.7573, 0.6781, 0.6995, 0.7499, 0.4832, 0.6259],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9998, 0.9999, 1.0000, 0.9994, 0.9996, 0.9995, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9995, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 175 | Batch_idx: 0 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 175 | Batch_idx: 10 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (1359/1408)
Epoch: 175 | Batch_idx: 20 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (2592/2688)
Epoch: 175 | Batch_idx: 30 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (3823/3968)
Epoch: 175 | Batch_idx: 40 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (5061/5248)
Epoch: 175 | Batch_idx: 50 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (6288/6528)
Epoch: 175 | Batch_idx: 60 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (7527/7808)
Epoch: 175 | Batch_idx: 70 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (8758/9088)
Epoch: 175 | Batch_idx: 80 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (9987/10368)
Epoch: 175 | Batch_idx: 90 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (11228/11648)
Epoch: 175 | Batch_idx: 100 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (12450/12928)
Epoch: 175 | Batch_idx: 110 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (13671/14208)
Epoch: 175 | Batch_idx: 120 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (14919/15488)
Epoch: 175 | Batch_idx: 130 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (16156/16768)
Epoch: 175 | Batch_idx: 140 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (17385/18048)
Epoch: 175 | Batch_idx: 150 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (18616/19328)
Epoch: 175 | Batch_idx: 160 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (19842/20608)
Epoch: 175 | Batch_idx: 170 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (21065/21888)
Epoch: 175 | Batch_idx: 180 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (22307/23168)
Epoch: 175 | Batch_idx: 190 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (23536/24448)
Epoch: 175 | Batch_idx: 200 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (24766/25728)
Epoch: 175 | Batch_idx: 210 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (25998/27008)
Epoch: 175 | Batch_idx: 220 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (27235/28288)
Epoch: 175 | Batch_idx: 230 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (28456/29568)
Epoch: 175 | Batch_idx: 240 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (29689/30848)
Epoch: 175 | Batch_idx: 250 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (30909/32128)
Epoch: 175 | Batch_idx: 260 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (32152/33408)
Epoch: 175 | Batch_idx: 270 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (33381/34688)
Epoch: 175 | Batch_idx: 280 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (34619/35968)
Epoch: 175 | Batch_idx: 290 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (35854/37248)
Epoch: 175 | Batch_idx: 300 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (37086/38528)
Epoch: 175 | Batch_idx: 310 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (38325/39808)
Epoch: 175 | Batch_idx: 320 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (39547/41088)
Epoch: 175 | Batch_idx: 330 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (40783/42368)
Epoch: 175 | Batch_idx: 340 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (42019/43648)
Epoch: 175 | Batch_idx: 350 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (43269/44928)
Epoch: 175 | Batch_idx: 360 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (44505/46208)
Epoch: 175 | Batch_idx: 370 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (45747/47488)
Epoch: 175 | Batch_idx: 380 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (46992/48768)
Epoch: 175 | Batch_idx: 390 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (48181/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_175.pth.tar'
# TEST : Loss: (0.3987) | Acc: (88.00%) (8860/10000)
percent tensor([0.5708, 0.5919, 0.5836, 0.5715, 0.5896, 0.5608, 0.5993, 0.5876, 0.5825,
        0.5854, 0.5785, 0.5910, 0.5764, 0.5885, 0.5795, 0.5705],
       device='cuda:0') torch.Size([16])
percent tensor([0.5456, 0.5430, 0.5355, 0.5256, 0.5335, 0.5143, 0.5482, 0.5408, 0.5425,
        0.5439, 0.5429, 0.5438, 0.5531, 0.5380, 0.5254, 0.5381],
       device='cuda:0') torch.Size([16])
percent tensor([0.6109, 0.6216, 0.6103, 0.6725, 0.6947, 0.6623, 0.6525, 0.7113, 0.6003,
        0.5545, 0.5412, 0.6157, 0.5596, 0.6527, 0.6922, 0.6177],
       device='cuda:0') torch.Size([16])
percent tensor([0.7510, 0.6998, 0.7230, 0.7212, 0.7325, 0.7438, 0.7400, 0.7253, 0.7118,
        0.7171, 0.7320, 0.6937, 0.6942, 0.7328, 0.7439, 0.7406],
       device='cuda:0') torch.Size([16])
percent tensor([0.5571, 0.6026, 0.5806, 0.6003, 0.5759, 0.6035, 0.5844, 0.5610, 0.6095,
        0.5851, 0.5911, 0.6079, 0.5638, 0.6445, 0.5539, 0.5833],
       device='cuda:0') torch.Size([16])
percent tensor([0.6416, 0.7141, 0.7271, 0.7440, 0.7342, 0.7061, 0.7017, 0.6888, 0.7386,
        0.7065, 0.7435, 0.7431, 0.6918, 0.7902, 0.6243, 0.6770],
       device='cuda:0') torch.Size([16])
percent tensor([0.5642, 0.6801, 0.7571, 0.7782, 0.6644, 0.8130, 0.6592, 0.5283, 0.6816,
        0.6801, 0.7357, 0.6507, 0.6567, 0.7186, 0.4434, 0.5987],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9998, 0.9999, 1.0000, 0.9996, 0.9996, 0.9994, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 176 | Batch_idx: 0 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 176 | Batch_idx: 10 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (97.00%) (1366/1408)
Epoch: 176 | Batch_idx: 20 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (96.00%) (2607/2688)
Epoch: 176 | Batch_idx: 30 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (3845/3968)
Epoch: 176 | Batch_idx: 40 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (5094/5248)
Epoch: 176 | Batch_idx: 50 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (6327/6528)
Epoch: 176 | Batch_idx: 60 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (7552/7808)
Epoch: 176 | Batch_idx: 70 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (8783/9088)
Epoch: 176 | Batch_idx: 80 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (10028/10368)
Epoch: 176 | Batch_idx: 90 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (11278/11648)
Epoch: 176 | Batch_idx: 100 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (12525/12928)
Epoch: 176 | Batch_idx: 110 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (13758/14208)
Epoch: 176 | Batch_idx: 120 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (15004/15488)
Epoch: 176 | Batch_idx: 130 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (16250/16768)
Epoch: 176 | Batch_idx: 140 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (17487/18048)
Epoch: 176 | Batch_idx: 150 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (18726/19328)
Epoch: 176 | Batch_idx: 160 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (19975/20608)
Epoch: 176 | Batch_idx: 170 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (21204/21888)
Epoch: 176 | Batch_idx: 180 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (22446/23168)
Epoch: 176 | Batch_idx: 190 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (23680/24448)
Epoch: 176 | Batch_idx: 200 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (24931/25728)
Epoch: 176 | Batch_idx: 210 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (26180/27008)
Epoch: 176 | Batch_idx: 220 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (27430/28288)
Epoch: 176 | Batch_idx: 230 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (28668/29568)
Epoch: 176 | Batch_idx: 240 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (29911/30848)
Epoch: 176 | Batch_idx: 250 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (31154/32128)
Epoch: 176 | Batch_idx: 260 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (32401/33408)
Epoch: 176 | Batch_idx: 270 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (97.00%) (33654/34688)
Epoch: 176 | Batch_idx: 280 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (34888/35968)
Epoch: 176 | Batch_idx: 290 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (36107/37248)
Epoch: 176 | Batch_idx: 300 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (37347/38528)
Epoch: 176 | Batch_idx: 310 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (38576/39808)
Epoch: 176 | Batch_idx: 320 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (39812/41088)
Epoch: 176 | Batch_idx: 330 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (41064/42368)
Epoch: 176 | Batch_idx: 340 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (42307/43648)
Epoch: 176 | Batch_idx: 350 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (43549/44928)
Epoch: 176 | Batch_idx: 360 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (44793/46208)
Epoch: 176 | Batch_idx: 370 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (46042/47488)
Epoch: 176 | Batch_idx: 380 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (47290/48768)
Epoch: 176 | Batch_idx: 390 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (48494/50000)
# TEST : Loss: (0.3843) | Acc: (88.00%) (8893/10000)
percent tensor([0.5708, 0.5923, 0.5830, 0.5715, 0.5891, 0.5611, 0.5993, 0.5874, 0.5826,
        0.5854, 0.5787, 0.5906, 0.5765, 0.5892, 0.5797, 0.5708],
       device='cuda:0') torch.Size([16])
percent tensor([0.5460, 0.5429, 0.5367, 0.5271, 0.5345, 0.5151, 0.5482, 0.5418, 0.5428,
        0.5441, 0.5427, 0.5443, 0.5529, 0.5382, 0.5261, 0.5388],
       device='cuda:0') torch.Size([16])
percent tensor([0.6106, 0.6233, 0.6131, 0.6755, 0.6973, 0.6626, 0.6546, 0.7150, 0.6058,
        0.5564, 0.5450, 0.6189, 0.5595, 0.6593, 0.6929, 0.6168],
       device='cuda:0') torch.Size([16])
percent tensor([0.7450, 0.6931, 0.7172, 0.7147, 0.7265, 0.7399, 0.7330, 0.7188, 0.7057,
        0.7107, 0.7252, 0.6872, 0.6882, 0.7265, 0.7358, 0.7354],
       device='cuda:0') torch.Size([16])
percent tensor([0.5598, 0.6020, 0.5849, 0.6054, 0.5819, 0.6098, 0.5831, 0.5645, 0.6098,
        0.5863, 0.5884, 0.6075, 0.5646, 0.6400, 0.5550, 0.5894],
       device='cuda:0') torch.Size([16])
percent tensor([0.6386, 0.7075, 0.7256, 0.7462, 0.7336, 0.7017, 0.6983, 0.6884, 0.7340,
        0.6998, 0.7397, 0.7406, 0.6863, 0.7876, 0.6216, 0.6734],
       device='cuda:0') torch.Size([16])
percent tensor([0.5473, 0.6770, 0.7562, 0.7750, 0.6613, 0.8091, 0.6577, 0.5188, 0.6640,
        0.6714, 0.7244, 0.6393, 0.6518, 0.7067, 0.4336, 0.5954],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9998, 0.9999, 1.0000, 0.9995, 0.9996, 0.9994, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 177 | Batch_idx: 0 |  Loss: (0.0272) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 177 | Batch_idx: 10 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (1370/1408)
Epoch: 177 | Batch_idx: 20 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (96.00%) (2606/2688)
Epoch: 177 | Batch_idx: 30 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (3849/3968)
Epoch: 177 | Batch_idx: 40 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (5091/5248)
Epoch: 177 | Batch_idx: 50 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (6338/6528)
Epoch: 177 | Batch_idx: 60 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (7587/7808)
Epoch: 177 | Batch_idx: 70 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (8836/9088)
Epoch: 177 | Batch_idx: 80 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (10081/10368)
Epoch: 177 | Batch_idx: 90 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (11329/11648)
Epoch: 177 | Batch_idx: 100 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (12585/12928)
Epoch: 177 | Batch_idx: 110 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (13827/14208)
Epoch: 177 | Batch_idx: 120 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (15079/15488)
Epoch: 177 | Batch_idx: 130 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (16327/16768)
Epoch: 177 | Batch_idx: 140 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (17580/18048)
Epoch: 177 | Batch_idx: 150 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (18823/19328)
Epoch: 177 | Batch_idx: 160 |  Loss: (0.0803) |  Loss2: (0.0000) | Acc: (97.00%) (20063/20608)
Epoch: 177 | Batch_idx: 170 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (21308/21888)
Epoch: 177 | Batch_idx: 180 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (22551/23168)
Epoch: 177 | Batch_idx: 190 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (23800/24448)
Epoch: 177 | Batch_idx: 200 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (25036/25728)
Epoch: 177 | Batch_idx: 210 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (26276/27008)
Epoch: 177 | Batch_idx: 220 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (27523/28288)
Epoch: 177 | Batch_idx: 230 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (28763/29568)
Epoch: 177 | Batch_idx: 240 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (30004/30848)
Epoch: 177 | Batch_idx: 250 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (31253/32128)
Epoch: 177 | Batch_idx: 260 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (32491/33408)
Epoch: 177 | Batch_idx: 270 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (33729/34688)
Epoch: 177 | Batch_idx: 280 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (34969/35968)
Epoch: 177 | Batch_idx: 290 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (36219/37248)
Epoch: 177 | Batch_idx: 300 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (37457/38528)
Epoch: 177 | Batch_idx: 310 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (38689/39808)
Epoch: 177 | Batch_idx: 320 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (39938/41088)
Epoch: 177 | Batch_idx: 330 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (41186/42368)
Epoch: 177 | Batch_idx: 340 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (42424/43648)
Epoch: 177 | Batch_idx: 350 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (43674/44928)
Epoch: 177 | Batch_idx: 360 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (44922/46208)
Epoch: 177 | Batch_idx: 370 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (46171/47488)
Epoch: 177 | Batch_idx: 380 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (47415/48768)
Epoch: 177 | Batch_idx: 390 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (48622/50000)
# TEST : Loss: (0.3768) | Acc: (89.00%) (8910/10000)
percent tensor([0.5732, 0.5949, 0.5861, 0.5738, 0.5922, 0.5634, 0.6022, 0.5902, 0.5849,
        0.5880, 0.5810, 0.5936, 0.5789, 0.5913, 0.5824, 0.5730],
       device='cuda:0') torch.Size([16])
percent tensor([0.5478, 0.5441, 0.5387, 0.5294, 0.5365, 0.5169, 0.5498, 0.5439, 0.5444,
        0.5453, 0.5439, 0.5459, 0.5544, 0.5393, 0.5280, 0.5408],
       device='cuda:0') torch.Size([16])
percent tensor([0.5983, 0.6084, 0.6029, 0.6654, 0.6863, 0.6521, 0.6415, 0.7052, 0.5960,
        0.5433, 0.5333, 0.6086, 0.5449, 0.6487, 0.6796, 0.6033],
       device='cuda:0') torch.Size([16])
percent tensor([0.7450, 0.6926, 0.7155, 0.7142, 0.7250, 0.7422, 0.7313, 0.7171, 0.7057,
        0.7105, 0.7257, 0.6860, 0.6885, 0.7270, 0.7352, 0.7365],
       device='cuda:0') torch.Size([16])
percent tensor([0.5623, 0.6037, 0.5894, 0.6069, 0.5860, 0.6141, 0.5849, 0.5681, 0.6117,
        0.5890, 0.5894, 0.6094, 0.5672, 0.6384, 0.5570, 0.5929],
       device='cuda:0') torch.Size([16])
percent tensor([0.6284, 0.6955, 0.7159, 0.7371, 0.7227, 0.6898, 0.6889, 0.6789, 0.7244,
        0.6879, 0.7311, 0.7307, 0.6760, 0.7769, 0.6103, 0.6616],
       device='cuda:0') torch.Size([16])
percent tensor([0.5556, 0.6975, 0.7642, 0.7779, 0.6668, 0.8173, 0.6726, 0.5202, 0.6748,
        0.6910, 0.7364, 0.6476, 0.6752, 0.7136, 0.4386, 0.6029],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9998, 0.9999, 1.0000, 0.9995, 0.9996, 0.9993, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 178 | Batch_idx: 0 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 178 | Batch_idx: 10 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (97.00%) (1366/1408)
Epoch: 178 | Batch_idx: 20 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (2618/2688)
Epoch: 178 | Batch_idx: 30 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (3868/3968)
Epoch: 178 | Batch_idx: 40 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (5110/5248)
Epoch: 178 | Batch_idx: 50 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (6356/6528)
Epoch: 178 | Batch_idx: 60 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (7600/7808)
Epoch: 178 | Batch_idx: 70 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (8848/9088)
Epoch: 178 | Batch_idx: 80 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (10100/10368)
Epoch: 178 | Batch_idx: 90 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (11342/11648)
Epoch: 178 | Batch_idx: 100 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (12586/12928)
Epoch: 178 | Batch_idx: 110 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (13821/14208)
Epoch: 178 | Batch_idx: 120 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (15062/15488)
Epoch: 178 | Batch_idx: 130 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (16310/16768)
Epoch: 178 | Batch_idx: 140 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (17552/18048)
Epoch: 178 | Batch_idx: 150 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (18810/19328)
Epoch: 178 | Batch_idx: 160 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (20061/20608)
Epoch: 178 | Batch_idx: 170 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (21312/21888)
Epoch: 178 | Batch_idx: 180 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (22548/23168)
Epoch: 178 | Batch_idx: 190 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (23796/24448)
Epoch: 178 | Batch_idx: 200 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (25042/25728)
Epoch: 178 | Batch_idx: 210 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (26287/27008)
Epoch: 178 | Batch_idx: 220 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (27521/28288)
Epoch: 178 | Batch_idx: 230 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (28760/29568)
Epoch: 178 | Batch_idx: 240 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (30004/30848)
Epoch: 178 | Batch_idx: 250 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (31247/32128)
Epoch: 178 | Batch_idx: 260 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (32485/33408)
Epoch: 178 | Batch_idx: 270 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (33724/34688)
Epoch: 178 | Batch_idx: 280 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (34974/35968)
Epoch: 178 | Batch_idx: 290 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (36232/37248)
Epoch: 178 | Batch_idx: 300 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (37479/38528)
Epoch: 178 | Batch_idx: 310 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (38735/39808)
Epoch: 178 | Batch_idx: 320 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (39975/41088)
Epoch: 178 | Batch_idx: 330 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (41226/42368)
Epoch: 178 | Batch_idx: 340 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (42474/43648)
Epoch: 178 | Batch_idx: 350 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (43724/44928)
Epoch: 178 | Batch_idx: 360 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (44971/46208)
Epoch: 178 | Batch_idx: 370 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (46225/47488)
Epoch: 178 | Batch_idx: 380 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (47466/48768)
Epoch: 178 | Batch_idx: 390 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (48659/50000)
# TEST : Loss: (0.3742) | Acc: (89.00%) (8934/10000)
percent tensor([0.5713, 0.5929, 0.5835, 0.5715, 0.5898, 0.5618, 0.6001, 0.5879, 0.5827,
        0.5858, 0.5792, 0.5912, 0.5770, 0.5891, 0.5805, 0.5710],
       device='cuda:0') torch.Size([16])
percent tensor([0.5477, 0.5439, 0.5395, 0.5298, 0.5368, 0.5168, 0.5497, 0.5443, 0.5446,
        0.5456, 0.5439, 0.5465, 0.5546, 0.5393, 0.5278, 0.5407],
       device='cuda:0') torch.Size([16])
percent tensor([0.6008, 0.6129, 0.6044, 0.6667, 0.6890, 0.6526, 0.6455, 0.7087, 0.5981,
        0.5448, 0.5355, 0.6100, 0.5483, 0.6505, 0.6839, 0.6060],
       device='cuda:0') torch.Size([16])
percent tensor([0.7443, 0.6921, 0.7145, 0.7135, 0.7240, 0.7427, 0.7303, 0.7152, 0.7045,
        0.7097, 0.7244, 0.6847, 0.6882, 0.7256, 0.7344, 0.7365],
       device='cuda:0') torch.Size([16])
percent tensor([0.5596, 0.5982, 0.5886, 0.6086, 0.5866, 0.6128, 0.5801, 0.5696, 0.6090,
        0.5841, 0.5841, 0.6071, 0.5617, 0.6352, 0.5530, 0.5915],
       device='cuda:0') torch.Size([16])
percent tensor([0.6296, 0.6967, 0.7157, 0.7376, 0.7223, 0.6902, 0.6895, 0.6817, 0.7245,
        0.6871, 0.7324, 0.7331, 0.6760, 0.7797, 0.6113, 0.6616],
       device='cuda:0') torch.Size([16])
percent tensor([0.5359, 0.6970, 0.7587, 0.7724, 0.6553, 0.8136, 0.6564, 0.5060, 0.6604,
        0.6796, 0.7294, 0.6325, 0.6702, 0.7102, 0.4181, 0.5936],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9998, 0.9999, 1.0000, 0.9995, 0.9996, 0.9993, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 179 | Batch_idx: 0 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 179 | Batch_idx: 10 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 179 | Batch_idx: 20 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (97.00%) (2612/2688)
Epoch: 179 | Batch_idx: 30 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (3861/3968)
Epoch: 179 | Batch_idx: 40 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (5115/5248)
Epoch: 179 | Batch_idx: 50 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (6364/6528)
Epoch: 179 | Batch_idx: 60 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (7617/7808)
Epoch: 179 | Batch_idx: 70 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (8865/9088)
Epoch: 179 | Batch_idx: 80 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (10108/10368)
Epoch: 179 | Batch_idx: 90 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (11348/11648)
Epoch: 179 | Batch_idx: 100 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (12590/12928)
Epoch: 179 | Batch_idx: 110 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (13840/14208)
Epoch: 179 | Batch_idx: 120 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (15092/15488)
Epoch: 179 | Batch_idx: 130 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (16343/16768)
Epoch: 179 | Batch_idx: 140 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (17594/18048)
Epoch: 179 | Batch_idx: 150 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (18841/19328)
Epoch: 179 | Batch_idx: 160 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (20089/20608)
Epoch: 179 | Batch_idx: 170 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (21341/21888)
Epoch: 179 | Batch_idx: 180 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (22585/23168)
Epoch: 179 | Batch_idx: 190 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (23834/24448)
Epoch: 179 | Batch_idx: 200 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (25086/25728)
Epoch: 179 | Batch_idx: 210 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (26331/27008)
Epoch: 179 | Batch_idx: 220 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (27576/28288)
Epoch: 179 | Batch_idx: 230 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (28812/29568)
Epoch: 179 | Batch_idx: 240 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (30053/30848)
Epoch: 179 | Batch_idx: 250 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (31296/32128)
Epoch: 179 | Batch_idx: 260 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (32549/33408)
Epoch: 179 | Batch_idx: 270 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (33796/34688)
Epoch: 179 | Batch_idx: 280 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (35049/35968)
Epoch: 179 | Batch_idx: 290 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (36282/37248)
Epoch: 179 | Batch_idx: 300 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (37526/38528)
Epoch: 179 | Batch_idx: 310 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (38775/39808)
Epoch: 179 | Batch_idx: 320 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (40019/41088)
Epoch: 179 | Batch_idx: 330 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (41263/42368)
Epoch: 179 | Batch_idx: 340 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (42515/43648)
Epoch: 179 | Batch_idx: 350 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (43771/44928)
Epoch: 179 | Batch_idx: 360 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (45028/46208)
Epoch: 179 | Batch_idx: 370 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (46273/47488)
Epoch: 179 | Batch_idx: 380 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (47516/48768)
Epoch: 179 | Batch_idx: 390 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (48710/50000)
# TEST : Loss: (0.3681) | Acc: (89.00%) (8946/10000)
percent tensor([0.5742, 0.5965, 0.5864, 0.5745, 0.5930, 0.5649, 0.6037, 0.5910, 0.5859,
        0.5891, 0.5825, 0.5944, 0.5801, 0.5927, 0.5839, 0.5741],
       device='cuda:0') torch.Size([16])
percent tensor([0.5475, 0.5434, 0.5396, 0.5301, 0.5369, 0.5169, 0.5492, 0.5442, 0.5442,
        0.5450, 0.5432, 0.5462, 0.5541, 0.5384, 0.5279, 0.5405],
       device='cuda:0') torch.Size([16])
percent tensor([0.6039, 0.6153, 0.6066, 0.6679, 0.6902, 0.6537, 0.6483, 0.7113, 0.6019,
        0.5471, 0.5382, 0.6110, 0.5526, 0.6536, 0.6851, 0.6081],
       device='cuda:0') torch.Size([16])
percent tensor([0.7491, 0.6961, 0.7183, 0.7174, 0.7284, 0.7484, 0.7346, 0.7193, 0.7086,
        0.7141, 0.7289, 0.6888, 0.6927, 0.7298, 0.7386, 0.7418],
       device='cuda:0') torch.Size([16])
percent tensor([0.5596, 0.5987, 0.5883, 0.6073, 0.5865, 0.6128, 0.5803, 0.5699, 0.6095,
        0.5844, 0.5838, 0.6065, 0.5629, 0.6339, 0.5534, 0.5919],
       device='cuda:0') torch.Size([16])
percent tensor([0.6200, 0.6854, 0.7068, 0.7297, 0.7120, 0.6801, 0.6802, 0.6705, 0.7133,
        0.6761, 0.7240, 0.7232, 0.6642, 0.7714, 0.6025, 0.6517],
       device='cuda:0') torch.Size([16])
percent tensor([0.5431, 0.7023, 0.7547, 0.7704, 0.6515, 0.8132, 0.6689, 0.4978, 0.6631,
        0.6874, 0.7376, 0.6330, 0.6752, 0.7190, 0.4297, 0.5997],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9998, 0.9999, 1.0000, 0.9994, 0.9996, 0.9993, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 180 | Batch_idx: 0 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 180 | Batch_idx: 10 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 180 | Batch_idx: 20 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (2610/2688)
Epoch: 180 | Batch_idx: 30 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (3859/3968)
Epoch: 180 | Batch_idx: 40 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (5106/5248)
Epoch: 180 | Batch_idx: 50 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (6353/6528)
Epoch: 180 | Batch_idx: 60 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (7590/7808)
Epoch: 180 | Batch_idx: 70 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (8830/9088)
Epoch: 180 | Batch_idx: 80 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (10083/10368)
Epoch: 180 | Batch_idx: 90 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (11318/11648)
Epoch: 180 | Batch_idx: 100 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (12569/12928)
Epoch: 180 | Batch_idx: 110 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (13805/14208)
Epoch: 180 | Batch_idx: 120 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (15046/15488)
Epoch: 180 | Batch_idx: 130 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (16287/16768)
Epoch: 180 | Batch_idx: 140 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (97.00%) (17523/18048)
Epoch: 180 | Batch_idx: 150 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (97.00%) (18774/19328)
Epoch: 180 | Batch_idx: 160 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (97.00%) (20005/20608)
Epoch: 180 | Batch_idx: 170 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (97.00%) (21257/21888)
Epoch: 180 | Batch_idx: 180 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (97.00%) (22478/23168)
Epoch: 180 | Batch_idx: 190 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (97.00%) (23723/24448)
Epoch: 180 | Batch_idx: 200 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (97.00%) (24964/25728)
Epoch: 180 | Batch_idx: 210 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (97.00%) (26209/27008)
Epoch: 180 | Batch_idx: 220 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (97.00%) (27445/28288)
Epoch: 180 | Batch_idx: 230 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (97.00%) (28682/29568)
Epoch: 180 | Batch_idx: 240 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (97.00%) (29924/30848)
Epoch: 180 | Batch_idx: 250 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (31162/32128)
Epoch: 180 | Batch_idx: 260 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (32385/33408)
Epoch: 180 | Batch_idx: 270 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (33617/34688)
Epoch: 180 | Batch_idx: 280 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (34852/35968)
Epoch: 180 | Batch_idx: 290 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (36079/37248)
Epoch: 180 | Batch_idx: 300 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (37322/38528)
Epoch: 180 | Batch_idx: 310 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (38559/39808)
Epoch: 180 | Batch_idx: 320 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (96.00%) (39787/41088)
Epoch: 180 | Batch_idx: 330 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (41019/42368)
Epoch: 180 | Batch_idx: 340 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (42245/43648)
Epoch: 180 | Batch_idx: 350 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (43488/44928)
Epoch: 180 | Batch_idx: 360 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (44730/46208)
Epoch: 180 | Batch_idx: 370 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (45965/47488)
Epoch: 180 | Batch_idx: 380 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (47198/48768)
Epoch: 180 | Batch_idx: 390 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (48404/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_180.pth.tar'
# TEST : Loss: (0.4033) | Acc: (88.00%) (8849/10000)
percent tensor([0.5748, 0.5978, 0.5851, 0.5742, 0.5927, 0.5659, 0.6049, 0.5903, 0.5869,
        0.5897, 0.5840, 0.5943, 0.5806, 0.5956, 0.5849, 0.5749],
       device='cuda:0') torch.Size([16])
percent tensor([0.5466, 0.5415, 0.5407, 0.5297, 0.5370, 0.5147, 0.5482, 0.5438, 0.5432,
        0.5440, 0.5415, 0.5465, 0.5529, 0.5356, 0.5267, 0.5390],
       device='cuda:0') torch.Size([16])
percent tensor([0.6022, 0.6207, 0.5912, 0.6485, 0.6792, 0.6522, 0.6480, 0.6957, 0.6010,
        0.5392, 0.5402, 0.5998, 0.5437, 0.6538, 0.6854, 0.6005],
       device='cuda:0') torch.Size([16])
percent tensor([0.7474, 0.6957, 0.7139, 0.7157, 0.7245, 0.7461, 0.7311, 0.7156, 0.7043,
        0.7125, 0.7292, 0.6867, 0.6933, 0.7256, 0.7392, 0.7412],
       device='cuda:0') torch.Size([16])
percent tensor([0.5612, 0.5985, 0.5929, 0.6151, 0.5920, 0.6132, 0.5809, 0.5741, 0.6131,
        0.5860, 0.5799, 0.6048, 0.5582, 0.6389, 0.5512, 0.5959],
       device='cuda:0') torch.Size([16])
percent tensor([0.6211, 0.6780, 0.7016, 0.7280, 0.7108, 0.6781, 0.6801, 0.6695, 0.7139,
        0.6747, 0.7232, 0.7210, 0.6612, 0.7618, 0.6106, 0.6552],
       device='cuda:0') torch.Size([16])
percent tensor([0.5820, 0.7050, 0.7573, 0.7860, 0.6348, 0.8085, 0.6657, 0.5021, 0.6659,
        0.7213, 0.7484, 0.6052, 0.6817, 0.7127, 0.4509, 0.6438],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9999, 1.0000, 0.9994, 0.9996, 0.9995, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9998, 0.9993, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(178.3678, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(821.7360, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(830.2731, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1525.3237, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(478.3679, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2282.5830, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4249.5625, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1363.8167, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6271.1504, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11609.6738, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3835.6172, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16131.1426, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 181 | Batch_idx: 0 |  Loss: (0.0177) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 181 | Batch_idx: 10 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 181 | Batch_idx: 20 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (2632/2688)
Epoch: 181 | Batch_idx: 30 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (3868/3968)
Epoch: 181 | Batch_idx: 40 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (5104/5248)
Epoch: 181 | Batch_idx: 50 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (6345/6528)
Epoch: 181 | Batch_idx: 60 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (7591/7808)
Epoch: 181 | Batch_idx: 70 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (8833/9088)
Epoch: 181 | Batch_idx: 80 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (10086/10368)
Epoch: 181 | Batch_idx: 90 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (11327/11648)
Epoch: 181 | Batch_idx: 100 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (12575/12928)
Epoch: 181 | Batch_idx: 110 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (13806/14208)
Epoch: 181 | Batch_idx: 120 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (15045/15488)
Epoch: 181 | Batch_idx: 130 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (16298/16768)
Epoch: 181 | Batch_idx: 140 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (17539/18048)
Epoch: 181 | Batch_idx: 150 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (18778/19328)
Epoch: 181 | Batch_idx: 160 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (20015/20608)
Epoch: 181 | Batch_idx: 170 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (21252/21888)
Epoch: 181 | Batch_idx: 180 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (22500/23168)
Epoch: 181 | Batch_idx: 190 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (23731/24448)
Epoch: 181 | Batch_idx: 200 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (24976/25728)
Epoch: 181 | Batch_idx: 210 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (26208/27008)
Epoch: 181 | Batch_idx: 220 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (27448/28288)
Epoch: 181 | Batch_idx: 230 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (28690/29568)
Epoch: 181 | Batch_idx: 240 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (29924/30848)
Epoch: 181 | Batch_idx: 250 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (96.00%) (31162/32128)
Epoch: 181 | Batch_idx: 260 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (32393/33408)
Epoch: 181 | Batch_idx: 270 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (96.00%) (33639/34688)
Epoch: 181 | Batch_idx: 280 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (96.00%) (34885/35968)
Epoch: 181 | Batch_idx: 290 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (36114/37248)
Epoch: 181 | Batch_idx: 300 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (37354/38528)
Epoch: 181 | Batch_idx: 310 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (38593/39808)
Epoch: 181 | Batch_idx: 320 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (39828/41088)
Epoch: 181 | Batch_idx: 330 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (41075/42368)
Epoch: 181 | Batch_idx: 340 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (42314/43648)
Epoch: 181 | Batch_idx: 350 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (43548/44928)
Epoch: 181 | Batch_idx: 360 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (44794/46208)
Epoch: 181 | Batch_idx: 370 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (46037/47488)
Epoch: 181 | Batch_idx: 380 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (47277/48768)
Epoch: 181 | Batch_idx: 390 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (48474/50000)
# TEST : Loss: (0.3929) | Acc: (89.00%) (8901/10000)
percent tensor([0.5751, 0.5975, 0.5850, 0.5737, 0.5926, 0.5661, 0.6046, 0.5901, 0.5868,
        0.5894, 0.5841, 0.5940, 0.5808, 0.5945, 0.5848, 0.5748],
       device='cuda:0') torch.Size([16])
percent tensor([0.5468, 0.5434, 0.5394, 0.5299, 0.5373, 0.5162, 0.5504, 0.5456, 0.5437,
        0.5444, 0.5426, 0.5465, 0.5529, 0.5394, 0.5278, 0.5398],
       device='cuda:0') torch.Size([16])
percent tensor([0.6068, 0.6140, 0.6073, 0.6702, 0.6861, 0.6498, 0.6466, 0.7061, 0.6041,
        0.5488, 0.5416, 0.6107, 0.5454, 0.6496, 0.6862, 0.6047],
       device='cuda:0') torch.Size([16])
percent tensor([0.7458, 0.6948, 0.7152, 0.7182, 0.7231, 0.7466, 0.7315, 0.7181, 0.7046,
        0.7125, 0.7274, 0.6869, 0.6903, 0.7298, 0.7379, 0.7392],
       device='cuda:0') torch.Size([16])
percent tensor([0.5586, 0.5996, 0.5893, 0.5983, 0.5916, 0.6125, 0.5816, 0.5681, 0.6108,
        0.5825, 0.5822, 0.6046, 0.5618, 0.6266, 0.5500, 0.5916],
       device='cuda:0') torch.Size([16])
percent tensor([0.6159, 0.6710, 0.7065, 0.7240, 0.6948, 0.6798, 0.6742, 0.6662, 0.7080,
        0.6716, 0.7216, 0.7078, 0.6588, 0.7537, 0.6015, 0.6556],
       device='cuda:0') torch.Size([16])
percent tensor([0.5439, 0.6723, 0.7443, 0.7822, 0.6068, 0.8014, 0.6629, 0.5072, 0.6608,
        0.6704, 0.7324, 0.6105, 0.6387, 0.6375, 0.4539, 0.5987],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9998, 0.9998, 0.9999, 0.9993, 0.9996, 0.9995, 0.9999,
        0.9999, 0.9999, 1.0000, 0.9999, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 182 | Batch_idx: 0 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 182 | Batch_idx: 10 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 182 | Batch_idx: 20 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (2614/2688)
Epoch: 182 | Batch_idx: 30 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (3851/3968)
Epoch: 182 | Batch_idx: 40 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (96.00%) (5089/5248)
Epoch: 182 | Batch_idx: 50 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (96.00%) (6329/6528)
Epoch: 182 | Batch_idx: 60 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (96.00%) (7572/7808)
Epoch: 182 | Batch_idx: 70 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (8816/9088)
Epoch: 182 | Batch_idx: 80 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (96.00%) (10054/10368)
Epoch: 182 | Batch_idx: 90 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (11304/11648)
Epoch: 182 | Batch_idx: 100 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (12548/12928)
Epoch: 182 | Batch_idx: 110 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (13789/14208)
Epoch: 182 | Batch_idx: 120 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (15024/15488)
Epoch: 182 | Batch_idx: 130 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (16273/16768)
Epoch: 182 | Batch_idx: 140 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (17513/18048)
Epoch: 182 | Batch_idx: 150 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (18765/19328)
Epoch: 182 | Batch_idx: 160 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (20016/20608)
Epoch: 182 | Batch_idx: 170 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (21256/21888)
Epoch: 182 | Batch_idx: 180 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (22494/23168)
Epoch: 182 | Batch_idx: 190 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (23731/24448)
Epoch: 182 | Batch_idx: 200 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (24982/25728)
Epoch: 182 | Batch_idx: 210 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (26220/27008)
Epoch: 182 | Batch_idx: 220 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (27470/28288)
Epoch: 182 | Batch_idx: 230 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (28724/29568)
Epoch: 182 | Batch_idx: 240 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (29965/30848)
Epoch: 182 | Batch_idx: 250 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (31209/32128)
Epoch: 182 | Batch_idx: 260 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (32452/33408)
Epoch: 182 | Batch_idx: 270 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (33690/34688)
Epoch: 182 | Batch_idx: 280 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (34923/35968)
Epoch: 182 | Batch_idx: 290 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (36155/37248)
Epoch: 182 | Batch_idx: 300 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (37391/38528)
Epoch: 182 | Batch_idx: 310 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (38635/39808)
Epoch: 182 | Batch_idx: 320 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (39877/41088)
Epoch: 182 | Batch_idx: 330 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (41114/42368)
Epoch: 182 | Batch_idx: 340 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (42356/43648)
Epoch: 182 | Batch_idx: 350 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (43591/44928)
Epoch: 182 | Batch_idx: 360 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (44833/46208)
Epoch: 182 | Batch_idx: 370 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (46070/47488)
Epoch: 182 | Batch_idx: 380 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (47309/48768)
Epoch: 182 | Batch_idx: 390 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (48512/50000)
# TEST : Loss: (0.4067) | Acc: (88.00%) (8851/10000)
percent tensor([0.5760, 0.5980, 0.5869, 0.5748, 0.5939, 0.5671, 0.6061, 0.5913, 0.5883,
        0.5905, 0.5852, 0.5962, 0.5820, 0.5954, 0.5853, 0.5758],
       device='cuda:0') torch.Size([16])
percent tensor([0.5474, 0.5443, 0.5413, 0.5293, 0.5377, 0.5155, 0.5519, 0.5458, 0.5454,
        0.5453, 0.5440, 0.5478, 0.5548, 0.5402, 0.5278, 0.5401],
       device='cuda:0') torch.Size([16])
percent tensor([0.6098, 0.6164, 0.6034, 0.6742, 0.6816, 0.6664, 0.6440, 0.7097, 0.6133,
        0.5471, 0.5472, 0.6023, 0.5553, 0.6533, 0.6924, 0.6140],
       device='cuda:0') torch.Size([16])
percent tensor([0.7468, 0.6922, 0.7157, 0.7142, 0.7231, 0.7519, 0.7283, 0.7194, 0.7020,
        0.7095, 0.7226, 0.6834, 0.6858, 0.7254, 0.7380, 0.7417],
       device='cuda:0') torch.Size([16])
percent tensor([0.5638, 0.5998, 0.5901, 0.6033, 0.5946, 0.6143, 0.5888, 0.5684, 0.6114,
        0.5835, 0.5888, 0.6119, 0.5682, 0.6305, 0.5581, 0.5909],
       device='cuda:0') torch.Size([16])
percent tensor([0.6281, 0.6758, 0.7150, 0.7269, 0.7028, 0.6857, 0.6797, 0.6574, 0.7167,
        0.6692, 0.7285, 0.7240, 0.6685, 0.7703, 0.6126, 0.6528],
       device='cuda:0') torch.Size([16])
percent tensor([0.5773, 0.7173, 0.7568, 0.7705, 0.6301, 0.8082, 0.6960, 0.4854, 0.7075,
        0.6973, 0.7700, 0.6488, 0.6806, 0.6893, 0.4784, 0.6112],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9998, 0.9999, 0.9994, 0.9997, 0.9994, 0.9999,
        0.9999, 0.9999, 1.0000, 0.9999, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 183 | Batch_idx: 0 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 183 | Batch_idx: 10 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 183 | Batch_idx: 20 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (2614/2688)
Epoch: 183 | Batch_idx: 30 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (3862/3968)
Epoch: 183 | Batch_idx: 40 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (5108/5248)
Epoch: 183 | Batch_idx: 50 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (6343/6528)
Epoch: 183 | Batch_idx: 60 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (7582/7808)
Epoch: 183 | Batch_idx: 70 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (8817/9088)
Epoch: 183 | Batch_idx: 80 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (10071/10368)
Epoch: 183 | Batch_idx: 90 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (11314/11648)
Epoch: 183 | Batch_idx: 100 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (12554/12928)
Epoch: 183 | Batch_idx: 110 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (13786/14208)
Epoch: 183 | Batch_idx: 120 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (15030/15488)
Epoch: 183 | Batch_idx: 130 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (16270/16768)
Epoch: 183 | Batch_idx: 140 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (17518/18048)
Epoch: 183 | Batch_idx: 150 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (18757/19328)
Epoch: 183 | Batch_idx: 160 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (19999/20608)
Epoch: 183 | Batch_idx: 170 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (21238/21888)
Epoch: 183 | Batch_idx: 180 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (22485/23168)
Epoch: 183 | Batch_idx: 190 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (23728/24448)
Epoch: 183 | Batch_idx: 200 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (24969/25728)
Epoch: 183 | Batch_idx: 210 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (26222/27008)
Epoch: 183 | Batch_idx: 220 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (27461/28288)
Epoch: 183 | Batch_idx: 230 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (28701/29568)
Epoch: 183 | Batch_idx: 240 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (29948/30848)
Epoch: 183 | Batch_idx: 250 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (31191/32128)
Epoch: 183 | Batch_idx: 260 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (32443/33408)
Epoch: 183 | Batch_idx: 270 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (33687/34688)
Epoch: 183 | Batch_idx: 280 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (34931/35968)
Epoch: 183 | Batch_idx: 290 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (36169/37248)
Epoch: 183 | Batch_idx: 300 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (37403/38528)
Epoch: 183 | Batch_idx: 310 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (38644/39808)
Epoch: 183 | Batch_idx: 320 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (39879/41088)
Epoch: 183 | Batch_idx: 330 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (41128/42368)
Epoch: 183 | Batch_idx: 340 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (42380/43648)
Epoch: 183 | Batch_idx: 350 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (43623/44928)
Epoch: 183 | Batch_idx: 360 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (44868/46208)
Epoch: 183 | Batch_idx: 370 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (46104/47488)
Epoch: 183 | Batch_idx: 380 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (47353/48768)
Epoch: 183 | Batch_idx: 390 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (48537/50000)
# TEST : Loss: (0.4663) | Acc: (87.00%) (8759/10000)
percent tensor([0.5757, 0.5964, 0.5860, 0.5746, 0.5937, 0.5671, 0.6043, 0.5901, 0.5871,
        0.5892, 0.5837, 0.5953, 0.5812, 0.5930, 0.5848, 0.5749],
       device='cuda:0') torch.Size([16])
percent tensor([0.5470, 0.5416, 0.5421, 0.5287, 0.5388, 0.5156, 0.5484, 0.5433, 0.5446,
        0.5440, 0.5424, 0.5484, 0.5538, 0.5354, 0.5260, 0.5385],
       device='cuda:0') torch.Size([16])
percent tensor([0.6116, 0.6171, 0.6129, 0.6635, 0.6872, 0.6667, 0.6486, 0.7088, 0.6154,
        0.5472, 0.5519, 0.6132, 0.5577, 0.6508, 0.6943, 0.6111],
       device='cuda:0') torch.Size([16])
percent tensor([0.7472, 0.6926, 0.7207, 0.7203, 0.7281, 0.7533, 0.7300, 0.7225, 0.7031,
        0.7099, 0.7235, 0.6896, 0.6880, 0.7257, 0.7395, 0.7422],
       device='cuda:0') torch.Size([16])
percent tensor([0.5621, 0.5983, 0.5878, 0.6029, 0.5939, 0.6095, 0.5871, 0.5700, 0.6123,
        0.5828, 0.5866, 0.6083, 0.5631, 0.6331, 0.5520, 0.5901],
       device='cuda:0') torch.Size([16])
percent tensor([0.6190, 0.6698, 0.7083, 0.7262, 0.7090, 0.6763, 0.6828, 0.6555, 0.7095,
        0.6664, 0.7191, 0.7118, 0.6623, 0.7524, 0.5950, 0.6432],
       device='cuda:0') torch.Size([16])
percent tensor([0.6001, 0.7049, 0.7343, 0.7776, 0.6410, 0.8176, 0.6738, 0.4935, 0.6631,
        0.6888, 0.7409, 0.5816, 0.6856, 0.6445, 0.4410, 0.6163],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9998, 0.9999, 0.9994, 0.9997, 0.9997, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9995, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 184 | Batch_idx: 0 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 184 | Batch_idx: 10 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (1374/1408)
Epoch: 184 | Batch_idx: 20 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (2627/2688)
Epoch: 184 | Batch_idx: 30 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (3883/3968)
Epoch: 184 | Batch_idx: 40 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (5122/5248)
Epoch: 184 | Batch_idx: 50 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (6361/6528)
Epoch: 184 | Batch_idx: 60 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (7597/7808)
Epoch: 184 | Batch_idx: 70 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (8847/9088)
Epoch: 184 | Batch_idx: 80 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (10100/10368)
Epoch: 184 | Batch_idx: 90 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (11344/11648)
Epoch: 184 | Batch_idx: 100 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (12596/12928)
Epoch: 184 | Batch_idx: 110 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (13846/14208)
Epoch: 184 | Batch_idx: 120 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (15085/15488)
Epoch: 184 | Batch_idx: 130 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (16331/16768)
Epoch: 184 | Batch_idx: 140 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (17577/18048)
Epoch: 184 | Batch_idx: 150 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (18827/19328)
Epoch: 184 | Batch_idx: 160 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (20072/20608)
Epoch: 184 | Batch_idx: 170 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (21322/21888)
Epoch: 184 | Batch_idx: 180 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (22564/23168)
Epoch: 184 | Batch_idx: 190 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (23814/24448)
Epoch: 184 | Batch_idx: 200 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (25061/25728)
Epoch: 184 | Batch_idx: 210 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (26308/27008)
Epoch: 184 | Batch_idx: 220 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (27548/28288)
Epoch: 184 | Batch_idx: 230 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (28788/29568)
Epoch: 184 | Batch_idx: 240 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (30026/30848)
Epoch: 184 | Batch_idx: 250 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (31275/32128)
Epoch: 184 | Batch_idx: 260 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (32519/33408)
Epoch: 184 | Batch_idx: 270 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (33766/34688)
Epoch: 184 | Batch_idx: 280 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (35015/35968)
Epoch: 184 | Batch_idx: 290 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (36259/37248)
Epoch: 184 | Batch_idx: 300 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (37501/38528)
Epoch: 184 | Batch_idx: 310 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (38744/39808)
Epoch: 184 | Batch_idx: 320 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (39995/41088)
Epoch: 184 | Batch_idx: 330 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (41244/42368)
Epoch: 184 | Batch_idx: 340 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (42494/43648)
Epoch: 184 | Batch_idx: 350 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (43737/44928)
Epoch: 184 | Batch_idx: 360 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (44977/46208)
Epoch: 184 | Batch_idx: 370 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (46229/47488)
Epoch: 184 | Batch_idx: 380 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (47475/48768)
Epoch: 184 | Batch_idx: 390 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (48684/50000)
# TEST : Loss: (0.4129) | Acc: (89.00%) (8908/10000)
percent tensor([0.5753, 0.5968, 0.5864, 0.5747, 0.5940, 0.5665, 0.6047, 0.5907, 0.5871,
        0.5896, 0.5837, 0.5951, 0.5810, 0.5935, 0.5848, 0.5749],
       device='cuda:0') torch.Size([16])
percent tensor([0.5475, 0.5441, 0.5384, 0.5296, 0.5356, 0.5159, 0.5500, 0.5440, 0.5451,
        0.5448, 0.5437, 0.5454, 0.5552, 0.5399, 0.5287, 0.5407],
       device='cuda:0') torch.Size([16])
percent tensor([0.6086, 0.6121, 0.6120, 0.6682, 0.6877, 0.6573, 0.6513, 0.7004, 0.6010,
        0.5422, 0.5388, 0.6137, 0.5491, 0.6524, 0.6839, 0.6073],
       device='cuda:0') torch.Size([16])
percent tensor([0.7465, 0.6959, 0.7117, 0.7148, 0.7190, 0.7479, 0.7308, 0.7208, 0.7035,
        0.7115, 0.7272, 0.6834, 0.6884, 0.7268, 0.7382, 0.7423],
       device='cuda:0') torch.Size([16])
percent tensor([0.5687, 0.5950, 0.5906, 0.6069, 0.5968, 0.6110, 0.5836, 0.5740, 0.6116,
        0.5845, 0.5828, 0.6113, 0.5686, 0.6278, 0.5530, 0.5949],
       device='cuda:0') torch.Size([16])
percent tensor([0.6317, 0.6686, 0.7122, 0.7252, 0.7140, 0.6848, 0.6868, 0.6703, 0.7111,
        0.6732, 0.7172, 0.7151, 0.6683, 0.7563, 0.6062, 0.6571],
       device='cuda:0') torch.Size([16])
percent tensor([0.6119, 0.6787, 0.7558, 0.7859, 0.6518, 0.8116, 0.6935, 0.5125, 0.6800,
        0.6798, 0.7528, 0.6320, 0.6443, 0.7055, 0.4595, 0.6247],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9998, 1.0000, 0.9993, 0.9996, 0.9995, 0.9999,
        0.9999, 1.0000, 0.9999, 1.0000, 0.9995, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 185 | Batch_idx: 0 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 185 | Batch_idx: 10 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 185 | Batch_idx: 20 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (2617/2688)
Epoch: 185 | Batch_idx: 30 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (3855/3968)
Epoch: 185 | Batch_idx: 40 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (96.00%) (5088/5248)
Epoch: 185 | Batch_idx: 50 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (6333/6528)
Epoch: 185 | Batch_idx: 60 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (96.00%) (7572/7808)
Epoch: 185 | Batch_idx: 70 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (96.00%) (8803/9088)
Epoch: 185 | Batch_idx: 80 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (96.00%) (10054/10368)
Epoch: 185 | Batch_idx: 90 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (96.00%) (11297/11648)
Epoch: 185 | Batch_idx: 100 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (96.00%) (12539/12928)
Epoch: 185 | Batch_idx: 110 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (96.00%) (13778/14208)
Epoch: 185 | Batch_idx: 120 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (96.00%) (15013/15488)
Epoch: 185 | Batch_idx: 130 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (96.00%) (16261/16768)
Epoch: 185 | Batch_idx: 140 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (17515/18048)
Epoch: 185 | Batch_idx: 150 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (18754/19328)
Epoch: 185 | Batch_idx: 160 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (19990/20608)
Epoch: 185 | Batch_idx: 170 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (96.00%) (21228/21888)
Epoch: 185 | Batch_idx: 180 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (96.00%) (22472/23168)
Epoch: 185 | Batch_idx: 190 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (23723/24448)
Epoch: 185 | Batch_idx: 200 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (24978/25728)
Epoch: 185 | Batch_idx: 210 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (26220/27008)
Epoch: 185 | Batch_idx: 220 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (27472/28288)
Epoch: 185 | Batch_idx: 230 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (28728/29568)
Epoch: 185 | Batch_idx: 240 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (29977/30848)
Epoch: 185 | Batch_idx: 250 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (31217/32128)
Epoch: 185 | Batch_idx: 260 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (32461/33408)
Epoch: 185 | Batch_idx: 270 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (33697/34688)
Epoch: 185 | Batch_idx: 280 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (34946/35968)
Epoch: 185 | Batch_idx: 290 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (36192/37248)
Epoch: 185 | Batch_idx: 300 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (37436/38528)
Epoch: 185 | Batch_idx: 310 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (38686/39808)
Epoch: 185 | Batch_idx: 320 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (39920/41088)
Epoch: 185 | Batch_idx: 330 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (41173/42368)
Epoch: 185 | Batch_idx: 340 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (42426/43648)
Epoch: 185 | Batch_idx: 350 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (43678/44928)
Epoch: 185 | Batch_idx: 360 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (44923/46208)
Epoch: 185 | Batch_idx: 370 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (46167/47488)
Epoch: 185 | Batch_idx: 380 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (47400/48768)
Epoch: 185 | Batch_idx: 390 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (48609/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_185.pth.tar'
# TEST : Loss: (0.3857) | Acc: (89.00%) (8937/10000)
percent tensor([0.5833, 0.6062, 0.5952, 0.5828, 0.6035, 0.5739, 0.6145, 0.6000, 0.5957,
        0.5986, 0.5921, 0.6045, 0.5894, 0.6025, 0.5934, 0.5829],
       device='cuda:0') torch.Size([16])
percent tensor([0.5360, 0.5323, 0.5251, 0.5165, 0.5223, 0.5051, 0.5374, 0.5317, 0.5326,
        0.5325, 0.5314, 0.5321, 0.5432, 0.5279, 0.5170, 0.5290],
       device='cuda:0') torch.Size([16])
percent tensor([0.6164, 0.6130, 0.6159, 0.6812, 0.6893, 0.6654, 0.6506, 0.7065, 0.6054,
        0.5466, 0.5401, 0.6119, 0.5527, 0.6618, 0.6867, 0.6161],
       device='cuda:0') torch.Size([16])
percent tensor([0.7475, 0.6977, 0.7113, 0.7125, 0.7202, 0.7464, 0.7322, 0.7209, 0.7051,
        0.7124, 0.7308, 0.6829, 0.6899, 0.7266, 0.7399, 0.7429],
       device='cuda:0') torch.Size([16])
percent tensor([0.5685, 0.5967, 0.5919, 0.6015, 0.5926, 0.6096, 0.5867, 0.5698, 0.6111,
        0.5856, 0.5799, 0.6116, 0.5747, 0.6245, 0.5554, 0.5917],
       device='cuda:0') torch.Size([16])
percent tensor([0.6410, 0.6874, 0.7209, 0.7411, 0.7261, 0.6945, 0.7013, 0.6860, 0.7279,
        0.6929, 0.7335, 0.7316, 0.6826, 0.7706, 0.6222, 0.6752],
       device='cuda:0') torch.Size([16])
percent tensor([0.5652, 0.6712, 0.7246, 0.7527, 0.6223, 0.7901, 0.6688, 0.4883, 0.6700,
        0.6593, 0.7363, 0.6153, 0.6318, 0.6712, 0.4357, 0.5975],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9999, 0.9998, 0.9999, 0.9993, 0.9996, 0.9994, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9993, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 186 | Batch_idx: 0 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 186 | Batch_idx: 10 |  Loss: (0.0665) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 186 | Batch_idx: 20 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (2620/2688)
Epoch: 186 | Batch_idx: 30 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (3860/3968)
Epoch: 186 | Batch_idx: 40 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (5104/5248)
Epoch: 186 | Batch_idx: 50 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (6353/6528)
Epoch: 186 | Batch_idx: 60 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (7604/7808)
Epoch: 186 | Batch_idx: 70 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (8846/9088)
Epoch: 186 | Batch_idx: 80 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (10096/10368)
Epoch: 186 | Batch_idx: 90 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (11338/11648)
Epoch: 186 | Batch_idx: 100 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (12580/12928)
Epoch: 186 | Batch_idx: 110 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (13832/14208)
Epoch: 186 | Batch_idx: 120 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (15080/15488)
Epoch: 186 | Batch_idx: 130 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (16329/16768)
Epoch: 186 | Batch_idx: 140 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (17571/18048)
Epoch: 186 | Batch_idx: 150 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (18820/19328)
Epoch: 186 | Batch_idx: 160 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (20073/20608)
Epoch: 186 | Batch_idx: 170 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (21321/21888)
Epoch: 186 | Batch_idx: 180 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (22569/23168)
Epoch: 186 | Batch_idx: 190 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (23823/24448)
Epoch: 186 | Batch_idx: 200 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (25078/25728)
Epoch: 186 | Batch_idx: 210 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (26318/27008)
Epoch: 186 | Batch_idx: 220 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (27567/28288)
Epoch: 186 | Batch_idx: 230 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (28806/29568)
Epoch: 186 | Batch_idx: 240 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (30047/30848)
Epoch: 186 | Batch_idx: 250 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (31293/32128)
Epoch: 186 | Batch_idx: 260 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (32547/33408)
Epoch: 186 | Batch_idx: 270 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (33800/34688)
Epoch: 186 | Batch_idx: 280 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (35048/35968)
Epoch: 186 | Batch_idx: 290 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (36293/37248)
Epoch: 186 | Batch_idx: 300 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (37541/38528)
Epoch: 186 | Batch_idx: 310 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (38790/39808)
Epoch: 186 | Batch_idx: 320 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (40041/41088)
Epoch: 186 | Batch_idx: 330 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (41284/42368)
Epoch: 186 | Batch_idx: 340 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (42530/43648)
Epoch: 186 | Batch_idx: 350 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (43777/44928)
Epoch: 186 | Batch_idx: 360 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (45023/46208)
Epoch: 186 | Batch_idx: 370 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (46267/47488)
Epoch: 186 | Batch_idx: 380 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (47516/48768)
Epoch: 186 | Batch_idx: 390 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (48718/50000)
# TEST : Loss: (0.3811) | Acc: (89.00%) (8961/10000)
percent tensor([0.5856, 0.6083, 0.5979, 0.5847, 0.6062, 0.5757, 0.6170, 0.6023, 0.5980,
        0.6008, 0.5941, 0.6072, 0.5915, 0.6044, 0.5954, 0.5848],
       device='cuda:0') torch.Size([16])
percent tensor([0.5350, 0.5307, 0.5238, 0.5150, 0.5207, 0.5044, 0.5358, 0.5305, 0.5312,
        0.5309, 0.5299, 0.5305, 0.5419, 0.5264, 0.5157, 0.5279],
       device='cuda:0') torch.Size([16])
percent tensor([0.6248, 0.6125, 0.6211, 0.6853, 0.6934, 0.6714, 0.6527, 0.7118, 0.6086,
        0.5486, 0.5411, 0.6134, 0.5556, 0.6631, 0.6895, 0.6211],
       device='cuda:0') torch.Size([16])
percent tensor([0.7421, 0.6923, 0.7062, 0.7057, 0.7147, 0.7409, 0.7272, 0.7147, 0.6989,
        0.7069, 0.7251, 0.6769, 0.6847, 0.7205, 0.7344, 0.7369],
       device='cuda:0') torch.Size([16])
percent tensor([0.5634, 0.5940, 0.5848, 0.5943, 0.5845, 0.6043, 0.5830, 0.5612, 0.6067,
        0.5826, 0.5776, 0.6063, 0.5728, 0.6210, 0.5511, 0.5874],
       device='cuda:0') torch.Size([16])
percent tensor([0.6304, 0.6811, 0.7157, 0.7366, 0.7200, 0.6881, 0.6927, 0.6779, 0.7239,
        0.6858, 0.7285, 0.7274, 0.6758, 0.7667, 0.6125, 0.6669],
       device='cuda:0') torch.Size([16])
percent tensor([0.5620, 0.6818, 0.7267, 0.7538, 0.6328, 0.7872, 0.6691, 0.4972, 0.6703,
        0.6683, 0.7337, 0.6217, 0.6352, 0.6638, 0.4466, 0.5991],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9998, 1.0000, 0.9993, 0.9996, 0.9994, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9994, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 187 | Batch_idx: 0 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 187 | Batch_idx: 10 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (97.00%) (1366/1408)
Epoch: 187 | Batch_idx: 20 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (2616/2688)
Epoch: 187 | Batch_idx: 30 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (3849/3968)
Epoch: 187 | Batch_idx: 40 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (5100/5248)
Epoch: 187 | Batch_idx: 50 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (6348/6528)
Epoch: 187 | Batch_idx: 60 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (7593/7808)
Epoch: 187 | Batch_idx: 70 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (8839/9088)
Epoch: 187 | Batch_idx: 80 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (10092/10368)
Epoch: 187 | Batch_idx: 90 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (11347/11648)
Epoch: 187 | Batch_idx: 100 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (12592/12928)
Epoch: 187 | Batch_idx: 110 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (13836/14208)
Epoch: 187 | Batch_idx: 120 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (15082/15488)
Epoch: 187 | Batch_idx: 130 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (16328/16768)
Epoch: 187 | Batch_idx: 140 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (17580/18048)
Epoch: 187 | Batch_idx: 150 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (18827/19328)
Epoch: 187 | Batch_idx: 160 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (20080/20608)
Epoch: 187 | Batch_idx: 170 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (21332/21888)
Epoch: 187 | Batch_idx: 180 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (22586/23168)
Epoch: 187 | Batch_idx: 190 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (23847/24448)
Epoch: 187 | Batch_idx: 200 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (25100/25728)
Epoch: 187 | Batch_idx: 210 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (26343/27008)
Epoch: 187 | Batch_idx: 220 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (27597/28288)
Epoch: 187 | Batch_idx: 230 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (28846/29568)
Epoch: 187 | Batch_idx: 240 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (30100/30848)
Epoch: 187 | Batch_idx: 250 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (31355/32128)
Epoch: 187 | Batch_idx: 260 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (32602/33408)
Epoch: 187 | Batch_idx: 270 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (33856/34688)
Epoch: 187 | Batch_idx: 280 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (35104/35968)
Epoch: 187 | Batch_idx: 290 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (36352/37248)
Epoch: 187 | Batch_idx: 300 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (37603/38528)
Epoch: 187 | Batch_idx: 310 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (38852/39808)
Epoch: 187 | Batch_idx: 320 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (40101/41088)
Epoch: 187 | Batch_idx: 330 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (41345/42368)
Epoch: 187 | Batch_idx: 340 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (42600/43648)
Epoch: 187 | Batch_idx: 350 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (43851/44928)
Epoch: 187 | Batch_idx: 360 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (45094/46208)
Epoch: 187 | Batch_idx: 370 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (46348/47488)
Epoch: 187 | Batch_idx: 380 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (47596/48768)
Epoch: 187 | Batch_idx: 390 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (48797/50000)
# TEST : Loss: (0.3797) | Acc: (89.00%) (8972/10000)
percent tensor([0.5805, 0.6022, 0.5924, 0.5799, 0.6003, 0.5709, 0.6107, 0.5966, 0.5928,
        0.5949, 0.5887, 0.6012, 0.5861, 0.5992, 0.5896, 0.5797],
       device='cuda:0') torch.Size([16])
percent tensor([0.5332, 0.5289, 0.5214, 0.5122, 0.5184, 0.5025, 0.5338, 0.5284, 0.5292,
        0.5289, 0.5281, 0.5281, 0.5400, 0.5246, 0.5137, 0.5259],
       device='cuda:0') torch.Size([16])
percent tensor([0.6208, 0.6081, 0.6184, 0.6816, 0.6881, 0.6663, 0.6477, 0.7077, 0.6036,
        0.5454, 0.5368, 0.6080, 0.5524, 0.6581, 0.6846, 0.6174],
       device='cuda:0') torch.Size([16])
percent tensor([0.7415, 0.6923, 0.7058, 0.7048, 0.7138, 0.7402, 0.7269, 0.7137, 0.6981,
        0.7063, 0.7247, 0.6767, 0.6854, 0.7196, 0.7343, 0.7362],
       device='cuda:0') torch.Size([16])
percent tensor([0.5689, 0.6009, 0.5886, 0.5989, 0.5882, 0.6085, 0.5896, 0.5653, 0.6124,
        0.5893, 0.5847, 0.6123, 0.5792, 0.6280, 0.5575, 0.5935],
       device='cuda:0') torch.Size([16])
percent tensor([0.6350, 0.6870, 0.7224, 0.7430, 0.7267, 0.6931, 0.6964, 0.6821, 0.7308,
        0.6911, 0.7347, 0.7342, 0.6809, 0.7745, 0.6164, 0.6703],
       device='cuda:0') torch.Size([16])
percent tensor([0.5733, 0.7012, 0.7376, 0.7595, 0.6524, 0.7962, 0.6825, 0.5060, 0.6873,
        0.6840, 0.7450, 0.6389, 0.6477, 0.6750, 0.4648, 0.6030],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9998, 1.0000, 0.9993, 0.9996, 0.9994, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9994, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 188 | Batch_idx: 0 |  Loss: (0.0324) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 188 | Batch_idx: 10 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 188 | Batch_idx: 20 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (2631/2688)
Epoch: 188 | Batch_idx: 30 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (3880/3968)
Epoch: 188 | Batch_idx: 40 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (5137/5248)
Epoch: 188 | Batch_idx: 50 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (6388/6528)
Epoch: 188 | Batch_idx: 60 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (7627/7808)
Epoch: 188 | Batch_idx: 70 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (8879/9088)
Epoch: 188 | Batch_idx: 80 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (10133/10368)
Epoch: 188 | Batch_idx: 90 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (11376/11648)
Epoch: 188 | Batch_idx: 100 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (12633/12928)
Epoch: 188 | Batch_idx: 110 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (13885/14208)
Epoch: 188 | Batch_idx: 120 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (15147/15488)
Epoch: 188 | Batch_idx: 130 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (16401/16768)
Epoch: 188 | Batch_idx: 140 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (17656/18048)
Epoch: 188 | Batch_idx: 150 |  Loss: (0.0673) |  Loss2: (0.0000) | Acc: (97.00%) (18916/19328)
Epoch: 188 | Batch_idx: 160 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (20167/20608)
Epoch: 188 | Batch_idx: 170 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (21416/21888)
Epoch: 188 | Batch_idx: 180 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (22665/23168)
Epoch: 188 | Batch_idx: 190 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (23914/24448)
Epoch: 188 | Batch_idx: 200 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (25167/25728)
Epoch: 188 | Batch_idx: 210 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (26416/27008)
Epoch: 188 | Batch_idx: 220 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (27671/28288)
Epoch: 188 | Batch_idx: 230 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (28927/29568)
Epoch: 188 | Batch_idx: 240 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (30191/30848)
Epoch: 188 | Batch_idx: 250 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (31444/32128)
Epoch: 188 | Batch_idx: 260 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (32700/33408)
Epoch: 188 | Batch_idx: 270 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (33958/34688)
Epoch: 188 | Batch_idx: 280 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (35208/35968)
Epoch: 188 | Batch_idx: 290 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (36464/37248)
Epoch: 188 | Batch_idx: 300 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (37724/38528)
Epoch: 188 | Batch_idx: 310 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (38975/39808)
Epoch: 188 | Batch_idx: 320 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (40226/41088)
Epoch: 188 | Batch_idx: 330 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (41480/42368)
Epoch: 188 | Batch_idx: 340 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (42736/43648)
Epoch: 188 | Batch_idx: 350 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (43985/44928)
Epoch: 188 | Batch_idx: 360 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (45224/46208)
Epoch: 188 | Batch_idx: 370 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (46471/47488)
Epoch: 188 | Batch_idx: 380 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (47726/48768)
Epoch: 188 | Batch_idx: 390 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (48934/50000)
# TEST : Loss: (0.3756) | Acc: (89.00%) (8976/10000)
percent tensor([0.5812, 0.6024, 0.5930, 0.5801, 0.6009, 0.5716, 0.6111, 0.5969, 0.5933,
        0.5952, 0.5892, 0.6018, 0.5866, 0.5994, 0.5900, 0.5801],
       device='cuda:0') torch.Size([16])
percent tensor([0.5336, 0.5291, 0.5218, 0.5124, 0.5188, 0.5028, 0.5341, 0.5288, 0.5295,
        0.5291, 0.5282, 0.5284, 0.5403, 0.5247, 0.5140, 0.5262],
       device='cuda:0') torch.Size([16])
percent tensor([0.6206, 0.6070, 0.6196, 0.6831, 0.6883, 0.6658, 0.6467, 0.7094, 0.6034,
        0.5455, 0.5356, 0.6079, 0.5523, 0.6572, 0.6839, 0.6172],
       device='cuda:0') torch.Size([16])
percent tensor([0.7416, 0.6933, 0.7061, 0.7042, 0.7139, 0.7403, 0.7277, 0.7134, 0.6983,
        0.7069, 0.7251, 0.6778, 0.6866, 0.7202, 0.7349, 0.7360],
       device='cuda:0') torch.Size([16])
percent tensor([0.5636, 0.5962, 0.5849, 0.5968, 0.5847, 0.6045, 0.5851, 0.5607, 0.6092,
        0.5848, 0.5807, 0.6093, 0.5741, 0.6250, 0.5529, 0.5885],
       device='cuda:0') torch.Size([16])
percent tensor([0.6303, 0.6829, 0.7197, 0.7404, 0.7230, 0.6910, 0.6919, 0.6788, 0.7274,
        0.6872, 0.7327, 0.7319, 0.6766, 0.7722, 0.6120, 0.6664],
       device='cuda:0') torch.Size([16])
percent tensor([0.5614, 0.6953, 0.7282, 0.7524, 0.6384, 0.7932, 0.6701, 0.4939, 0.6736,
        0.6765, 0.7399, 0.6203, 0.6336, 0.6678, 0.4514, 0.5943],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9998, 1.0000, 0.9994, 0.9996, 0.9994, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9994, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 189 | Batch_idx: 0 |  Loss: (0.0327) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 189 | Batch_idx: 10 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (1385/1408)
Epoch: 189 | Batch_idx: 20 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (2635/2688)
Epoch: 189 | Batch_idx: 30 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (98.00%) (3891/3968)
Epoch: 189 | Batch_idx: 40 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (98.00%) (5149/5248)
Epoch: 189 | Batch_idx: 50 |  Loss: (0.0652) |  Loss2: (0.0000) | Acc: (97.00%) (6382/6528)
Epoch: 189 | Batch_idx: 60 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (7632/7808)
Epoch: 189 | Batch_idx: 70 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (8883/9088)
Epoch: 189 | Batch_idx: 80 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (10133/10368)
Epoch: 189 | Batch_idx: 90 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (11374/11648)
Epoch: 189 | Batch_idx: 100 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (12627/12928)
Epoch: 189 | Batch_idx: 110 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (13869/14208)
Epoch: 189 | Batch_idx: 120 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (15128/15488)
Epoch: 189 | Batch_idx: 130 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (16385/16768)
Epoch: 189 | Batch_idx: 140 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (17633/18048)
Epoch: 189 | Batch_idx: 150 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (18881/19328)
Epoch: 189 | Batch_idx: 160 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (20132/20608)
Epoch: 189 | Batch_idx: 170 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (21383/21888)
Epoch: 189 | Batch_idx: 180 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (22640/23168)
Epoch: 189 | Batch_idx: 190 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (23894/24448)
Epoch: 189 | Batch_idx: 200 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (25146/25728)
Epoch: 189 | Batch_idx: 210 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (26404/27008)
Epoch: 189 | Batch_idx: 220 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (27642/28288)
Epoch: 189 | Batch_idx: 230 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (28900/29568)
Epoch: 189 | Batch_idx: 240 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (30150/30848)
Epoch: 189 | Batch_idx: 250 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (31402/32128)
Epoch: 189 | Batch_idx: 260 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (32652/33408)
Epoch: 189 | Batch_idx: 270 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (33907/34688)
Epoch: 189 | Batch_idx: 280 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (35164/35968)
Epoch: 189 | Batch_idx: 290 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (36415/37248)
Epoch: 189 | Batch_idx: 300 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (37672/38528)
Epoch: 189 | Batch_idx: 310 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (38922/39808)
Epoch: 189 | Batch_idx: 320 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (40176/41088)
Epoch: 189 | Batch_idx: 330 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (41431/42368)
Epoch: 189 | Batch_idx: 340 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (42685/43648)
Epoch: 189 | Batch_idx: 350 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (43947/44928)
Epoch: 189 | Batch_idx: 360 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (45197/46208)
Epoch: 189 | Batch_idx: 370 |  Loss: (0.0671) |  Loss2: (0.0000) | Acc: (97.00%) (46448/47488)
Epoch: 189 | Batch_idx: 380 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (47704/48768)
Epoch: 189 | Batch_idx: 390 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (48907/50000)
# TEST : Loss: (0.3740) | Acc: (89.00%) (8972/10000)
percent tensor([0.5829, 0.6043, 0.5947, 0.5815, 0.6027, 0.5731, 0.6132, 0.5985, 0.5953,
        0.5969, 0.5910, 0.6036, 0.5883, 0.6014, 0.5916, 0.5816],
       device='cuda:0') torch.Size([16])
percent tensor([0.5323, 0.5281, 0.5204, 0.5111, 0.5175, 0.5018, 0.5329, 0.5275, 0.5282,
        0.5279, 0.5271, 0.5271, 0.5392, 0.5235, 0.5130, 0.5250],
       device='cuda:0') torch.Size([16])
percent tensor([0.6189, 0.6051, 0.6177, 0.6830, 0.6860, 0.6643, 0.6443, 0.7083, 0.6026,
        0.5447, 0.5348, 0.6061, 0.5495, 0.6592, 0.6813, 0.6161],
       device='cuda:0') torch.Size([16])
percent tensor([0.7476, 0.7003, 0.7113, 0.7092, 0.7192, 0.7451, 0.7349, 0.7190, 0.7045,
        0.7139, 0.7324, 0.6849, 0.6943, 0.7270, 0.7419, 0.7422],
       device='cuda:0') torch.Size([16])
percent tensor([0.5637, 0.5974, 0.5850, 0.5967, 0.5855, 0.6042, 0.5862, 0.5604, 0.6094,
        0.5854, 0.5813, 0.6097, 0.5735, 0.6255, 0.5538, 0.5888],
       device='cuda:0') torch.Size([16])
percent tensor([0.6235, 0.6776, 0.7154, 0.7349, 0.7181, 0.6865, 0.6856, 0.6734, 0.7233,
        0.6819, 0.7283, 0.7273, 0.6718, 0.7665, 0.6052, 0.6595],
       device='cuda:0') torch.Size([16])
percent tensor([0.5831, 0.7155, 0.7426, 0.7618, 0.6572, 0.8028, 0.6889, 0.5140, 0.6946,
        0.7012, 0.7542, 0.6441, 0.6541, 0.6820, 0.4779, 0.6064],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9998, 1.0000, 0.9993, 0.9997, 0.9994, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9994, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 190 | Batch_idx: 0 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 190 | Batch_idx: 10 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 190 | Batch_idx: 20 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (2614/2688)
Epoch: 190 | Batch_idx: 30 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (3863/3968)
Epoch: 190 | Batch_idx: 40 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (5111/5248)
Epoch: 190 | Batch_idx: 50 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (6370/6528)
Epoch: 190 | Batch_idx: 60 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (7621/7808)
Epoch: 190 | Batch_idx: 70 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (8870/9088)
Epoch: 190 | Batch_idx: 80 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (10117/10368)
Epoch: 190 | Batch_idx: 90 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (11368/11648)
Epoch: 190 | Batch_idx: 100 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (12618/12928)
Epoch: 190 | Batch_idx: 110 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (13865/14208)
Epoch: 190 | Batch_idx: 120 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (15119/15488)
Epoch: 190 | Batch_idx: 130 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (16371/16768)
Epoch: 190 | Batch_idx: 140 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (17622/18048)
Epoch: 190 | Batch_idx: 150 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (18868/19328)
Epoch: 190 | Batch_idx: 160 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (20117/20608)
Epoch: 190 | Batch_idx: 170 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (21363/21888)
Epoch: 190 | Batch_idx: 180 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (22618/23168)
Epoch: 190 | Batch_idx: 190 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (23865/24448)
Epoch: 190 | Batch_idx: 200 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (25115/25728)
Epoch: 190 | Batch_idx: 210 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (26364/27008)
Epoch: 190 | Batch_idx: 220 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (27619/28288)
Epoch: 190 | Batch_idx: 230 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (28865/29568)
Epoch: 190 | Batch_idx: 240 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (30105/30848)
Epoch: 190 | Batch_idx: 250 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (31341/32128)
Epoch: 190 | Batch_idx: 260 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (32587/33408)
Epoch: 190 | Batch_idx: 270 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (33830/34688)
Epoch: 190 | Batch_idx: 280 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (35076/35968)
Epoch: 190 | Batch_idx: 290 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (36317/37248)
Epoch: 190 | Batch_idx: 300 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (37566/38528)
Epoch: 190 | Batch_idx: 310 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (38801/39808)
Epoch: 190 | Batch_idx: 320 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (40035/41088)
Epoch: 190 | Batch_idx: 330 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (41276/42368)
Epoch: 190 | Batch_idx: 340 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (42531/43648)
Epoch: 190 | Batch_idx: 350 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (43774/44928)
Epoch: 190 | Batch_idx: 360 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (45029/46208)
Epoch: 190 | Batch_idx: 370 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (46272/47488)
Epoch: 190 | Batch_idx: 380 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (47503/48768)
Epoch: 190 | Batch_idx: 390 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (48689/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_190.pth.tar'
# TEST : Loss: (0.4384) | Acc: (87.00%) (8798/10000)
percent tensor([0.5831, 0.6055, 0.5945, 0.5823, 0.6021, 0.5733, 0.6133, 0.5993, 0.5957,
        0.5972, 0.5913, 0.6036, 0.5884, 0.6034, 0.5924, 0.5824],
       device='cuda:0') torch.Size([16])
percent tensor([0.5338, 0.5235, 0.5255, 0.5124, 0.5218, 0.5049, 0.5312, 0.5274, 0.5280,
        0.5262, 0.5255, 0.5295, 0.5380, 0.5173, 0.5115, 0.5232],
       device='cuda:0') torch.Size([16])
percent tensor([0.6224, 0.6115, 0.6170, 0.6775, 0.6857, 0.6707, 0.6439, 0.7112, 0.6102,
        0.5465, 0.5446, 0.6081, 0.5548, 0.6637, 0.6854, 0.6215],
       device='cuda:0') torch.Size([16])
percent tensor([0.7501, 0.6972, 0.7099, 0.7089, 0.7204, 0.7553, 0.7334, 0.7167, 0.7020,
        0.7116, 0.7335, 0.6834, 0.6941, 0.7262, 0.7429, 0.7420],
       device='cuda:0') torch.Size([16])
percent tensor([0.5596, 0.6041, 0.5954, 0.6101, 0.5936, 0.6034, 0.5906, 0.5709, 0.6122,
        0.5877, 0.5795, 0.6160, 0.5743, 0.6267, 0.5557, 0.5947],
       device='cuda:0') torch.Size([16])
percent tensor([0.6103, 0.6770, 0.6890, 0.7177, 0.7080, 0.6719, 0.6883, 0.6587, 0.7230,
        0.6790, 0.7380, 0.7144, 0.6713, 0.7762, 0.6003, 0.6517],
       device='cuda:0') torch.Size([16])
percent tensor([0.5791, 0.7174, 0.7315, 0.7486, 0.6421, 0.7875, 0.7067, 0.5059, 0.7142,
        0.7171, 0.7602, 0.6229, 0.6804, 0.6788, 0.4823, 0.5897],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9999, 1.0000, 0.9995, 0.9998, 0.9996, 0.9999,
        0.9999, 1.0000, 1.0000, 0.9999, 0.9995, 0.9998, 0.9993],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(178.5847, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(821.8058, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(831.2761, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1523.4769, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(476.7598, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2285.5264, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4245.4658, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1358.8734, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6279.4180, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11575.0986, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3820.7002, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16066.5908, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 191 | Batch_idx: 0 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 191 | Batch_idx: 10 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (1370/1408)
Epoch: 191 | Batch_idx: 20 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (2623/2688)
Epoch: 191 | Batch_idx: 30 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (3881/3968)
Epoch: 191 | Batch_idx: 40 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (5139/5248)
Epoch: 191 | Batch_idx: 50 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (6385/6528)
Epoch: 191 | Batch_idx: 60 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (7643/7808)
Epoch: 191 | Batch_idx: 70 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (8891/9088)
Epoch: 191 | Batch_idx: 80 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (10134/10368)
Epoch: 191 | Batch_idx: 90 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (11385/11648)
Epoch: 191 | Batch_idx: 100 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (12639/12928)
Epoch: 191 | Batch_idx: 110 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (13892/14208)
Epoch: 191 | Batch_idx: 120 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (15140/15488)
Epoch: 191 | Batch_idx: 130 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (16386/16768)
Epoch: 191 | Batch_idx: 140 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (17632/18048)
Epoch: 191 | Batch_idx: 150 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (18876/19328)
Epoch: 191 | Batch_idx: 160 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (20129/20608)
Epoch: 191 | Batch_idx: 170 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (21377/21888)
Epoch: 191 | Batch_idx: 180 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (22629/23168)
Epoch: 191 | Batch_idx: 190 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (23870/24448)
Epoch: 191 | Batch_idx: 200 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (25105/25728)
Epoch: 191 | Batch_idx: 210 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (26355/27008)
Epoch: 191 | Batch_idx: 220 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (27595/28288)
Epoch: 191 | Batch_idx: 230 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (28839/29568)
Epoch: 191 | Batch_idx: 240 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (30077/30848)
Epoch: 191 | Batch_idx: 250 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (31313/32128)
Epoch: 191 | Batch_idx: 260 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (32558/33408)
Epoch: 191 | Batch_idx: 270 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (33803/34688)
Epoch: 191 | Batch_idx: 280 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (35044/35968)
Epoch: 191 | Batch_idx: 290 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (36297/37248)
Epoch: 191 | Batch_idx: 300 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (37535/38528)
Epoch: 191 | Batch_idx: 310 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (38779/39808)
Epoch: 191 | Batch_idx: 320 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (40032/41088)
Epoch: 191 | Batch_idx: 330 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (41266/42368)
Epoch: 191 | Batch_idx: 340 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (42500/43648)
Epoch: 191 | Batch_idx: 350 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (43743/44928)
Epoch: 191 | Batch_idx: 360 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (44983/46208)
Epoch: 191 | Batch_idx: 370 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (46216/47488)
Epoch: 191 | Batch_idx: 380 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (47458/48768)
Epoch: 191 | Batch_idx: 390 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (48663/50000)
# TEST : Loss: (0.4118) | Acc: (88.00%) (8885/10000)
percent tensor([0.5842, 0.6052, 0.5947, 0.5824, 0.6030, 0.5744, 0.6134, 0.5994, 0.5967,
        0.5973, 0.5928, 0.6035, 0.5895, 0.6024, 0.5927, 0.5831],
       device='cuda:0') torch.Size([16])
percent tensor([0.5348, 0.5281, 0.5242, 0.5131, 0.5218, 0.5053, 0.5344, 0.5282, 0.5299,
        0.5290, 0.5287, 0.5293, 0.5406, 0.5247, 0.5135, 0.5270],
       device='cuda:0') torch.Size([16])
percent tensor([0.6237, 0.6123, 0.6323, 0.6921, 0.6955, 0.6655, 0.6523, 0.7227, 0.6110,
        0.5563, 0.5433, 0.6209, 0.5593, 0.6567, 0.6859, 0.6178],
       device='cuda:0') torch.Size([16])
percent tensor([0.7495, 0.7006, 0.7080, 0.7032, 0.7181, 0.7486, 0.7357, 0.7157, 0.7061,
        0.7120, 0.7307, 0.6837, 0.6976, 0.7295, 0.7399, 0.7402],
       device='cuda:0') torch.Size([16])
percent tensor([0.5606, 0.5974, 0.5885, 0.6017, 0.5953, 0.6018, 0.5857, 0.5655, 0.6085,
        0.5838, 0.5805, 0.6132, 0.5644, 0.6270, 0.5537, 0.5861],
       device='cuda:0') torch.Size([16])
percent tensor([0.6139, 0.6686, 0.7137, 0.7395, 0.7269, 0.6809, 0.6760, 0.6626, 0.7149,
        0.6664, 0.7242, 0.7241, 0.6667, 0.7657, 0.5984, 0.6446],
       device='cuda:0') torch.Size([16])
percent tensor([0.5602, 0.7028, 0.7340, 0.7566, 0.6520, 0.7963, 0.6621, 0.5059, 0.6550,
        0.7007, 0.7258, 0.6096, 0.6632, 0.6939, 0.4701, 0.5889],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 0.9997, 1.0000, 0.9994, 0.9997, 0.9996, 0.9999,
        1.0000, 0.9999, 0.9999, 0.9999, 0.9994, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 192 | Batch_idx: 0 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 192 | Batch_idx: 10 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 192 | Batch_idx: 20 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (2625/2688)
Epoch: 192 | Batch_idx: 30 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (3873/3968)
Epoch: 192 | Batch_idx: 40 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (5123/5248)
Epoch: 192 | Batch_idx: 50 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (6371/6528)
Epoch: 192 | Batch_idx: 60 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (7612/7808)
Epoch: 192 | Batch_idx: 70 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (8866/9088)
Epoch: 192 | Batch_idx: 80 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (10120/10368)
Epoch: 192 | Batch_idx: 90 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (11360/11648)
Epoch: 192 | Batch_idx: 100 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (12614/12928)
Epoch: 192 | Batch_idx: 110 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (13865/14208)
Epoch: 192 | Batch_idx: 120 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (15101/15488)
Epoch: 192 | Batch_idx: 130 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (16346/16768)
Epoch: 192 | Batch_idx: 140 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (17595/18048)
Epoch: 192 | Batch_idx: 150 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (18843/19328)
Epoch: 192 | Batch_idx: 160 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (20085/20608)
Epoch: 192 | Batch_idx: 170 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (21336/21888)
Epoch: 192 | Batch_idx: 180 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (22589/23168)
Epoch: 192 | Batch_idx: 190 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (23834/24448)
Epoch: 192 | Batch_idx: 200 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (25090/25728)
Epoch: 192 | Batch_idx: 210 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (26337/27008)
Epoch: 192 | Batch_idx: 220 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (27585/28288)
Epoch: 192 | Batch_idx: 230 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (28842/29568)
Epoch: 192 | Batch_idx: 240 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (30103/30848)
Epoch: 192 | Batch_idx: 250 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (31351/32128)
Epoch: 192 | Batch_idx: 260 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (32596/33408)
Epoch: 192 | Batch_idx: 270 |  Loss: (0.0742) |  Loss2: (0.0000) | Acc: (97.00%) (33838/34688)
Epoch: 192 | Batch_idx: 280 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (35087/35968)
Epoch: 192 | Batch_idx: 290 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (36336/37248)
Epoch: 192 | Batch_idx: 300 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (37585/38528)
Epoch: 192 | Batch_idx: 310 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (38838/39808)
Epoch: 192 | Batch_idx: 320 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (40086/41088)
Epoch: 192 | Batch_idx: 330 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (41324/42368)
Epoch: 192 | Batch_idx: 340 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (42568/43648)
Epoch: 192 | Batch_idx: 350 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (43813/44928)
Epoch: 192 | Batch_idx: 360 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (45046/46208)
Epoch: 192 | Batch_idx: 370 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (46291/47488)
Epoch: 192 | Batch_idx: 380 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (47540/48768)
Epoch: 192 | Batch_idx: 390 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (48744/50000)
# TEST : Loss: (0.4181) | Acc: (88.00%) (8866/10000)
percent tensor([0.5839, 0.6044, 0.5966, 0.5828, 0.6039, 0.5745, 0.6136, 0.5997, 0.5961,
        0.5977, 0.5918, 0.6055, 0.5890, 0.6007, 0.5927, 0.5828],
       device='cuda:0') torch.Size([16])
percent tensor([0.5334, 0.5274, 0.5228, 0.5128, 0.5200, 0.5040, 0.5335, 0.5278, 0.5278,
        0.5282, 0.5272, 0.5277, 0.5390, 0.5237, 0.5126, 0.5258],
       device='cuda:0') torch.Size([16])
percent tensor([0.6220, 0.6043, 0.6166, 0.6818, 0.6840, 0.6648, 0.6430, 0.7107, 0.6091,
        0.5474, 0.5418, 0.6108, 0.5554, 0.6487, 0.6839, 0.6149],
       device='cuda:0') torch.Size([16])
percent tensor([0.7508, 0.7022, 0.7099, 0.7038, 0.7243, 0.7497, 0.7348, 0.7189, 0.7091,
        0.7160, 0.7343, 0.6841, 0.6998, 0.7303, 0.7420, 0.7422],
       device='cuda:0') torch.Size([16])
percent tensor([0.5566, 0.5997, 0.5804, 0.5927, 0.5788, 0.5977, 0.5871, 0.5587, 0.6054,
        0.5814, 0.5847, 0.6062, 0.5636, 0.6318, 0.5492, 0.5835],
       device='cuda:0') torch.Size([16])
percent tensor([0.6090, 0.6737, 0.7122, 0.7252, 0.7183, 0.6732, 0.6834, 0.6644, 0.7161,
        0.6726, 0.7290, 0.7228, 0.6690, 0.7651, 0.6055, 0.6507],
       device='cuda:0') torch.Size([16])
percent tensor([0.5467, 0.7137, 0.7419, 0.7404, 0.6393, 0.7898, 0.6730, 0.5052, 0.6657,
        0.6882, 0.7491, 0.6147, 0.6447, 0.6703, 0.5013, 0.5992],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9999, 1.0000, 0.9992, 0.9997, 0.9996, 0.9999,
        0.9999, 0.9999, 1.0000, 0.9999, 0.9995, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 193 | Batch_idx: 0 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 193 | Batch_idx: 10 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (1372/1408)
Epoch: 193 | Batch_idx: 20 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (2624/2688)
Epoch: 193 | Batch_idx: 30 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (3870/3968)
Epoch: 193 | Batch_idx: 40 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (5111/5248)
Epoch: 193 | Batch_idx: 50 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (6359/6528)
Epoch: 193 | Batch_idx: 60 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (7605/7808)
Epoch: 193 | Batch_idx: 70 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (8860/9088)
Epoch: 193 | Batch_idx: 80 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (10101/10368)
Epoch: 193 | Batch_idx: 90 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (11337/11648)
Epoch: 193 | Batch_idx: 100 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (12586/12928)
Epoch: 193 | Batch_idx: 110 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (13839/14208)
Epoch: 193 | Batch_idx: 120 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (15089/15488)
Epoch: 193 | Batch_idx: 130 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (16342/16768)
Epoch: 193 | Batch_idx: 140 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (17583/18048)
Epoch: 193 | Batch_idx: 150 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (18826/19328)
Epoch: 193 | Batch_idx: 160 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (20077/20608)
Epoch: 193 | Batch_idx: 170 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (21326/21888)
Epoch: 193 | Batch_idx: 180 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (22566/23168)
Epoch: 193 | Batch_idx: 190 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (23818/24448)
Epoch: 193 | Batch_idx: 200 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (25069/25728)
Epoch: 193 | Batch_idx: 210 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (26310/27008)
Epoch: 193 | Batch_idx: 220 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (27556/28288)
Epoch: 193 | Batch_idx: 230 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (28805/29568)
Epoch: 193 | Batch_idx: 240 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (30059/30848)
Epoch: 193 | Batch_idx: 250 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (31309/32128)
Epoch: 193 | Batch_idx: 260 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (32552/33408)
Epoch: 193 | Batch_idx: 270 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (33799/34688)
Epoch: 193 | Batch_idx: 280 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (35045/35968)
Epoch: 193 | Batch_idx: 290 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (36296/37248)
Epoch: 193 | Batch_idx: 300 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (37539/38528)
Epoch: 193 | Batch_idx: 310 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (38779/39808)
Epoch: 193 | Batch_idx: 320 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (40023/41088)
Epoch: 193 | Batch_idx: 330 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (41266/42368)
Epoch: 193 | Batch_idx: 340 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (42509/43648)
Epoch: 193 | Batch_idx: 350 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (43758/44928)
Epoch: 193 | Batch_idx: 360 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (45009/46208)
Epoch: 193 | Batch_idx: 370 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (46253/47488)
Epoch: 193 | Batch_idx: 380 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (47485/48768)
Epoch: 193 | Batch_idx: 390 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (48702/50000)
# TEST : Loss: (0.4153) | Acc: (88.00%) (8880/10000)
percent tensor([0.5842, 0.6050, 0.5964, 0.5828, 0.6038, 0.5738, 0.6137, 0.6001, 0.5966,
        0.5979, 0.5918, 0.6055, 0.5892, 0.6021, 0.5928, 0.5827],
       device='cuda:0') torch.Size([16])
percent tensor([0.5334, 0.5252, 0.5251, 0.5140, 0.5216, 0.5028, 0.5327, 0.5286, 0.5285,
        0.5276, 0.5256, 0.5302, 0.5379, 0.5205, 0.5118, 0.5255],
       device='cuda:0') torch.Size([16])
percent tensor([0.6246, 0.6195, 0.6129, 0.6793, 0.6824, 0.6677, 0.6454, 0.7122, 0.6194,
        0.5547, 0.5514, 0.6118, 0.5677, 0.6633, 0.6900, 0.6192],
       device='cuda:0') torch.Size([16])
percent tensor([0.7464, 0.6995, 0.7067, 0.7082, 0.7173, 0.7485, 0.7326, 0.7142, 0.7002,
        0.7124, 0.7316, 0.6810, 0.6948, 0.7301, 0.7410, 0.7402],
       device='cuda:0') torch.Size([16])
percent tensor([0.5619, 0.6043, 0.5937, 0.6001, 0.5928, 0.5997, 0.5883, 0.5706, 0.6106,
        0.5885, 0.5846, 0.6101, 0.5726, 0.6244, 0.5510, 0.5907],
       device='cuda:0') torch.Size([16])
percent tensor([0.6201, 0.6830, 0.7128, 0.7227, 0.7200, 0.6798, 0.6859, 0.6597, 0.7130,
        0.6752, 0.7199, 0.7242, 0.6683, 0.7723, 0.5988, 0.6449],
       device='cuda:0') torch.Size([16])
percent tensor([0.5786, 0.6959, 0.7646, 0.7667, 0.6830, 0.8000, 0.6908, 0.5162, 0.6539,
        0.6945, 0.7036, 0.6242, 0.6396, 0.6616, 0.4889, 0.5780],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9999, 1.0000, 0.9995, 0.9997, 0.9997, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9992, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 194 | Batch_idx: 0 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 194 | Batch_idx: 10 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (1367/1408)
Epoch: 194 | Batch_idx: 20 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (2616/2688)
Epoch: 194 | Batch_idx: 30 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (3861/3968)
Epoch: 194 | Batch_idx: 40 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (5108/5248)
Epoch: 194 | Batch_idx: 50 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (6356/6528)
Epoch: 194 | Batch_idx: 60 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (7599/7808)
Epoch: 194 | Batch_idx: 70 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (8851/9088)
Epoch: 194 | Batch_idx: 80 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (10102/10368)
Epoch: 194 | Batch_idx: 90 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (11356/11648)
Epoch: 194 | Batch_idx: 100 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (12602/12928)
Epoch: 194 | Batch_idx: 110 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (13862/14208)
Epoch: 194 | Batch_idx: 120 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (15116/15488)
Epoch: 194 | Batch_idx: 130 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (16372/16768)
Epoch: 194 | Batch_idx: 140 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (17625/18048)
Epoch: 194 | Batch_idx: 150 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (18860/19328)
Epoch: 194 | Batch_idx: 160 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (20107/20608)
Epoch: 194 | Batch_idx: 170 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (21365/21888)
Epoch: 194 | Batch_idx: 180 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (22609/23168)
Epoch: 194 | Batch_idx: 190 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (23855/24448)
Epoch: 194 | Batch_idx: 200 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (25094/25728)
Epoch: 194 | Batch_idx: 210 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (26354/27008)
Epoch: 194 | Batch_idx: 220 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (27601/28288)
Epoch: 194 | Batch_idx: 230 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (28847/29568)
Epoch: 194 | Batch_idx: 240 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (30090/30848)
Epoch: 194 | Batch_idx: 250 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (31341/32128)
Epoch: 194 | Batch_idx: 260 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (32587/33408)
Epoch: 194 | Batch_idx: 270 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (33836/34688)
Epoch: 194 | Batch_idx: 280 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (35083/35968)
Epoch: 194 | Batch_idx: 290 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (36321/37248)
Epoch: 194 | Batch_idx: 300 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (37570/38528)
Epoch: 194 | Batch_idx: 310 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (38819/39808)
Epoch: 194 | Batch_idx: 320 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (40060/41088)
Epoch: 194 | Batch_idx: 330 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (41299/42368)
Epoch: 194 | Batch_idx: 340 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (42554/43648)
Epoch: 194 | Batch_idx: 350 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (43799/44928)
Epoch: 194 | Batch_idx: 360 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (45048/46208)
Epoch: 194 | Batch_idx: 370 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (46297/47488)
Epoch: 194 | Batch_idx: 380 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (47547/48768)
Epoch: 194 | Batch_idx: 390 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (48730/50000)
# TEST : Loss: (0.4232) | Acc: (88.00%) (8879/10000)
percent tensor([0.5836, 0.6036, 0.5973, 0.5822, 0.6047, 0.5746, 0.6138, 0.5998, 0.5961,
        0.5977, 0.5911, 0.6060, 0.5886, 0.6005, 0.5923, 0.5824],
       device='cuda:0') torch.Size([16])
percent tensor([0.5330, 0.5280, 0.5216, 0.5132, 0.5184, 0.5040, 0.5336, 0.5292, 0.5283,
        0.5285, 0.5272, 0.5271, 0.5391, 0.5251, 0.5139, 0.5268],
       device='cuda:0') torch.Size([16])
percent tensor([0.6228, 0.6064, 0.6157, 0.6804, 0.6839, 0.6656, 0.6418, 0.7107, 0.6113,
        0.5477, 0.5441, 0.6129, 0.5621, 0.6453, 0.6861, 0.6149],
       device='cuda:0') torch.Size([16])
percent tensor([0.7471, 0.7022, 0.7072, 0.7104, 0.7212, 0.7511, 0.7346, 0.7147, 0.7017,
        0.7137, 0.7303, 0.6835, 0.6967, 0.7314, 0.7428, 0.7425],
       device='cuda:0') torch.Size([16])
percent tensor([0.5569, 0.5943, 0.5834, 0.5889, 0.5781, 0.6011, 0.5814, 0.5600, 0.6052,
        0.5834, 0.5774, 0.6052, 0.5617, 0.6298, 0.5449, 0.5842],
       device='cuda:0') torch.Size([16])
percent tensor([0.6139, 0.6864, 0.7094, 0.7279, 0.7126, 0.6805, 0.6686, 0.6562, 0.7154,
        0.6802, 0.7279, 0.7236, 0.6691, 0.7751, 0.5972, 0.6392],
       device='cuda:0') torch.Size([16])
percent tensor([0.5491, 0.6742, 0.7485, 0.7707, 0.6963, 0.8071, 0.6458, 0.5028, 0.6602,
        0.6665, 0.7269, 0.6300, 0.6275, 0.6395, 0.4880, 0.5824],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9999, 0.9999, 0.9999, 0.9995, 0.9996, 0.9994, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 195 | Batch_idx: 0 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 195 | Batch_idx: 10 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (1378/1408)
Epoch: 195 | Batch_idx: 20 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (2616/2688)
Epoch: 195 | Batch_idx: 30 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (97.00%) (3849/3968)
Epoch: 195 | Batch_idx: 40 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (5079/5248)
Epoch: 195 | Batch_idx: 50 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (6308/6528)
Epoch: 195 | Batch_idx: 60 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (7531/7808)
Epoch: 195 | Batch_idx: 70 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (8762/9088)
Epoch: 195 | Batch_idx: 80 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (9973/10368)
Epoch: 195 | Batch_idx: 90 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (11200/11648)
Epoch: 195 | Batch_idx: 100 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (12434/12928)
Epoch: 195 | Batch_idx: 110 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (13681/14208)
Epoch: 195 | Batch_idx: 120 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (14910/15488)
Epoch: 195 | Batch_idx: 130 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (16144/16768)
Epoch: 195 | Batch_idx: 140 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (17376/18048)
Epoch: 195 | Batch_idx: 150 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (18611/19328)
Epoch: 195 | Batch_idx: 160 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (19849/20608)
Epoch: 195 | Batch_idx: 170 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (21084/21888)
Epoch: 195 | Batch_idx: 180 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (22323/23168)
Epoch: 195 | Batch_idx: 190 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (23548/24448)
Epoch: 195 | Batch_idx: 200 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (24776/25728)
Epoch: 195 | Batch_idx: 210 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (26011/27008)
Epoch: 195 | Batch_idx: 220 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (27258/28288)
Epoch: 195 | Batch_idx: 230 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (28492/29568)
Epoch: 195 | Batch_idx: 240 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (29738/30848)
Epoch: 195 | Batch_idx: 250 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (30970/32128)
Epoch: 195 | Batch_idx: 260 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (32210/33408)
Epoch: 195 | Batch_idx: 270 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (33438/34688)
Epoch: 195 | Batch_idx: 280 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (34674/35968)
Epoch: 195 | Batch_idx: 290 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (35911/37248)
Epoch: 195 | Batch_idx: 300 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (37159/38528)
Epoch: 195 | Batch_idx: 310 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (38394/39808)
Epoch: 195 | Batch_idx: 320 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (39635/41088)
Epoch: 195 | Batch_idx: 330 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (40870/42368)
Epoch: 195 | Batch_idx: 340 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (42101/43648)
Epoch: 195 | Batch_idx: 350 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (43332/44928)
Epoch: 195 | Batch_idx: 360 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (44577/46208)
Epoch: 195 | Batch_idx: 370 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (45820/47488)
Epoch: 195 | Batch_idx: 380 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (47058/48768)
Epoch: 195 | Batch_idx: 390 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (48250/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_195.pth.tar'
# TEST : Loss: (0.4222) | Acc: (88.00%) (8889/10000)
percent tensor([0.5782, 0.5972, 0.5911, 0.5770, 0.5980, 0.5694, 0.6071, 0.5935, 0.5897,
        0.5916, 0.5852, 0.5995, 0.5830, 0.5943, 0.5864, 0.5770],
       device='cuda:0') torch.Size([16])
percent tensor([0.5290, 0.5241, 0.5175, 0.5081, 0.5147, 0.4998, 0.5302, 0.5252, 0.5248,
        0.5241, 0.5227, 0.5222, 0.5346, 0.5230, 0.5094, 0.5221],
       device='cuda:0') torch.Size([16])
percent tensor([0.6187, 0.6103, 0.6083, 0.6891, 0.6823, 0.6721, 0.6395, 0.7127, 0.6120,
        0.5498, 0.5473, 0.6099, 0.5555, 0.6550, 0.6919, 0.6214],
       device='cuda:0') torch.Size([16])
percent tensor([0.7580, 0.7119, 0.7170, 0.7198, 0.7298, 0.7626, 0.7472, 0.7257, 0.7106,
        0.7244, 0.7398, 0.6930, 0.7058, 0.7401, 0.7548, 0.7527],
       device='cuda:0') torch.Size([16])
percent tensor([0.5493, 0.5879, 0.5808, 0.5897, 0.5802, 0.5911, 0.5725, 0.5518, 0.5983,
        0.5776, 0.5694, 0.5975, 0.5540, 0.6207, 0.5370, 0.5769],
       device='cuda:0') torch.Size([16])
percent tensor([0.5932, 0.6671, 0.6929, 0.7153, 0.7054, 0.6674, 0.6513, 0.6421, 0.6996,
        0.6672, 0.7103, 0.7151, 0.6484, 0.7613, 0.5743, 0.6243],
       device='cuda:0') torch.Size([16])
percent tensor([0.5165, 0.6596, 0.7125, 0.7421, 0.6577, 0.7858, 0.6139, 0.4388, 0.6282,
        0.6638, 0.6981, 0.6053, 0.6078, 0.6192, 0.4354, 0.5397],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9999, 0.9995, 0.9997, 0.9993, 0.9999,
        0.9999, 0.9999, 1.0000, 0.9999, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 196 | Batch_idx: 0 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 196 | Batch_idx: 10 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (95.00%) (1350/1408)
Epoch: 196 | Batch_idx: 20 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (2589/2688)
Epoch: 196 | Batch_idx: 30 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (3832/3968)
Epoch: 196 | Batch_idx: 40 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (5077/5248)
Epoch: 196 | Batch_idx: 50 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (6321/6528)
Epoch: 196 | Batch_idx: 60 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (7564/7808)
Epoch: 196 | Batch_idx: 70 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (8802/9088)
Epoch: 196 | Batch_idx: 80 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (10046/10368)
Epoch: 196 | Batch_idx: 90 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (11301/11648)
Epoch: 196 | Batch_idx: 100 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (96.00%) (12536/12928)
Epoch: 196 | Batch_idx: 110 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (96.00%) (13773/14208)
Epoch: 196 | Batch_idx: 120 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (96.00%) (15020/15488)
Epoch: 196 | Batch_idx: 130 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (96.00%) (16260/16768)
Epoch: 196 | Batch_idx: 140 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (96.00%) (17502/18048)
Epoch: 196 | Batch_idx: 150 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (96.00%) (18746/19328)
Epoch: 196 | Batch_idx: 160 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (96.00%) (19989/20608)
Epoch: 196 | Batch_idx: 170 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (96.00%) (21228/21888)
Epoch: 196 | Batch_idx: 180 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (96.00%) (22460/23168)
Epoch: 196 | Batch_idx: 190 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (96.00%) (23695/24448)
Epoch: 196 | Batch_idx: 200 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (96.00%) (24947/25728)
Epoch: 196 | Batch_idx: 210 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (96.00%) (26179/27008)
Epoch: 196 | Batch_idx: 220 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (96.00%) (27418/28288)
Epoch: 196 | Batch_idx: 230 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (96.00%) (28663/29568)
Epoch: 196 | Batch_idx: 240 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (96.00%) (29910/30848)
Epoch: 196 | Batch_idx: 250 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (96.00%) (31159/32128)
Epoch: 196 | Batch_idx: 260 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (96.00%) (32403/33408)
Epoch: 196 | Batch_idx: 270 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (96.00%) (33638/34688)
Epoch: 196 | Batch_idx: 280 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (96.00%) (34887/35968)
Epoch: 196 | Batch_idx: 290 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (36140/37248)
Epoch: 196 | Batch_idx: 300 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (37383/38528)
Epoch: 196 | Batch_idx: 310 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (38627/39808)
Epoch: 196 | Batch_idx: 320 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (39871/41088)
Epoch: 196 | Batch_idx: 330 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (41116/42368)
Epoch: 196 | Batch_idx: 340 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (42362/43648)
Epoch: 196 | Batch_idx: 350 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (43613/44928)
Epoch: 196 | Batch_idx: 360 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (44851/46208)
Epoch: 196 | Batch_idx: 370 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (46106/47488)
Epoch: 196 | Batch_idx: 380 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (47359/48768)
Epoch: 196 | Batch_idx: 390 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (48561/50000)
# TEST : Loss: (0.4119) | Acc: (89.00%) (8926/10000)
percent tensor([0.5745, 0.5927, 0.5879, 0.5734, 0.5942, 0.5658, 0.6026, 0.5896, 0.5857,
        0.5875, 0.5812, 0.5958, 0.5791, 0.5895, 0.5824, 0.5732],
       device='cuda:0') torch.Size([16])
percent tensor([0.5331, 0.5289, 0.5217, 0.5121, 0.5196, 0.5031, 0.5352, 0.5300, 0.5292,
        0.5284, 0.5271, 0.5266, 0.5389, 0.5271, 0.5137, 0.5261],
       device='cuda:0') torch.Size([16])
percent tensor([0.6168, 0.6097, 0.6063, 0.6906, 0.6834, 0.6710, 0.6389, 0.7124, 0.6101,
        0.5480, 0.5439, 0.6099, 0.5524, 0.6546, 0.6923, 0.6183],
       device='cuda:0') torch.Size([16])
percent tensor([0.7597, 0.7134, 0.7167, 0.7206, 0.7306, 0.7636, 0.7480, 0.7275, 0.7116,
        0.7258, 0.7415, 0.6926, 0.7069, 0.7411, 0.7560, 0.7542],
       device='cuda:0') torch.Size([16])
percent tensor([0.5458, 0.5880, 0.5775, 0.5830, 0.5755, 0.5836, 0.5709, 0.5474, 0.5960,
        0.5784, 0.5690, 0.5950, 0.5533, 0.6203, 0.5321, 0.5726],
       device='cuda:0') torch.Size([16])
percent tensor([0.5906, 0.6636, 0.6931, 0.7152, 0.7054, 0.6642, 0.6492, 0.6409, 0.6987,
        0.6632, 0.7075, 0.7118, 0.6441, 0.7596, 0.5678, 0.6207],
       device='cuda:0') torch.Size([16])
percent tensor([0.5373, 0.6858, 0.7283, 0.7533, 0.6673, 0.7899, 0.6324, 0.4501, 0.6524,
        0.6892, 0.7191, 0.6284, 0.6363, 0.6428, 0.4456, 0.5516],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9999, 0.9995, 0.9997, 0.9994, 0.9999,
        0.9999, 0.9999, 1.0000, 0.9999, 0.9996, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 197 | Batch_idx: 0 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 197 | Batch_idx: 10 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 197 | Batch_idx: 20 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (2624/2688)
Epoch: 197 | Batch_idx: 30 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (3870/3968)
Epoch: 197 | Batch_idx: 40 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (5115/5248)
Epoch: 197 | Batch_idx: 50 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (6356/6528)
Epoch: 197 | Batch_idx: 60 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (7601/7808)
Epoch: 197 | Batch_idx: 70 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (8848/9088)
Epoch: 197 | Batch_idx: 80 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (10097/10368)
Epoch: 197 | Batch_idx: 90 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (11338/11648)
Epoch: 197 | Batch_idx: 100 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (12584/12928)
Epoch: 197 | Batch_idx: 110 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (13838/14208)
Epoch: 197 | Batch_idx: 120 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (15083/15488)
Epoch: 197 | Batch_idx: 130 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (16328/16768)
Epoch: 197 | Batch_idx: 140 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (17572/18048)
Epoch: 197 | Batch_idx: 150 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (18820/19328)
Epoch: 197 | Batch_idx: 160 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (20069/20608)
Epoch: 197 | Batch_idx: 170 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (21321/21888)
Epoch: 197 | Batch_idx: 180 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (22560/23168)
Epoch: 197 | Batch_idx: 190 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (23804/24448)
Epoch: 197 | Batch_idx: 200 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (25052/25728)
Epoch: 197 | Batch_idx: 210 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (26299/27008)
Epoch: 197 | Batch_idx: 220 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (27543/28288)
Epoch: 197 | Batch_idx: 230 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (28796/29568)
Epoch: 197 | Batch_idx: 240 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (30047/30848)
Epoch: 197 | Batch_idx: 250 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (31301/32128)
Epoch: 197 | Batch_idx: 260 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (32552/33408)
Epoch: 197 | Batch_idx: 270 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (33801/34688)
Epoch: 197 | Batch_idx: 280 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (35058/35968)
Epoch: 197 | Batch_idx: 290 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (36315/37248)
Epoch: 197 | Batch_idx: 300 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (37552/38528)
Epoch: 197 | Batch_idx: 310 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (38801/39808)
Epoch: 197 | Batch_idx: 320 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (40050/41088)
Epoch: 197 | Batch_idx: 330 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (41302/42368)
Epoch: 197 | Batch_idx: 340 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (42548/43648)
Epoch: 197 | Batch_idx: 350 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (43803/44928)
Epoch: 197 | Batch_idx: 360 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (45045/46208)
Epoch: 197 | Batch_idx: 370 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (46290/47488)
Epoch: 197 | Batch_idx: 380 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (47547/48768)
Epoch: 197 | Batch_idx: 390 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (48761/50000)
# TEST : Loss: (0.4006) | Acc: (89.00%) (8928/10000)
percent tensor([0.5759, 0.5942, 0.5894, 0.5748, 0.5958, 0.5675, 0.6041, 0.5910, 0.5871,
        0.5890, 0.5827, 0.5974, 0.5806, 0.5906, 0.5840, 0.5746],
       device='cuda:0') torch.Size([16])
percent tensor([0.5318, 0.5273, 0.5210, 0.5111, 0.5186, 0.5016, 0.5336, 0.5290, 0.5278,
        0.5269, 0.5254, 0.5253, 0.5373, 0.5252, 0.5122, 0.5246],
       device='cuda:0') torch.Size([16])
percent tensor([0.6123, 0.6083, 0.5993, 0.6855, 0.6790, 0.6678, 0.6369, 0.7079, 0.6058,
        0.5435, 0.5404, 0.6042, 0.5483, 0.6521, 0.6902, 0.6138],
       device='cuda:0') torch.Size([16])
percent tensor([0.7586, 0.7122, 0.7167, 0.7214, 0.7304, 0.7624, 0.7468, 0.7268, 0.7108,
        0.7251, 0.7404, 0.6909, 0.7062, 0.7398, 0.7545, 0.7536],
       device='cuda:0') torch.Size([16])
percent tensor([0.5509, 0.5959, 0.5826, 0.5887, 0.5822, 0.5884, 0.5777, 0.5529, 0.6021,
        0.5856, 0.5749, 0.6023, 0.5582, 0.6281, 0.5385, 0.5779],
       device='cuda:0') torch.Size([16])
percent tensor([0.5921, 0.6649, 0.6950, 0.7157, 0.7065, 0.6650, 0.6494, 0.6398, 0.6992,
        0.6639, 0.7069, 0.7093, 0.6430, 0.7607, 0.5644, 0.6202],
       device='cuda:0') torch.Size([16])
percent tensor([0.5319, 0.6839, 0.7222, 0.7496, 0.6564, 0.7851, 0.6272, 0.4437, 0.6449,
        0.6857, 0.7151, 0.6155, 0.6305, 0.6419, 0.4315, 0.5426],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9999, 0.9999, 0.9995, 0.9997, 0.9993, 0.9999,
        0.9999, 0.9999, 1.0000, 0.9999, 0.9996, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 198 | Batch_idx: 0 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 198 | Batch_idx: 10 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (98.00%) (1385/1408)
Epoch: 198 | Batch_idx: 20 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (2626/2688)
Epoch: 198 | Batch_idx: 30 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (3880/3968)
Epoch: 198 | Batch_idx: 40 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (5122/5248)
Epoch: 198 | Batch_idx: 50 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (6373/6528)
Epoch: 198 | Batch_idx: 60 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (7620/7808)
Epoch: 198 | Batch_idx: 70 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (8874/9088)
Epoch: 198 | Batch_idx: 80 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (10115/10368)
Epoch: 198 | Batch_idx: 90 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (11360/11648)
Epoch: 198 | Batch_idx: 100 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (12613/12928)
Epoch: 198 | Batch_idx: 110 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (13863/14208)
Epoch: 198 | Batch_idx: 120 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (15103/15488)
Epoch: 198 | Batch_idx: 130 |  Loss: (0.0742) |  Loss2: (0.0000) | Acc: (97.00%) (16350/16768)
Epoch: 198 | Batch_idx: 140 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (17601/18048)
Epoch: 198 | Batch_idx: 150 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (18849/19328)
Epoch: 198 | Batch_idx: 160 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (20106/20608)
Epoch: 198 | Batch_idx: 170 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (21357/21888)
Epoch: 198 | Batch_idx: 180 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (22601/23168)
Epoch: 198 | Batch_idx: 190 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (23854/24448)
Epoch: 198 | Batch_idx: 200 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (25107/25728)
Epoch: 198 | Batch_idx: 210 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (26354/27008)
Epoch: 198 | Batch_idx: 220 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (27612/28288)
Epoch: 198 | Batch_idx: 230 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (28858/29568)
Epoch: 198 | Batch_idx: 240 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (30113/30848)
Epoch: 198 | Batch_idx: 250 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (31366/32128)
Epoch: 198 | Batch_idx: 260 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (32624/33408)
Epoch: 198 | Batch_idx: 270 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (33874/34688)
Epoch: 198 | Batch_idx: 280 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (35121/35968)
Epoch: 198 | Batch_idx: 290 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (36371/37248)
Epoch: 198 | Batch_idx: 300 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (37623/38528)
Epoch: 198 | Batch_idx: 310 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (38878/39808)
Epoch: 198 | Batch_idx: 320 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (40135/41088)
Epoch: 198 | Batch_idx: 330 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (41384/42368)
Epoch: 198 | Batch_idx: 340 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (42632/43648)
Epoch: 198 | Batch_idx: 350 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (43874/44928)
Epoch: 198 | Batch_idx: 360 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (45128/46208)
Epoch: 198 | Batch_idx: 370 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (46382/47488)
Epoch: 198 | Batch_idx: 380 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (47636/48768)
Epoch: 198 | Batch_idx: 390 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (48838/50000)
# TEST : Loss: (0.3988) | Acc: (89.00%) (8931/10000)
percent tensor([0.5756, 0.5936, 0.5887, 0.5741, 0.5951, 0.5671, 0.6034, 0.5902, 0.5865,
        0.5885, 0.5824, 0.5968, 0.5803, 0.5896, 0.5835, 0.5742],
       device='cuda:0') torch.Size([16])
percent tensor([0.5339, 0.5291, 0.5237, 0.5131, 0.5212, 0.5030, 0.5360, 0.5318, 0.5302,
        0.5289, 0.5274, 0.5277, 0.5394, 0.5270, 0.5139, 0.5263],
       device='cuda:0') torch.Size([16])
percent tensor([0.6080, 0.6086, 0.5950, 0.6804, 0.6772, 0.6617, 0.6362, 0.7056, 0.6008,
        0.5408, 0.5370, 0.6017, 0.5469, 0.6476, 0.6886, 0.6094],
       device='cuda:0') torch.Size([16])
percent tensor([0.7604, 0.7137, 0.7199, 0.7253, 0.7336, 0.7653, 0.7485, 0.7290, 0.7127,
        0.7269, 0.7413, 0.6927, 0.7077, 0.7417, 0.7563, 0.7557],
       device='cuda:0') torch.Size([16])
percent tensor([0.5545, 0.6023, 0.5858, 0.5929, 0.5847, 0.5911, 0.5827, 0.5560, 0.6073,
        0.5916, 0.5810, 0.6089, 0.5629, 0.6362, 0.5429, 0.5824],
       device='cuda:0') torch.Size([16])
percent tensor([0.5972, 0.6680, 0.6977, 0.7184, 0.7086, 0.6699, 0.6530, 0.6431, 0.7011,
        0.6667, 0.7112, 0.7107, 0.6453, 0.7649, 0.5660, 0.6226],
       device='cuda:0') torch.Size([16])
percent tensor([0.5438, 0.6942, 0.7321, 0.7628, 0.6682, 0.7899, 0.6346, 0.4576, 0.6519,
        0.6966, 0.7290, 0.6247, 0.6411, 0.6542, 0.4402, 0.5499],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9999, 0.9995, 0.9997, 0.9994, 0.9999,
        0.9999, 1.0000, 1.0000, 0.9999, 0.9996, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 199 | Batch_idx: 0 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 199 | Batch_idx: 10 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 199 | Batch_idx: 20 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (2630/2688)
Epoch: 199 | Batch_idx: 30 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (97.00%) (3887/3968)
Epoch: 199 | Batch_idx: 40 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (5139/5248)
Epoch: 199 | Batch_idx: 50 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (6395/6528)
Epoch: 199 | Batch_idx: 60 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (7642/7808)
Epoch: 199 | Batch_idx: 70 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (8896/9088)
Epoch: 199 | Batch_idx: 80 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (10144/10368)
Epoch: 199 | Batch_idx: 90 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (11398/11648)
Epoch: 199 | Batch_idx: 100 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (12661/12928)
Epoch: 199 | Batch_idx: 110 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (13909/14208)
Epoch: 199 | Batch_idx: 120 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (15157/15488)
Epoch: 199 | Batch_idx: 130 |  Loss: (0.0662) |  Loss2: (0.0000) | Acc: (97.00%) (16413/16768)
Epoch: 199 | Batch_idx: 140 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (17663/18048)
Epoch: 199 | Batch_idx: 150 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (18915/19328)
Epoch: 199 | Batch_idx: 160 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (20174/20608)
Epoch: 199 | Batch_idx: 170 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (21433/21888)
Epoch: 199 | Batch_idx: 180 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (22682/23168)
Epoch: 199 | Batch_idx: 190 |  Loss: (0.0671) |  Loss2: (0.0000) | Acc: (97.00%) (23929/24448)
Epoch: 199 | Batch_idx: 200 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (25177/25728)
Epoch: 199 | Batch_idx: 210 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (26435/27008)
Epoch: 199 | Batch_idx: 220 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (27680/28288)
Epoch: 199 | Batch_idx: 230 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (28932/29568)
Epoch: 199 | Batch_idx: 240 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (30188/30848)
Epoch: 199 | Batch_idx: 250 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (31427/32128)
Epoch: 199 | Batch_idx: 260 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (32677/33408)
Epoch: 199 | Batch_idx: 270 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (33930/34688)
Epoch: 199 | Batch_idx: 280 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (35190/35968)
Epoch: 199 | Batch_idx: 290 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (36440/37248)
Epoch: 199 | Batch_idx: 300 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (37690/38528)
Epoch: 199 | Batch_idx: 310 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (38939/39808)
Epoch: 199 | Batch_idx: 320 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (40190/41088)
Epoch: 199 | Batch_idx: 330 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (41433/42368)
Epoch: 199 | Batch_idx: 340 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (42693/43648)
Epoch: 199 | Batch_idx: 350 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (43943/44928)
Epoch: 199 | Batch_idx: 360 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (45191/46208)
Epoch: 199 | Batch_idx: 370 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (46448/47488)
Epoch: 199 | Batch_idx: 380 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (47696/48768)
Epoch: 199 | Batch_idx: 390 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (48905/50000)
# TEST : Loss: (0.3952) | Acc: (89.00%) (8948/10000)
percent tensor([0.5746, 0.5920, 0.5880, 0.5731, 0.5941, 0.5661, 0.6019, 0.5889, 0.5853,
        0.5873, 0.5811, 0.5959, 0.5792, 0.5878, 0.5822, 0.5731],
       device='cuda:0') torch.Size([16])
percent tensor([0.5348, 0.5302, 0.5247, 0.5142, 0.5224, 0.5038, 0.5373, 0.5330, 0.5311,
        0.5298, 0.5283, 0.5288, 0.5401, 0.5279, 0.5151, 0.5272],
       device='cuda:0') torch.Size([16])
percent tensor([0.6104, 0.6122, 0.5964, 0.6822, 0.6792, 0.6639, 0.6392, 0.7078, 0.6036,
        0.5441, 0.5407, 0.6050, 0.5489, 0.6525, 0.6909, 0.6108],
       device='cuda:0') torch.Size([16])
percent tensor([0.7568, 0.7108, 0.7167, 0.7217, 0.7299, 0.7612, 0.7455, 0.7258, 0.7097,
        0.7240, 0.7383, 0.6890, 0.7047, 0.7393, 0.7517, 0.7522],
       device='cuda:0') torch.Size([16])
percent tensor([0.5492, 0.5976, 0.5819, 0.5888, 0.5800, 0.5853, 0.5768, 0.5507, 0.6025,
        0.5876, 0.5765, 0.6042, 0.5578, 0.6322, 0.5371, 0.5765],
       device='cuda:0') torch.Size([16])
percent tensor([0.6101, 0.6784, 0.7089, 0.7291, 0.7196, 0.6803, 0.6658, 0.6548, 0.7115,
        0.6780, 0.7203, 0.7200, 0.6560, 0.7746, 0.5786, 0.6362],
       device='cuda:0') torch.Size([16])
percent tensor([0.5629, 0.7029, 0.7418, 0.7708, 0.6800, 0.7944, 0.6521, 0.4761, 0.6625,
        0.7092, 0.7397, 0.6435, 0.6530, 0.6609, 0.4647, 0.5642],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9999, 0.9995, 0.9997, 0.9994, 0.9999,
        0.9999, 1.0000, 1.0000, 0.9999, 0.9996, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 200 | Batch_idx: 0 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 200 | Batch_idx: 10 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (98.00%) (1381/1408)
Epoch: 200 | Batch_idx: 20 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (98.00%) (2641/2688)
Epoch: 200 | Batch_idx: 30 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (3884/3968)
Epoch: 200 | Batch_idx: 40 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (98.00%) (5144/5248)
Epoch: 200 | Batch_idx: 50 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (6387/6528)
Epoch: 200 | Batch_idx: 60 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (7641/7808)
Epoch: 200 | Batch_idx: 70 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (8886/9088)
Epoch: 200 | Batch_idx: 80 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (10143/10368)
Epoch: 200 | Batch_idx: 90 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (11388/11648)
Epoch: 200 | Batch_idx: 100 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (12645/12928)
Epoch: 200 | Batch_idx: 110 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (13886/14208)
Epoch: 200 | Batch_idx: 120 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (15144/15488)
Epoch: 200 | Batch_idx: 130 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (16391/16768)
Epoch: 200 | Batch_idx: 140 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (17642/18048)
Epoch: 200 | Batch_idx: 150 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (18895/19328)
Epoch: 200 | Batch_idx: 160 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (20153/20608)
Epoch: 200 | Batch_idx: 170 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (21410/21888)
Epoch: 200 | Batch_idx: 180 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (22668/23168)
Epoch: 200 | Batch_idx: 190 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (23915/24448)
Epoch: 200 | Batch_idx: 200 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (25165/25728)
Epoch: 200 | Batch_idx: 210 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (26410/27008)
Epoch: 200 | Batch_idx: 220 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (27650/28288)
Epoch: 200 | Batch_idx: 230 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (28890/29568)
Epoch: 200 | Batch_idx: 240 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (30145/30848)
Epoch: 200 | Batch_idx: 250 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (31392/32128)
Epoch: 200 | Batch_idx: 260 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (32633/33408)
Epoch: 200 | Batch_idx: 270 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (33885/34688)
Epoch: 200 | Batch_idx: 280 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (35129/35968)
Epoch: 200 | Batch_idx: 290 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (36376/37248)
Epoch: 200 | Batch_idx: 300 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (37634/38528)
Epoch: 200 | Batch_idx: 310 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (38873/39808)
Epoch: 200 | Batch_idx: 320 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (40128/41088)
Epoch: 200 | Batch_idx: 330 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (41366/42368)
Epoch: 200 | Batch_idx: 340 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (42620/43648)
Epoch: 200 | Batch_idx: 350 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (43880/44928)
Epoch: 200 | Batch_idx: 360 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (45133/46208)
Epoch: 200 | Batch_idx: 370 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (46377/47488)
Epoch: 200 | Batch_idx: 380 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (47628/48768)
Epoch: 200 | Batch_idx: 390 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (48832/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_200.pth.tar'
# TEST : Loss: (0.4311) | Acc: (88.00%) (8872/10000)
percent tensor([0.5793, 0.5981, 0.5919, 0.5775, 0.5992, 0.5709, 0.6070, 0.5938, 0.5902,
        0.5919, 0.5863, 0.6000, 0.5838, 0.5924, 0.5877, 0.5774],
       device='cuda:0') torch.Size([16])
percent tensor([0.5382, 0.5295, 0.5299, 0.5173, 0.5275, 0.5082, 0.5371, 0.5347, 0.5326,
        0.5314, 0.5303, 0.5333, 0.5426, 0.5227, 0.5166, 0.5296],
       device='cuda:0') torch.Size([16])
percent tensor([0.6157, 0.6289, 0.6151, 0.6797, 0.6880, 0.6582, 0.6550, 0.7140, 0.6120,
        0.5580, 0.5444, 0.6231, 0.5561, 0.6696, 0.6911, 0.6132],
       device='cuda:0') torch.Size([16])
percent tensor([0.7567, 0.7123, 0.7216, 0.7199, 0.7318, 0.7636, 0.7453, 0.7277, 0.7169,
        0.7249, 0.7368, 0.6921, 0.7026, 0.7418, 0.7517, 0.7527],
       device='cuda:0') torch.Size([16])
percent tensor([0.5640, 0.6119, 0.5905, 0.5985, 0.5913, 0.5928, 0.5957, 0.5652, 0.6173,
        0.6004, 0.5967, 0.6171, 0.5750, 0.6448, 0.5540, 0.5871],
       device='cuda:0') torch.Size([16])
percent tensor([0.6282, 0.6876, 0.7146, 0.7339, 0.7223, 0.6934, 0.6872, 0.6732, 0.7223,
        0.6871, 0.7308, 0.7197, 0.6779, 0.7672, 0.6105, 0.6478],
       device='cuda:0') torch.Size([16])
percent tensor([0.5495, 0.7042, 0.7124, 0.7677, 0.6126, 0.7874, 0.6811, 0.5014, 0.6698,
        0.6962, 0.7525, 0.5888, 0.6659, 0.6823, 0.4904, 0.5923],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9999, 0.9999, 0.9994, 0.9998, 0.9995, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(178.7499, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(822.3644, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(832.0186, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1521.6702, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(475.0027, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2287.7766, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4240.9849, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1353.9829, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6287.8711, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11539.4180, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3805.9436, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16002.2285, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 201 | Batch_idx: 0 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 201 | Batch_idx: 10 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 201 | Batch_idx: 20 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (2625/2688)
Epoch: 201 | Batch_idx: 30 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (3868/3968)
Epoch: 201 | Batch_idx: 40 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (5107/5248)
Epoch: 201 | Batch_idx: 50 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (6353/6528)
Epoch: 201 | Batch_idx: 60 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (7600/7808)
Epoch: 201 | Batch_idx: 70 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (8857/9088)
Epoch: 201 | Batch_idx: 80 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (10107/10368)
Epoch: 201 | Batch_idx: 90 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (11369/11648)
Epoch: 201 | Batch_idx: 100 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (12619/12928)
Epoch: 201 | Batch_idx: 110 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (13869/14208)
Epoch: 201 | Batch_idx: 120 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (15124/15488)
Epoch: 201 | Batch_idx: 130 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (16370/16768)
Epoch: 201 | Batch_idx: 140 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (17625/18048)
Epoch: 201 | Batch_idx: 150 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (18870/19328)
Epoch: 201 | Batch_idx: 160 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (20123/20608)
Epoch: 201 | Batch_idx: 170 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (21373/21888)
Epoch: 201 | Batch_idx: 180 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (22620/23168)
Epoch: 201 | Batch_idx: 190 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (23874/24448)
Epoch: 201 | Batch_idx: 200 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (25121/25728)
Epoch: 201 | Batch_idx: 210 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (26375/27008)
Epoch: 201 | Batch_idx: 220 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (27624/28288)
Epoch: 201 | Batch_idx: 230 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (28876/29568)
Epoch: 201 | Batch_idx: 240 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (30124/30848)
Epoch: 201 | Batch_idx: 250 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (31368/32128)
Epoch: 201 | Batch_idx: 260 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (32610/33408)
Epoch: 201 | Batch_idx: 270 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (33859/34688)
Epoch: 201 | Batch_idx: 280 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (35100/35968)
Epoch: 201 | Batch_idx: 290 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (36347/37248)
Epoch: 201 | Batch_idx: 300 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (37595/38528)
Epoch: 201 | Batch_idx: 310 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (38844/39808)
Epoch: 201 | Batch_idx: 320 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (40093/41088)
Epoch: 201 | Batch_idx: 330 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (41334/42368)
Epoch: 201 | Batch_idx: 340 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (42583/43648)
Epoch: 201 | Batch_idx: 350 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (43835/44928)
Epoch: 201 | Batch_idx: 360 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (45088/46208)
Epoch: 201 | Batch_idx: 370 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (46325/47488)
Epoch: 201 | Batch_idx: 380 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (47565/48768)
Epoch: 201 | Batch_idx: 390 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (48764/50000)
# TEST : Loss: (0.4301) | Acc: (88.00%) (8857/10000)
percent tensor([0.5801, 0.6000, 0.5903, 0.5776, 0.5979, 0.5711, 0.6083, 0.5942, 0.5922,
        0.5929, 0.5884, 0.5993, 0.5852, 0.5963, 0.5886, 0.5785],
       device='cuda:0') torch.Size([16])
percent tensor([0.5417, 0.5354, 0.5338, 0.5224, 0.5300, 0.5103, 0.5429, 0.5405, 0.5365,
        0.5361, 0.5340, 0.5373, 0.5466, 0.5297, 0.5213, 0.5335],
       device='cuda:0') torch.Size([16])
percent tensor([0.6180, 0.6247, 0.6225, 0.6837, 0.6960, 0.6647, 0.6562, 0.7170, 0.6145,
        0.5597, 0.5524, 0.6255, 0.5636, 0.6672, 0.6937, 0.6166],
       device='cuda:0') torch.Size([16])
percent tensor([0.7580, 0.7112, 0.7216, 0.7182, 0.7309, 0.7686, 0.7439, 0.7253, 0.7131,
        0.7237, 0.7395, 0.6934, 0.7027, 0.7410, 0.7539, 0.7525],
       device='cuda:0') torch.Size([16])
percent tensor([0.5676, 0.6176, 0.5914, 0.6093, 0.5963, 0.6021, 0.6045, 0.5743, 0.6196,
        0.6053, 0.5977, 0.6185, 0.5786, 0.6541, 0.5593, 0.5975],
       device='cuda:0') torch.Size([16])
percent tensor([0.6421, 0.6926, 0.7417, 0.7524, 0.7378, 0.6986, 0.6955, 0.6753, 0.7435,
        0.7006, 0.7429, 0.7309, 0.6825, 0.7923, 0.6156, 0.6707],
       device='cuda:0') torch.Size([16])
percent tensor([0.5567, 0.7219, 0.7316, 0.7654, 0.6223, 0.7853, 0.6818, 0.4752, 0.6923,
        0.7138, 0.7503, 0.5898, 0.6755, 0.6825, 0.4632, 0.6100],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9997, 0.9996, 1.0000,
        1.0000, 1.0000, 0.9999, 1.0000, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 202 | Batch_idx: 0 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 202 | Batch_idx: 10 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (1375/1408)
Epoch: 202 | Batch_idx: 20 |  Loss: (0.0620) |  Loss2: (0.0000) | Acc: (97.00%) (2632/2688)
Epoch: 202 | Batch_idx: 30 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (3883/3968)
Epoch: 202 | Batch_idx: 40 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (5133/5248)
Epoch: 202 | Batch_idx: 50 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (6386/6528)
Epoch: 202 | Batch_idx: 60 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (7636/7808)
Epoch: 202 | Batch_idx: 70 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (8889/9088)
Epoch: 202 | Batch_idx: 80 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (10143/10368)
Epoch: 202 | Batch_idx: 90 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (11397/11648)
Epoch: 202 | Batch_idx: 100 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (12647/12928)
Epoch: 202 | Batch_idx: 110 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (13895/14208)
Epoch: 202 | Batch_idx: 120 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (15149/15488)
Epoch: 202 | Batch_idx: 130 |  Loss: (0.0655) |  Loss2: (0.0000) | Acc: (97.00%) (16405/16768)
Epoch: 202 | Batch_idx: 140 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (17662/18048)
Epoch: 202 | Batch_idx: 150 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (18916/19328)
Epoch: 202 | Batch_idx: 160 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (20159/20608)
Epoch: 202 | Batch_idx: 170 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (21415/21888)
Epoch: 202 | Batch_idx: 180 |  Loss: (0.0671) |  Loss2: (0.0000) | Acc: (97.00%) (22660/23168)
Epoch: 202 | Batch_idx: 190 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (23897/24448)
Epoch: 202 | Batch_idx: 200 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (25147/25728)
Epoch: 202 | Batch_idx: 210 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (26408/27008)
Epoch: 202 | Batch_idx: 220 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (27660/28288)
Epoch: 202 | Batch_idx: 230 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (28903/29568)
Epoch: 202 | Batch_idx: 240 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (30153/30848)
Epoch: 202 | Batch_idx: 250 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (31411/32128)
Epoch: 202 | Batch_idx: 260 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (32664/33408)
Epoch: 202 | Batch_idx: 270 |  Loss: (0.0673) |  Loss2: (0.0000) | Acc: (97.00%) (33916/34688)
Epoch: 202 | Batch_idx: 280 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (35154/35968)
Epoch: 202 | Batch_idx: 290 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (36407/37248)
Epoch: 202 | Batch_idx: 300 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (37660/38528)
Epoch: 202 | Batch_idx: 310 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (38908/39808)
Epoch: 202 | Batch_idx: 320 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (40156/41088)
Epoch: 202 | Batch_idx: 330 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (41399/42368)
Epoch: 202 | Batch_idx: 340 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (42640/43648)
Epoch: 202 | Batch_idx: 350 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (43878/44928)
Epoch: 202 | Batch_idx: 360 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (45126/46208)
Epoch: 202 | Batch_idx: 370 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (46369/47488)
Epoch: 202 | Batch_idx: 380 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (47612/48768)
Epoch: 202 | Batch_idx: 390 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (48809/50000)
# TEST : Loss: (0.4093) | Acc: (88.00%) (8879/10000)
percent tensor([0.5820, 0.6024, 0.5951, 0.5804, 0.6025, 0.5728, 0.6117, 0.5971, 0.5946,
        0.5957, 0.5899, 0.6042, 0.5871, 0.5981, 0.5908, 0.5807],
       device='cuda:0') torch.Size([16])
percent tensor([0.5443, 0.5390, 0.5332, 0.5229, 0.5305, 0.5123, 0.5468, 0.5407, 0.5399,
        0.5393, 0.5379, 0.5381, 0.5496, 0.5348, 0.5242, 0.5363],
       device='cuda:0') torch.Size([16])
percent tensor([0.6285, 0.6106, 0.6182, 0.6877, 0.6917, 0.6760, 0.6436, 0.7070, 0.6023,
        0.5487, 0.5445, 0.6113, 0.5597, 0.6480, 0.6899, 0.6239],
       device='cuda:0') torch.Size([16])
percent tensor([0.7584, 0.7074, 0.7265, 0.7206, 0.7373, 0.7582, 0.7456, 0.7337, 0.7134,
        0.7234, 0.7366, 0.6891, 0.7031, 0.7399, 0.7490, 0.7523],
       device='cuda:0') torch.Size([16])
percent tensor([0.5696, 0.6200, 0.5937, 0.6069, 0.5985, 0.6134, 0.6055, 0.5694, 0.6197,
        0.6083, 0.5980, 0.6251, 0.5805, 0.6539, 0.5597, 0.6033],
       device='cuda:0') torch.Size([16])
percent tensor([0.6360, 0.7043, 0.7344, 0.7510, 0.7453, 0.7084, 0.6904, 0.6824, 0.7437,
        0.7024, 0.7394, 0.7339, 0.6837, 0.7944, 0.6139, 0.6708],
       device='cuda:0') torch.Size([16])
percent tensor([0.5011, 0.7258, 0.6983, 0.7275, 0.6272, 0.7696, 0.6381, 0.4506, 0.6750,
        0.7145, 0.7345, 0.5905, 0.6914, 0.6436, 0.4275, 0.5978],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9998, 0.9999, 0.9999, 0.9995, 0.9997, 0.9996, 0.9999,
        1.0000, 1.0000, 1.0000, 0.9999, 0.9998, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 203 | Batch_idx: 0 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 203 | Batch_idx: 10 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (98.00%) (1383/1408)
Epoch: 203 | Batch_idx: 20 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (2641/2688)
Epoch: 203 | Batch_idx: 30 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (3888/3968)
Epoch: 203 | Batch_idx: 40 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (5137/5248)
Epoch: 203 | Batch_idx: 50 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (6389/6528)
Epoch: 203 | Batch_idx: 60 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (7642/7808)
Epoch: 203 | Batch_idx: 70 |  Loss: (0.0662) |  Loss2: (0.0000) | Acc: (97.00%) (8899/9088)
Epoch: 203 | Batch_idx: 80 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (10148/10368)
Epoch: 203 | Batch_idx: 90 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (11410/11648)
Epoch: 203 | Batch_idx: 100 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (98.00%) (12671/12928)
Epoch: 203 | Batch_idx: 110 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (98.00%) (13929/14208)
Epoch: 203 | Batch_idx: 120 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (15177/15488)
Epoch: 203 | Batch_idx: 130 |  Loss: (0.0652) |  Loss2: (0.0000) | Acc: (97.00%) (16430/16768)
Epoch: 203 | Batch_idx: 140 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (17685/18048)
Epoch: 203 | Batch_idx: 150 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (18934/19328)
Epoch: 203 | Batch_idx: 160 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (20186/20608)
Epoch: 203 | Batch_idx: 170 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (21429/21888)
Epoch: 203 | Batch_idx: 180 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (22681/23168)
Epoch: 203 | Batch_idx: 190 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (23940/24448)
Epoch: 203 | Batch_idx: 200 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (25185/25728)
Epoch: 203 | Batch_idx: 210 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (26433/27008)
Epoch: 203 | Batch_idx: 220 |  Loss: (0.0673) |  Loss2: (0.0000) | Acc: (97.00%) (27691/28288)
Epoch: 203 | Batch_idx: 230 |  Loss: (0.0673) |  Loss2: (0.0000) | Acc: (97.00%) (28944/29568)
Epoch: 203 | Batch_idx: 240 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (30185/30848)
Epoch: 203 | Batch_idx: 250 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (31425/32128)
Epoch: 203 | Batch_idx: 260 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (32681/33408)
Epoch: 203 | Batch_idx: 270 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (33927/34688)
Epoch: 203 | Batch_idx: 280 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (35178/35968)
Epoch: 203 | Batch_idx: 290 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (36435/37248)
Epoch: 203 | Batch_idx: 300 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (37684/38528)
Epoch: 203 | Batch_idx: 310 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (38932/39808)
Epoch: 203 | Batch_idx: 320 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (40182/41088)
Epoch: 203 | Batch_idx: 330 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (41436/42368)
Epoch: 203 | Batch_idx: 340 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (42684/43648)
Epoch: 203 | Batch_idx: 350 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (43940/44928)
Epoch: 203 | Batch_idx: 360 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (45202/46208)
Epoch: 203 | Batch_idx: 370 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (46458/47488)
Epoch: 203 | Batch_idx: 380 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (47701/48768)
Epoch: 203 | Batch_idx: 390 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (48907/50000)
# TEST : Loss: (0.4257) | Acc: (88.00%) (8833/10000)
percent tensor([0.5833, 0.6053, 0.5951, 0.5822, 0.6030, 0.5741, 0.6133, 0.5990, 0.5954,
        0.5976, 0.5917, 0.6046, 0.5887, 0.6006, 0.5932, 0.5826],
       device='cuda:0') torch.Size([16])
percent tensor([0.5419, 0.5378, 0.5344, 0.5223, 0.5322, 0.5091, 0.5443, 0.5392, 0.5368,
        0.5384, 0.5348, 0.5397, 0.5466, 0.5307, 0.5217, 0.5329],
       device='cuda:0') torch.Size([16])
percent tensor([0.6299, 0.6198, 0.6175, 0.6800, 0.6940, 0.6707, 0.6513, 0.7167, 0.6036,
        0.5607, 0.5493, 0.6187, 0.5642, 0.6531, 0.6947, 0.6260],
       device='cuda:0') torch.Size([16])
percent tensor([0.7604, 0.7059, 0.7262, 0.7209, 0.7354, 0.7597, 0.7421, 0.7303, 0.7122,
        0.7238, 0.7383, 0.6910, 0.7007, 0.7361, 0.7492, 0.7518],
       device='cuda:0') torch.Size([16])
percent tensor([0.5698, 0.6197, 0.5978, 0.6145, 0.6008, 0.6126, 0.6053, 0.5729, 0.6249,
        0.6088, 0.6033, 0.6285, 0.5815, 0.6543, 0.5636, 0.6030],
       device='cuda:0') torch.Size([16])
percent tensor([0.6343, 0.7106, 0.7405, 0.7619, 0.7539, 0.7080, 0.7101, 0.6845, 0.7471,
        0.7090, 0.7508, 0.7319, 0.6783, 0.7976, 0.6198, 0.6624],
       device='cuda:0') torch.Size([16])
percent tensor([0.5474, 0.7256, 0.7248, 0.7862, 0.6376, 0.7989, 0.6666, 0.4813, 0.6816,
        0.6961, 0.7434, 0.5977, 0.6413, 0.6721, 0.4652, 0.5703],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9999, 1.0000, 1.0000, 0.9992, 0.9998, 0.9996, 0.9999,
        0.9999, 1.0000, 1.0000, 0.9999, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 204 | Batch_idx: 0 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 204 | Batch_idx: 10 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 204 | Batch_idx: 20 |  Loss: (0.0662) |  Loss2: (0.0000) | Acc: (97.00%) (2629/2688)
Epoch: 204 | Batch_idx: 30 |  Loss: (0.0662) |  Loss2: (0.0000) | Acc: (97.00%) (3876/3968)
Epoch: 204 | Batch_idx: 40 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (5129/5248)
Epoch: 204 | Batch_idx: 50 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (6389/6528)
Epoch: 204 | Batch_idx: 60 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (7635/7808)
Epoch: 204 | Batch_idx: 70 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (8890/9088)
Epoch: 204 | Batch_idx: 80 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (10145/10368)
Epoch: 204 | Batch_idx: 90 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (97.00%) (11404/11648)
Epoch: 204 | Batch_idx: 100 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (12653/12928)
Epoch: 204 | Batch_idx: 110 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (13911/14208)
Epoch: 204 | Batch_idx: 120 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (15170/15488)
Epoch: 204 | Batch_idx: 130 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (16420/16768)
Epoch: 204 | Batch_idx: 140 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (17668/18048)
Epoch: 204 | Batch_idx: 150 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (97.00%) (18928/19328)
Epoch: 204 | Batch_idx: 160 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (97.00%) (20184/20608)
Epoch: 204 | Batch_idx: 170 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (21431/21888)
Epoch: 204 | Batch_idx: 180 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (22683/23168)
Epoch: 204 | Batch_idx: 190 |  Loss: (0.0634) |  Loss2: (0.0000) | Acc: (97.00%) (23935/24448)
Epoch: 204 | Batch_idx: 200 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (25186/25728)
Epoch: 204 | Batch_idx: 210 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (26437/27008)
Epoch: 204 | Batch_idx: 220 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (27696/28288)
Epoch: 204 | Batch_idx: 230 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (28951/29568)
Epoch: 204 | Batch_idx: 240 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (30202/30848)
Epoch: 204 | Batch_idx: 250 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (31445/32128)
Epoch: 204 | Batch_idx: 260 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (32703/33408)
Epoch: 204 | Batch_idx: 270 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (33964/34688)
Epoch: 204 | Batch_idx: 280 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (35214/35968)
Epoch: 204 | Batch_idx: 290 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (36458/37248)
Epoch: 204 | Batch_idx: 300 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (37706/38528)
Epoch: 204 | Batch_idx: 310 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (38954/39808)
Epoch: 204 | Batch_idx: 320 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (40199/41088)
Epoch: 204 | Batch_idx: 330 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (97.00%) (41450/42368)
Epoch: 204 | Batch_idx: 340 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (42697/43648)
Epoch: 204 | Batch_idx: 350 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (43948/44928)
Epoch: 204 | Batch_idx: 360 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (45198/46208)
Epoch: 204 | Batch_idx: 370 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (46455/47488)
Epoch: 204 | Batch_idx: 380 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (47696/48768)
Epoch: 204 | Batch_idx: 390 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (48906/50000)
# TEST : Loss: (0.4398) | Acc: (88.00%) (8872/10000)
percent tensor([0.5838, 0.6038, 0.5965, 0.5820, 0.6038, 0.5744, 0.6132, 0.5982, 0.5958,
        0.5973, 0.5913, 0.6058, 0.5889, 0.5997, 0.5923, 0.5823],
       device='cuda:0') torch.Size([16])
percent tensor([0.5432, 0.5379, 0.5320, 0.5208, 0.5298, 0.5117, 0.5449, 0.5393, 0.5394,
        0.5384, 0.5370, 0.5379, 0.5484, 0.5339, 0.5232, 0.5349],
       device='cuda:0') torch.Size([16])
percent tensor([0.6189, 0.6261, 0.5974, 0.6639, 0.6766, 0.6606, 0.6495, 0.7008, 0.5967,
        0.5473, 0.5416, 0.5978, 0.5555, 0.6594, 0.6900, 0.6121],
       device='cuda:0') torch.Size([16])
percent tensor([0.7587, 0.7127, 0.7254, 0.7210, 0.7352, 0.7561, 0.7472, 0.7347, 0.7166,
        0.7285, 0.7437, 0.6944, 0.7046, 0.7461, 0.7505, 0.7487],
       device='cuda:0') torch.Size([16])
percent tensor([0.5749, 0.6265, 0.6008, 0.6185, 0.6017, 0.6158, 0.6088, 0.5738, 0.6267,
        0.6120, 0.6091, 0.6283, 0.5873, 0.6583, 0.5674, 0.6068],
       device='cuda:0') torch.Size([16])
percent tensor([0.6447, 0.7189, 0.7483, 0.7588, 0.7434, 0.7197, 0.7137, 0.6894, 0.7531,
        0.7145, 0.7519, 0.7443, 0.6870, 0.8099, 0.6202, 0.6824],
       device='cuda:0') torch.Size([16])
percent tensor([0.5355, 0.7521, 0.7566, 0.7651, 0.6418, 0.7946, 0.6747, 0.5005, 0.7143,
        0.7317, 0.7536, 0.6528, 0.6795, 0.7397, 0.4752, 0.5909],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9999, 0.9999, 0.9999, 0.9995, 0.9997, 0.9996, 0.9999,
        1.0000, 1.0000, 1.0000, 0.9999, 0.9995, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 205 | Batch_idx: 0 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 205 | Batch_idx: 10 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (98.00%) (1380/1408)
Epoch: 205 | Batch_idx: 20 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (2634/2688)
Epoch: 205 | Batch_idx: 30 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (3886/3968)
Epoch: 205 | Batch_idx: 40 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (5134/5248)
Epoch: 205 | Batch_idx: 50 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (97.00%) (6395/6528)
Epoch: 205 | Batch_idx: 60 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (7646/7808)
Epoch: 205 | Batch_idx: 70 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (8898/9088)
Epoch: 205 | Batch_idx: 80 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (10154/10368)
Epoch: 205 | Batch_idx: 90 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (11400/11648)
Epoch: 205 | Batch_idx: 100 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (12659/12928)
Epoch: 205 | Batch_idx: 110 |  Loss: (0.0655) |  Loss2: (0.0000) | Acc: (97.00%) (13899/14208)
Epoch: 205 | Batch_idx: 120 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (15144/15488)
Epoch: 205 | Batch_idx: 130 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (16398/16768)
Epoch: 205 | Batch_idx: 140 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (17651/18048)
Epoch: 205 | Batch_idx: 150 |  Loss: (0.0661) |  Loss2: (0.0000) | Acc: (97.00%) (18910/19328)
Epoch: 205 | Batch_idx: 160 |  Loss: (0.0658) |  Loss2: (0.0000) | Acc: (97.00%) (20165/20608)
Epoch: 205 | Batch_idx: 170 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (21416/21888)
Epoch: 205 | Batch_idx: 180 |  Loss: (0.0661) |  Loss2: (0.0000) | Acc: (97.00%) (22667/23168)
Epoch: 205 | Batch_idx: 190 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (23916/24448)
Epoch: 205 | Batch_idx: 200 |  Loss: (0.0662) |  Loss2: (0.0000) | Acc: (97.00%) (25163/25728)
Epoch: 205 | Batch_idx: 210 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (26419/27008)
Epoch: 205 | Batch_idx: 220 |  Loss: (0.0658) |  Loss2: (0.0000) | Acc: (97.00%) (27667/28288)
Epoch: 205 | Batch_idx: 230 |  Loss: (0.0661) |  Loss2: (0.0000) | Acc: (97.00%) (28920/29568)
Epoch: 205 | Batch_idx: 240 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (30176/30848)
Epoch: 205 | Batch_idx: 250 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (31427/32128)
Epoch: 205 | Batch_idx: 260 |  Loss: (0.0658) |  Loss2: (0.0000) | Acc: (97.00%) (32678/33408)
Epoch: 205 | Batch_idx: 270 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (33932/34688)
Epoch: 205 | Batch_idx: 280 |  Loss: (0.0655) |  Loss2: (0.0000) | Acc: (97.00%) (35191/35968)
Epoch: 205 | Batch_idx: 290 |  Loss: (0.0655) |  Loss2: (0.0000) | Acc: (97.00%) (36444/37248)
Epoch: 205 | Batch_idx: 300 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (37696/38528)
Epoch: 205 | Batch_idx: 310 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (38950/39808)
Epoch: 205 | Batch_idx: 320 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (40203/41088)
Epoch: 205 | Batch_idx: 330 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (41453/42368)
Epoch: 205 | Batch_idx: 340 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (42713/43648)
Epoch: 205 | Batch_idx: 350 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (43965/44928)
Epoch: 205 | Batch_idx: 360 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (45214/46208)
Epoch: 205 | Batch_idx: 370 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (46458/47488)
Epoch: 205 | Batch_idx: 380 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (47716/48768)
Epoch: 205 | Batch_idx: 390 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (48927/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_205.pth.tar'
# TEST : Loss: (0.4347) | Acc: (88.00%) (8869/10000)
percent tensor([0.5863, 0.6087, 0.5986, 0.5851, 0.6069, 0.5767, 0.6176, 0.6022, 0.5987,
        0.6013, 0.5952, 0.6085, 0.5919, 0.6048, 0.5961, 0.5856],
       device='cuda:0') torch.Size([16])
percent tensor([0.5403, 0.5358, 0.5344, 0.5223, 0.5306, 0.5085, 0.5432, 0.5406, 0.5357,
        0.5369, 0.5327, 0.5383, 0.5454, 0.5309, 0.5209, 0.5327],
       device='cuda:0') torch.Size([16])
percent tensor([0.6277, 0.6255, 0.6079, 0.6833, 0.6868, 0.6640, 0.6546, 0.7158, 0.6088,
        0.5567, 0.5449, 0.6091, 0.5592, 0.6686, 0.6944, 0.6241],
       device='cuda:0') torch.Size([16])
percent tensor([0.7545, 0.7058, 0.7213, 0.7176, 0.7290, 0.7532, 0.7375, 0.7246, 0.7087,
        0.7224, 0.7376, 0.6862, 0.6970, 0.7399, 0.7443, 0.7450],
       device='cuda:0') torch.Size([16])
percent tensor([0.5792, 0.6228, 0.6053, 0.6191, 0.6063, 0.6171, 0.6098, 0.5827, 0.6295,
        0.6161, 0.6125, 0.6381, 0.5912, 0.6584, 0.5670, 0.6113],
       device='cuda:0') torch.Size([16])
percent tensor([0.6425, 0.7078, 0.7363, 0.7735, 0.7441, 0.7333, 0.7115, 0.6854, 0.7357,
        0.7068, 0.7482, 0.7379, 0.6781, 0.8010, 0.6423, 0.6872],
       device='cuda:0') torch.Size([16])
percent tensor([0.5624, 0.7273, 0.7239, 0.7717, 0.5907, 0.8236, 0.6903, 0.4565, 0.6638,
        0.6872, 0.7437, 0.5950, 0.6596, 0.6319, 0.4862, 0.6074],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9998, 0.9994, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9998, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 206 | Batch_idx: 0 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 206 | Batch_idx: 10 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (1378/1408)
Epoch: 206 | Batch_idx: 20 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (98.00%) (2639/2688)
Epoch: 206 | Batch_idx: 30 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (98.00%) (3892/3968)
Epoch: 206 | Batch_idx: 40 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (5148/5248)
Epoch: 206 | Batch_idx: 50 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (98.00%) (6404/6528)
Epoch: 206 | Batch_idx: 60 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (7658/7808)
Epoch: 206 | Batch_idx: 70 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (97.00%) (8906/9088)
Epoch: 206 | Batch_idx: 80 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (97.00%) (10160/10368)
Epoch: 206 | Batch_idx: 90 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (98.00%) (11417/11648)
Epoch: 206 | Batch_idx: 100 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (12674/12928)
Epoch: 206 | Batch_idx: 110 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (13923/14208)
Epoch: 206 | Batch_idx: 120 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (98.00%) (15183/15488)
Epoch: 206 | Batch_idx: 130 |  Loss: (0.0613) |  Loss2: (0.0000) | Acc: (98.00%) (16446/16768)
Epoch: 206 | Batch_idx: 140 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (98.00%) (17693/18048)
Epoch: 206 | Batch_idx: 150 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (18934/19328)
Epoch: 206 | Batch_idx: 160 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (20195/20608)
Epoch: 206 | Batch_idx: 170 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (21450/21888)
Epoch: 206 | Batch_idx: 180 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (22694/23168)
Epoch: 206 | Batch_idx: 190 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (23953/24448)
Epoch: 206 | Batch_idx: 200 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (25208/25728)
Epoch: 206 | Batch_idx: 210 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (97.00%) (26463/27008)
Epoch: 206 | Batch_idx: 220 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (27719/28288)
Epoch: 206 | Batch_idx: 230 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (28966/29568)
Epoch: 206 | Batch_idx: 240 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (30218/30848)
Epoch: 206 | Batch_idx: 250 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (31464/32128)
Epoch: 206 | Batch_idx: 260 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (32719/33408)
Epoch: 206 | Batch_idx: 270 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (33960/34688)
Epoch: 206 | Batch_idx: 280 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (35217/35968)
Epoch: 206 | Batch_idx: 290 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (36469/37248)
Epoch: 206 | Batch_idx: 300 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (37719/38528)
Epoch: 206 | Batch_idx: 310 |  Loss: (0.0642) |  Loss2: (0.0000) | Acc: (97.00%) (38970/39808)
Epoch: 206 | Batch_idx: 320 |  Loss: (0.0642) |  Loss2: (0.0000) | Acc: (97.00%) (40222/41088)
Epoch: 206 | Batch_idx: 330 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (41478/42368)
Epoch: 206 | Batch_idx: 340 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (42719/43648)
Epoch: 206 | Batch_idx: 350 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (43966/44928)
Epoch: 206 | Batch_idx: 360 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (45215/46208)
Epoch: 206 | Batch_idx: 370 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (46462/47488)
Epoch: 206 | Batch_idx: 380 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (47719/48768)
Epoch: 206 | Batch_idx: 390 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (48922/50000)
# TEST : Loss: (0.4427) | Acc: (88.00%) (8845/10000)
percent tensor([0.5881, 0.6095, 0.6023, 0.5871, 0.6096, 0.5781, 0.6189, 0.6045, 0.6005,
        0.6032, 0.5963, 0.6117, 0.5937, 0.6039, 0.5978, 0.5871],
       device='cuda:0') torch.Size([16])
percent tensor([0.5426, 0.5388, 0.5319, 0.5216, 0.5297, 0.5134, 0.5450, 0.5400, 0.5384,
        0.5380, 0.5362, 0.5379, 0.5480, 0.5349, 0.5242, 0.5351],
       device='cuda:0') torch.Size([16])
percent tensor([0.6232, 0.6199, 0.6187, 0.6880, 0.6913, 0.6765, 0.6522, 0.7118, 0.6003,
        0.5570, 0.5431, 0.6158, 0.5532, 0.6546, 0.6992, 0.6258],
       device='cuda:0') torch.Size([16])
percent tensor([0.7579, 0.7095, 0.7247, 0.7257, 0.7339, 0.7611, 0.7436, 0.7304, 0.7110,
        0.7277, 0.7387, 0.6948, 0.7000, 0.7375, 0.7536, 0.7510],
       device='cuda:0') torch.Size([16])
percent tensor([0.5757, 0.6213, 0.5987, 0.6120, 0.6065, 0.6180, 0.6032, 0.5742, 0.6267,
        0.6100, 0.6096, 0.6303, 0.5876, 0.6593, 0.5597, 0.6082],
       device='cuda:0') torch.Size([16])
percent tensor([0.6397, 0.7049, 0.7420, 0.7641, 0.7476, 0.7100, 0.7143, 0.6882, 0.7426,
        0.6999, 0.7434, 0.7341, 0.6783, 0.8082, 0.6204, 0.6754],
       device='cuda:0') torch.Size([16])
percent tensor([0.5213, 0.7241, 0.7257, 0.7518, 0.6015, 0.7545, 0.6592, 0.4675, 0.6446,
        0.6654, 0.7303, 0.5499, 0.6394, 0.6551, 0.4321, 0.5706],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9999, 0.9994, 0.9999, 0.9995, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 207 | Batch_idx: 0 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 207 | Batch_idx: 10 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (1375/1408)
Epoch: 207 | Batch_idx: 20 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (97.00%) (2633/2688)
Epoch: 207 | Batch_idx: 30 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (97.00%) (3876/3968)
Epoch: 207 | Batch_idx: 40 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (97.00%) (5134/5248)
Epoch: 207 | Batch_idx: 50 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (97.00%) (6391/6528)
Epoch: 207 | Batch_idx: 60 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (97.00%) (7647/7808)
Epoch: 207 | Batch_idx: 70 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (97.00%) (8900/9088)
Epoch: 207 | Batch_idx: 80 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (97.00%) (10158/10368)
Epoch: 207 | Batch_idx: 90 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (97.00%) (11413/11648)
Epoch: 207 | Batch_idx: 100 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (12671/12928)
Epoch: 207 | Batch_idx: 110 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (98.00%) (13932/14208)
Epoch: 207 | Batch_idx: 120 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (15185/15488)
Epoch: 207 | Batch_idx: 130 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (16441/16768)
Epoch: 207 | Batch_idx: 140 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (17696/18048)
Epoch: 207 | Batch_idx: 150 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (18954/19328)
Epoch: 207 | Batch_idx: 160 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (20208/20608)
Epoch: 207 | Batch_idx: 170 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (21465/21888)
Epoch: 207 | Batch_idx: 180 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (22720/23168)
Epoch: 207 | Batch_idx: 190 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (23974/24448)
Epoch: 207 | Batch_idx: 200 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (25227/25728)
Epoch: 207 | Batch_idx: 210 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (26478/27008)
Epoch: 207 | Batch_idx: 220 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (98.00%) (27733/28288)
Epoch: 207 | Batch_idx: 230 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (98.00%) (28981/29568)
Epoch: 207 | Batch_idx: 240 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (30241/30848)
Epoch: 207 | Batch_idx: 250 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (31489/32128)
Epoch: 207 | Batch_idx: 260 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (98.00%) (32747/33408)
Epoch: 207 | Batch_idx: 270 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (98.00%) (33998/34688)
Epoch: 207 | Batch_idx: 280 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (97.00%) (35244/35968)
Epoch: 207 | Batch_idx: 290 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (97.00%) (36496/37248)
Epoch: 207 | Batch_idx: 300 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (97.00%) (37754/38528)
Epoch: 207 | Batch_idx: 310 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (39003/39808)
Epoch: 207 | Batch_idx: 320 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (40257/41088)
Epoch: 207 | Batch_idx: 330 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (41511/42368)
Epoch: 207 | Batch_idx: 340 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (97.00%) (42758/43648)
Epoch: 207 | Batch_idx: 350 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (44001/44928)
Epoch: 207 | Batch_idx: 360 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (45248/46208)
Epoch: 207 | Batch_idx: 370 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (97.00%) (46502/47488)
Epoch: 207 | Batch_idx: 380 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (47749/48768)
Epoch: 207 | Batch_idx: 390 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (48952/50000)
# TEST : Loss: (0.4348) | Acc: (88.00%) (8866/10000)
percent tensor([0.5861, 0.6083, 0.5984, 0.5848, 0.6064, 0.5760, 0.6168, 0.6018, 0.5983,
        0.6009, 0.5944, 0.6080, 0.5918, 0.6040, 0.5957, 0.5853],
       device='cuda:0') torch.Size([16])
percent tensor([0.5462, 0.5411, 0.5394, 0.5255, 0.5365, 0.5147, 0.5495, 0.5443, 0.5420,
        0.5428, 0.5398, 0.5446, 0.5521, 0.5344, 0.5273, 0.5378],
       device='cuda:0') torch.Size([16])
percent tensor([0.6251, 0.6259, 0.6137, 0.6786, 0.6921, 0.6806, 0.6559, 0.7086, 0.6007,
        0.5548, 0.5477, 0.6141, 0.5579, 0.6547, 0.7009, 0.6240],
       device='cuda:0') torch.Size([16])
percent tensor([0.7604, 0.7100, 0.7254, 0.7229, 0.7342, 0.7632, 0.7450, 0.7313, 0.7172,
        0.7259, 0.7406, 0.6946, 0.7041, 0.7419, 0.7539, 0.7522],
       device='cuda:0') torch.Size([16])
percent tensor([0.5745, 0.6178, 0.5980, 0.6257, 0.6023, 0.6152, 0.5990, 0.5718, 0.6266,
        0.6063, 0.6019, 0.6258, 0.5802, 0.6610, 0.5565, 0.6059],
       device='cuda:0') torch.Size([16])
percent tensor([0.6429, 0.7055, 0.7436, 0.7616, 0.7415, 0.7058, 0.7045, 0.6862, 0.7495,
        0.7066, 0.7492, 0.7315, 0.6890, 0.7931, 0.6201, 0.6730],
       device='cuda:0') torch.Size([16])
percent tensor([0.5644, 0.7128, 0.7219, 0.7494, 0.6004, 0.7517, 0.6458, 0.4716, 0.6778,
        0.7067, 0.7324, 0.5769, 0.6815, 0.6684, 0.4603, 0.5594],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9994, 0.9999, 0.9996, 0.9998,
        1.0000, 1.0000, 0.9999, 0.9999, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 208 | Batch_idx: 0 |  Loss: (0.0304) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 208 | Batch_idx: 10 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 208 | Batch_idx: 20 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (98.00%) (2646/2688)
Epoch: 208 | Batch_idx: 30 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (3902/3968)
Epoch: 208 | Batch_idx: 40 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (5160/5248)
Epoch: 208 | Batch_idx: 50 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (6425/6528)
Epoch: 208 | Batch_idx: 60 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (7681/7808)
Epoch: 208 | Batch_idx: 70 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (8936/9088)
Epoch: 208 | Batch_idx: 80 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (10194/10368)
Epoch: 208 | Batch_idx: 90 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (11446/11648)
Epoch: 208 | Batch_idx: 100 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (12701/12928)
Epoch: 208 | Batch_idx: 110 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (13951/14208)
Epoch: 208 | Batch_idx: 120 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (15201/15488)
Epoch: 208 | Batch_idx: 130 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (98.00%) (16451/16768)
Epoch: 208 | Batch_idx: 140 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (17713/18048)
Epoch: 208 | Batch_idx: 150 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (18968/19328)
Epoch: 208 | Batch_idx: 160 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (98.00%) (20224/20608)
Epoch: 208 | Batch_idx: 170 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (21485/21888)
Epoch: 208 | Batch_idx: 180 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (22745/23168)
Epoch: 208 | Batch_idx: 190 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (98.00%) (24003/24448)
Epoch: 208 | Batch_idx: 200 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (25249/25728)
Epoch: 208 | Batch_idx: 210 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (98.00%) (26511/27008)
Epoch: 208 | Batch_idx: 220 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (98.00%) (27766/28288)
Epoch: 208 | Batch_idx: 230 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (98.00%) (29017/29568)
Epoch: 208 | Batch_idx: 240 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (98.00%) (30269/30848)
Epoch: 208 | Batch_idx: 250 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (98.00%) (31520/32128)
Epoch: 208 | Batch_idx: 260 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (98.00%) (32773/33408)
Epoch: 208 | Batch_idx: 270 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (98.00%) (34030/34688)
Epoch: 208 | Batch_idx: 280 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (98.00%) (35286/35968)
Epoch: 208 | Batch_idx: 290 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (98.00%) (36541/37248)
Epoch: 208 | Batch_idx: 300 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (98.00%) (37795/38528)
Epoch: 208 | Batch_idx: 310 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (98.00%) (39054/39808)
Epoch: 208 | Batch_idx: 320 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (98.00%) (40310/41088)
Epoch: 208 | Batch_idx: 330 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (98.00%) (41555/42368)
Epoch: 208 | Batch_idx: 340 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (98.00%) (42807/43648)
Epoch: 208 | Batch_idx: 350 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (44062/44928)
Epoch: 208 | Batch_idx: 360 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (98.00%) (45308/46208)
Epoch: 208 | Batch_idx: 370 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (98.00%) (46560/47488)
Epoch: 208 | Batch_idx: 380 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (98.00%) (47817/48768)
Epoch: 208 | Batch_idx: 390 |  Loss: (0.0613) |  Loss2: (0.0000) | Acc: (98.00%) (49023/50000)
# TEST : Loss: (0.4160) | Acc: (89.00%) (8926/10000)
percent tensor([0.5841, 0.6056, 0.5985, 0.5829, 0.6050, 0.5740, 0.6150, 0.6003, 0.5963,
        0.5992, 0.5921, 0.6076, 0.5895, 0.6008, 0.5935, 0.5829],
       device='cuda:0') torch.Size([16])
percent tensor([0.5475, 0.5416, 0.5394, 0.5255, 0.5372, 0.5156, 0.5501, 0.5436, 0.5420,
        0.5432, 0.5402, 0.5456, 0.5532, 0.5351, 0.5275, 0.5386],
       device='cuda:0') torch.Size([16])
percent tensor([0.6299, 0.6330, 0.6119, 0.6870, 0.6892, 0.6763, 0.6572, 0.7126, 0.6072,
        0.5622, 0.5545, 0.6132, 0.5674, 0.6586, 0.7041, 0.6307],
       device='cuda:0') torch.Size([16])
percent tensor([0.7634, 0.7139, 0.7270, 0.7264, 0.7348, 0.7611, 0.7495, 0.7344, 0.7210,
        0.7307, 0.7439, 0.6958, 0.7087, 0.7470, 0.7549, 0.7540],
       device='cuda:0') torch.Size([16])
percent tensor([0.5732, 0.6168, 0.6068, 0.6272, 0.6109, 0.6202, 0.6024, 0.5782, 0.6299,
        0.6052, 0.6029, 0.6340, 0.5788, 0.6588, 0.5646, 0.6075],
       device='cuda:0') torch.Size([16])
percent tensor([0.6597, 0.7167, 0.7526, 0.7815, 0.7571, 0.7320, 0.7115, 0.7063, 0.7449,
        0.7056, 0.7533, 0.7415, 0.6877, 0.8065, 0.6274, 0.6881],
       device='cuda:0') torch.Size([16])
percent tensor([0.5705, 0.6981, 0.7224, 0.7487, 0.5998, 0.7916, 0.6377, 0.4929, 0.6353,
        0.6932, 0.7220, 0.5732, 0.6370, 0.6689, 0.4736, 0.5667],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9998, 0.9996, 0.9999,
        0.9999, 0.9999, 1.0000, 0.9999, 0.9994, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 209 | Batch_idx: 0 |  Loss: (0.0250) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 209 | Batch_idx: 10 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 209 | Batch_idx: 20 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (2648/2688)
Epoch: 209 | Batch_idx: 30 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (3907/3968)
Epoch: 209 | Batch_idx: 40 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (5161/5248)
Epoch: 209 | Batch_idx: 50 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (6420/6528)
Epoch: 209 | Batch_idx: 60 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (7690/7808)
Epoch: 209 | Batch_idx: 70 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (8937/9088)
Epoch: 209 | Batch_idx: 80 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (10195/10368)
Epoch: 209 | Batch_idx: 90 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (11448/11648)
Epoch: 209 | Batch_idx: 100 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (12703/12928)
Epoch: 209 | Batch_idx: 110 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (13960/14208)
Epoch: 209 | Batch_idx: 120 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (15210/15488)
Epoch: 209 | Batch_idx: 130 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (16467/16768)
Epoch: 209 | Batch_idx: 140 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (17722/18048)
Epoch: 209 | Batch_idx: 150 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (18973/19328)
Epoch: 209 | Batch_idx: 160 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (20237/20608)
Epoch: 209 | Batch_idx: 170 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (21506/21888)
Epoch: 209 | Batch_idx: 180 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (22757/23168)
Epoch: 209 | Batch_idx: 190 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (24016/24448)
Epoch: 209 | Batch_idx: 200 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (25270/25728)
Epoch: 209 | Batch_idx: 210 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (26533/27008)
Epoch: 209 | Batch_idx: 220 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (27787/28288)
Epoch: 209 | Batch_idx: 230 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (29045/29568)
Epoch: 209 | Batch_idx: 240 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (30297/30848)
Epoch: 209 | Batch_idx: 250 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (31554/32128)
Epoch: 209 | Batch_idx: 260 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (32816/33408)
Epoch: 209 | Batch_idx: 270 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (34079/34688)
Epoch: 209 | Batch_idx: 280 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (35340/35968)
Epoch: 209 | Batch_idx: 290 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (36597/37248)
Epoch: 209 | Batch_idx: 300 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (37855/38528)
Epoch: 209 | Batch_idx: 310 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (39115/39808)
Epoch: 209 | Batch_idx: 320 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (40358/41088)
Epoch: 209 | Batch_idx: 330 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (41612/42368)
Epoch: 209 | Batch_idx: 340 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (42867/43648)
Epoch: 209 | Batch_idx: 350 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (44130/44928)
Epoch: 209 | Batch_idx: 360 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (45381/46208)
Epoch: 209 | Batch_idx: 370 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (46629/47488)
Epoch: 209 | Batch_idx: 380 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (47877/48768)
Epoch: 209 | Batch_idx: 390 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (49079/50000)
# TEST : Loss: (0.4286) | Acc: (88.00%) (8855/10000)
percent tensor([0.5826, 0.6049, 0.5961, 0.5828, 0.6032, 0.5727, 0.6133, 0.5998, 0.5947,
        0.5980, 0.5909, 0.6052, 0.5884, 0.6006, 0.5925, 0.5825],
       device='cuda:0') torch.Size([16])
percent tensor([0.5450, 0.5410, 0.5341, 0.5228, 0.5329, 0.5136, 0.5478, 0.5415, 0.5404,
        0.5403, 0.5385, 0.5409, 0.5508, 0.5356, 0.5258, 0.5367],
       device='cuda:0') torch.Size([16])
percent tensor([0.6207, 0.6238, 0.6341, 0.6906, 0.7014, 0.6654, 0.6631, 0.7203, 0.6100,
        0.5640, 0.5504, 0.6367, 0.5653, 0.6566, 0.6964, 0.6210],
       device='cuda:0') torch.Size([16])
percent tensor([0.7584, 0.7046, 0.7243, 0.7253, 0.7355, 0.7564, 0.7411, 0.7285, 0.7158,
        0.7240, 0.7374, 0.6936, 0.7024, 0.7347, 0.7475, 0.7462],
       device='cuda:0') torch.Size([16])
percent tensor([0.5790, 0.6240, 0.6017, 0.6240, 0.6059, 0.6198, 0.6091, 0.5811, 0.6299,
        0.6128, 0.6092, 0.6265, 0.5815, 0.6632, 0.5684, 0.6124],
       device='cuda:0') torch.Size([16])
percent tensor([0.6494, 0.7189, 0.7357, 0.7768, 0.7531, 0.7082, 0.7117, 0.6967, 0.7398,
        0.7122, 0.7478, 0.7285, 0.6917, 0.8040, 0.6344, 0.6809],
       device='cuda:0') torch.Size([16])
percent tensor([0.5894, 0.7417, 0.6899, 0.7281, 0.5842, 0.7849, 0.6590, 0.4609, 0.6384,
        0.7185, 0.7436, 0.5536, 0.6877, 0.6421, 0.4851, 0.5613],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9998, 0.9998, 0.9999, 0.9996, 0.9998, 0.9995, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9997, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 210 | Batch_idx: 0 |  Loss: (0.0312) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 210 | Batch_idx: 10 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (1378/1408)
Epoch: 210 | Batch_idx: 20 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (97.00%) (2634/2688)
Epoch: 210 | Batch_idx: 30 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (97.00%) (3883/3968)
Epoch: 210 | Batch_idx: 40 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (97.00%) (5141/5248)
Epoch: 210 | Batch_idx: 50 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (97.00%) (6388/6528)
Epoch: 210 | Batch_idx: 60 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (7639/7808)
Epoch: 210 | Batch_idx: 70 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (97.00%) (8892/9088)
Epoch: 210 | Batch_idx: 80 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (97.00%) (10151/10368)
Epoch: 210 | Batch_idx: 90 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (97.00%) (11405/11648)
Epoch: 210 | Batch_idx: 100 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (12670/12928)
Epoch: 210 | Batch_idx: 110 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (13929/14208)
Epoch: 210 | Batch_idx: 120 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (97.00%) (15175/15488)
Epoch: 210 | Batch_idx: 130 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (97.00%) (16432/16768)
Epoch: 210 | Batch_idx: 140 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (97.00%) (17681/18048)
Epoch: 210 | Batch_idx: 150 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (18944/19328)
Epoch: 210 | Batch_idx: 160 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (20196/20608)
Epoch: 210 | Batch_idx: 170 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (21452/21888)
Epoch: 210 | Batch_idx: 180 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (22712/23168)
Epoch: 210 | Batch_idx: 190 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (23971/24448)
Epoch: 210 | Batch_idx: 200 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (25230/25728)
Epoch: 210 | Batch_idx: 210 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (26481/27008)
Epoch: 210 | Batch_idx: 220 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (27738/28288)
Epoch: 210 | Batch_idx: 230 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (28990/29568)
Epoch: 210 | Batch_idx: 240 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (30246/30848)
Epoch: 210 | Batch_idx: 250 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (31503/32128)
Epoch: 210 | Batch_idx: 260 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (32760/33408)
Epoch: 210 | Batch_idx: 270 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (34021/34688)
Epoch: 210 | Batch_idx: 280 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (35277/35968)
Epoch: 210 | Batch_idx: 290 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (36538/37248)
Epoch: 210 | Batch_idx: 300 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (37793/38528)
Epoch: 210 | Batch_idx: 310 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (39058/39808)
Epoch: 210 | Batch_idx: 320 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (40309/41088)
Epoch: 210 | Batch_idx: 330 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (41567/42368)
Epoch: 210 | Batch_idx: 340 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (42817/43648)
Epoch: 210 | Batch_idx: 350 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (44068/44928)
Epoch: 210 | Batch_idx: 360 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (45326/46208)
Epoch: 210 | Batch_idx: 370 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (46582/47488)
Epoch: 210 | Batch_idx: 380 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (47831/48768)
Epoch: 210 | Batch_idx: 390 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (49040/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_210.pth.tar'
# TEST : Loss: (0.4267) | Acc: (88.00%) (8891/10000)
percent tensor([0.5876, 0.6099, 0.6014, 0.5864, 0.6090, 0.5776, 0.6195, 0.6042, 0.6004,
        0.6030, 0.5960, 0.6113, 0.5933, 0.6059, 0.5974, 0.5867],
       device='cuda:0') torch.Size([16])
percent tensor([0.5489, 0.5438, 0.5384, 0.5266, 0.5366, 0.5166, 0.5512, 0.5450, 0.5430,
        0.5440, 0.5412, 0.5454, 0.5552, 0.5370, 0.5289, 0.5410],
       device='cuda:0') torch.Size([16])
percent tensor([0.6375, 0.6361, 0.6267, 0.6850, 0.7029, 0.6758, 0.6733, 0.7210, 0.6267,
        0.5766, 0.5656, 0.6365, 0.5842, 0.6715, 0.7050, 0.6331],
       device='cuda:0') torch.Size([16])
percent tensor([0.7608, 0.7131, 0.7240, 0.7264, 0.7320, 0.7557, 0.7461, 0.7332, 0.7151,
        0.7280, 0.7401, 0.6935, 0.7036, 0.7414, 0.7506, 0.7517],
       device='cuda:0') torch.Size([16])
percent tensor([0.5721, 0.6139, 0.6014, 0.6160, 0.6052, 0.6151, 0.6039, 0.5737, 0.6294,
        0.6035, 0.6038, 0.6290, 0.5723, 0.6569, 0.5642, 0.6020],
       device='cuda:0') torch.Size([16])
percent tensor([0.6418, 0.7029, 0.7425, 0.7707, 0.7497, 0.7212, 0.7071, 0.6958, 0.7439,
        0.6940, 0.7524, 0.7348, 0.6861, 0.8042, 0.6242, 0.6664],
       device='cuda:0') torch.Size([16])
percent tensor([0.5295, 0.6960, 0.7241, 0.7625, 0.6000, 0.7783, 0.6530, 0.5003, 0.6908,
        0.6840, 0.7197, 0.6068, 0.6641, 0.6590, 0.4464, 0.5387],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9995, 0.9998, 0.9997, 0.9998,
        1.0000, 1.0000, 0.9999, 0.9999, 0.9991, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(179.5436, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(825.3613, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(836.6177, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1523.4240, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(473.3656, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2300.9121, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4248.2715, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1349.4385, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6323.5493, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11512.7969, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3791.1362, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15936.7949, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 211 | Batch_idx: 0 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 211 | Batch_idx: 10 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (97.00%) (1374/1408)
Epoch: 211 | Batch_idx: 20 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (97.00%) (2632/2688)
Epoch: 211 | Batch_idx: 30 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (97.00%) (3887/3968)
Epoch: 211 | Batch_idx: 40 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (5152/5248)
Epoch: 211 | Batch_idx: 50 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (6409/6528)
Epoch: 211 | Batch_idx: 60 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (7664/7808)
Epoch: 211 | Batch_idx: 70 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (8927/9088)
Epoch: 211 | Batch_idx: 80 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (10187/10368)
Epoch: 211 | Batch_idx: 90 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (11450/11648)
Epoch: 211 | Batch_idx: 100 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (12713/12928)
Epoch: 211 | Batch_idx: 110 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (13970/14208)
Epoch: 211 | Batch_idx: 120 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (15219/15488)
Epoch: 211 | Batch_idx: 130 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (16478/16768)
Epoch: 211 | Batch_idx: 140 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (17733/18048)
Epoch: 211 | Batch_idx: 150 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (18984/19328)
Epoch: 211 | Batch_idx: 160 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (20240/20608)
Epoch: 211 | Batch_idx: 170 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (21493/21888)
Epoch: 211 | Batch_idx: 180 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (22748/23168)
Epoch: 211 | Batch_idx: 190 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (24002/24448)
Epoch: 211 | Batch_idx: 200 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (25260/25728)
Epoch: 211 | Batch_idx: 210 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (26518/27008)
Epoch: 211 | Batch_idx: 220 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (27773/28288)
Epoch: 211 | Batch_idx: 230 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (29025/29568)
Epoch: 211 | Batch_idx: 240 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (30272/30848)
Epoch: 211 | Batch_idx: 250 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (31528/32128)
Epoch: 211 | Batch_idx: 260 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (32777/33408)
Epoch: 211 | Batch_idx: 270 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (34027/34688)
Epoch: 211 | Batch_idx: 280 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (35286/35968)
Epoch: 211 | Batch_idx: 290 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (36535/37248)
Epoch: 211 | Batch_idx: 300 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (37798/38528)
Epoch: 211 | Batch_idx: 310 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (39053/39808)
Epoch: 211 | Batch_idx: 320 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (40301/41088)
Epoch: 211 | Batch_idx: 330 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (41562/42368)
Epoch: 211 | Batch_idx: 340 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (42827/43648)
Epoch: 211 | Batch_idx: 350 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (44082/44928)
Epoch: 211 | Batch_idx: 360 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (45335/46208)
Epoch: 211 | Batch_idx: 370 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (46590/47488)
Epoch: 211 | Batch_idx: 380 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (47845/48768)
Epoch: 211 | Batch_idx: 390 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (49054/50000)
# TEST : Loss: (0.4083) | Acc: (89.00%) (8922/10000)
percent tensor([0.5859, 0.6082, 0.5987, 0.5849, 0.6069, 0.5760, 0.6168, 0.6020, 0.5978,
        0.6011, 0.5941, 0.6085, 0.5913, 0.6030, 0.5957, 0.5852],
       device='cuda:0') torch.Size([16])
percent tensor([0.5494, 0.5454, 0.5405, 0.5277, 0.5377, 0.5159, 0.5525, 0.5468, 0.5445,
        0.5460, 0.5429, 0.5463, 0.5556, 0.5384, 0.5306, 0.5413],
       device='cuda:0') torch.Size([16])
percent tensor([0.6252, 0.6254, 0.6230, 0.6811, 0.7008, 0.6777, 0.6614, 0.7086, 0.6137,
        0.5642, 0.5488, 0.6318, 0.5614, 0.6605, 0.6997, 0.6169],
       device='cuda:0') torch.Size([16])
percent tensor([0.7601, 0.7101, 0.7261, 0.7292, 0.7345, 0.7632, 0.7417, 0.7314, 0.7154,
        0.7270, 0.7360, 0.6924, 0.7005, 0.7416, 0.7522, 0.7522],
       device='cuda:0') torch.Size([16])
percent tensor([0.5762, 0.6141, 0.5990, 0.6194, 0.6045, 0.6156, 0.6053, 0.5743, 0.6258,
        0.6067, 0.6112, 0.6323, 0.5779, 0.6601, 0.5674, 0.6053],
       device='cuda:0') torch.Size([16])
percent tensor([0.6388, 0.6990, 0.7383, 0.7713, 0.7563, 0.7156, 0.6991, 0.6898, 0.7525,
        0.7063, 0.7562, 0.7416, 0.6860, 0.7957, 0.6312, 0.6677],
       device='cuda:0') torch.Size([16])
percent tensor([0.5191, 0.6990, 0.7086, 0.7551, 0.5801, 0.7560, 0.6456, 0.4865, 0.6670,
        0.6532, 0.7073, 0.5827, 0.6624, 0.6112, 0.4397, 0.5516],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9993, 0.9998, 0.9997, 0.9999,
        0.9999, 1.0000, 1.0000, 0.9999, 0.9995, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 212 | Batch_idx: 0 |  Loss: (0.0250) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 212 | Batch_idx: 10 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (97.00%) (1376/1408)
Epoch: 212 | Batch_idx: 20 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (97.00%) (2628/2688)
Epoch: 212 | Batch_idx: 30 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (3889/3968)
Epoch: 212 | Batch_idx: 40 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (5152/5248)
Epoch: 212 | Batch_idx: 50 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (6399/6528)
Epoch: 212 | Batch_idx: 60 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (97.00%) (7645/7808)
Epoch: 212 | Batch_idx: 70 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (97.00%) (8901/9088)
Epoch: 212 | Batch_idx: 80 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (97.00%) (10158/10368)
Epoch: 212 | Batch_idx: 90 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (11422/11648)
Epoch: 212 | Batch_idx: 100 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (97.00%) (12668/12928)
Epoch: 212 | Batch_idx: 110 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (97.00%) (13923/14208)
Epoch: 212 | Batch_idx: 120 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (97.00%) (15178/15488)
Epoch: 212 | Batch_idx: 130 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (16433/16768)
Epoch: 212 | Batch_idx: 140 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (17697/18048)
Epoch: 212 | Batch_idx: 150 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (18946/19328)
Epoch: 212 | Batch_idx: 160 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (20198/20608)
Epoch: 212 | Batch_idx: 170 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (21458/21888)
Epoch: 212 | Batch_idx: 180 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (22718/23168)
Epoch: 212 | Batch_idx: 190 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (23977/24448)
Epoch: 212 | Batch_idx: 200 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (25231/25728)
Epoch: 212 | Batch_idx: 210 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (26471/27008)
Epoch: 212 | Batch_idx: 220 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (97.00%) (27722/28288)
Epoch: 212 | Batch_idx: 230 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (98.00%) (28981/29568)
Epoch: 212 | Batch_idx: 240 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (30242/30848)
Epoch: 212 | Batch_idx: 250 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (98.00%) (31498/32128)
Epoch: 212 | Batch_idx: 260 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (32765/33408)
Epoch: 212 | Batch_idx: 270 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (34018/34688)
Epoch: 212 | Batch_idx: 280 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (35270/35968)
Epoch: 212 | Batch_idx: 290 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (36531/37248)
Epoch: 212 | Batch_idx: 300 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (37790/38528)
Epoch: 212 | Batch_idx: 310 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (39042/39808)
Epoch: 212 | Batch_idx: 320 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (40298/41088)
Epoch: 212 | Batch_idx: 330 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (41548/42368)
Epoch: 212 | Batch_idx: 340 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (42809/43648)
Epoch: 212 | Batch_idx: 350 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (98.00%) (44062/44928)
Epoch: 212 | Batch_idx: 360 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (45322/46208)
Epoch: 212 | Batch_idx: 370 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (46581/47488)
Epoch: 212 | Batch_idx: 380 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (47834/48768)
Epoch: 212 | Batch_idx: 390 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (49036/50000)
# TEST : Loss: (0.4587) | Acc: (88.00%) (8816/10000)
percent tensor([0.5891, 0.6135, 0.6013, 0.5884, 0.6093, 0.5784, 0.6217, 0.6057, 0.6016,
        0.6052, 0.5985, 0.6124, 0.5953, 0.6091, 0.5998, 0.5890],
       device='cuda:0') torch.Size([16])
percent tensor([0.5497, 0.5451, 0.5428, 0.5289, 0.5409, 0.5179, 0.5541, 0.5464, 0.5447,
        0.5462, 0.5425, 0.5495, 0.5554, 0.5384, 0.5305, 0.5419],
       device='cuda:0') torch.Size([16])
percent tensor([0.6323, 0.6295, 0.6237, 0.6875, 0.6947, 0.6726, 0.6637, 0.7165, 0.6125,
        0.5663, 0.5553, 0.6265, 0.5707, 0.6649, 0.7002, 0.6287],
       device='cuda:0') torch.Size([16])
percent tensor([0.7592, 0.7093, 0.7252, 0.7234, 0.7273, 0.7565, 0.7424, 0.7326, 0.7130,
        0.7243, 0.7373, 0.6928, 0.6991, 0.7456, 0.7501, 0.7490],
       device='cuda:0') torch.Size([16])
percent tensor([0.5769, 0.6202, 0.6082, 0.6256, 0.6200, 0.6176, 0.6146, 0.5879, 0.6307,
        0.6142, 0.6128, 0.6368, 0.5854, 0.6586, 0.5698, 0.6101],
       device='cuda:0') torch.Size([16])
percent tensor([0.6359, 0.7037, 0.7430, 0.7667, 0.7542, 0.7157, 0.7065, 0.6879, 0.7407,
        0.7058, 0.7593, 0.7375, 0.6877, 0.7942, 0.6262, 0.6758],
       device='cuda:0') torch.Size([16])
percent tensor([0.5177, 0.6962, 0.7227, 0.7554, 0.5849, 0.7762, 0.6278, 0.5007, 0.6614,
        0.6641, 0.7447, 0.5914, 0.6531, 0.6424, 0.4745, 0.5364],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9991, 0.9997, 0.9997, 0.9999,
        1.0000, 1.0000, 1.0000, 0.9999, 0.9996, 0.9999, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 213 | Batch_idx: 0 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 213 | Batch_idx: 10 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 213 | Batch_idx: 20 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (2644/2688)
Epoch: 213 | Batch_idx: 30 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (3911/3968)
Epoch: 213 | Batch_idx: 40 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (5162/5248)
Epoch: 213 | Batch_idx: 50 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (6422/6528)
Epoch: 213 | Batch_idx: 60 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (7676/7808)
Epoch: 213 | Batch_idx: 70 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (8929/9088)
Epoch: 213 | Batch_idx: 80 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (10189/10368)
Epoch: 213 | Batch_idx: 90 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (11442/11648)
Epoch: 213 | Batch_idx: 100 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (12698/12928)
Epoch: 213 | Batch_idx: 110 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (13962/14208)
Epoch: 213 | Batch_idx: 120 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (15215/15488)
Epoch: 213 | Batch_idx: 130 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (16474/16768)
Epoch: 213 | Batch_idx: 140 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (17725/18048)
Epoch: 213 | Batch_idx: 150 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (18973/19328)
Epoch: 213 | Batch_idx: 160 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (20225/20608)
Epoch: 213 | Batch_idx: 170 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (21474/21888)
Epoch: 213 | Batch_idx: 180 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (22731/23168)
Epoch: 213 | Batch_idx: 190 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (23987/24448)
Epoch: 213 | Batch_idx: 200 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (25240/25728)
Epoch: 213 | Batch_idx: 210 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (26505/27008)
Epoch: 213 | Batch_idx: 220 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (27758/28288)
Epoch: 213 | Batch_idx: 230 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (29006/29568)
Epoch: 213 | Batch_idx: 240 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (30260/30848)
Epoch: 213 | Batch_idx: 250 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (31520/32128)
Epoch: 213 | Batch_idx: 260 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (32779/33408)
Epoch: 213 | Batch_idx: 270 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (34036/34688)
Epoch: 213 | Batch_idx: 280 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (35286/35968)
Epoch: 213 | Batch_idx: 290 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (36545/37248)
Epoch: 213 | Batch_idx: 300 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (37803/38528)
Epoch: 213 | Batch_idx: 310 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (39065/39808)
Epoch: 213 | Batch_idx: 320 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (40332/41088)
Epoch: 213 | Batch_idx: 330 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (41598/42368)
Epoch: 213 | Batch_idx: 340 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (42848/43648)
Epoch: 213 | Batch_idx: 350 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (44107/44928)
Epoch: 213 | Batch_idx: 360 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (45364/46208)
Epoch: 213 | Batch_idx: 370 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (46618/47488)
Epoch: 213 | Batch_idx: 380 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (47872/48768)
Epoch: 213 | Batch_idx: 390 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (49092/50000)
# TEST : Loss: (0.4209) | Acc: (88.00%) (8870/10000)
percent tensor([0.5881, 0.6125, 0.5999, 0.5873, 0.6086, 0.5778, 0.6205, 0.6046, 0.6011,
        0.6040, 0.5973, 0.6106, 0.5942, 0.6093, 0.5986, 0.5882],
       device='cuda:0') torch.Size([16])
percent tensor([0.5500, 0.5444, 0.5413, 0.5285, 0.5396, 0.5168, 0.5524, 0.5463, 0.5442,
        0.5461, 0.5422, 0.5469, 0.5563, 0.5362, 0.5300, 0.5419],
       device='cuda:0') torch.Size([16])
percent tensor([0.6307, 0.6345, 0.6163, 0.6818, 0.6904, 0.6776, 0.6615, 0.7105, 0.6130,
        0.5612, 0.5580, 0.6203, 0.5701, 0.6718, 0.7017, 0.6249],
       device='cuda:0') torch.Size([16])
percent tensor([0.7619, 0.7088, 0.7326, 0.7248, 0.7363, 0.7609, 0.7433, 0.7370, 0.7128,
        0.7266, 0.7365, 0.6963, 0.7011, 0.7386, 0.7515, 0.7508],
       device='cuda:0') torch.Size([16])
percent tensor([0.5857, 0.6226, 0.6057, 0.6305, 0.6125, 0.6236, 0.6147, 0.5849, 0.6398,
        0.6173, 0.6175, 0.6321, 0.5899, 0.6657, 0.5755, 0.6154],
       device='cuda:0') torch.Size([16])
percent tensor([0.6511, 0.7204, 0.7429, 0.7723, 0.7500, 0.7231, 0.7115, 0.6864, 0.7566,
        0.7154, 0.7561, 0.7343, 0.6979, 0.8016, 0.6418, 0.6801],
       device='cuda:0') torch.Size([16])
percent tensor([0.5343, 0.7085, 0.7158, 0.7429, 0.5854, 0.7672, 0.6306, 0.4792, 0.6747,
        0.6662, 0.7009, 0.5503, 0.6729, 0.6366, 0.4925, 0.5408],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 1.0000, 0.9994, 0.9999, 0.9998, 0.9998,
        0.9999, 1.0000, 1.0000, 1.0000, 0.9995, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 214 | Batch_idx: 0 |  Loss: (0.0326) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 214 | Batch_idx: 10 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (1386/1408)
Epoch: 214 | Batch_idx: 20 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (2647/2688)
Epoch: 214 | Batch_idx: 30 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (3909/3968)
Epoch: 214 | Batch_idx: 40 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (5175/5248)
Epoch: 214 | Batch_idx: 50 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (6436/6528)
Epoch: 214 | Batch_idx: 60 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (7700/7808)
Epoch: 214 | Batch_idx: 70 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (8966/9088)
Epoch: 214 | Batch_idx: 80 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (10226/10368)
Epoch: 214 | Batch_idx: 90 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (11479/11648)
Epoch: 214 | Batch_idx: 100 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (12743/12928)
Epoch: 214 | Batch_idx: 110 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (14001/14208)
Epoch: 214 | Batch_idx: 120 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (15257/15488)
Epoch: 214 | Batch_idx: 130 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (16518/16768)
Epoch: 214 | Batch_idx: 140 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (17786/18048)
Epoch: 214 | Batch_idx: 150 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (19043/19328)
Epoch: 214 | Batch_idx: 160 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (20301/20608)
Epoch: 214 | Batch_idx: 170 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (21565/21888)
Epoch: 214 | Batch_idx: 180 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (22824/23168)
Epoch: 214 | Batch_idx: 190 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (24082/24448)
Epoch: 214 | Batch_idx: 200 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (25344/25728)
Epoch: 214 | Batch_idx: 210 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (26599/27008)
Epoch: 214 | Batch_idx: 220 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (27858/28288)
Epoch: 214 | Batch_idx: 230 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (29121/29568)
Epoch: 214 | Batch_idx: 240 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (30378/30848)
Epoch: 214 | Batch_idx: 250 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (31636/32128)
Epoch: 214 | Batch_idx: 260 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (32896/33408)
Epoch: 214 | Batch_idx: 270 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (34152/34688)
Epoch: 214 | Batch_idx: 280 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (35403/35968)
Epoch: 214 | Batch_idx: 290 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (36660/37248)
Epoch: 214 | Batch_idx: 300 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (37906/38528)
Epoch: 214 | Batch_idx: 310 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (39172/39808)
Epoch: 214 | Batch_idx: 320 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (40429/41088)
Epoch: 214 | Batch_idx: 330 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (41680/42368)
Epoch: 214 | Batch_idx: 340 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (42937/43648)
Epoch: 214 | Batch_idx: 350 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (44187/44928)
Epoch: 214 | Batch_idx: 360 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (45441/46208)
Epoch: 214 | Batch_idx: 370 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (46702/47488)
Epoch: 214 | Batch_idx: 380 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (47956/48768)
Epoch: 214 | Batch_idx: 390 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (49158/50000)
# TEST : Loss: (0.4516) | Acc: (88.00%) (8864/10000)
percent tensor([0.5845, 0.6100, 0.5943, 0.5840, 0.6034, 0.5748, 0.6163, 0.6008, 0.5978,
        0.5997, 0.5943, 0.6045, 0.5908, 0.6076, 0.5953, 0.5850],
       device='cuda:0') torch.Size([16])
percent tensor([0.5477, 0.5428, 0.5386, 0.5261, 0.5369, 0.5151, 0.5502, 0.5449, 0.5414,
        0.5440, 0.5403, 0.5447, 0.5545, 0.5349, 0.5288, 0.5394],
       device='cuda:0') torch.Size([16])
percent tensor([0.6390, 0.6357, 0.6211, 0.6922, 0.6983, 0.6878, 0.6702, 0.7074, 0.6082,
        0.5685, 0.5589, 0.6262, 0.5689, 0.6806, 0.7084, 0.6398],
       device='cuda:0') torch.Size([16])
percent tensor([0.7646, 0.7149, 0.7324, 0.7306, 0.7390, 0.7662, 0.7499, 0.7386, 0.7195,
        0.7298, 0.7415, 0.6960, 0.7053, 0.7465, 0.7581, 0.7596],
       device='cuda:0') torch.Size([16])
percent tensor([0.5813, 0.6189, 0.6115, 0.6303, 0.6140, 0.6153, 0.6084, 0.5812, 0.6343,
        0.6138, 0.6098, 0.6413, 0.5932, 0.6536, 0.5683, 0.6098],
       device='cuda:0') torch.Size([16])
percent tensor([0.6569, 0.7232, 0.7470, 0.7754, 0.7616, 0.7268, 0.7136, 0.6947, 0.7578,
        0.7282, 0.7599, 0.7478, 0.7107, 0.8049, 0.6394, 0.6898],
       device='cuda:0') torch.Size([16])
percent tensor([0.5529, 0.7275, 0.6996, 0.7486, 0.5707, 0.7830, 0.6719, 0.4941, 0.6919,
        0.6999, 0.7313, 0.5896, 0.6900, 0.6906, 0.4754, 0.5631],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 0.9999, 1.0000, 0.9995, 0.9998, 0.9996, 0.9999,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9992, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 215 | Batch_idx: 0 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 215 | Batch_idx: 10 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 215 | Batch_idx: 20 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (97.00%) (2634/2688)
Epoch: 215 | Batch_idx: 30 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (3892/3968)
Epoch: 215 | Batch_idx: 40 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (5150/5248)
Epoch: 215 | Batch_idx: 50 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (6408/6528)
Epoch: 215 | Batch_idx: 60 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (7667/7808)
Epoch: 215 | Batch_idx: 70 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (8926/9088)
Epoch: 215 | Batch_idx: 80 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (10182/10368)
Epoch: 215 | Batch_idx: 90 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (11446/11648)
Epoch: 215 | Batch_idx: 100 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (12705/12928)
Epoch: 215 | Batch_idx: 110 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (13964/14208)
Epoch: 215 | Batch_idx: 120 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (15229/15488)
Epoch: 215 | Batch_idx: 130 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (16489/16768)
Epoch: 215 | Batch_idx: 140 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (17755/18048)
Epoch: 215 | Batch_idx: 150 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (19008/19328)
Epoch: 215 | Batch_idx: 160 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (20262/20608)
Epoch: 215 | Batch_idx: 170 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (21528/21888)
Epoch: 215 | Batch_idx: 180 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (22788/23168)
Epoch: 215 | Batch_idx: 190 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (24043/24448)
Epoch: 215 | Batch_idx: 200 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (25294/25728)
Epoch: 215 | Batch_idx: 210 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (26552/27008)
Epoch: 215 | Batch_idx: 220 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (27807/28288)
Epoch: 215 | Batch_idx: 230 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (29067/29568)
Epoch: 215 | Batch_idx: 240 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (30321/30848)
Epoch: 215 | Batch_idx: 250 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (31578/32128)
Epoch: 215 | Batch_idx: 260 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (32830/33408)
Epoch: 215 | Batch_idx: 270 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (34095/34688)
Epoch: 215 | Batch_idx: 280 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (35347/35968)
Epoch: 215 | Batch_idx: 290 |  Loss: (0.0513) |  Loss2: (0.0000) | Acc: (98.00%) (36604/37248)
Epoch: 215 | Batch_idx: 300 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (37864/38528)
Epoch: 215 | Batch_idx: 310 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (39130/39808)
Epoch: 215 | Batch_idx: 320 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (40394/41088)
Epoch: 215 | Batch_idx: 330 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (41655/42368)
Epoch: 215 | Batch_idx: 340 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (42911/43648)
Epoch: 215 | Batch_idx: 350 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (44175/44928)
Epoch: 215 | Batch_idx: 360 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (45430/46208)
Epoch: 215 | Batch_idx: 370 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (46690/47488)
Epoch: 215 | Batch_idx: 380 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (47953/48768)
Epoch: 215 | Batch_idx: 390 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (49161/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_215.pth.tar'
# TEST : Loss: (0.4280) | Acc: (89.00%) (8916/10000)
percent tensor([0.5891, 0.6118, 0.6034, 0.5891, 0.6111, 0.5793, 0.6205, 0.6060, 0.6018,
        0.6047, 0.5975, 0.6128, 0.5948, 0.6074, 0.5989, 0.5887],
       device='cuda:0') torch.Size([16])
percent tensor([0.5466, 0.5431, 0.5378, 0.5250, 0.5349, 0.5133, 0.5497, 0.5439, 0.5417,
        0.5433, 0.5399, 0.5439, 0.5528, 0.5357, 0.5277, 0.5382],
       device='cuda:0') torch.Size([16])
percent tensor([0.6269, 0.6270, 0.6192, 0.6857, 0.6949, 0.6803, 0.6590, 0.7100, 0.6092,
        0.5601, 0.5471, 0.6188, 0.5648, 0.6684, 0.6981, 0.6258],
       device='cuda:0') torch.Size([16])
percent tensor([0.7639, 0.7126, 0.7360, 0.7295, 0.7422, 0.7631, 0.7505, 0.7354, 0.7231,
        0.7298, 0.7425, 0.7001, 0.7077, 0.7430, 0.7516, 0.7559],
       device='cuda:0') torch.Size([16])
percent tensor([0.5931, 0.6298, 0.6102, 0.6350, 0.6127, 0.6215, 0.6166, 0.5886, 0.6390,
        0.6231, 0.6236, 0.6435, 0.5973, 0.6678, 0.5814, 0.6170],
       device='cuda:0') torch.Size([16])
percent tensor([0.6703, 0.7158, 0.7545, 0.7786, 0.7653, 0.7305, 0.7206, 0.6926, 0.7621,
        0.7191, 0.7615, 0.7462, 0.7177, 0.8060, 0.6427, 0.6910],
       device='cuda:0') torch.Size([16])
percent tensor([0.5903, 0.7305, 0.7092, 0.7653, 0.5995, 0.8001, 0.6589, 0.4676, 0.6988,
        0.7087, 0.7420, 0.5935, 0.7207, 0.6545, 0.4920, 0.5713],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 1.0000, 0.9995, 0.9999, 0.9996, 0.9999,
        0.9999, 1.0000, 1.0000, 1.0000, 0.9995, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 216 | Batch_idx: 0 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 216 | Batch_idx: 10 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 216 | Batch_idx: 20 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (2655/2688)
Epoch: 216 | Batch_idx: 30 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (3917/3968)
Epoch: 216 | Batch_idx: 40 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (5173/5248)
Epoch: 216 | Batch_idx: 50 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (6436/6528)
Epoch: 216 | Batch_idx: 60 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (7692/7808)
Epoch: 216 | Batch_idx: 70 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (8953/9088)
Epoch: 216 | Batch_idx: 80 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (10214/10368)
Epoch: 216 | Batch_idx: 90 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (11474/11648)
Epoch: 216 | Batch_idx: 100 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (12734/12928)
Epoch: 216 | Batch_idx: 110 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (13992/14208)
Epoch: 216 | Batch_idx: 120 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (15256/15488)
Epoch: 216 | Batch_idx: 130 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (16513/16768)
Epoch: 216 | Batch_idx: 140 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (17768/18048)
Epoch: 216 | Batch_idx: 150 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (19023/19328)
Epoch: 216 | Batch_idx: 160 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (20280/20608)
Epoch: 216 | Batch_idx: 170 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (21531/21888)
Epoch: 216 | Batch_idx: 180 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (22794/23168)
Epoch: 216 | Batch_idx: 190 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (24054/24448)
Epoch: 216 | Batch_idx: 200 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (25310/25728)
Epoch: 216 | Batch_idx: 210 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (26574/27008)
Epoch: 216 | Batch_idx: 220 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (27832/28288)
Epoch: 216 | Batch_idx: 230 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (29087/29568)
Epoch: 216 | Batch_idx: 240 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (30352/30848)
Epoch: 216 | Batch_idx: 250 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (31611/32128)
Epoch: 216 | Batch_idx: 260 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (32872/33408)
Epoch: 216 | Batch_idx: 270 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (34131/34688)
Epoch: 216 | Batch_idx: 280 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (35385/35968)
Epoch: 216 | Batch_idx: 290 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (36644/37248)
Epoch: 216 | Batch_idx: 300 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (37892/38528)
Epoch: 216 | Batch_idx: 310 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (39145/39808)
Epoch: 216 | Batch_idx: 320 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (40401/41088)
Epoch: 216 | Batch_idx: 330 |  Loss: (0.0513) |  Loss2: (0.0000) | Acc: (98.00%) (41657/42368)
Epoch: 216 | Batch_idx: 340 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (42913/43648)
Epoch: 216 | Batch_idx: 350 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (44171/44928)
Epoch: 216 | Batch_idx: 360 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (45423/46208)
Epoch: 216 | Batch_idx: 370 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (46679/47488)
Epoch: 216 | Batch_idx: 380 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (47936/48768)
Epoch: 216 | Batch_idx: 390 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (49148/50000)
# TEST : Loss: (0.4190) | Acc: (89.00%) (8944/10000)
percent tensor([0.5916, 0.6137, 0.6048, 0.5913, 0.6134, 0.5812, 0.6229, 0.6072, 0.6033,
        0.6065, 0.5994, 0.6148, 0.5970, 0.6089, 0.6010, 0.5906],
       device='cuda:0') torch.Size([16])
percent tensor([0.5493, 0.5442, 0.5408, 0.5289, 0.5384, 0.5161, 0.5518, 0.5454, 0.5437,
        0.5454, 0.5418, 0.5457, 0.5558, 0.5369, 0.5295, 0.5415],
       device='cuda:0') torch.Size([16])
percent tensor([0.6300, 0.6316, 0.6204, 0.6906, 0.6898, 0.6788, 0.6606, 0.7145, 0.6151,
        0.5632, 0.5513, 0.6207, 0.5635, 0.6772, 0.6982, 0.6302],
       device='cuda:0') torch.Size([16])
percent tensor([0.7664, 0.7141, 0.7344, 0.7323, 0.7385, 0.7672, 0.7507, 0.7342, 0.7207,
        0.7311, 0.7426, 0.6998, 0.7110, 0.7464, 0.7541, 0.7593],
       device='cuda:0') torch.Size([16])
percent tensor([0.5817, 0.6250, 0.6119, 0.6320, 0.6183, 0.6203, 0.6176, 0.5891, 0.6344,
        0.6182, 0.6187, 0.6432, 0.5865, 0.6634, 0.5776, 0.6144],
       device='cuda:0') torch.Size([16])
percent tensor([0.6600, 0.7309, 0.7561, 0.7799, 0.7664, 0.7357, 0.7240, 0.7000, 0.7617,
        0.7235, 0.7699, 0.7533, 0.7158, 0.8004, 0.6581, 0.6858],
       device='cuda:0') torch.Size([16])
percent tensor([0.5648, 0.7367, 0.7313, 0.7789, 0.5948, 0.7960, 0.6567, 0.4543, 0.7073,
        0.7006, 0.7458, 0.6187, 0.6951, 0.6392, 0.5037, 0.5260],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 0.9999, 0.9999, 0.9994, 0.9998, 0.9994, 0.9999,
        0.9999, 1.0000, 1.0000, 0.9999, 0.9995, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 217 | Batch_idx: 0 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 217 | Batch_idx: 10 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (1390/1408)
Epoch: 217 | Batch_idx: 20 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (2651/2688)
Epoch: 217 | Batch_idx: 30 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (3915/3968)
Epoch: 217 | Batch_idx: 40 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (5176/5248)
Epoch: 217 | Batch_idx: 50 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (6432/6528)
Epoch: 217 | Batch_idx: 60 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (7691/7808)
Epoch: 217 | Batch_idx: 70 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (8951/9088)
Epoch: 217 | Batch_idx: 80 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (10207/10368)
Epoch: 217 | Batch_idx: 90 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (11465/11648)
Epoch: 217 | Batch_idx: 100 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (12715/12928)
Epoch: 217 | Batch_idx: 110 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (13981/14208)
Epoch: 217 | Batch_idx: 120 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (15238/15488)
Epoch: 217 | Batch_idx: 130 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (16503/16768)
Epoch: 217 | Batch_idx: 140 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (17768/18048)
Epoch: 217 | Batch_idx: 150 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (19030/19328)
Epoch: 217 | Batch_idx: 160 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (20287/20608)
Epoch: 217 | Batch_idx: 170 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (21547/21888)
Epoch: 217 | Batch_idx: 180 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (22802/23168)
Epoch: 217 | Batch_idx: 190 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (24058/24448)
Epoch: 217 | Batch_idx: 200 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (25321/25728)
Epoch: 217 | Batch_idx: 210 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (26581/27008)
Epoch: 217 | Batch_idx: 220 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (27846/28288)
Epoch: 217 | Batch_idx: 230 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (29093/29568)
Epoch: 217 | Batch_idx: 240 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (30349/30848)
Epoch: 217 | Batch_idx: 250 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (31602/32128)
Epoch: 217 | Batch_idx: 260 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (32863/33408)
Epoch: 217 | Batch_idx: 270 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (34126/34688)
Epoch: 217 | Batch_idx: 280 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (35385/35968)
Epoch: 217 | Batch_idx: 290 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (36645/37248)
Epoch: 217 | Batch_idx: 300 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (37886/38528)
Epoch: 217 | Batch_idx: 310 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (39144/39808)
Epoch: 217 | Batch_idx: 320 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (40402/41088)
Epoch: 217 | Batch_idx: 330 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (41662/42368)
Epoch: 217 | Batch_idx: 340 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (42915/43648)
Epoch: 217 | Batch_idx: 350 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (44179/44928)
Epoch: 217 | Batch_idx: 360 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (45435/46208)
Epoch: 217 | Batch_idx: 370 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (46693/47488)
Epoch: 217 | Batch_idx: 380 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (47947/48768)
Epoch: 217 | Batch_idx: 390 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (49161/50000)
# TEST : Loss: (0.4247) | Acc: (89.00%) (8915/10000)
percent tensor([0.5878, 0.6114, 0.6003, 0.5877, 0.6086, 0.5783, 0.6193, 0.6040, 0.6003,
        0.6031, 0.5966, 0.6102, 0.5933, 0.6080, 0.5978, 0.5877],
       device='cuda:0') torch.Size([16])
percent tensor([0.5507, 0.5455, 0.5403, 0.5291, 0.5392, 0.5186, 0.5525, 0.5464, 0.5447,
        0.5452, 0.5418, 0.5463, 0.5555, 0.5373, 0.5310, 0.5424],
       device='cuda:0') torch.Size([16])
percent tensor([0.6260, 0.6214, 0.6107, 0.6832, 0.6815, 0.6698, 0.6540, 0.7116, 0.6086,
        0.5603, 0.5513, 0.6153, 0.5632, 0.6661, 0.6915, 0.6230],
       device='cuda:0') torch.Size([16])
percent tensor([0.7639, 0.7096, 0.7296, 0.7269, 0.7339, 0.7632, 0.7460, 0.7338, 0.7179,
        0.7299, 0.7393, 0.6956, 0.7049, 0.7422, 0.7515, 0.7551],
       device='cuda:0') torch.Size([16])
percent tensor([0.5871, 0.6292, 0.6155, 0.6336, 0.6167, 0.6277, 0.6183, 0.5853, 0.6365,
        0.6228, 0.6235, 0.6451, 0.5963, 0.6650, 0.5798, 0.6187],
       device='cuda:0') torch.Size([16])
percent tensor([0.6723, 0.7222, 0.7620, 0.7974, 0.7750, 0.7452, 0.7338, 0.7120, 0.7707,
        0.7350, 0.7795, 0.7577, 0.7159, 0.8144, 0.6517, 0.6959],
       device='cuda:0') torch.Size([16])
percent tensor([0.5928, 0.7263, 0.7570, 0.7832, 0.6376, 0.8088, 0.6773, 0.4799, 0.7057,
        0.7263, 0.7465, 0.6354, 0.7003, 0.6417, 0.5174, 0.5572],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9999, 0.9997, 0.9999,
        1.0000, 1.0000, 1.0000, 0.9999, 0.9994, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 218 | Batch_idx: 0 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 218 | Batch_idx: 10 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (1393/1408)
Epoch: 218 | Batch_idx: 20 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (2652/2688)
Epoch: 218 | Batch_idx: 30 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (3917/3968)
Epoch: 218 | Batch_idx: 40 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (5183/5248)
Epoch: 218 | Batch_idx: 50 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (6442/6528)
Epoch: 218 | Batch_idx: 60 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (7705/7808)
Epoch: 218 | Batch_idx: 70 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (8967/9088)
Epoch: 218 | Batch_idx: 80 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (10226/10368)
Epoch: 218 | Batch_idx: 90 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (11482/11648)
Epoch: 218 | Batch_idx: 100 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (12744/12928)
Epoch: 218 | Batch_idx: 110 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (13997/14208)
Epoch: 218 | Batch_idx: 120 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (15257/15488)
Epoch: 218 | Batch_idx: 130 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (16515/16768)
Epoch: 218 | Batch_idx: 140 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (17776/18048)
Epoch: 218 | Batch_idx: 150 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (19041/19328)
Epoch: 218 | Batch_idx: 160 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (20296/20608)
Epoch: 218 | Batch_idx: 170 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (21557/21888)
Epoch: 218 | Batch_idx: 180 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (22815/23168)
Epoch: 218 | Batch_idx: 190 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (24079/24448)
Epoch: 218 | Batch_idx: 200 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (25340/25728)
Epoch: 218 | Batch_idx: 210 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (26605/27008)
Epoch: 218 | Batch_idx: 220 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (27869/28288)
Epoch: 218 | Batch_idx: 230 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (29121/29568)
Epoch: 218 | Batch_idx: 240 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (30381/30848)
Epoch: 218 | Batch_idx: 250 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (31646/32128)
Epoch: 218 | Batch_idx: 260 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (32907/33408)
Epoch: 218 | Batch_idx: 270 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (34170/34688)
Epoch: 218 | Batch_idx: 280 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (35425/35968)
Epoch: 218 | Batch_idx: 290 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (36684/37248)
Epoch: 218 | Batch_idx: 300 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (37943/38528)
Epoch: 218 | Batch_idx: 310 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (39200/39808)
Epoch: 218 | Batch_idx: 320 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (40458/41088)
Epoch: 218 | Batch_idx: 330 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (41705/42368)
Epoch: 218 | Batch_idx: 340 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (42961/43648)
Epoch: 218 | Batch_idx: 350 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (44215/44928)
Epoch: 218 | Batch_idx: 360 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (45471/46208)
Epoch: 218 | Batch_idx: 370 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (46716/47488)
Epoch: 218 | Batch_idx: 380 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (47966/48768)
Epoch: 218 | Batch_idx: 390 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (49162/50000)
# TEST : Loss: (0.4330) | Acc: (89.00%) (8928/10000)
percent tensor([0.5899, 0.6138, 0.6020, 0.5887, 0.6109, 0.5800, 0.6221, 0.6058, 0.6027,
        0.6053, 0.5993, 0.6124, 0.5956, 0.6100, 0.6001, 0.5894],
       device='cuda:0') torch.Size([16])
percent tensor([0.5527, 0.5469, 0.5441, 0.5309, 0.5430, 0.5225, 0.5547, 0.5476, 0.5471,
        0.5479, 0.5453, 0.5500, 0.5584, 0.5374, 0.5334, 0.5448],
       device='cuda:0') torch.Size([16])
percent tensor([0.6328, 0.6257, 0.6126, 0.6820, 0.6813, 0.6754, 0.6566, 0.7041, 0.6118,
        0.5569, 0.5486, 0.6111, 0.5599, 0.6829, 0.6913, 0.6236],
       device='cuda:0') torch.Size([16])
percent tensor([0.7644, 0.7128, 0.7266, 0.7264, 0.7344, 0.7595, 0.7469, 0.7368, 0.7141,
        0.7298, 0.7435, 0.6939, 0.7025, 0.7453, 0.7545, 0.7559],
       device='cuda:0') torch.Size([16])
percent tensor([0.5865, 0.6295, 0.6179, 0.6395, 0.6241, 0.6350, 0.6201, 0.5952, 0.6407,
        0.6218, 0.6256, 0.6492, 0.5958, 0.6628, 0.5864, 0.6136],
       device='cuda:0') torch.Size([16])
percent tensor([0.6661, 0.7354, 0.7653, 0.7921, 0.7729, 0.7495, 0.7327, 0.6956, 0.7729,
        0.7350, 0.7840, 0.7605, 0.7152, 0.8171, 0.6588, 0.6840],
       device='cuda:0') torch.Size([16])
percent tensor([0.5613, 0.7405, 0.7528, 0.7745, 0.5989, 0.8042, 0.6508, 0.4429, 0.6961,
        0.7115, 0.7579, 0.6035, 0.6967, 0.6768, 0.4645, 0.5525],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 1.0000, 0.9996, 0.9998, 0.9996, 0.9999,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9995, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 219 | Batch_idx: 0 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 219 | Batch_idx: 10 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (97.00%) (1376/1408)
Epoch: 219 | Batch_idx: 20 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (2635/2688)
Epoch: 219 | Batch_idx: 30 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (3894/3968)
Epoch: 219 | Batch_idx: 40 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (5158/5248)
Epoch: 219 | Batch_idx: 50 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (6412/6528)
Epoch: 219 | Batch_idx: 60 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (7670/7808)
Epoch: 219 | Batch_idx: 70 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (8924/9088)
Epoch: 219 | Batch_idx: 80 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (10182/10368)
Epoch: 219 | Batch_idx: 90 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (11440/11648)
Epoch: 219 | Batch_idx: 100 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (12692/12928)
Epoch: 219 | Batch_idx: 110 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (13954/14208)
Epoch: 219 | Batch_idx: 120 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (15211/15488)
Epoch: 219 | Batch_idx: 130 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (16470/16768)
Epoch: 219 | Batch_idx: 140 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (17734/18048)
Epoch: 219 | Batch_idx: 150 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (18997/19328)
Epoch: 219 | Batch_idx: 160 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (20263/20608)
Epoch: 219 | Batch_idx: 170 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (21517/21888)
Epoch: 219 | Batch_idx: 180 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (22774/23168)
Epoch: 219 | Batch_idx: 190 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (24037/24448)
Epoch: 219 | Batch_idx: 200 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (25295/25728)
Epoch: 219 | Batch_idx: 210 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (26553/27008)
Epoch: 219 | Batch_idx: 220 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (27811/28288)
Epoch: 219 | Batch_idx: 230 |  Loss: (0.0524) |  Loss2: (0.0000) | Acc: (98.00%) (29071/29568)
Epoch: 219 | Batch_idx: 240 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (30328/30848)
Epoch: 219 | Batch_idx: 250 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (31582/32128)
Epoch: 219 | Batch_idx: 260 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (32838/33408)
Epoch: 219 | Batch_idx: 270 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (34095/34688)
Epoch: 219 | Batch_idx: 280 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (35354/35968)
Epoch: 219 | Batch_idx: 290 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (36610/37248)
Epoch: 219 | Batch_idx: 300 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (37863/38528)
Epoch: 219 | Batch_idx: 310 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (39115/39808)
Epoch: 219 | Batch_idx: 320 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (40367/41088)
Epoch: 219 | Batch_idx: 330 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (41634/42368)
Epoch: 219 | Batch_idx: 340 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (42891/43648)
Epoch: 219 | Batch_idx: 350 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (44156/44928)
Epoch: 219 | Batch_idx: 360 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (45414/46208)
Epoch: 219 | Batch_idx: 370 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (46664/47488)
Epoch: 219 | Batch_idx: 380 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (47925/48768)
Epoch: 219 | Batch_idx: 390 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (49141/50000)
# TEST : Loss: (0.4258) | Acc: (88.00%) (8894/10000)
percent tensor([0.5878, 0.6100, 0.6002, 0.5865, 0.6082, 0.5783, 0.6184, 0.6034, 0.6001,
        0.6021, 0.5966, 0.6095, 0.5932, 0.6054, 0.5973, 0.5865],
       device='cuda:0') torch.Size([16])
percent tensor([0.5497, 0.5457, 0.5414, 0.5280, 0.5395, 0.5152, 0.5536, 0.5463, 0.5449,
        0.5455, 0.5423, 0.5478, 0.5567, 0.5383, 0.5294, 0.5412],
       device='cuda:0') torch.Size([16])
percent tensor([0.6261, 0.6156, 0.6139, 0.6809, 0.6839, 0.6736, 0.6500, 0.7107, 0.6087,
        0.5572, 0.5503, 0.6143, 0.5628, 0.6576, 0.6902, 0.6222],
       device='cuda:0') torch.Size([16])
percent tensor([0.7651, 0.7089, 0.7263, 0.7242, 0.7324, 0.7629, 0.7462, 0.7314, 0.7192,
        0.7251, 0.7413, 0.6926, 0.7019, 0.7451, 0.7499, 0.7580],
       device='cuda:0') torch.Size([16])
percent tensor([0.5813, 0.6275, 0.6189, 0.6415, 0.6208, 0.6254, 0.6148, 0.5882, 0.6383,
        0.6195, 0.6177, 0.6480, 0.5899, 0.6667, 0.5739, 0.6118],
       device='cuda:0') torch.Size([16])
percent tensor([0.6620, 0.7273, 0.7617, 0.7850, 0.7715, 0.7274, 0.7297, 0.6993, 0.7614,
        0.7264, 0.7800, 0.7583, 0.7160, 0.8044, 0.6399, 0.6872],
       device='cuda:0') torch.Size([16])
percent tensor([0.5363, 0.7182, 0.7345, 0.7741, 0.6200, 0.7926, 0.6255, 0.4596, 0.6386,
        0.6955, 0.7453, 0.5867, 0.6882, 0.6046, 0.4430, 0.5426],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 1.0000, 0.9999, 1.0000, 0.9997, 0.9998, 0.9996, 0.9999,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9996, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 220 | Batch_idx: 0 |  Loss: (0.0210) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 220 | Batch_idx: 10 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 220 | Batch_idx: 20 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (2640/2688)
Epoch: 220 | Batch_idx: 30 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (3903/3968)
Epoch: 220 | Batch_idx: 40 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (5170/5248)
Epoch: 220 | Batch_idx: 50 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (6429/6528)
Epoch: 220 | Batch_idx: 60 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (7684/7808)
Epoch: 220 | Batch_idx: 70 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (8948/9088)
Epoch: 220 | Batch_idx: 80 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (10206/10368)
Epoch: 220 | Batch_idx: 90 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (11472/11648)
Epoch: 220 | Batch_idx: 100 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (12728/12928)
Epoch: 220 | Batch_idx: 110 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (13987/14208)
Epoch: 220 | Batch_idx: 120 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (15248/15488)
Epoch: 220 | Batch_idx: 130 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (16507/16768)
Epoch: 220 | Batch_idx: 140 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (17772/18048)
Epoch: 220 | Batch_idx: 150 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (19033/19328)
Epoch: 220 | Batch_idx: 160 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (20298/20608)
Epoch: 220 | Batch_idx: 170 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (21564/21888)
Epoch: 220 | Batch_idx: 180 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (22821/23168)
Epoch: 220 | Batch_idx: 190 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (24074/24448)
Epoch: 220 | Batch_idx: 200 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (25340/25728)
Epoch: 220 | Batch_idx: 210 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (26599/27008)
Epoch: 220 | Batch_idx: 220 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (27858/28288)
Epoch: 220 | Batch_idx: 230 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (29126/29568)
Epoch: 220 | Batch_idx: 240 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (30377/30848)
Epoch: 220 | Batch_idx: 250 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (31631/32128)
Epoch: 220 | Batch_idx: 260 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (32886/33408)
Epoch: 220 | Batch_idx: 270 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (34148/34688)
Epoch: 220 | Batch_idx: 280 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (35408/35968)
Epoch: 220 | Batch_idx: 290 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (36668/37248)
Epoch: 220 | Batch_idx: 300 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (37926/38528)
Epoch: 220 | Batch_idx: 310 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (39188/39808)
Epoch: 220 | Batch_idx: 320 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (40451/41088)
Epoch: 220 | Batch_idx: 330 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (41713/42368)
Epoch: 220 | Batch_idx: 340 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (42975/43648)
Epoch: 220 | Batch_idx: 350 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (44232/44928)
Epoch: 220 | Batch_idx: 360 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (45492/46208)
Epoch: 220 | Batch_idx: 370 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (46749/47488)
Epoch: 220 | Batch_idx: 380 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (48009/48768)
Epoch: 220 | Batch_idx: 390 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (49228/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_220.pth.tar'
# TEST : Loss: (0.4363) | Acc: (89.00%) (8904/10000)
percent tensor([0.5883, 0.6109, 0.6016, 0.5878, 0.6097, 0.5784, 0.6196, 0.6045, 0.6008,
        0.6034, 0.5970, 0.6111, 0.5941, 0.6063, 0.5979, 0.5875],
       device='cuda:0') torch.Size([16])
percent tensor([0.5510, 0.5485, 0.5376, 0.5271, 0.5377, 0.5192, 0.5542, 0.5446, 0.5467,
        0.5475, 0.5456, 0.5460, 0.5580, 0.5421, 0.5330, 0.5444],
       device='cuda:0') torch.Size([16])
percent tensor([0.6331, 0.6302, 0.6204, 0.6865, 0.6924, 0.6745, 0.6638, 0.7082, 0.6196,
        0.5607, 0.5598, 0.6243, 0.5727, 0.6735, 0.6964, 0.6257],
       device='cuda:0') torch.Size([16])
percent tensor([0.7594, 0.7129, 0.7276, 0.7279, 0.7360, 0.7590, 0.7478, 0.7352, 0.7125,
        0.7270, 0.7410, 0.6954, 0.7010, 0.7457, 0.7510, 0.7538],
       device='cuda:0') torch.Size([16])
percent tensor([0.5849, 0.6193, 0.6172, 0.6387, 0.6178, 0.6267, 0.6112, 0.5889, 0.6422,
        0.6154, 0.6158, 0.6413, 0.5878, 0.6627, 0.5720, 0.6119],
       device='cuda:0') torch.Size([16])
percent tensor([0.6652, 0.7333, 0.7560, 0.7818, 0.7717, 0.7369, 0.7349, 0.7066, 0.7727,
        0.7264, 0.7737, 0.7607, 0.7184, 0.8193, 0.6513, 0.6897],
       device='cuda:0') torch.Size([16])
percent tensor([0.5497, 0.7428, 0.6985, 0.7271, 0.5734, 0.7800, 0.6779, 0.4584, 0.7005,
        0.7055, 0.7684, 0.6260, 0.7136, 0.6890, 0.4743, 0.5243],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 1.0000, 0.9995, 0.9999, 0.9997, 0.9999,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9997, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(180.2250, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(827.6347, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(840.0979, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1524.4722, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(471.9272, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2312.0349, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4252.3184, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1344.7300, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6354.2065, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11485.2900, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3776.5757, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15872.1904, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 221 | Batch_idx: 0 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 221 | Batch_idx: 10 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (99.00%) (1395/1408)
Epoch: 221 | Batch_idx: 20 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (99.00%) (2662/2688)
Epoch: 221 | Batch_idx: 30 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (3922/3968)
Epoch: 221 | Batch_idx: 40 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (5177/5248)
Epoch: 221 | Batch_idx: 50 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (6434/6528)
Epoch: 221 | Batch_idx: 60 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (7701/7808)
Epoch: 221 | Batch_idx: 70 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (8961/9088)
Epoch: 221 | Batch_idx: 80 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (10220/10368)
Epoch: 221 | Batch_idx: 90 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (11481/11648)
Epoch: 221 | Batch_idx: 100 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (12737/12928)
Epoch: 221 | Batch_idx: 110 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (14000/14208)
Epoch: 221 | Batch_idx: 120 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (15261/15488)
Epoch: 221 | Batch_idx: 130 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (16524/16768)
Epoch: 221 | Batch_idx: 140 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (17784/18048)
Epoch: 221 | Batch_idx: 150 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (19041/19328)
Epoch: 221 | Batch_idx: 160 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (20294/20608)
Epoch: 221 | Batch_idx: 170 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (21560/21888)
Epoch: 221 | Batch_idx: 180 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (22819/23168)
Epoch: 221 | Batch_idx: 190 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (24077/24448)
Epoch: 221 | Batch_idx: 200 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (25343/25728)
Epoch: 221 | Batch_idx: 210 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (26598/27008)
Epoch: 221 | Batch_idx: 220 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (27862/28288)
Epoch: 221 | Batch_idx: 230 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (29124/29568)
Epoch: 221 | Batch_idx: 240 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (30384/30848)
Epoch: 221 | Batch_idx: 250 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (31646/32128)
Epoch: 221 | Batch_idx: 260 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (32915/33408)
Epoch: 221 | Batch_idx: 270 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (34173/34688)
Epoch: 221 | Batch_idx: 280 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (35438/35968)
Epoch: 221 | Batch_idx: 290 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (36697/37248)
Epoch: 221 | Batch_idx: 300 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (37953/38528)
Epoch: 221 | Batch_idx: 310 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (39205/39808)
Epoch: 221 | Batch_idx: 320 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (40467/41088)
Epoch: 221 | Batch_idx: 330 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (41721/42368)
Epoch: 221 | Batch_idx: 340 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (42978/43648)
Epoch: 221 | Batch_idx: 350 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (44239/44928)
Epoch: 221 | Batch_idx: 360 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (45503/46208)
Epoch: 221 | Batch_idx: 370 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (46755/47488)
Epoch: 221 | Batch_idx: 380 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (48016/48768)
Epoch: 221 | Batch_idx: 390 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (49221/50000)
# TEST : Loss: (0.4293) | Acc: (88.00%) (8897/10000)
percent tensor([0.5882, 0.6112, 0.6019, 0.5881, 0.6097, 0.5791, 0.6197, 0.6048, 0.6013,
        0.6033, 0.5974, 0.6115, 0.5940, 0.6067, 0.5984, 0.5877],
       device='cuda:0') torch.Size([16])
percent tensor([0.5534, 0.5476, 0.5453, 0.5308, 0.5444, 0.5204, 0.5563, 0.5486, 0.5480,
        0.5494, 0.5462, 0.5531, 0.5599, 0.5390, 0.5329, 0.5442],
       device='cuda:0') torch.Size([16])
percent tensor([0.6230, 0.6336, 0.6172, 0.6947, 0.6859, 0.6662, 0.6577, 0.7169, 0.6092,
        0.5636, 0.5500, 0.6213, 0.5692, 0.6704, 0.6974, 0.6302],
       device='cuda:0') torch.Size([16])
percent tensor([0.7644, 0.7070, 0.7357, 0.7295, 0.7396, 0.7667, 0.7451, 0.7350, 0.7187,
        0.7247, 0.7389, 0.6993, 0.7041, 0.7377, 0.7512, 0.7580],
       device='cuda:0') torch.Size([16])
percent tensor([0.5777, 0.6205, 0.6116, 0.6231, 0.6153, 0.6182, 0.6132, 0.5879, 0.6328,
        0.6121, 0.6078, 0.6352, 0.5768, 0.6676, 0.5681, 0.6093],
       device='cuda:0') torch.Size([16])
percent tensor([0.6568, 0.7294, 0.7634, 0.7885, 0.7660, 0.7392, 0.7307, 0.7011, 0.7556,
        0.7207, 0.7751, 0.7585, 0.7096, 0.8068, 0.6442, 0.6869],
       device='cuda:0') torch.Size([16])
percent tensor([0.5250, 0.6998, 0.7327, 0.7699, 0.5746, 0.8130, 0.6254, 0.4557, 0.6100,
        0.6891, 0.7299, 0.5661, 0.6577, 0.6129, 0.4311, 0.5408],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9998, 0.9994, 0.9998,
        1.0000, 1.0000, 1.0000, 0.9999, 0.9995, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 222 | Batch_idx: 0 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 222 | Batch_idx: 10 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (1385/1408)
Epoch: 222 | Batch_idx: 20 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (2647/2688)
Epoch: 222 | Batch_idx: 30 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (3907/3968)
Epoch: 222 | Batch_idx: 40 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (5173/5248)
Epoch: 222 | Batch_idx: 50 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (6430/6528)
Epoch: 222 | Batch_idx: 60 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (7693/7808)
Epoch: 222 | Batch_idx: 70 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (8959/9088)
Epoch: 222 | Batch_idx: 80 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (10214/10368)
Epoch: 222 | Batch_idx: 90 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (11478/11648)
Epoch: 222 | Batch_idx: 100 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (12737/12928)
Epoch: 222 | Batch_idx: 110 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (14004/14208)
Epoch: 222 | Batch_idx: 120 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (15268/15488)
Epoch: 222 | Batch_idx: 130 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (16529/16768)
Epoch: 222 | Batch_idx: 140 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (17789/18048)
Epoch: 222 | Batch_idx: 150 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (19056/19328)
Epoch: 222 | Batch_idx: 160 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (20320/20608)
Epoch: 222 | Batch_idx: 170 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (21579/21888)
Epoch: 222 | Batch_idx: 180 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (22842/23168)
Epoch: 222 | Batch_idx: 190 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (24099/24448)
Epoch: 222 | Batch_idx: 200 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (25365/25728)
Epoch: 222 | Batch_idx: 210 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (26632/27008)
Epoch: 222 | Batch_idx: 220 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (27899/28288)
Epoch: 222 | Batch_idx: 230 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (29164/29568)
Epoch: 222 | Batch_idx: 240 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (30430/30848)
Epoch: 222 | Batch_idx: 250 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (31698/32128)
Epoch: 222 | Batch_idx: 260 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (32961/33408)
Epoch: 222 | Batch_idx: 270 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (34222/34688)
Epoch: 222 | Batch_idx: 280 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (35485/35968)
Epoch: 222 | Batch_idx: 290 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (36741/37248)
Epoch: 222 | Batch_idx: 300 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (38002/38528)
Epoch: 222 | Batch_idx: 310 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (39262/39808)
Epoch: 222 | Batch_idx: 320 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (40523/41088)
Epoch: 222 | Batch_idx: 330 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (41781/42368)
Epoch: 222 | Batch_idx: 340 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (43041/43648)
Epoch: 222 | Batch_idx: 350 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (44311/44928)
Epoch: 222 | Batch_idx: 360 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (45569/46208)
Epoch: 222 | Batch_idx: 370 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (46831/47488)
Epoch: 222 | Batch_idx: 380 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (48098/48768)
Epoch: 222 | Batch_idx: 390 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (49318/50000)
# TEST : Loss: (0.4226) | Acc: (89.00%) (8933/10000)
percent tensor([0.5884, 0.6116, 0.6003, 0.5882, 0.6088, 0.5801, 0.6201, 0.6041, 0.6005,
        0.6033, 0.5974, 0.6106, 0.5943, 0.6077, 0.5991, 0.5881],
       device='cuda:0') torch.Size([16])
percent tensor([0.5543, 0.5499, 0.5441, 0.5323, 0.5430, 0.5213, 0.5580, 0.5493, 0.5489,
        0.5497, 0.5473, 0.5506, 0.5613, 0.5417, 0.5349, 0.5460],
       device='cuda:0') torch.Size([16])
percent tensor([0.6230, 0.6248, 0.6188, 0.6823, 0.6924, 0.6709, 0.6522, 0.7121, 0.6061,
        0.5518, 0.5439, 0.6181, 0.5617, 0.6618, 0.6925, 0.6226],
       device='cuda:0') torch.Size([16])
percent tensor([0.7686, 0.7110, 0.7380, 0.7362, 0.7446, 0.7685, 0.7493, 0.7385, 0.7207,
        0.7314, 0.7458, 0.7013, 0.7076, 0.7418, 0.7548, 0.7594],
       device='cuda:0') torch.Size([16])
percent tensor([0.5852, 0.6273, 0.6121, 0.6285, 0.6195, 0.6323, 0.6179, 0.5933, 0.6416,
        0.6192, 0.6197, 0.6392, 0.5853, 0.6755, 0.5780, 0.6191],
       device='cuda:0') torch.Size([16])
percent tensor([0.6599, 0.7300, 0.7626, 0.7777, 0.7680, 0.7497, 0.7316, 0.6992, 0.7751,
        0.7260, 0.7818, 0.7593, 0.7152, 0.8128, 0.6543, 0.6976],
       device='cuda:0') torch.Size([16])
percent tensor([0.5240, 0.7405, 0.7460, 0.7704, 0.5841, 0.8171, 0.6330, 0.4559, 0.6964,
        0.7160, 0.7768, 0.6181, 0.7012, 0.6439, 0.4689, 0.5536],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9999, 0.9994, 0.9998,
        0.9999, 1.0000, 1.0000, 1.0000, 0.9995, 0.9999, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 223 | Batch_idx: 0 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 223 | Batch_idx: 10 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (1388/1408)
Epoch: 223 | Batch_idx: 20 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (2644/2688)
Epoch: 223 | Batch_idx: 30 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (3904/3968)
Epoch: 223 | Batch_idx: 40 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (5165/5248)
Epoch: 223 | Batch_idx: 50 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (6428/6528)
Epoch: 223 | Batch_idx: 60 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (7690/7808)
Epoch: 223 | Batch_idx: 70 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (8953/9088)
Epoch: 223 | Batch_idx: 80 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (10208/10368)
Epoch: 223 | Batch_idx: 90 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (11469/11648)
Epoch: 223 | Batch_idx: 100 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (12741/12928)
Epoch: 223 | Batch_idx: 110 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (14005/14208)
Epoch: 223 | Batch_idx: 120 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (15265/15488)
Epoch: 223 | Batch_idx: 130 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (16524/16768)
Epoch: 223 | Batch_idx: 140 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (17783/18048)
Epoch: 223 | Batch_idx: 150 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (19046/19328)
Epoch: 223 | Batch_idx: 160 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (20305/20608)
Epoch: 223 | Batch_idx: 170 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (21567/21888)
Epoch: 223 | Batch_idx: 180 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (22832/23168)
Epoch: 223 | Batch_idx: 190 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (24089/24448)
Epoch: 223 | Batch_idx: 200 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (25348/25728)
Epoch: 223 | Batch_idx: 210 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (26601/27008)
Epoch: 223 | Batch_idx: 220 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (27860/28288)
Epoch: 223 | Batch_idx: 230 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (29119/29568)
Epoch: 223 | Batch_idx: 240 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (30375/30848)
Epoch: 223 | Batch_idx: 250 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (31632/32128)
Epoch: 223 | Batch_idx: 260 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (32888/33408)
Epoch: 223 | Batch_idx: 270 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (34144/34688)
Epoch: 223 | Batch_idx: 280 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (35411/35968)
Epoch: 223 | Batch_idx: 290 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (36664/37248)
Epoch: 223 | Batch_idx: 300 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (37923/38528)
Epoch: 223 | Batch_idx: 310 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (39185/39808)
Epoch: 223 | Batch_idx: 320 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (40447/41088)
Epoch: 223 | Batch_idx: 330 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (41703/42368)
Epoch: 223 | Batch_idx: 340 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (42968/43648)
Epoch: 223 | Batch_idx: 350 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (44229/44928)
Epoch: 223 | Batch_idx: 360 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (45485/46208)
Epoch: 223 | Batch_idx: 370 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (46747/47488)
Epoch: 223 | Batch_idx: 380 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (48004/48768)
Epoch: 223 | Batch_idx: 390 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (49211/50000)
# TEST : Loss: (0.4355) | Acc: (89.00%) (8931/10000)
percent tensor([0.5893, 0.6135, 0.6037, 0.5899, 0.6117, 0.5799, 0.6220, 0.6066, 0.6025,
        0.6053, 0.5987, 0.6133, 0.5955, 0.6087, 0.6004, 0.5892],
       device='cuda:0') torch.Size([16])
percent tensor([0.5535, 0.5488, 0.5470, 0.5328, 0.5448, 0.5197, 0.5574, 0.5506, 0.5480,
        0.5499, 0.5455, 0.5532, 0.5594, 0.5400, 0.5340, 0.5450],
       device='cuda:0') torch.Size([16])
percent tensor([0.6357, 0.6296, 0.6248, 0.6820, 0.6936, 0.6781, 0.6629, 0.7175, 0.6143,
        0.5638, 0.5524, 0.6253, 0.5726, 0.6659, 0.7005, 0.6278],
       device='cuda:0') torch.Size([16])
percent tensor([0.7662, 0.7125, 0.7301, 0.7315, 0.7409, 0.7644, 0.7493, 0.7362, 0.7199,
        0.7303, 0.7444, 0.6976, 0.7049, 0.7458, 0.7550, 0.7585],
       device='cuda:0') torch.Size([16])
percent tensor([0.5812, 0.6225, 0.6181, 0.6336, 0.6175, 0.6231, 0.6112, 0.5932, 0.6373,
        0.6140, 0.6139, 0.6394, 0.5855, 0.6677, 0.5739, 0.6124],
       device='cuda:0') torch.Size([16])
percent tensor([0.6619, 0.7328, 0.7635, 0.7799, 0.7769, 0.7442, 0.7338, 0.7166, 0.7713,
        0.7260, 0.7793, 0.7561, 0.7097, 0.8135, 0.6525, 0.6984],
       device='cuda:0') torch.Size([16])
percent tensor([0.5436, 0.7416, 0.7267, 0.7657, 0.6171, 0.8054, 0.6161, 0.4565, 0.6625,
        0.7103, 0.7555, 0.5911, 0.6785, 0.6161, 0.4675, 0.5668],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9998, 0.9995, 0.9999,
        1.0000, 1.0000, 1.0000, 0.9999, 0.9993, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 224 | Batch_idx: 0 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 224 | Batch_idx: 10 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (1388/1408)
Epoch: 224 | Batch_idx: 20 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (2655/2688)
Epoch: 224 | Batch_idx: 30 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (3917/3968)
Epoch: 224 | Batch_idx: 40 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (5187/5248)
Epoch: 224 | Batch_idx: 50 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (6448/6528)
Epoch: 224 | Batch_idx: 60 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (7712/7808)
Epoch: 224 | Batch_idx: 70 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (8975/9088)
Epoch: 224 | Batch_idx: 80 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (10235/10368)
Epoch: 224 | Batch_idx: 90 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (11501/11648)
Epoch: 224 | Batch_idx: 100 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (12768/12928)
Epoch: 224 | Batch_idx: 110 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (14039/14208)
Epoch: 224 | Batch_idx: 120 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (15300/15488)
Epoch: 224 | Batch_idx: 130 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (16563/16768)
Epoch: 224 | Batch_idx: 140 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (17829/18048)
Epoch: 224 | Batch_idx: 150 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (19092/19328)
Epoch: 224 | Batch_idx: 160 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (20354/20608)
Epoch: 224 | Batch_idx: 170 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (21622/21888)
Epoch: 224 | Batch_idx: 180 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (22887/23168)
Epoch: 224 | Batch_idx: 190 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (24151/24448)
Epoch: 224 | Batch_idx: 200 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (25408/25728)
Epoch: 224 | Batch_idx: 210 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (26668/27008)
Epoch: 224 | Batch_idx: 220 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (27928/28288)
Epoch: 224 | Batch_idx: 230 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (29191/29568)
Epoch: 224 | Batch_idx: 240 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (30456/30848)
Epoch: 224 | Batch_idx: 250 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (31724/32128)
Epoch: 224 | Batch_idx: 260 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (32983/33408)
Epoch: 224 | Batch_idx: 270 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (34245/34688)
Epoch: 224 | Batch_idx: 280 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (35509/35968)
Epoch: 224 | Batch_idx: 290 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (36769/37248)
Epoch: 224 | Batch_idx: 300 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (38030/38528)
Epoch: 224 | Batch_idx: 310 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (39290/39808)
Epoch: 224 | Batch_idx: 320 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (40553/41088)
Epoch: 224 | Batch_idx: 330 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (41815/42368)
Epoch: 224 | Batch_idx: 340 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (43078/43648)
Epoch: 224 | Batch_idx: 350 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (44332/44928)
Epoch: 224 | Batch_idx: 360 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (45600/46208)
Epoch: 224 | Batch_idx: 370 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (46857/47488)
Epoch: 224 | Batch_idx: 380 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (48118/48768)
Epoch: 224 | Batch_idx: 390 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (49321/50000)
# TEST : Loss: (0.4564) | Acc: (88.00%) (8859/10000)
percent tensor([0.5906, 0.6137, 0.6050, 0.5907, 0.6131, 0.5808, 0.6229, 0.6077, 0.6027,
        0.6065, 0.5992, 0.6146, 0.5966, 0.6084, 0.6008, 0.5900],
       device='cuda:0') torch.Size([16])
percent tensor([0.5532, 0.5509, 0.5460, 0.5342, 0.5435, 0.5210, 0.5579, 0.5515, 0.5473,
        0.5504, 0.5458, 0.5527, 0.5599, 0.5429, 0.5357, 0.5462],
       device='cuda:0') torch.Size([16])
percent tensor([0.6244, 0.6307, 0.6233, 0.6818, 0.6992, 0.6739, 0.6602, 0.7167, 0.6141,
        0.5636, 0.5521, 0.6217, 0.5662, 0.6732, 0.6991, 0.6242],
       device='cuda:0') torch.Size([16])
percent tensor([0.7705, 0.7110, 0.7395, 0.7358, 0.7468, 0.7686, 0.7511, 0.7401, 0.7206,
        0.7331, 0.7423, 0.7033, 0.7090, 0.7421, 0.7548, 0.7605],
       device='cuda:0') torch.Size([16])
percent tensor([0.5883, 0.6326, 0.6126, 0.6337, 0.6202, 0.6353, 0.6222, 0.5870, 0.6435,
        0.6243, 0.6232, 0.6412, 0.5889, 0.6775, 0.5841, 0.6200],
       device='cuda:0') torch.Size([16])
percent tensor([0.6552, 0.7379, 0.7540, 0.7768, 0.7609, 0.7335, 0.7232, 0.7073, 0.7683,
        0.7288, 0.7795, 0.7521, 0.7203, 0.8108, 0.6475, 0.6733],
       device='cuda:0') torch.Size([16])
percent tensor([0.5228, 0.7521, 0.7299, 0.7557, 0.5656, 0.7757, 0.6004, 0.4598, 0.6628,
        0.6974, 0.7707, 0.6162, 0.7077, 0.6425, 0.4736, 0.4959],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 1.0000, 0.9999, 0.9999, 0.9999, 0.9995, 0.9999, 0.9994, 0.9998,
        1.0000, 1.0000, 1.0000, 0.9999, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 225 | Batch_idx: 0 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 225 | Batch_idx: 10 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (1381/1408)
Epoch: 225 | Batch_idx: 20 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (2646/2688)
Epoch: 225 | Batch_idx: 30 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (3908/3968)
Epoch: 225 | Batch_idx: 40 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (5169/5248)
Epoch: 225 | Batch_idx: 50 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (6423/6528)
Epoch: 225 | Batch_idx: 60 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (7681/7808)
Epoch: 225 | Batch_idx: 70 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (8937/9088)
Epoch: 225 | Batch_idx: 80 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (10202/10368)
Epoch: 225 | Batch_idx: 90 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (11465/11648)
Epoch: 225 | Batch_idx: 100 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (12730/12928)
Epoch: 225 | Batch_idx: 110 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (13998/14208)
Epoch: 225 | Batch_idx: 120 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (15268/15488)
Epoch: 225 | Batch_idx: 130 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (16534/16768)
Epoch: 225 | Batch_idx: 140 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (17789/18048)
Epoch: 225 | Batch_idx: 150 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (19052/19328)
Epoch: 225 | Batch_idx: 160 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (20306/20608)
Epoch: 225 | Batch_idx: 170 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (21566/21888)
Epoch: 225 | Batch_idx: 180 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (22827/23168)
Epoch: 225 | Batch_idx: 190 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (24088/24448)
Epoch: 225 | Batch_idx: 200 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (25359/25728)
Epoch: 225 | Batch_idx: 210 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (26611/27008)
Epoch: 225 | Batch_idx: 220 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (27871/28288)
Epoch: 225 | Batch_idx: 230 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (29137/29568)
Epoch: 225 | Batch_idx: 240 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (30396/30848)
Epoch: 225 | Batch_idx: 250 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (31657/32128)
Epoch: 225 | Batch_idx: 260 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (32915/33408)
Epoch: 225 | Batch_idx: 270 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (34174/34688)
Epoch: 225 | Batch_idx: 280 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (35433/35968)
Epoch: 225 | Batch_idx: 290 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (36697/37248)
Epoch: 225 | Batch_idx: 300 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (37959/38528)
Epoch: 225 | Batch_idx: 310 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (39220/39808)
Epoch: 225 | Batch_idx: 320 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (40474/41088)
Epoch: 225 | Batch_idx: 330 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (41730/42368)
Epoch: 225 | Batch_idx: 340 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (42991/43648)
Epoch: 225 | Batch_idx: 350 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (44251/44928)
Epoch: 225 | Batch_idx: 360 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (45512/46208)
Epoch: 225 | Batch_idx: 370 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (46766/47488)
Epoch: 225 | Batch_idx: 380 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (48023/48768)
Epoch: 225 | Batch_idx: 390 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (49231/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_225.pth.tar'
# TEST : Loss: (0.4260) | Acc: (89.00%) (8919/10000)
percent tensor([0.5897, 0.6139, 0.6036, 0.5899, 0.6116, 0.5799, 0.6222, 0.6073, 0.6027,
        0.6057, 0.5987, 0.6130, 0.5957, 0.6091, 0.6001, 0.5897],
       device='cuda:0') torch.Size([16])
percent tensor([0.5536, 0.5507, 0.5417, 0.5333, 0.5404, 0.5211, 0.5573, 0.5492, 0.5482,
        0.5496, 0.5468, 0.5486, 0.5605, 0.5459, 0.5357, 0.5471],
       device='cuda:0') torch.Size([16])
percent tensor([0.6341, 0.6348, 0.6159, 0.6846, 0.6983, 0.6877, 0.6702, 0.7150, 0.6197,
        0.5626, 0.5631, 0.6220, 0.5708, 0.6797, 0.7070, 0.6302],
       device='cuda:0') torch.Size([16])
percent tensor([0.7697, 0.7181, 0.7374, 0.7349, 0.7459, 0.7702, 0.7552, 0.7427, 0.7263,
        0.7367, 0.7477, 0.7059, 0.7096, 0.7522, 0.7596, 0.7642],
       device='cuda:0') torch.Size([16])
percent tensor([0.5922, 0.6335, 0.6225, 0.6334, 0.6252, 0.6380, 0.6207, 0.5954, 0.6451,
        0.6263, 0.6201, 0.6438, 0.5924, 0.6758, 0.5829, 0.6199],
       device='cuda:0') torch.Size([16])
percent tensor([0.6725, 0.7360, 0.7537, 0.7880, 0.7722, 0.7345, 0.7312, 0.7041, 0.7706,
        0.7348, 0.7761, 0.7571, 0.7213, 0.8212, 0.6615, 0.6961],
       device='cuda:0') torch.Size([16])
percent tensor([0.5442, 0.7285, 0.7045, 0.7591, 0.5878, 0.7770, 0.6141, 0.4437, 0.6433,
        0.7042, 0.7509, 0.6245, 0.6836, 0.6480, 0.4667, 0.5550],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9998, 0.9994, 0.9999,
        1.0000, 1.0000, 1.0000, 0.9999, 0.9994, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 226 | Batch_idx: 0 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 226 | Batch_idx: 10 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 226 | Batch_idx: 20 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (2646/2688)
Epoch: 226 | Batch_idx: 30 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (3912/3968)
Epoch: 226 | Batch_idx: 40 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (5174/5248)
Epoch: 226 | Batch_idx: 50 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (6440/6528)
Epoch: 226 | Batch_idx: 60 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (7698/7808)
Epoch: 226 | Batch_idx: 70 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (8964/9088)
Epoch: 226 | Batch_idx: 80 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (10232/10368)
Epoch: 226 | Batch_idx: 90 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (11500/11648)
Epoch: 226 | Batch_idx: 100 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (12767/12928)
Epoch: 226 | Batch_idx: 110 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (14029/14208)
Epoch: 226 | Batch_idx: 120 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (15292/15488)
Epoch: 226 | Batch_idx: 130 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (16551/16768)
Epoch: 226 | Batch_idx: 140 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (17810/18048)
Epoch: 226 | Batch_idx: 150 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (19074/19328)
Epoch: 226 | Batch_idx: 160 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (20332/20608)
Epoch: 226 | Batch_idx: 170 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (21592/21888)
Epoch: 226 | Batch_idx: 180 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (22845/23168)
Epoch: 226 | Batch_idx: 190 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (24112/24448)
Epoch: 226 | Batch_idx: 200 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (25379/25728)
Epoch: 226 | Batch_idx: 210 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (26642/27008)
Epoch: 226 | Batch_idx: 220 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (27910/28288)
Epoch: 226 | Batch_idx: 230 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (29174/29568)
Epoch: 226 | Batch_idx: 240 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (30442/30848)
Epoch: 226 | Batch_idx: 250 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (31699/32128)
Epoch: 226 | Batch_idx: 260 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (32964/33408)
Epoch: 226 | Batch_idx: 270 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (34225/34688)
Epoch: 226 | Batch_idx: 280 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (35489/35968)
Epoch: 226 | Batch_idx: 290 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (36745/37248)
Epoch: 226 | Batch_idx: 300 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (38005/38528)
Epoch: 226 | Batch_idx: 310 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (39272/39808)
Epoch: 226 | Batch_idx: 320 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (40524/41088)
Epoch: 226 | Batch_idx: 330 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (41786/42368)
Epoch: 226 | Batch_idx: 340 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (43035/43648)
Epoch: 226 | Batch_idx: 350 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (44295/44928)
Epoch: 226 | Batch_idx: 360 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (45551/46208)
Epoch: 226 | Batch_idx: 370 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (46814/47488)
Epoch: 226 | Batch_idx: 380 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (48076/48768)
Epoch: 226 | Batch_idx: 390 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (49289/50000)
# TEST : Loss: (0.4322) | Acc: (89.00%) (8951/10000)
percent tensor([0.5891, 0.6118, 0.6015, 0.5879, 0.6098, 0.5793, 0.6205, 0.6048, 0.6012,
        0.6039, 0.5977, 0.6115, 0.5950, 0.6072, 0.5988, 0.5882],
       device='cuda:0') torch.Size([16])
percent tensor([0.5537, 0.5498, 0.5444, 0.5325, 0.5429, 0.5216, 0.5569, 0.5498, 0.5482,
        0.5493, 0.5469, 0.5500, 0.5609, 0.5414, 0.5352, 0.5460],
       device='cuda:0') torch.Size([16])
percent tensor([0.6270, 0.6229, 0.6188, 0.6836, 0.6913, 0.6719, 0.6565, 0.7126, 0.6034,
        0.5515, 0.5395, 0.6109, 0.5570, 0.6633, 0.6959, 0.6269],
       device='cuda:0') torch.Size([16])
percent tensor([0.7718, 0.7161, 0.7345, 0.7360, 0.7465, 0.7705, 0.7565, 0.7425, 0.7264,
        0.7358, 0.7508, 0.7068, 0.7117, 0.7472, 0.7584, 0.7639],
       device='cuda:0') torch.Size([16])
percent tensor([0.5902, 0.6414, 0.6125, 0.6295, 0.6195, 0.6397, 0.6256, 0.5929, 0.6386,
        0.6219, 0.6210, 0.6400, 0.5871, 0.6812, 0.5848, 0.6203],
       device='cuda:0') torch.Size([16])
percent tensor([0.6724, 0.7444, 0.7595, 0.7807, 0.7718, 0.7472, 0.7320, 0.7068, 0.7722,
        0.7428, 0.7839, 0.7644, 0.7250, 0.8205, 0.6548, 0.7033],
       device='cuda:0') torch.Size([16])
percent tensor([0.5650, 0.7517, 0.7315, 0.7538, 0.5919, 0.8066, 0.6060, 0.4681, 0.6644,
        0.7405, 0.7564, 0.6267, 0.7007, 0.7122, 0.4542, 0.5737],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 0.9995, 0.9999,
        1.0000, 1.0000, 0.9999, 0.9999, 0.9993, 0.9999, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 227 | Batch_idx: 0 |  Loss: (0.0277) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 227 | Batch_idx: 10 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (1391/1408)
Epoch: 227 | Batch_idx: 20 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (2649/2688)
Epoch: 227 | Batch_idx: 30 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (3916/3968)
Epoch: 227 | Batch_idx: 40 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (5180/5248)
Epoch: 227 | Batch_idx: 50 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (6441/6528)
Epoch: 227 | Batch_idx: 60 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (7706/7808)
Epoch: 227 | Batch_idx: 70 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (8971/9088)
Epoch: 227 | Batch_idx: 80 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (10230/10368)
Epoch: 227 | Batch_idx: 90 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (11485/11648)
Epoch: 227 | Batch_idx: 100 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (12751/12928)
Epoch: 227 | Batch_idx: 110 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (14018/14208)
Epoch: 227 | Batch_idx: 120 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (15286/15488)
Epoch: 227 | Batch_idx: 130 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (16543/16768)
Epoch: 227 | Batch_idx: 140 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (17805/18048)
Epoch: 227 | Batch_idx: 150 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (19068/19328)
Epoch: 227 | Batch_idx: 160 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (20328/20608)
Epoch: 227 | Batch_idx: 170 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (21588/21888)
Epoch: 227 | Batch_idx: 180 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (22856/23168)
Epoch: 227 | Batch_idx: 190 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (24123/24448)
Epoch: 227 | Batch_idx: 200 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (25383/25728)
Epoch: 227 | Batch_idx: 210 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (26644/27008)
Epoch: 227 | Batch_idx: 220 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (27905/28288)
Epoch: 227 | Batch_idx: 230 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (29164/29568)
Epoch: 227 | Batch_idx: 240 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (30425/30848)
Epoch: 227 | Batch_idx: 250 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (31698/32128)
Epoch: 227 | Batch_idx: 260 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (32960/33408)
Epoch: 227 | Batch_idx: 270 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (34222/34688)
Epoch: 227 | Batch_idx: 280 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (35481/35968)
Epoch: 227 | Batch_idx: 290 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (36740/37248)
Epoch: 227 | Batch_idx: 300 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (38006/38528)
Epoch: 227 | Batch_idx: 310 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (39273/39808)
Epoch: 227 | Batch_idx: 320 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (40536/41088)
Epoch: 227 | Batch_idx: 330 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (41790/42368)
Epoch: 227 | Batch_idx: 340 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (43057/43648)
Epoch: 227 | Batch_idx: 350 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (44322/44928)
Epoch: 227 | Batch_idx: 360 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (45584/46208)
Epoch: 227 | Batch_idx: 370 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (46849/47488)
Epoch: 227 | Batch_idx: 380 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (48114/48768)
Epoch: 227 | Batch_idx: 390 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (49332/50000)
# TEST : Loss: (0.4285) | Acc: (89.00%) (8959/10000)
percent tensor([0.5903, 0.6122, 0.6045, 0.5894, 0.6122, 0.5810, 0.6212, 0.6062, 0.6022,
        0.6049, 0.5982, 0.6137, 0.5957, 0.6063, 0.5998, 0.5889],
       device='cuda:0') torch.Size([16])
percent tensor([0.5565, 0.5526, 0.5470, 0.5352, 0.5463, 0.5246, 0.5598, 0.5516, 0.5508,
        0.5523, 0.5495, 0.5558, 0.5634, 0.5443, 0.5382, 0.5487],
       device='cuda:0') torch.Size([16])
percent tensor([0.6215, 0.6335, 0.6058, 0.6814, 0.6886, 0.6741, 0.6597, 0.7098, 0.6017,
        0.5560, 0.5437, 0.6086, 0.5532, 0.6780, 0.6998, 0.6261],
       device='cuda:0') torch.Size([16])
percent tensor([0.7682, 0.7108, 0.7336, 0.7323, 0.7413, 0.7686, 0.7504, 0.7329, 0.7231,
        0.7319, 0.7455, 0.7030, 0.7086, 0.7461, 0.7543, 0.7601],
       device='cuda:0') torch.Size([16])
percent tensor([0.5978, 0.6380, 0.6332, 0.6473, 0.6341, 0.6407, 0.6247, 0.6072, 0.6489,
        0.6262, 0.6227, 0.6482, 0.5926, 0.6761, 0.5898, 0.6280],
       device='cuda:0') torch.Size([16])
percent tensor([0.6808, 0.7432, 0.7615, 0.7823, 0.7733, 0.7428, 0.7354, 0.7146, 0.7739,
        0.7445, 0.7890, 0.7668, 0.7273, 0.8333, 0.6665, 0.7020],
       device='cuda:0') torch.Size([16])
percent tensor([0.5745, 0.7209, 0.7356, 0.7462, 0.5991, 0.8016, 0.6482, 0.4756, 0.6600,
        0.7314, 0.7598, 0.6018, 0.6520, 0.7106, 0.4894, 0.5560],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9998, 0.9995, 0.9999,
        1.0000, 1.0000, 1.0000, 0.9999, 0.9995, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 228 | Batch_idx: 0 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 228 | Batch_idx: 10 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (1390/1408)
Epoch: 228 | Batch_idx: 20 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (2652/2688)
Epoch: 228 | Batch_idx: 30 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (3917/3968)
Epoch: 228 | Batch_idx: 40 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (5181/5248)
Epoch: 228 | Batch_idx: 50 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (6438/6528)
Epoch: 228 | Batch_idx: 60 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (7694/7808)
Epoch: 228 | Batch_idx: 70 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (8962/9088)
Epoch: 228 | Batch_idx: 80 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (10229/10368)
Epoch: 228 | Batch_idx: 90 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (11495/11648)
Epoch: 228 | Batch_idx: 100 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (12767/12928)
Epoch: 228 | Batch_idx: 110 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (14034/14208)
Epoch: 228 | Batch_idx: 120 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (15290/15488)
Epoch: 228 | Batch_idx: 130 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (16556/16768)
Epoch: 228 | Batch_idx: 140 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (17820/18048)
Epoch: 228 | Batch_idx: 150 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (19093/19328)
Epoch: 228 | Batch_idx: 160 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (20362/20608)
Epoch: 228 | Batch_idx: 170 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (21625/21888)
Epoch: 228 | Batch_idx: 180 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (22887/23168)
Epoch: 228 | Batch_idx: 190 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (24152/24448)
Epoch: 228 | Batch_idx: 200 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (25411/25728)
Epoch: 228 | Batch_idx: 210 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (26679/27008)
Epoch: 228 | Batch_idx: 220 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (27942/28288)
Epoch: 228 | Batch_idx: 230 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (29213/29568)
Epoch: 228 | Batch_idx: 240 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (30474/30848)
Epoch: 228 | Batch_idx: 250 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (31733/32128)
Epoch: 228 | Batch_idx: 260 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (32995/33408)
Epoch: 228 | Batch_idx: 270 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (34254/34688)
Epoch: 228 | Batch_idx: 280 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (35513/35968)
Epoch: 228 | Batch_idx: 290 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (36770/37248)
Epoch: 228 | Batch_idx: 300 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (38036/38528)
Epoch: 228 | Batch_idx: 310 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (39296/39808)
Epoch: 228 | Batch_idx: 320 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (40564/41088)
Epoch: 228 | Batch_idx: 330 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (41826/42368)
Epoch: 228 | Batch_idx: 340 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (43088/43648)
Epoch: 228 | Batch_idx: 350 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (44348/44928)
Epoch: 228 | Batch_idx: 360 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (45609/46208)
Epoch: 228 | Batch_idx: 370 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (46872/47488)
Epoch: 228 | Batch_idx: 380 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (48136/48768)
Epoch: 228 | Batch_idx: 390 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (49346/50000)
# TEST : Loss: (0.4201) | Acc: (89.00%) (8922/10000)
percent tensor([0.5865, 0.6080, 0.6001, 0.5863, 0.6078, 0.5780, 0.6165, 0.6021, 0.5973,
        0.6006, 0.5937, 0.6086, 0.5915, 0.6024, 0.5961, 0.5855],
       device='cuda:0') torch.Size([16])
percent tensor([0.5560, 0.5517, 0.5466, 0.5352, 0.5453, 0.5234, 0.5590, 0.5524, 0.5501,
        0.5522, 0.5487, 0.5543, 0.5630, 0.5436, 0.5370, 0.5479],
       device='cuda:0') torch.Size([16])
percent tensor([0.6246, 0.6289, 0.6089, 0.6860, 0.6895, 0.6792, 0.6548, 0.7097, 0.5927,
        0.5534, 0.5434, 0.6141, 0.5512, 0.6651, 0.7006, 0.6282],
       device='cuda:0') torch.Size([16])
percent tensor([0.7726, 0.7194, 0.7359, 0.7399, 0.7487, 0.7693, 0.7556, 0.7423, 0.7278,
        0.7413, 0.7514, 0.7082, 0.7105, 0.7561, 0.7611, 0.7660],
       device='cuda:0') torch.Size([16])
percent tensor([0.5924, 0.6327, 0.6277, 0.6443, 0.6252, 0.6406, 0.6179, 0.5934, 0.6433,
        0.6201, 0.6185, 0.6424, 0.5867, 0.6748, 0.5852, 0.6228],
       device='cuda:0') torch.Size([16])
percent tensor([0.6806, 0.7350, 0.7715, 0.7888, 0.7818, 0.7554, 0.7243, 0.7082, 0.7677,
        0.7305, 0.7872, 0.7573, 0.7239, 0.8215, 0.6696, 0.7066],
       device='cuda:0') torch.Size([16])
percent tensor([0.5486, 0.7023, 0.7220, 0.7365, 0.5843, 0.7993, 0.6174, 0.4531, 0.6313,
        0.6492, 0.7485, 0.5600, 0.6502, 0.6183, 0.4612, 0.5593],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 1.0000, 0.9995, 0.9998, 0.9996, 0.9999,
        0.9999, 1.0000, 1.0000, 0.9999, 0.9994, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 229 | Batch_idx: 0 |  Loss: (0.0150) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 229 | Batch_idx: 10 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (1381/1408)
Epoch: 229 | Batch_idx: 20 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (2644/2688)
Epoch: 229 | Batch_idx: 30 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (3903/3968)
Epoch: 229 | Batch_idx: 40 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (5164/5248)
Epoch: 229 | Batch_idx: 50 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (6423/6528)
Epoch: 229 | Batch_idx: 60 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (7686/7808)
Epoch: 229 | Batch_idx: 70 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (8947/9088)
Epoch: 229 | Batch_idx: 80 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (10211/10368)
Epoch: 229 | Batch_idx: 90 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (11479/11648)
Epoch: 229 | Batch_idx: 100 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (12744/12928)
Epoch: 229 | Batch_idx: 110 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (14009/14208)
Epoch: 229 | Batch_idx: 120 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (15272/15488)
Epoch: 229 | Batch_idx: 130 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (16542/16768)
Epoch: 229 | Batch_idx: 140 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (17804/18048)
Epoch: 229 | Batch_idx: 150 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (19067/19328)
Epoch: 229 | Batch_idx: 160 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (20331/20608)
Epoch: 229 | Batch_idx: 170 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (21596/21888)
Epoch: 229 | Batch_idx: 180 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (22863/23168)
Epoch: 229 | Batch_idx: 190 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (24129/24448)
Epoch: 229 | Batch_idx: 200 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (25395/25728)
Epoch: 229 | Batch_idx: 210 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (26656/27008)
Epoch: 229 | Batch_idx: 220 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (27916/28288)
Epoch: 229 | Batch_idx: 230 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (29177/29568)
Epoch: 229 | Batch_idx: 240 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (30440/30848)
Epoch: 229 | Batch_idx: 250 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (31703/32128)
Epoch: 229 | Batch_idx: 260 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (32970/33408)
Epoch: 229 | Batch_idx: 270 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (34230/34688)
Epoch: 229 | Batch_idx: 280 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (35495/35968)
Epoch: 229 | Batch_idx: 290 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (36757/37248)
Epoch: 229 | Batch_idx: 300 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (38018/38528)
Epoch: 229 | Batch_idx: 310 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (39284/39808)
Epoch: 229 | Batch_idx: 320 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (40549/41088)
Epoch: 229 | Batch_idx: 330 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (41807/42368)
Epoch: 229 | Batch_idx: 340 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (43073/43648)
Epoch: 229 | Batch_idx: 350 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (44330/44928)
Epoch: 229 | Batch_idx: 360 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (45596/46208)
Epoch: 229 | Batch_idx: 370 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (46864/47488)
Epoch: 229 | Batch_idx: 380 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (48126/48768)
Epoch: 229 | Batch_idx: 390 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (49345/50000)
# TEST : Loss: (0.4412) | Acc: (89.00%) (8924/10000)
percent tensor([0.5918, 0.6139, 0.6065, 0.5920, 0.6144, 0.5831, 0.6237, 0.6086, 0.6034,
        0.6072, 0.5997, 0.6161, 0.5978, 0.6087, 0.6018, 0.5913],
       device='cuda:0') torch.Size([16])
percent tensor([0.5530, 0.5492, 0.5429, 0.5341, 0.5416, 0.5221, 0.5563, 0.5486, 0.5474,
        0.5493, 0.5462, 0.5495, 0.5607, 0.5432, 0.5350, 0.5466],
       device='cuda:0') torch.Size([16])
percent tensor([0.6307, 0.6366, 0.6191, 0.6852, 0.6939, 0.6772, 0.6672, 0.7141, 0.6092,
        0.5623, 0.5544, 0.6258, 0.5645, 0.6791, 0.7023, 0.6294],
       device='cuda:0') torch.Size([16])
percent tensor([0.7714, 0.7160, 0.7370, 0.7355, 0.7486, 0.7734, 0.7557, 0.7416, 0.7268,
        0.7381, 0.7511, 0.7026, 0.7101, 0.7467, 0.7588, 0.7618],
       device='cuda:0') torch.Size([16])
percent tensor([0.5991, 0.6391, 0.6283, 0.6458, 0.6294, 0.6357, 0.6225, 0.5982, 0.6482,
        0.6305, 0.6237, 0.6514, 0.5919, 0.6790, 0.5877, 0.6363],
       device='cuda:0') torch.Size([16])
percent tensor([0.6663, 0.7302, 0.7628, 0.7824, 0.7688, 0.7297, 0.7249, 0.7163, 0.7674,
        0.7251, 0.7802, 0.7547, 0.7239, 0.8174, 0.6560, 0.6926],
       device='cuda:0') torch.Size([16])
percent tensor([0.5363, 0.6971, 0.7398, 0.7403, 0.5818, 0.7641, 0.6146, 0.4729, 0.6658,
        0.6755, 0.7412, 0.5904, 0.6779, 0.6474, 0.4523, 0.5315],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9995, 0.9999, 0.9996, 0.9999,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9993, 0.9999, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 230 | Batch_idx: 0 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 230 | Batch_idx: 10 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (98.00%) (1391/1408)
Epoch: 230 | Batch_idx: 20 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (2653/2688)
Epoch: 230 | Batch_idx: 30 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (3920/3968)
Epoch: 230 | Batch_idx: 40 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (5186/5248)
Epoch: 230 | Batch_idx: 50 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (6453/6528)
Epoch: 230 | Batch_idx: 60 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (7720/7808)
Epoch: 230 | Batch_idx: 70 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (8986/9088)
Epoch: 230 | Batch_idx: 80 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (10248/10368)
Epoch: 230 | Batch_idx: 90 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (11504/11648)
Epoch: 230 | Batch_idx: 100 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (12769/12928)
Epoch: 230 | Batch_idx: 110 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (14031/14208)
Epoch: 230 | Batch_idx: 120 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (15298/15488)
Epoch: 230 | Batch_idx: 130 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (16561/16768)
Epoch: 230 | Batch_idx: 140 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (17821/18048)
Epoch: 230 | Batch_idx: 150 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (19089/19328)
Epoch: 230 | Batch_idx: 160 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (20359/20608)
Epoch: 230 | Batch_idx: 170 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (21625/21888)
Epoch: 230 | Batch_idx: 180 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (22887/23168)
Epoch: 230 | Batch_idx: 190 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (24149/24448)
Epoch: 230 | Batch_idx: 200 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (25401/25728)
Epoch: 230 | Batch_idx: 210 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (26667/27008)
Epoch: 230 | Batch_idx: 220 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (27921/28288)
Epoch: 230 | Batch_idx: 230 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (29181/29568)
Epoch: 230 | Batch_idx: 240 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (30447/30848)
Epoch: 230 | Batch_idx: 250 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (31707/32128)
Epoch: 230 | Batch_idx: 260 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (32968/33408)
Epoch: 230 | Batch_idx: 270 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (34230/34688)
Epoch: 230 | Batch_idx: 280 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (35492/35968)
Epoch: 230 | Batch_idx: 290 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (36755/37248)
Epoch: 230 | Batch_idx: 300 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (38014/38528)
Epoch: 230 | Batch_idx: 310 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (39271/39808)
Epoch: 230 | Batch_idx: 320 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (40535/41088)
Epoch: 230 | Batch_idx: 330 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (41797/42368)
Epoch: 230 | Batch_idx: 340 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (43062/43648)
Epoch: 230 | Batch_idx: 350 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (44316/44928)
Epoch: 230 | Batch_idx: 360 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (45575/46208)
Epoch: 230 | Batch_idx: 370 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (46839/47488)
Epoch: 230 | Batch_idx: 380 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (48105/48768)
Epoch: 230 | Batch_idx: 390 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (49319/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_230.pth.tar'
# TEST : Loss: (0.4246) | Acc: (89.00%) (8934/10000)
percent tensor([0.5900, 0.6124, 0.6026, 0.5901, 0.6106, 0.5805, 0.6210, 0.6061, 0.6018,
        0.6048, 0.5982, 0.6122, 0.5959, 0.6081, 0.5998, 0.5898],
       device='cuda:0') torch.Size([16])
percent tensor([0.5546, 0.5517, 0.5443, 0.5349, 0.5435, 0.5221, 0.5580, 0.5505, 0.5481,
        0.5520, 0.5474, 0.5527, 0.5621, 0.5435, 0.5365, 0.5479],
       device='cuda:0') torch.Size([16])
percent tensor([0.6290, 0.6235, 0.6175, 0.6902, 0.6930, 0.6790, 0.6583, 0.7172, 0.6060,
        0.5592, 0.5492, 0.6201, 0.5589, 0.6670, 0.6982, 0.6265],
       device='cuda:0') torch.Size([16])
percent tensor([0.7669, 0.7169, 0.7331, 0.7357, 0.7426, 0.7674, 0.7529, 0.7377, 0.7208,
        0.7375, 0.7473, 0.7002, 0.7063, 0.7505, 0.7565, 0.7614],
       device='cuda:0') torch.Size([16])
percent tensor([0.5946, 0.6362, 0.6278, 0.6450, 0.6292, 0.6403, 0.6236, 0.5997, 0.6450,
        0.6251, 0.6211, 0.6514, 0.5919, 0.6775, 0.5851, 0.6330],
       device='cuda:0') torch.Size([16])
percent tensor([0.6702, 0.7409, 0.7658, 0.7872, 0.7686, 0.7406, 0.7332, 0.7205, 0.7729,
        0.7315, 0.7850, 0.7603, 0.7277, 0.8198, 0.6672, 0.6970],
       device='cuda:0') torch.Size([16])
percent tensor([0.5325, 0.7376, 0.7325, 0.7570, 0.5984, 0.7783, 0.6586, 0.4841, 0.6889,
        0.6930, 0.7558, 0.6095, 0.7032, 0.6611, 0.4951, 0.5552],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 1.0000, 0.9994, 0.9998, 0.9997, 0.9999,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9995, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(180.7260, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(829.4572, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(842.8344, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1524.6890, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(470.2910, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2320.2656, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4255.1875, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1339.9453, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6379.5962, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11455.9346, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3761.9761, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15807.7939, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 231 | Batch_idx: 0 |  Loss: (0.0233) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 231 | Batch_idx: 10 |  Loss: (0.0314) |  Loss2: (0.0000) | Acc: (98.00%) (1393/1408)
Epoch: 231 | Batch_idx: 20 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (2654/2688)
Epoch: 231 | Batch_idx: 30 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (3921/3968)
Epoch: 231 | Batch_idx: 40 |  Loss: (0.0349) |  Loss2: (0.0000) | Acc: (98.00%) (5188/5248)
Epoch: 231 | Batch_idx: 50 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (6452/6528)
Epoch: 231 | Batch_idx: 60 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (7723/7808)
Epoch: 231 | Batch_idx: 70 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (8984/9088)
Epoch: 231 | Batch_idx: 80 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (10243/10368)
Epoch: 231 | Batch_idx: 90 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (11514/11648)
Epoch: 231 | Batch_idx: 100 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (12768/12928)
Epoch: 231 | Batch_idx: 110 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (14032/14208)
Epoch: 231 | Batch_idx: 120 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (15291/15488)
Epoch: 231 | Batch_idx: 130 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (16552/16768)
Epoch: 231 | Batch_idx: 140 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (17818/18048)
Epoch: 231 | Batch_idx: 150 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (19076/19328)
Epoch: 231 | Batch_idx: 160 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (20336/20608)
Epoch: 231 | Batch_idx: 170 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (21597/21888)
Epoch: 231 | Batch_idx: 180 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (22864/23168)
Epoch: 231 | Batch_idx: 190 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (24125/24448)
Epoch: 231 | Batch_idx: 200 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (25392/25728)
Epoch: 231 | Batch_idx: 210 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (26655/27008)
Epoch: 231 | Batch_idx: 220 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (27918/28288)
Epoch: 231 | Batch_idx: 230 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (29181/29568)
Epoch: 231 | Batch_idx: 240 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (30447/30848)
Epoch: 231 | Batch_idx: 250 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (31714/32128)
Epoch: 231 | Batch_idx: 260 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (32976/33408)
Epoch: 231 | Batch_idx: 270 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (34235/34688)
Epoch: 231 | Batch_idx: 280 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (35494/35968)
Epoch: 231 | Batch_idx: 290 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (36762/37248)
Epoch: 231 | Batch_idx: 300 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (38021/38528)
Epoch: 231 | Batch_idx: 310 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (39289/39808)
Epoch: 231 | Batch_idx: 320 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (40547/41088)
Epoch: 231 | Batch_idx: 330 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (41809/42368)
Epoch: 231 | Batch_idx: 340 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (43077/43648)
Epoch: 231 | Batch_idx: 350 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (44340/44928)
Epoch: 231 | Batch_idx: 360 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (45606/46208)
Epoch: 231 | Batch_idx: 370 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (46871/47488)
Epoch: 231 | Batch_idx: 380 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (48141/48768)
Epoch: 231 | Batch_idx: 390 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (49354/50000)
# TEST : Loss: (0.4127) | Acc: (89.00%) (8962/10000)
percent tensor([0.5912, 0.6139, 0.6063, 0.5915, 0.6137, 0.5811, 0.6232, 0.6086, 0.6037,
        0.6068, 0.5996, 0.6154, 0.5974, 0.6083, 0.6011, 0.5905],
       device='cuda:0') torch.Size([16])
percent tensor([0.5537, 0.5498, 0.5420, 0.5312, 0.5419, 0.5216, 0.5571, 0.5484, 0.5484,
        0.5502, 0.5475, 0.5505, 0.5612, 0.5429, 0.5349, 0.5454],
       device='cuda:0') torch.Size([16])
percent tensor([0.6255, 0.6219, 0.6166, 0.6946, 0.6949, 0.6805, 0.6529, 0.7130, 0.6040,
        0.5579, 0.5484, 0.6194, 0.5577, 0.6575, 0.6976, 0.6274],
       device='cuda:0') torch.Size([16])
percent tensor([0.7677, 0.7164, 0.7365, 0.7411, 0.7462, 0.7687, 0.7541, 0.7409, 0.7259,
        0.7387, 0.7493, 0.7063, 0.7079, 0.7500, 0.7580, 0.7629],
       device='cuda:0') torch.Size([16])
percent tensor([0.5969, 0.6373, 0.6296, 0.6455, 0.6301, 0.6424, 0.6197, 0.6003, 0.6499,
        0.6224, 0.6207, 0.6499, 0.5968, 0.6829, 0.5810, 0.6329],
       device='cuda:0') torch.Size([16])
percent tensor([0.6653, 0.7466, 0.7659, 0.7976, 0.7719, 0.7292, 0.7210, 0.7156, 0.7822,
        0.7388, 0.7907, 0.7626, 0.7325, 0.8267, 0.6593, 0.7011],
       device='cuda:0') torch.Size([16])
percent tensor([0.5409, 0.7487, 0.7564, 0.7581, 0.6058, 0.7692, 0.6212, 0.4487, 0.6813,
        0.6990, 0.7725, 0.6091, 0.7064, 0.6720, 0.4969, 0.5561],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 1.0000, 0.9995, 0.9998, 0.9997, 0.9999,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9995, 0.9999, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 232 | Batch_idx: 0 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 232 | Batch_idx: 10 |  Loss: (0.0319) |  Loss2: (0.0000) | Acc: (99.00%) (1394/1408)
Epoch: 232 | Batch_idx: 20 |  Loss: (0.0342) |  Loss2: (0.0000) | Acc: (98.00%) (2659/2688)
Epoch: 232 | Batch_idx: 30 |  Loss: (0.0343) |  Loss2: (0.0000) | Acc: (98.00%) (3924/3968)
Epoch: 232 | Batch_idx: 40 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (5184/5248)
Epoch: 232 | Batch_idx: 50 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (6445/6528)
Epoch: 232 | Batch_idx: 60 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (7705/7808)
Epoch: 232 | Batch_idx: 70 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (8972/9088)
Epoch: 232 | Batch_idx: 80 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (10233/10368)
Epoch: 232 | Batch_idx: 90 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (11490/11648)
Epoch: 232 | Batch_idx: 100 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (12757/12928)
Epoch: 232 | Batch_idx: 110 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (14015/14208)
Epoch: 232 | Batch_idx: 120 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (15278/15488)
Epoch: 232 | Batch_idx: 130 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (16536/16768)
Epoch: 232 | Batch_idx: 140 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (17799/18048)
Epoch: 232 | Batch_idx: 150 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (19064/19328)
Epoch: 232 | Batch_idx: 160 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (20328/20608)
Epoch: 232 | Batch_idx: 170 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (21591/21888)
Epoch: 232 | Batch_idx: 180 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (22851/23168)
Epoch: 232 | Batch_idx: 190 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (24118/24448)
Epoch: 232 | Batch_idx: 200 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (25375/25728)
Epoch: 232 | Batch_idx: 210 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (26641/27008)
Epoch: 232 | Batch_idx: 220 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (27902/28288)
Epoch: 232 | Batch_idx: 230 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (29157/29568)
Epoch: 232 | Batch_idx: 240 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (30422/30848)
Epoch: 232 | Batch_idx: 250 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (31687/32128)
Epoch: 232 | Batch_idx: 260 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (32955/33408)
Epoch: 232 | Batch_idx: 270 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (34221/34688)
Epoch: 232 | Batch_idx: 280 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (35477/35968)
Epoch: 232 | Batch_idx: 290 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (36742/37248)
Epoch: 232 | Batch_idx: 300 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (38006/38528)
Epoch: 232 | Batch_idx: 310 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (39266/39808)
Epoch: 232 | Batch_idx: 320 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (40529/41088)
Epoch: 232 | Batch_idx: 330 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (41789/42368)
Epoch: 232 | Batch_idx: 340 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (43048/43648)
Epoch: 232 | Batch_idx: 350 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (44314/44928)
Epoch: 232 | Batch_idx: 360 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (45574/46208)
Epoch: 232 | Batch_idx: 370 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (46837/47488)
Epoch: 232 | Batch_idx: 380 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (48104/48768)
Epoch: 232 | Batch_idx: 390 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (49307/50000)
# TEST : Loss: (0.4264) | Acc: (89.00%) (8917/10000)
percent tensor([0.5907, 0.6145, 0.6032, 0.5907, 0.6115, 0.5803, 0.6228, 0.6078, 0.6035,
        0.6059, 0.5996, 0.6134, 0.5972, 0.6106, 0.6008, 0.5904],
       device='cuda:0') torch.Size([16])
percent tensor([0.5584, 0.5533, 0.5459, 0.5346, 0.5462, 0.5244, 0.5611, 0.5527, 0.5518,
        0.5534, 0.5512, 0.5545, 0.5657, 0.5457, 0.5382, 0.5502],
       device='cuda:0') torch.Size([16])
percent tensor([0.6252, 0.6274, 0.6282, 0.6939, 0.6976, 0.6762, 0.6627, 0.7198, 0.6101,
        0.5673, 0.5516, 0.6307, 0.5564, 0.6688, 0.7023, 0.6296],
       device='cuda:0') torch.Size([16])
percent tensor([0.7689, 0.7204, 0.7333, 0.7369, 0.7411, 0.7668, 0.7557, 0.7431, 0.7297,
        0.7378, 0.7518, 0.7038, 0.7125, 0.7562, 0.7594, 0.7626],
       device='cuda:0') torch.Size([16])
percent tensor([0.5971, 0.6310, 0.6357, 0.6479, 0.6388, 0.6445, 0.6222, 0.6017, 0.6503,
        0.6252, 0.6195, 0.6513, 0.5898, 0.6721, 0.5787, 0.6269],
       device='cuda:0') torch.Size([16])
percent tensor([0.6679, 0.7390, 0.7630, 0.7781, 0.7649, 0.7275, 0.7256, 0.7095, 0.7657,
        0.7344, 0.7849, 0.7601, 0.7286, 0.8201, 0.6541, 0.6804],
       device='cuda:0') torch.Size([16])
percent tensor([0.5091, 0.7000, 0.7110, 0.7417, 0.5847, 0.7497, 0.6290, 0.4452, 0.6432,
        0.6797, 0.7419, 0.5911, 0.6630, 0.5894, 0.4742, 0.5209],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 1.0000, 0.9993, 0.9998, 0.9995, 0.9999,
        1.0000, 1.0000, 1.0000, 0.9999, 0.9993, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 233 | Batch_idx: 0 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 233 | Batch_idx: 10 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (1391/1408)
Epoch: 233 | Batch_idx: 20 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (2647/2688)
Epoch: 233 | Batch_idx: 30 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (3912/3968)
Epoch: 233 | Batch_idx: 40 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (5174/5248)
Epoch: 233 | Batch_idx: 50 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (6443/6528)
Epoch: 233 | Batch_idx: 60 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (7708/7808)
Epoch: 233 | Batch_idx: 70 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (8976/9088)
Epoch: 233 | Batch_idx: 80 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (10242/10368)
Epoch: 233 | Batch_idx: 90 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (11507/11648)
Epoch: 233 | Batch_idx: 100 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (12772/12928)
Epoch: 233 | Batch_idx: 110 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (14041/14208)
Epoch: 233 | Batch_idx: 120 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (15307/15488)
Epoch: 233 | Batch_idx: 130 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (16577/16768)
Epoch: 233 | Batch_idx: 140 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (17842/18048)
Epoch: 233 | Batch_idx: 150 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (19108/19328)
Epoch: 233 | Batch_idx: 160 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (20369/20608)
Epoch: 233 | Batch_idx: 170 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (21637/21888)
Epoch: 233 | Batch_idx: 180 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (22904/23168)
Epoch: 233 | Batch_idx: 190 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (24166/24448)
Epoch: 233 | Batch_idx: 200 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (25430/25728)
Epoch: 233 | Batch_idx: 210 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (26696/27008)
Epoch: 233 | Batch_idx: 220 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (27962/28288)
Epoch: 233 | Batch_idx: 230 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (29222/29568)
Epoch: 233 | Batch_idx: 240 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (30491/30848)
Epoch: 233 | Batch_idx: 250 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (31752/32128)
Epoch: 233 | Batch_idx: 260 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (33014/33408)
Epoch: 233 | Batch_idx: 270 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (34276/34688)
Epoch: 233 | Batch_idx: 280 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (35537/35968)
Epoch: 233 | Batch_idx: 290 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (36798/37248)
Epoch: 233 | Batch_idx: 300 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (38052/38528)
Epoch: 233 | Batch_idx: 310 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (39317/39808)
Epoch: 233 | Batch_idx: 320 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (40582/41088)
Epoch: 233 | Batch_idx: 330 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (41846/42368)
Epoch: 233 | Batch_idx: 340 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (43113/43648)
Epoch: 233 | Batch_idx: 350 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (44366/44928)
Epoch: 233 | Batch_idx: 360 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (45631/46208)
Epoch: 233 | Batch_idx: 370 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (46897/47488)
Epoch: 233 | Batch_idx: 380 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (48155/48768)
Epoch: 233 | Batch_idx: 390 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (49363/50000)
# TEST : Loss: (0.4288) | Acc: (89.00%) (8923/10000)
percent tensor([0.5908, 0.6139, 0.6038, 0.5903, 0.6116, 0.5805, 0.6224, 0.6080, 0.6037,
        0.6059, 0.5994, 0.6136, 0.5969, 0.6096, 0.6007, 0.5902],
       device='cuda:0') torch.Size([16])
percent tensor([0.5542, 0.5509, 0.5437, 0.5318, 0.5423, 0.5211, 0.5590, 0.5498, 0.5489,
        0.5507, 0.5478, 0.5516, 0.5614, 0.5448, 0.5353, 0.5462],
       device='cuda:0') torch.Size([16])
percent tensor([0.6397, 0.6269, 0.6380, 0.7010, 0.7066, 0.6896, 0.6644, 0.7243, 0.6136,
        0.5685, 0.5554, 0.6360, 0.5659, 0.6591, 0.7108, 0.6393],
       device='cuda:0') torch.Size([16])
percent tensor([0.7720, 0.7172, 0.7307, 0.7302, 0.7412, 0.7695, 0.7552, 0.7410, 0.7289,
        0.7388, 0.7512, 0.7018, 0.7107, 0.7535, 0.7592, 0.7628],
       device='cuda:0') torch.Size([16])
percent tensor([0.5965, 0.6394, 0.6381, 0.6505, 0.6416, 0.6422, 0.6237, 0.6113, 0.6498,
        0.6314, 0.6196, 0.6580, 0.6000, 0.6755, 0.5817, 0.6309],
       device='cuda:0') torch.Size([16])
percent tensor([0.6790, 0.7449, 0.7689, 0.7944, 0.7826, 0.7347, 0.7375, 0.7226, 0.7756,
        0.7413, 0.7862, 0.7603, 0.7279, 0.8262, 0.6621, 0.6983],
       device='cuda:0') torch.Size([16])
percent tensor([0.5800, 0.7675, 0.7455, 0.7903, 0.6213, 0.7896, 0.6791, 0.4937, 0.6780,
        0.7291, 0.7738, 0.5973, 0.6964, 0.6379, 0.4926, 0.5647],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9999, 0.9996, 0.9999,
        1.0000, 1.0000, 1.0000, 0.9999, 0.9995, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 234 | Batch_idx: 0 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 234 | Batch_idx: 10 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (1386/1408)
Epoch: 234 | Batch_idx: 20 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (2651/2688)
Epoch: 234 | Batch_idx: 30 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (3918/3968)
Epoch: 234 | Batch_idx: 40 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (5187/5248)
Epoch: 234 | Batch_idx: 50 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (6452/6528)
Epoch: 234 | Batch_idx: 60 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (7712/7808)
Epoch: 234 | Batch_idx: 70 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (8983/9088)
Epoch: 234 | Batch_idx: 80 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (10241/10368)
Epoch: 234 | Batch_idx: 90 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (11506/11648)
Epoch: 234 | Batch_idx: 100 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (12770/12928)
Epoch: 234 | Batch_idx: 110 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (14029/14208)
Epoch: 234 | Batch_idx: 120 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (15292/15488)
Epoch: 234 | Batch_idx: 130 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (16554/16768)
Epoch: 234 | Batch_idx: 140 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (17816/18048)
Epoch: 234 | Batch_idx: 150 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (19086/19328)
Epoch: 234 | Batch_idx: 160 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (20346/20608)
Epoch: 234 | Batch_idx: 170 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (21609/21888)
Epoch: 234 | Batch_idx: 180 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (22873/23168)
Epoch: 234 | Batch_idx: 190 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (24137/24448)
Epoch: 234 | Batch_idx: 200 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (25403/25728)
Epoch: 234 | Batch_idx: 210 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (26666/27008)
Epoch: 234 | Batch_idx: 220 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (27929/28288)
Epoch: 234 | Batch_idx: 230 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (29191/29568)
Epoch: 234 | Batch_idx: 240 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (30456/30848)
Epoch: 234 | Batch_idx: 250 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (31711/32128)
Epoch: 234 | Batch_idx: 260 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (32972/33408)
Epoch: 234 | Batch_idx: 270 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (34242/34688)
Epoch: 234 | Batch_idx: 280 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (35509/35968)
Epoch: 234 | Batch_idx: 290 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (36763/37248)
Epoch: 234 | Batch_idx: 300 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (38023/38528)
Epoch: 234 | Batch_idx: 310 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (39282/39808)
Epoch: 234 | Batch_idx: 320 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (40548/41088)
Epoch: 234 | Batch_idx: 330 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (41818/42368)
Epoch: 234 | Batch_idx: 340 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (43079/43648)
Epoch: 234 | Batch_idx: 350 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (44340/44928)
Epoch: 234 | Batch_idx: 360 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (45604/46208)
Epoch: 234 | Batch_idx: 370 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (46864/47488)
Epoch: 234 | Batch_idx: 380 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (48128/48768)
Epoch: 234 | Batch_idx: 390 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (49349/50000)
# TEST : Loss: (0.4275) | Acc: (89.00%) (8926/10000)
percent tensor([0.5923, 0.6157, 0.6067, 0.5925, 0.6141, 0.5820, 0.6247, 0.6108, 0.6048,
        0.6079, 0.6010, 0.6161, 0.5986, 0.6106, 0.6026, 0.5920],
       device='cuda:0') torch.Size([16])
percent tensor([0.5535, 0.5532, 0.5430, 0.5324, 0.5417, 0.5214, 0.5597, 0.5513, 0.5490,
        0.5520, 0.5485, 0.5521, 0.5618, 0.5455, 0.5373, 0.5469],
       device='cuda:0') torch.Size([16])
percent tensor([0.6280, 0.6250, 0.6229, 0.6876, 0.6980, 0.6890, 0.6570, 0.7157, 0.6164,
        0.5616, 0.5565, 0.6207, 0.5597, 0.6711, 0.7055, 0.6278],
       device='cuda:0') torch.Size([16])
percent tensor([0.7719, 0.7174, 0.7351, 0.7371, 0.7458, 0.7694, 0.7555, 0.7441, 0.7308,
        0.7384, 0.7533, 0.7067, 0.7102, 0.7551, 0.7586, 0.7634],
       device='cuda:0') torch.Size([16])
percent tensor([0.5987, 0.6411, 0.6332, 0.6521, 0.6377, 0.6491, 0.6287, 0.6060, 0.6590,
        0.6316, 0.6261, 0.6539, 0.5981, 0.6881, 0.5857, 0.6320],
       device='cuda:0') torch.Size([16])
percent tensor([0.6783, 0.7473, 0.7686, 0.7929, 0.7708, 0.7334, 0.7321, 0.7205, 0.7731,
        0.7315, 0.7843, 0.7531, 0.7240, 0.8261, 0.6645, 0.7010],
       device='cuda:0') torch.Size([16])
percent tensor([0.5606, 0.7402, 0.7515, 0.7746, 0.5927, 0.7633, 0.6412, 0.5200, 0.6663,
        0.6992, 0.7661, 0.5811, 0.6842, 0.6253, 0.4890, 0.5625],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9995, 0.9998, 0.9997, 0.9999,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9996, 0.9999, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 235 | Batch_idx: 0 |  Loss: (0.0145) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 235 | Batch_idx: 10 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (1392/1408)
Epoch: 235 | Batch_idx: 20 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (2660/2688)
Epoch: 235 | Batch_idx: 30 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (3922/3968)
Epoch: 235 | Batch_idx: 40 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (5186/5248)
Epoch: 235 | Batch_idx: 50 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (6456/6528)
Epoch: 235 | Batch_idx: 60 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (7721/7808)
Epoch: 235 | Batch_idx: 70 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (8991/9088)
Epoch: 235 | Batch_idx: 80 |  Loss: (0.0344) |  Loss2: (0.0000) | Acc: (98.00%) (10260/10368)
Epoch: 235 | Batch_idx: 90 |  Loss: (0.0338) |  Loss2: (0.0000) | Acc: (99.00%) (11533/11648)
Epoch: 235 | Batch_idx: 100 |  Loss: (0.0344) |  Loss2: (0.0000) | Acc: (98.00%) (12796/12928)
Epoch: 235 | Batch_idx: 110 |  Loss: (0.0346) |  Loss2: (0.0000) | Acc: (98.00%) (14063/14208)
Epoch: 235 | Batch_idx: 120 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (15324/15488)
Epoch: 235 | Batch_idx: 130 |  Loss: (0.0351) |  Loss2: (0.0000) | Acc: (98.00%) (16592/16768)
Epoch: 235 | Batch_idx: 140 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (17849/18048)
Epoch: 235 | Batch_idx: 150 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (19106/19328)
Epoch: 235 | Batch_idx: 160 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (20358/20608)
Epoch: 235 | Batch_idx: 170 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (21619/21888)
Epoch: 235 | Batch_idx: 180 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (22883/23168)
Epoch: 235 | Batch_idx: 190 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (24144/24448)
Epoch: 235 | Batch_idx: 200 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (25411/25728)
Epoch: 235 | Batch_idx: 210 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (26680/27008)
Epoch: 235 | Batch_idx: 220 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (27942/28288)
Epoch: 235 | Batch_idx: 230 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (29214/29568)
Epoch: 235 | Batch_idx: 240 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (30485/30848)
Epoch: 235 | Batch_idx: 250 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (31748/32128)
Epoch: 235 | Batch_idx: 260 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (33005/33408)
Epoch: 235 | Batch_idx: 270 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (34270/34688)
Epoch: 235 | Batch_idx: 280 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (35538/35968)
Epoch: 235 | Batch_idx: 290 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (36804/37248)
Epoch: 235 | Batch_idx: 300 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (38069/38528)
Epoch: 235 | Batch_idx: 310 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (39337/39808)
Epoch: 235 | Batch_idx: 320 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (40606/41088)
Epoch: 235 | Batch_idx: 330 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (41871/42368)
Epoch: 235 | Batch_idx: 340 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (43132/43648)
Epoch: 235 | Batch_idx: 350 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (44396/44928)
Epoch: 235 | Batch_idx: 360 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (45665/46208)
Epoch: 235 | Batch_idx: 370 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (46918/47488)
Epoch: 235 | Batch_idx: 380 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (48183/48768)
Epoch: 235 | Batch_idx: 390 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (49399/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_235.pth.tar'
# TEST : Loss: (0.4416) | Acc: (88.00%) (8877/10000)
percent tensor([0.5925, 0.6172, 0.6068, 0.5938, 0.6142, 0.5821, 0.6257, 0.6110, 0.6048,
        0.6089, 0.6012, 0.6168, 0.5995, 0.6126, 0.6034, 0.5925],
       device='cuda:0') torch.Size([16])
percent tensor([0.5568, 0.5550, 0.5447, 0.5347, 0.5450, 0.5242, 0.5613, 0.5534, 0.5523,
        0.5538, 0.5513, 0.5528, 0.5657, 0.5485, 0.5389, 0.5504],
       device='cuda:0') torch.Size([16])
percent tensor([0.6343, 0.6310, 0.6243, 0.6944, 0.6967, 0.6846, 0.6586, 0.7241, 0.6197,
        0.5645, 0.5627, 0.6257, 0.5686, 0.6691, 0.7074, 0.6338],
       device='cuda:0') torch.Size([16])
percent tensor([0.7744, 0.7132, 0.7462, 0.7431, 0.7521, 0.7726, 0.7561, 0.7448, 0.7301,
        0.7396, 0.7534, 0.7125, 0.7107, 0.7515, 0.7610, 0.7653],
       device='cuda:0') torch.Size([16])
percent tensor([0.5966, 0.6444, 0.6244, 0.6528, 0.6318, 0.6473, 0.6298, 0.6038, 0.6545,
        0.6279, 0.6236, 0.6459, 0.5970, 0.6883, 0.5860, 0.6325],
       device='cuda:0') torch.Size([16])
percent tensor([0.6707, 0.7495, 0.7726, 0.7904, 0.7680, 0.7305, 0.7263, 0.7123, 0.7802,
        0.7355, 0.7855, 0.7600, 0.7305, 0.8206, 0.6551, 0.6988],
       device='cuda:0') torch.Size([16])
percent tensor([0.5604, 0.7351, 0.7228, 0.7310, 0.5846, 0.7782, 0.6045, 0.4476, 0.6769,
        0.7091, 0.7638, 0.5603, 0.7227, 0.5829, 0.4721, 0.5576],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9997, 0.9992, 0.9999,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9995, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 236 | Batch_idx: 0 |  Loss: (0.0255) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 236 | Batch_idx: 10 |  Loss: (0.0352) |  Loss2: (0.0000) | Acc: (99.00%) (1394/1408)
Epoch: 236 | Batch_idx: 20 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (2661/2688)
Epoch: 236 | Batch_idx: 30 |  Loss: (0.0334) |  Loss2: (0.0000) | Acc: (99.00%) (3933/3968)
Epoch: 236 | Batch_idx: 40 |  Loss: (0.0322) |  Loss2: (0.0000) | Acc: (99.00%) (5205/5248)
Epoch: 236 | Batch_idx: 50 |  Loss: (0.0315) |  Loss2: (0.0000) | Acc: (99.00%) (6474/6528)
Epoch: 236 | Batch_idx: 60 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (99.00%) (7736/7808)
Epoch: 236 | Batch_idx: 70 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (99.00%) (9008/9088)
Epoch: 236 | Batch_idx: 80 |  Loss: (0.0326) |  Loss2: (0.0000) | Acc: (99.00%) (10277/10368)
Epoch: 236 | Batch_idx: 90 |  Loss: (0.0324) |  Loss2: (0.0000) | Acc: (99.00%) (11544/11648)
Epoch: 236 | Batch_idx: 100 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (99.00%) (12808/12928)
Epoch: 236 | Batch_idx: 110 |  Loss: (0.0328) |  Loss2: (0.0000) | Acc: (99.00%) (14078/14208)
Epoch: 236 | Batch_idx: 120 |  Loss: (0.0327) |  Loss2: (0.0000) | Acc: (99.00%) (15344/15488)
Epoch: 236 | Batch_idx: 130 |  Loss: (0.0328) |  Loss2: (0.0000) | Acc: (99.00%) (16609/16768)
Epoch: 236 | Batch_idx: 140 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (99.00%) (17877/18048)
Epoch: 236 | Batch_idx: 150 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (99.00%) (19137/19328)
Epoch: 236 | Batch_idx: 160 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (99.00%) (20411/20608)
Epoch: 236 | Batch_idx: 170 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (99.00%) (21677/21888)
Epoch: 236 | Batch_idx: 180 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (99.00%) (22947/23168)
Epoch: 236 | Batch_idx: 190 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (99.00%) (24214/24448)
Epoch: 236 | Batch_idx: 200 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (99.00%) (25483/25728)
Epoch: 236 | Batch_idx: 210 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (99.00%) (26752/27008)
Epoch: 236 | Batch_idx: 220 |  Loss: (0.0327) |  Loss2: (0.0000) | Acc: (99.00%) (28020/28288)
Epoch: 236 | Batch_idx: 230 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (99.00%) (29284/29568)
Epoch: 236 | Batch_idx: 240 |  Loss: (0.0327) |  Loss2: (0.0000) | Acc: (99.00%) (30558/30848)
Epoch: 236 | Batch_idx: 250 |  Loss: (0.0326) |  Loss2: (0.0000) | Acc: (99.00%) (31825/32128)
Epoch: 236 | Batch_idx: 260 |  Loss: (0.0326) |  Loss2: (0.0000) | Acc: (99.00%) (33093/33408)
Epoch: 236 | Batch_idx: 270 |  Loss: (0.0326) |  Loss2: (0.0000) | Acc: (99.00%) (34362/34688)
Epoch: 236 | Batch_idx: 280 |  Loss: (0.0328) |  Loss2: (0.0000) | Acc: (99.00%) (35623/35968)
Epoch: 236 | Batch_idx: 290 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (99.00%) (36888/37248)
Epoch: 236 | Batch_idx: 300 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (99.00%) (38148/38528)
Epoch: 236 | Batch_idx: 310 |  Loss: (0.0335) |  Loss2: (0.0000) | Acc: (98.00%) (39407/39808)
Epoch: 236 | Batch_idx: 320 |  Loss: (0.0339) |  Loss2: (0.0000) | Acc: (98.00%) (40667/41088)
Epoch: 236 | Batch_idx: 330 |  Loss: (0.0339) |  Loss2: (0.0000) | Acc: (98.00%) (41936/42368)
Epoch: 236 | Batch_idx: 340 |  Loss: (0.0347) |  Loss2: (0.0000) | Acc: (98.00%) (43190/43648)
Epoch: 236 | Batch_idx: 350 |  Loss: (0.0348) |  Loss2: (0.0000) | Acc: (98.00%) (44454/44928)
Epoch: 236 | Batch_idx: 360 |  Loss: (0.0349) |  Loss2: (0.0000) | Acc: (98.00%) (45718/46208)
Epoch: 236 | Batch_idx: 370 |  Loss: (0.0349) |  Loss2: (0.0000) | Acc: (98.00%) (46985/47488)
Epoch: 236 | Batch_idx: 380 |  Loss: (0.0348) |  Loss2: (0.0000) | Acc: (98.00%) (48253/48768)
Epoch: 236 | Batch_idx: 390 |  Loss: (0.0348) |  Loss2: (0.0000) | Acc: (98.00%) (49471/50000)
# TEST : Loss: (0.4199) | Acc: (89.00%) (8949/10000)
percent tensor([0.5930, 0.6169, 0.6064, 0.5927, 0.6147, 0.5824, 0.6255, 0.6103, 0.6052,
        0.6085, 0.6014, 0.6163, 0.5994, 0.6115, 0.6032, 0.5925],
       device='cuda:0') torch.Size([16])
percent tensor([0.5580, 0.5524, 0.5486, 0.5357, 0.5479, 0.5241, 0.5606, 0.5539, 0.5515,
        0.5530, 0.5502, 0.5553, 0.5657, 0.5422, 0.5381, 0.5497],
       device='cuda:0') torch.Size([16])
percent tensor([0.6202, 0.6235, 0.6118, 0.6769, 0.6819, 0.6712, 0.6509, 0.7094, 0.6043,
        0.5562, 0.5524, 0.6161, 0.5540, 0.6676, 0.6943, 0.6182],
       device='cuda:0') torch.Size([16])
percent tensor([0.7724, 0.7159, 0.7402, 0.7413, 0.7484, 0.7741, 0.7555, 0.7434, 0.7283,
        0.7372, 0.7513, 0.7066, 0.7108, 0.7494, 0.7609, 0.7654],
       device='cuda:0') torch.Size([16])
percent tensor([0.5991, 0.6472, 0.6337, 0.6510, 0.6399, 0.6419, 0.6315, 0.6112, 0.6536,
        0.6333, 0.6319, 0.6521, 0.6021, 0.6825, 0.5876, 0.6297],
       device='cuda:0') torch.Size([16])
percent tensor([0.6727, 0.7499, 0.7695, 0.7932, 0.7686, 0.7346, 0.7362, 0.7233, 0.7783,
        0.7443, 0.7848, 0.7691, 0.7298, 0.8224, 0.6605, 0.6915],
       device='cuda:0') torch.Size([16])
percent tensor([0.5742, 0.7151, 0.7537, 0.7765, 0.5779, 0.7803, 0.6220, 0.4794, 0.6815,
        0.7083, 0.7265, 0.5994, 0.6990, 0.5247, 0.4939, 0.5469],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9995, 0.9999, 0.9993, 0.9999,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9994, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 237 | Batch_idx: 0 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 237 | Batch_idx: 10 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (1386/1408)
Epoch: 237 | Batch_idx: 20 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (2653/2688)
Epoch: 237 | Batch_idx: 30 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (3917/3968)
Epoch: 237 | Batch_idx: 40 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (5180/5248)
Epoch: 237 | Batch_idx: 50 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (6442/6528)
Epoch: 237 | Batch_idx: 60 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (7708/7808)
Epoch: 237 | Batch_idx: 70 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (8969/9088)
Epoch: 237 | Batch_idx: 80 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (10242/10368)
Epoch: 237 | Batch_idx: 90 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (11505/11648)
Epoch: 237 | Batch_idx: 100 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (12768/12928)
Epoch: 237 | Batch_idx: 110 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (14039/14208)
Epoch: 237 | Batch_idx: 120 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (15302/15488)
Epoch: 237 | Batch_idx: 130 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (16573/16768)
Epoch: 237 | Batch_idx: 140 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (17842/18048)
Epoch: 237 | Batch_idx: 150 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (19107/19328)
Epoch: 237 | Batch_idx: 160 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (20366/20608)
Epoch: 237 | Batch_idx: 170 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (21628/21888)
Epoch: 237 | Batch_idx: 180 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (22898/23168)
Epoch: 237 | Batch_idx: 190 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (24157/24448)
Epoch: 237 | Batch_idx: 200 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (25423/25728)
Epoch: 237 | Batch_idx: 210 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (26683/27008)
Epoch: 237 | Batch_idx: 220 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (27950/28288)
Epoch: 237 | Batch_idx: 230 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (29217/29568)
Epoch: 237 | Batch_idx: 240 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (30481/30848)
Epoch: 237 | Batch_idx: 250 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (31749/32128)
Epoch: 237 | Batch_idx: 260 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (33015/33408)
Epoch: 237 | Batch_idx: 270 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (34281/34688)
Epoch: 237 | Batch_idx: 280 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (35547/35968)
Epoch: 237 | Batch_idx: 290 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (36812/37248)
Epoch: 237 | Batch_idx: 300 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (38078/38528)
Epoch: 237 | Batch_idx: 310 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (39343/39808)
Epoch: 237 | Batch_idx: 320 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (40600/41088)
Epoch: 237 | Batch_idx: 330 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (41856/42368)
Epoch: 237 | Batch_idx: 340 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (43123/43648)
Epoch: 237 | Batch_idx: 350 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (44383/44928)
Epoch: 237 | Batch_idx: 360 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (45647/46208)
Epoch: 237 | Batch_idx: 370 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (46911/47488)
Epoch: 237 | Batch_idx: 380 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (48180/48768)
Epoch: 237 | Batch_idx: 390 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (49398/50000)
# TEST : Loss: (0.4479) | Acc: (89.00%) (8930/10000)
percent tensor([0.5932, 0.6169, 0.6082, 0.5933, 0.6163, 0.5827, 0.6263, 0.6113, 0.6054,
        0.6094, 0.6011, 0.6180, 0.5996, 0.6112, 0.6034, 0.5924],
       device='cuda:0') torch.Size([16])
percent tensor([0.5544, 0.5512, 0.5419, 0.5317, 0.5416, 0.5213, 0.5573, 0.5497, 0.5480,
        0.5497, 0.5482, 0.5502, 0.5630, 0.5433, 0.5358, 0.5465],
       device='cuda:0') torch.Size([16])
percent tensor([0.6302, 0.6269, 0.6280, 0.6867, 0.7007, 0.6733, 0.6629, 0.7234, 0.6115,
        0.5678, 0.5544, 0.6317, 0.5647, 0.6659, 0.7025, 0.6250],
       device='cuda:0') torch.Size([16])
percent tensor([0.7744, 0.7209, 0.7352, 0.7390, 0.7469, 0.7680, 0.7589, 0.7457, 0.7286,
        0.7419, 0.7548, 0.7048, 0.7142, 0.7530, 0.7610, 0.7667],
       device='cuda:0') torch.Size([16])
percent tensor([0.6008, 0.6476, 0.6411, 0.6551, 0.6428, 0.6453, 0.6354, 0.5999, 0.6559,
        0.6310, 0.6316, 0.6571, 0.5951, 0.6839, 0.5896, 0.6295],
       device='cuda:0') torch.Size([16])
percent tensor([0.6675, 0.7501, 0.7631, 0.7907, 0.7666, 0.7332, 0.7347, 0.7009, 0.7699,
        0.7352, 0.7801, 0.7622, 0.7275, 0.8272, 0.6563, 0.6975],
       device='cuda:0') torch.Size([16])
percent tensor([0.5468, 0.7732, 0.7280, 0.7498, 0.5747, 0.7654, 0.6673, 0.4336, 0.6499,
        0.7067, 0.7594, 0.5888, 0.6897, 0.6070, 0.4537, 0.5625],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9999, 0.9996, 0.9999,
        1.0000, 1.0000, 1.0000, 0.9999, 0.9994, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 238 | Batch_idx: 0 |  Loss: (0.0294) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 238 | Batch_idx: 10 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 238 | Batch_idx: 20 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (2650/2688)
Epoch: 238 | Batch_idx: 30 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (3917/3968)
Epoch: 238 | Batch_idx: 40 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (5183/5248)
Epoch: 238 | Batch_idx: 50 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (6443/6528)
Epoch: 238 | Batch_idx: 60 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (7712/7808)
Epoch: 238 | Batch_idx: 70 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (8974/9088)
Epoch: 238 | Batch_idx: 80 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (10236/10368)
Epoch: 238 | Batch_idx: 90 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (11497/11648)
Epoch: 238 | Batch_idx: 100 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (12760/12928)
Epoch: 238 | Batch_idx: 110 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (14022/14208)
Epoch: 238 | Batch_idx: 120 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (15284/15488)
Epoch: 238 | Batch_idx: 130 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (16552/16768)
Epoch: 238 | Batch_idx: 140 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (17816/18048)
Epoch: 238 | Batch_idx: 150 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (19080/19328)
Epoch: 238 | Batch_idx: 160 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (20348/20608)
Epoch: 238 | Batch_idx: 170 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (21623/21888)
Epoch: 238 | Batch_idx: 180 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (22893/23168)
Epoch: 238 | Batch_idx: 190 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (24159/24448)
Epoch: 238 | Batch_idx: 200 |  Loss: (0.0352) |  Loss2: (0.0000) | Acc: (98.00%) (25428/25728)
Epoch: 238 | Batch_idx: 210 |  Loss: (0.0351) |  Loss2: (0.0000) | Acc: (98.00%) (26694/27008)
Epoch: 238 | Batch_idx: 220 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (27957/28288)
Epoch: 238 | Batch_idx: 230 |  Loss: (0.0352) |  Loss2: (0.0000) | Acc: (98.00%) (29223/29568)
Epoch: 238 | Batch_idx: 240 |  Loss: (0.0351) |  Loss2: (0.0000) | Acc: (98.00%) (30487/30848)
Epoch: 238 | Batch_idx: 250 |  Loss: (0.0350) |  Loss2: (0.0000) | Acc: (98.00%) (31757/32128)
Epoch: 238 | Batch_idx: 260 |  Loss: (0.0351) |  Loss2: (0.0000) | Acc: (98.00%) (33023/33408)
Epoch: 238 | Batch_idx: 270 |  Loss: (0.0352) |  Loss2: (0.0000) | Acc: (98.00%) (34286/34688)
Epoch: 238 | Batch_idx: 280 |  Loss: (0.0352) |  Loss2: (0.0000) | Acc: (98.00%) (35547/35968)
Epoch: 238 | Batch_idx: 290 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (36810/37248)
Epoch: 238 | Batch_idx: 300 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (38076/38528)
Epoch: 238 | Batch_idx: 310 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (39336/39808)
Epoch: 238 | Batch_idx: 320 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (40600/41088)
Epoch: 238 | Batch_idx: 330 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (41866/42368)
Epoch: 238 | Batch_idx: 340 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (43132/43648)
Epoch: 238 | Batch_idx: 350 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (44402/44928)
Epoch: 238 | Batch_idx: 360 |  Loss: (0.0356) |  Loss2: (0.0000) | Acc: (98.00%) (45673/46208)
Epoch: 238 | Batch_idx: 370 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (46940/47488)
Epoch: 238 | Batch_idx: 380 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (48204/48768)
Epoch: 238 | Batch_idx: 390 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (49427/50000)
# TEST : Loss: (0.4405) | Acc: (89.00%) (8922/10000)
percent tensor([0.5914, 0.6160, 0.6042, 0.5915, 0.6128, 0.5812, 0.6245, 0.6085, 0.6032,
        0.6075, 0.5999, 0.6149, 0.5977, 0.6112, 0.6022, 0.5911],
       device='cuda:0') torch.Size([16])
percent tensor([0.5549, 0.5519, 0.5451, 0.5339, 0.5440, 0.5206, 0.5595, 0.5507, 0.5484,
        0.5516, 0.5475, 0.5533, 0.5626, 0.5434, 0.5359, 0.5471],
       device='cuda:0') torch.Size([16])
percent tensor([0.6346, 0.6248, 0.6278, 0.6880, 0.7034, 0.6923, 0.6584, 0.7230, 0.6159,
        0.5625, 0.5542, 0.6347, 0.5599, 0.6640, 0.7057, 0.6267],
       device='cuda:0') torch.Size([16])
percent tensor([0.7690, 0.7139, 0.7352, 0.7371, 0.7423, 0.7683, 0.7503, 0.7414, 0.7260,
        0.7375, 0.7501, 0.7037, 0.7074, 0.7483, 0.7567, 0.7633],
       device='cuda:0') torch.Size([16])
percent tensor([0.6020, 0.6455, 0.6371, 0.6549, 0.6410, 0.6476, 0.6356, 0.6003, 0.6565,
        0.6357, 0.6318, 0.6565, 0.6033, 0.6822, 0.5930, 0.6339],
       device='cuda:0') torch.Size([16])
percent tensor([0.6702, 0.7416, 0.7704, 0.7915, 0.7608, 0.7254, 0.7383, 0.7234, 0.7791,
        0.7431, 0.7913, 0.7605, 0.7319, 0.8304, 0.6685, 0.6967],
       device='cuda:0') torch.Size([16])
percent tensor([0.5515, 0.7551, 0.7144, 0.7656, 0.5773, 0.7575, 0.6549, 0.4824, 0.6597,
        0.7182, 0.7673, 0.5714, 0.7037, 0.6179, 0.4877, 0.5677],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9994, 0.9999, 0.9995, 0.9999,
        1.0000, 1.0000, 1.0000, 0.9999, 0.9996, 0.9999, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 239 | Batch_idx: 0 |  Loss: (0.0167) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 239 | Batch_idx: 10 |  Loss: (0.0276) |  Loss2: (0.0000) | Acc: (99.00%) (1398/1408)
Epoch: 239 | Batch_idx: 20 |  Loss: (0.0267) |  Loss2: (0.0000) | Acc: (99.00%) (2667/2688)
Epoch: 239 | Batch_idx: 30 |  Loss: (0.0265) |  Loss2: (0.0000) | Acc: (99.00%) (3938/3968)
Epoch: 239 | Batch_idx: 40 |  Loss: (0.0295) |  Loss2: (0.0000) | Acc: (99.00%) (5203/5248)
Epoch: 239 | Batch_idx: 50 |  Loss: (0.0291) |  Loss2: (0.0000) | Acc: (99.00%) (6475/6528)
Epoch: 239 | Batch_idx: 60 |  Loss: (0.0300) |  Loss2: (0.0000) | Acc: (99.00%) (7742/7808)
Epoch: 239 | Batch_idx: 70 |  Loss: (0.0321) |  Loss2: (0.0000) | Acc: (99.00%) (9001/9088)
Epoch: 239 | Batch_idx: 80 |  Loss: (0.0325) |  Loss2: (0.0000) | Acc: (99.00%) (10270/10368)
Epoch: 239 | Batch_idx: 90 |  Loss: (0.0326) |  Loss2: (0.0000) | Acc: (99.00%) (11539/11648)
Epoch: 239 | Batch_idx: 100 |  Loss: (0.0320) |  Loss2: (0.0000) | Acc: (99.00%) (12808/12928)
Epoch: 239 | Batch_idx: 110 |  Loss: (0.0322) |  Loss2: (0.0000) | Acc: (99.00%) (14072/14208)
Epoch: 239 | Batch_idx: 120 |  Loss: (0.0321) |  Loss2: (0.0000) | Acc: (99.00%) (15339/15488)
Epoch: 239 | Batch_idx: 130 |  Loss: (0.0318) |  Loss2: (0.0000) | Acc: (99.00%) (16607/16768)
Epoch: 239 | Batch_idx: 140 |  Loss: (0.0323) |  Loss2: (0.0000) | Acc: (99.00%) (17869/18048)
Epoch: 239 | Batch_idx: 150 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (98.00%) (19132/19328)
Epoch: 239 | Batch_idx: 160 |  Loss: (0.0327) |  Loss2: (0.0000) | Acc: (98.00%) (20399/20608)
Epoch: 239 | Batch_idx: 170 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (98.00%) (21660/21888)
Epoch: 239 | Batch_idx: 180 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (98.00%) (22925/23168)
Epoch: 239 | Batch_idx: 190 |  Loss: (0.0335) |  Loss2: (0.0000) | Acc: (98.00%) (24191/24448)
Epoch: 239 | Batch_idx: 200 |  Loss: (0.0334) |  Loss2: (0.0000) | Acc: (98.00%) (25460/25728)
Epoch: 239 | Batch_idx: 210 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (98.00%) (26730/27008)
Epoch: 239 | Batch_idx: 220 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (98.00%) (27999/28288)
Epoch: 239 | Batch_idx: 230 |  Loss: (0.0335) |  Loss2: (0.0000) | Acc: (98.00%) (29258/29568)
Epoch: 239 | Batch_idx: 240 |  Loss: (0.0335) |  Loss2: (0.0000) | Acc: (98.00%) (30523/30848)
Epoch: 239 | Batch_idx: 250 |  Loss: (0.0338) |  Loss2: (0.0000) | Acc: (98.00%) (31787/32128)
Epoch: 239 | Batch_idx: 260 |  Loss: (0.0336) |  Loss2: (0.0000) | Acc: (98.00%) (33054/33408)
Epoch: 239 | Batch_idx: 270 |  Loss: (0.0334) |  Loss2: (0.0000) | Acc: (98.00%) (34323/34688)
Epoch: 239 | Batch_idx: 280 |  Loss: (0.0339) |  Loss2: (0.0000) | Acc: (98.00%) (35583/35968)
Epoch: 239 | Batch_idx: 290 |  Loss: (0.0335) |  Loss2: (0.0000) | Acc: (98.00%) (36853/37248)
Epoch: 239 | Batch_idx: 300 |  Loss: (0.0335) |  Loss2: (0.0000) | Acc: (98.00%) (38123/38528)
Epoch: 239 | Batch_idx: 310 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (98.00%) (39396/39808)
Epoch: 239 | Batch_idx: 320 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (98.00%) (40657/41088)
Epoch: 239 | Batch_idx: 330 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (98.00%) (41928/42368)
Epoch: 239 | Batch_idx: 340 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (98.00%) (43198/43648)
Epoch: 239 | Batch_idx: 350 |  Loss: (0.0328) |  Loss2: (0.0000) | Acc: (98.00%) (44469/44928)
Epoch: 239 | Batch_idx: 360 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (98.00%) (45736/46208)
Epoch: 239 | Batch_idx: 370 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (98.00%) (47004/47488)
Epoch: 239 | Batch_idx: 380 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (98.00%) (48270/48768)
Epoch: 239 | Batch_idx: 390 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (98.00%) (49487/50000)
# TEST : Loss: (0.4259) | Acc: (89.00%) (8954/10000)
percent tensor([0.5905, 0.6120, 0.6060, 0.5902, 0.6136, 0.5806, 0.6222, 0.6071, 0.6020,
        0.6055, 0.5979, 0.6155, 0.5961, 0.6064, 0.5997, 0.5892],
       device='cuda:0') torch.Size([16])
percent tensor([0.5556, 0.5499, 0.5477, 0.5346, 0.5454, 0.5210, 0.5590, 0.5518, 0.5495,
        0.5520, 0.5488, 0.5547, 0.5628, 0.5417, 0.5352, 0.5475],
       device='cuda:0') torch.Size([16])
percent tensor([0.6340, 0.6456, 0.6238, 0.6976, 0.6967, 0.6887, 0.6672, 0.7208, 0.6090,
        0.5717, 0.5574, 0.6347, 0.5684, 0.6846, 0.7125, 0.6342],
       device='cuda:0') torch.Size([16])
percent tensor([0.7758, 0.7226, 0.7429, 0.7417, 0.7535, 0.7787, 0.7600, 0.7464, 0.7330,
        0.7450, 0.7580, 0.7114, 0.7166, 0.7516, 0.7650, 0.7708],
       device='cuda:0') torch.Size([16])
percent tensor([0.6003, 0.6498, 0.6289, 0.6458, 0.6344, 0.6434, 0.6288, 0.5921, 0.6541,
        0.6352, 0.6342, 0.6503, 0.6026, 0.6822, 0.5862, 0.6323],
       device='cuda:0') torch.Size([16])
percent tensor([0.6749, 0.7489, 0.7773, 0.7927, 0.7798, 0.7356, 0.7315, 0.7149, 0.7845,
        0.7466, 0.7926, 0.7600, 0.7409, 0.8287, 0.6546, 0.7049],
       device='cuda:0') torch.Size([16])
percent tensor([0.5606, 0.7418, 0.7397, 0.7611, 0.6014, 0.7842, 0.6162, 0.4513, 0.7022,
        0.7061, 0.7773, 0.5686, 0.7190, 0.6099, 0.4542, 0.5650],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9998, 0.9994, 0.9999,
        1.0000, 1.0000, 0.9999, 1.0000, 0.9993, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(181.0631, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(830.9482, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(845.1711, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1525.0608, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(468.7738, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2326.4104, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4255.0352, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1335.6222, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6398.2607, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11428.3643, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3748.9319, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15750.5410, device='cuda:0', grad_fn=<NormBackward0>)
2 hours 11 mins 31 secs for training